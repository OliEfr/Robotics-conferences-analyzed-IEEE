<!DOCTYPE HTML>
<html>
 <head>
  <meta content="en-us" http-equiv="Content-Language"/>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
  <meta content="width=device-width" name="viewport"/>
  <script src="https://ras.papercept.net/conferences/scripts/dom-drag.js" type="text/javascript">
  </script>
  <script src="jquery-1.11.1.min.js">
  </script>
  <title>
   IROS 2024 Program | Friday October 18, 2024
  </title>
  <style type="text/css">
   body, table, td, th{
	Font-Family : sans-serif;
	Font-Size : 10pt;
}
.r {text-align: right}
.blue {color: #0000FF;}
td {vertical-align: top; text-align: left}
.c {text-align: center}
table.s {
	border-collapse:collapse;
	border-width: 1px;
}
table.s td{
	border-width: 1px;
	padding: 4px;
	border-style: solid;
	border-color: gray;
}
table.t {
	border-collapse: collapse;
	border-width: 0px;
}
table.t td{
	border-width: 0px;
	padding: 4px;
	border-style: solid;
	border-color: gray;
}
.dots {
    background:url('./images/dot.gif') repeat-x center;
}
.field {
    background-color: #FFFFFF;
}
#pTitle { /* Page title */
   font-size: 14pt;
   line-height: 1.5em;
}
#pSubTitle { /* Page subtitle */
   color: #909090;
   font-size: 10pt; 
   line-height: 1.5em;
}
#container {
	position: absolute;
	width: 100%;
	margin-top: 2px;
/*	overflow: hidden; */
}

.sHdr {   /* Session header Content list */
   background-color: #F0E68C
}
      
.sSHdr {   /* Subsession header Content list */
   background-color: #f8f3c6 
}
      
table.trk { /* Track table Content list */
   border-collapse: collapse;
   border-width: 0px;
   margin: auto;
/**   width: 640px; **/
   width: 720px;
}
table.trk td{
   border-width: 0px;
   padding: 4px;
   border-style: solid;
   border-color: gray;
 }
      
.pHdr {  /* Paper header Content list */
   background-color: #E6E6FA;
   color: black;
}
hr.thin { /* Horizontal rule content list */
   border: 0px; 
   height: .8px; 
   background-color: #8888FF;
}
      
.pTtl {  /* Paper title Content list */
   font-size: 11pt;
   font-style: italic;
}
      
.ssHdr {  /* Subsession header container session Content list */
   background-color: #DDDDDD;
   color: black;
}
      
.ssTtl {  /* Subsession title container session Content list */
   font-size: 10pt;
   font-style: normal;
   font-weight: bold;
}
  </style>
  <script language="JavaScript">
   function initXMLHttp(){
   var oRequest = false;
   try {
      oRequest = new XMLHttpRequest();
   }  catch (trymicrosoft) {
      try {
         oRequest = new ActiveXObject("Msxml2.XMLHTTP");
      }  catch (othermicrosoft) {
         try {
            oRequest = new ActiveXObject("Microsoft.XMLHTTP");
         }  catch (failed) {
            oRequest = false;
         }
      }
   }
   if (!oRequest){
      alert("Error initializing XMLHttpRequest! Your browser does not support AJAX");
   }
   return oRequest;
}
function modify(number,kk){
   var check = document.getElementById('mod' + kk).checked;
   if (check){
      action = 'Add';
   }
   else{
      action = 'Delete';
   }
   
//   url = 'https://ras.papercept.net/conferences/scripts/myprogram.pl?ConfID=425&' + action + number;
//   window.open(url,'myprogrampage');

   modifyItem("https://ras.papercept.net/conferences/scripts/myprogram_aja.pl","425",action,number)

}


function modifyItem(url,ConfID,action,number){
   var oRequest = initXMLHttp();
   if (!oRequest){return;}
   
   // Send the request

   oRequest.open("post",url, true);
   var sParams = 'ConfID=' + ConfID + '&Action=' + action + '&Number=' + number;
   document.body.style.cursor = 'wait';
   oRequest.send(sParams);

   // Process the response
   
   oRequest.onreadystatechange = function(){ 
      if (oRequest && oRequest.readyState && oRequest.readyState == 4){
         document.body.style.cursor = 'auto';
         var responseText = oRequest.responseText;
         if (responseText.substring(0,5) == 'Error'){
            alert(responseText);
         }
         else{
         
//            alert(responseText);

         }
      }
   } 
}

var iIntervalId;  // Global variable
function modsession(id,kk){
   var check = document.getElementById('mod' + kk).checked;
   if (check){
      action = 'AddSession';
   }
   else{
      action = 'DelSession';
   }

//   url = 'https://ras.papercept.net/conferences/scripts/myprogram.pl?ConfID=425&' + action + id;
//   window.open(url,'myprogrampage');

   modifySession("https://ras.papercept.net/conferences/scripts/myprogram_aja.pl","425",action,id)

}

function modifySession(url,ConfID,action,id){
   var oRequest = initXMLHttp();
   if (!oRequest){return;}
   
   // Send the request

   oRequest.open("post",url, true);
   var sParams = 'ConfID=' + ConfID + '&Action=' + action + '&ID=' + id;
   document.body.style.cursor = 'wait';
   oRequest.send(sParams);

   // Process the response
   
   oRequest.onreadystatechange = function(){ 
      if (oRequest && oRequest.readyState && oRequest.readyState == 4){
         document.body.style.cursor = 'auto';
         var responseText = oRequest.responseText;
         if (responseText.substring(0,5) == 'Error'){
            alert(responseText);
         }
         else{
         
//            alert(responseText);

         }
      }
   } 
}

function getCookie(sName){
   var sRE = "(?:; )?" + sName + "=([^;]*);?";   
   var oRE = new RegExp(sRE);
   if (oRE.test(document.cookie)){
      return decodeURIComponent(RegExp["$1"]);}
   else{
      return null;
   }
}
function loadprogram(){
   var list = getCookie("IROS24");
   if (list){
      var List = list.split(",");
      for (var i=0; i<List.length; i++){
         var names = document.getElementsByName('modify' + List[i]);
         if (names.length){
            for (var j=0; j<names.length; j++){
               names[j].checked = true;
            }
         }
      }
   }
}
function reset(){

   // Uncheck all modify and addsession checkboxes

   var ins = document.getElementsByTagName('input');
   for (var i=0; i<ins.length; i++){
      if (ins[i].type == 'checkbox' && ins[i].id && ins[i].id.substring(0,3) == 'mod'){
         ins[i].checked = false;
      }
   }
   
   // Reload the program
   
   loadprogram();
}
function startreset(){
   iIntervalId = setInterval(reset,2000);
}
function viewAbstract(number){
   var box = document.getElementById('Ab' + number);
   if (box.style.display == 'block'){
      box.style.display = 'none';
   }
   else if (box && box.style.display == 'none'){
      box.style.display = 'block';
   }
}
function openAllAbstracts(){
   var d = document.getElementsByTagName('div');
   var count = d.length;
   if (count == 0){return;}
   for (var i=0; i<d.length; i++){
      if (d[i].id && d[i].id.substring(0,2) == 'Ab' && d[i].style.display == 'none'){
         d[i].style.display = 'block';
      }
   }
}
function closeAllAbstracts(){
   var d = document.getElementsByTagName('div');
   for (var i=0; i<d.length; i++){
      if (d[i].id && d[i].id.substring(0,2) == 'Ab'){
         d[i].style.display = 'none';
      }
   }
}
var uhash;
var pColor;
$(function() { 

   // Check for URL hash

   uhash = location.hash.substring(1);
   if (uhash.slice(-1) == '_'){
      uhash = null;
   }
   if (uhash){
   
      // Mark the session
   
      pColor = $('#' + uhash).parent().css('backgroundColor');
      $('#' + uhash).parent().css('backgroundColor','#FF8888');
   }
});


$(function() { 

   // Check for URL hash

   uhash = location.hash.substring(1);
   if (uhash.slice(-1) == '_'){
      uhash = null;
   }
   if (uhash){

      // Set the widths
      
      setwidth();
      
      // If claasical view is required then return

      if (!ghit){return;} 
      
      // Reset left margin for FF

      document.getElementById('container').scrollLeft = 0;;

      // Discover the table and the block and determine the block Id
   
      var rt = $('#' + uhash);
      var done = false;
      while (!done){
         rt = rt.parent();    
         var etype = rt.get(0).tagName;  
         if (rt.is("table")){      
            done = true;
         }
      }
      rt = rt.parent().parent().parent();
      var iid = rt.attr('id')

      // Show the block

      initialize();
      $('#' + iid).show();
      $( '#A' + iid ).focus();
      var ypos = $('#' + iid).offset().top;      
      window.scrollTo(0,ypos);

      // Cancel the scroll to uhash

      var url = location.href;
      url += '_';
      location.href = url;
      
      // Scroll into view

      var leftPosition = $('#' + uhash).parent().position().left;
      var topOffset = $('#' + uhash).parent().offset().top;
      var divOffset = $('#' + iid).find('div').offset().top;
      var topPosition = topOffset-divOffset;
      $('#' + iid).find('div').scrollLeft(leftPosition);
      $('#' + iid).find('div').scrollTop(topPosition);
   }
   else{
      setwidth();
      initialize();
   }
});

var ghit = false;
function setwidth(){
   var viewportwidth = $( window ).width();
   var viewportheight = $( window ).height();
   var sdiv = $( ".sdiv" );
   for (var i=0; i<sdiv.length; i++){
      $(sdiv[i]).css({width: .98*viewportwidth + 'px'});
      $(sdiv[i]).css("height", .9*viewportheight-50 + 'px');      
   }

   // Detect horizontal overflow on any of the divs
   
   var divs = document.getElementsByTagName('div');
   for (var i=0; i<divs.length; i++){
      if (divs[i].id && divs[i].id.substring(0,3) == 'div'){
         if (divs[i].scrollWidth > divs[i].clientWidth){
            ghit = true;
            break;
         }
      }
   }
   if (!ghit){
      for (var i=0; i<divs.length; i++){
         divs[i].style.height = 'auto';
      }
   }
}

function selfollowing(hsh){
   $('#' + uhash).parent().css('backgroundColor',pColor);
   setwidth();
   initialize();
   if (hsh == 'TheTop'){
      var ypos = $('#container').offset().top;
      window.scrollTo(0,ypos)
   }
   else{
      $('#' + hsh).show();
      $( '#A' + hsh ).focus();
      var ypos = $('#' + hsh).offset().top;
      window.scrollTo(0,ypos)
   }
}

function initialize(){

   // Show all day blocks
   
   var blcks = $('.blck');
   for (var i=0; i<blcks.length; i++){
      blcks[i].style.display = 'block';
   }

   // Detect horizontal overflow on any of the divs
   
   var hit = false;
   var divs = document.getElementsByTagName('div');
   for (var i=0; i<divs.length; i++){
      if (divs[i].id && divs[i].id.substring(0,3) == 'div'){
         if (divs[i].scrollWidth > divs[i].clientWidth || divs[i].scrollHeight > divs[i].clientHeight){
            hit = true;
            break;
         }
      }
   }
   if (hit){
   
      // Set overflow hidden on body. This will prevent it from scrolling
      
      $("body").css("overflow", "hidden");
      document.getElementById('start').style.display = 'inline';
      
      // Hide all day blocks
   
      var blcks = $('.blck');
      for (var i=0; i<blcks.length; i++){
         blcks[i].style.display = 'none';
      }
      var scrlis = $('.scrlis');
      for (var i=0; i<scrlis.length; i++){
         scrlis.show();
      }
   }
   else{
      $("body").css("overflow", "auto");
      document.getElementById('start').style.display = 'none';
      var blcks = $('.sdiv');
      for (var i=0; i<blcks.length; i++){
        blcks[i].style.height = 'auto';
      }
      var scrlis = $('.scrlis');
      for (var i=0; i<scrlis.length; i++){
         scrlis.hide();
      }
   }
   return;
}
  </script>
 </head>
 <body onresize="setwidth(); initialize()">
  <form action="https://ras.papercept.net/conferences/scripts/myprogram.pl" name="myprogram">
   <div id="container">
    <body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0">
     <table border="0" cellpadding="0" cellspacing="0" width="100%">
      <tr>
       <td border="0" height="140" style="background:linear-gradient(to right,#53A8E5,#F78B00);" width="100%">
        <img alt="" border="0" height="140" src="/images/iros/iros24_l.png" style="position:absolute;left:200px;top:0px;"/>
        <img alt="" border="0" height="130" src="/images/iros/iros24_r.png" style="position:absolute;right:200px;top:5px;"/>
       </td>
      </tr>
     </table>
     <table border="0" cellpadding="0" cellspacing="0" height="80%" width="100%">
      <tr>
       <td height="100%" style="background-color:#9F7F59;" width="5">
       </td>
       <td width="5">
       </td>
       <td height="100%" valign="top" width="100%">
        <br/>
        <div class="c" id="TheTop">
         <span id="pTitle">
          <a href="http://iros2024-abudhabi.org" target="_blank">
           <b>
            2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
           </b>
          </a>
          <br/>
         </span>
         <span id="pSubTitle">
          <b>
           October 14-18, 2024, Abu Dhabi, UAE
          </b>
         </span>
         <br/>
         <br/>
        </div>
        <div class="c" style="position: relative">
         <a href="IROS24_ProgramAtAGlanceWeb.html">
          Program at a Glance
         </a>
         <a href="IROS24_ContentListWeb_1.html">
          Monday
         </a>
         <a href="IROS24_ContentListWeb_2.html">
          Tuesday
         </a>
         <a href="IROS24_ContentListWeb_3.html">
          Wednesday
         </a>
         <a href="IROS24_ContentListWeb_4.html">
          Thursday
         </a>
         <a href="IROS24_ContentListWeb_5.html">
          Friday
         </a>
         <a href="IROS24_AuthorIndexWeb.html">
          Author Index
         </a>
         <a href="IROS24_KeywordIndexWeb.html">
          Keyword Index
         </a>
        </div>
        <div class="c">
         <p style="color: gray">
          Last updated on October 5, 2024. This conference program is tentative and subject to change
         </p>
        </div>
        <div class="c">
         <h3>
          Technical Program for Friday October 18, 2024
         </h3>
        </div>
        <p class="c">
        </p>
        <div class="c">
         <span style="color:gray ">
          To show or hide the keywords and abstract (text summary) of a paper (if available), click on the paper title
         </span>
         <br/>
         <a href="javascript:openAllAbstracts()" title="Click to open all abstracts">
          Open all abstracts
         </a>
         <a href="javascript:closeAllAbstracts()" title="Click to close all abstracts">
          Close all abstracts
         </a>
        </div>
        <div class="c">
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frpi6t1">
             <b>
              FrPI6T1
             </b>
            </a>
           </td>
           <td class="r">
            Room 1
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frpi6t1" title="Click to go to the Program at a Glance">
             <b>
              Humanoid and Bipedal Locomotion
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#161571" title="Click to go to the Author Index">
             Pucci, Daniele
            </a>
           </td>
           <td class="r">
            Italian Institute of Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t1_01">
             09:00-10:00, Paper FrPI6T1.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('205'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Demonstrating a Robust Walking Algorithm for Underactuated Bipedal Robots in Non-Flat, Non-Stationary Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#313446" title="Click to go to the Author Index">
             Dosunmu-Ogunbi, Oluwami
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351052" title="Click to go to the Author Index">
             Shrivastava, Aayushi
            </a>
           </td>
           <td class="r">
            University of Michigan Ann Arbor
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103202" title="Click to go to the Author Index">
             Grizzle, J.W
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab205" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work explores an innovative algorithm designed to enhance the mobility of underactuated bipedal robots across challenging terrains, especially when navigating through spaces with constrained opportunities for foot support, like steps or stairs. By combining ankle torque with a refined angular momentum-based linear inverted pendulum model (ALIP), our method allows variability in the robot's center of mass height. We employ a dual-strategy controller that merges virtual constraints for precise motion regulation across essential degrees of freedom with an ALIP-centric model predictive control (MPC) framework, aimed at enforcing gait stability. The effectiveness of our feedback design is demonstrated through its application on the Cassie bipedal robot, which features 20 degrees of freedom. Key to our implementation is the development of tailored nominal trajectories and an optimized MPC that reduces the execution time to under 500 microsecondsâ€”and, hence, is compatible with Cassie's controller update frequency. This paper not only showcases the successful hardware deployment but also demonstrates a new capability, a bipedal robot using a moving walkway.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t1_02">
             09:00-10:00, Paper FrPI6T1.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('217'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Compliance Optimization Control for Rigid-Soft Hybrid System and Its Application in Humanoid Robot Motion Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#225168" title="Click to go to the Author Index">
             He, Zewen
            </a>
           </td>
           <td class="r">
            University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#273063" title="Click to go to the Author Index">
             Ishigaki, Taiki
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#117307" title="Click to go to the Author Index">
             Yamamoto, Ko
            </a>
           </td>
           <td class="r">
            University of Tokyo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab217" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Flexibility and softness play a significant role in dynamic human motions. This includes the flexibility owing to ligaments in the human body and the softness of external structures such as a leaf-spring-type prosthesis. Thus, robotic systems need to utilize such flexibility to achieve dynamic and energy-efficient motion. In this study, we proposed a compliance optimization-based control framework for a rigid-soft hybrid robot system where the continuous deformation of a flexible structure is represented using the piece-wise constant strain (PCS) model. We divided the hybrid system into two states: single support and double support. We validated the proposed method in these states using forward dynamics simulations, assuming a hybrid link system that consists of a humanoid robot with a flexible prosthesis.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t1_03">
             09:00-10:00, Paper FrPI6T1.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('323'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Whole-Body Humanoid Robot Locomotion with Human Reference
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372752" title="Click to go to the Author Index">
             Zhang, Qiang
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391715" title="Click to go to the Author Index">
             Cui, Peter
            </a>
           </td>
           <td class="r">
            Peter &amp; David Robotics (Beijing) Co, . Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391718" title="Click to go to the Author Index">
             Yan, David
            </a>
           </td>
           <td class="r">
            Peter &amp; David Robotics (Beijing) Co, . Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372392" title="Click to go to the Author Index">
             Sun, Jingkai
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology(GZ)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372721" title="Click to go to the Author Index">
             Duan, Yiqun
            </a>
           </td>
           <td class="r">
            University of Technolgoy Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#311169" title="Click to go to the Author Index">
             Han, Gang
            </a>
           </td>
           <td class="r">
            PND Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#244158" title="Click to go to the Author Index">
             Zhao, Wen
            </a>
           </td>
           <td class="r">
            Nankai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391847" title="Click to go to the Author Index">
             Zhang, Weining
            </a>
           </td>
           <td class="r">
            Beijing Innovation Center of Humanoid Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#198626" title="Click to go to the Author Index">
             Guo, Yijie
            </a>
           </td>
           <td class="r">
            UBTECH Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391720" title="Click to go to the Author Index">
             Zhang, Arthur
            </a>
           </td>
           <td class="r">
            Peter &amp; David Robotics (Beijing) Co, . Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354054" title="Click to go to the Author Index">
             Xu, Renjing
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab323" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#humanoid_robot_systems" title="Click to go to the Keyword Index">
               Humanoid Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recently, humanoid robots have made significant advances in their ability to perform complex tasks due to the deployment of Reinforcement Learning (RL), however, the inherent complexity of humanoid robots, including the difficulty of planning complex reward functions and training entire complex systems, still poses a notable challenge. To conquer these challenges, after many iterations and in-depth investigations, we have meticulously developed a full-size humanoid robot, "Adam", whose innovative structural design greatly improves the efficiency and effectiveness of the imitation learning process. In addition, we have developed a novel imitation learning framework based on an adversarial motion prior, which applies not only to Adam but also to humanoid robots in general. Using the framework, Adam can exhibit unprecedented human-like characteristics in locomotion tasks. Our experimental results demonstrate that the proposed framework enables Adam to achieve human-comparable performance in complex locomotion tasks, marking the first time that human locomotion data has been used for imitation learning in a full-size humanoid robot.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t1_04">
             09:00-10:00, Paper FrPI6T1.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('574'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Toward Understanding Key Estimation in Learning Robust Humanoid Locomotion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#290016" title="Click to go to the Author Index">
             Wang, Zhicheng
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#367056" title="Click to go to the Author Index">
             Wei, Wandi
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392868" title="Click to go to the Author Index">
             Yu, Ruiqi
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113218" title="Click to go to the Author Index">
             Wu, Jun
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#232612" title="Click to go to the Author Index">
             Zhu, Qiuguo
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab574" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurate state estimation plays a critical role in ensuring the robust control of humanoid robots, particularly in the context of learning-based control policies for legged robots. However, there is a notable gap in analytical research concerning estimations. Therefore, we endeavor to further understand how various types of estimations influence the decision-making processes of policies. In this paper, we provide quantitative insight into the effectiveness of learned state estimations, employing saliency analysis to identify key estimation variables and optimize their combination for humanoid locomotion tasks. Evaluations assessing tracking precision and robustness are conducted on comparative groups of policies with varying estimation combinations in both simulated and real-world environments. Results validated that the proposed policy is capable of crossing the sim-to-real gap and demonstrating superior performance relative to alternative policy configurations.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t1_05">
             09:00-10:00, Paper FrPI6T1.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('627'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Joint-Level IS-MPC: A Whole-Body MPC with Centroidal Feasibility for Humanoid Locomotion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#312226" title="Click to go to the Author Index">
             Belvedere, Tommaso
            </a>
           </td>
           <td class="r">
            CNRS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#202191" title="Click to go to the Author Index">
             Scianca, Nicola
            </a>
           </td>
           <td class="r">
            Sapienza University of Rome
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107358" title="Click to go to the Author Index">
             Lanari, Leonardo
            </a>
           </td>
           <td class="r">
            Sapienza University of Rome
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101925" title="Click to go to the Author Index">
             Oriolo, Giuseppe
            </a>
           </td>
           <td class="r">
            Sapienza University of Rome
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab627" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#whole_body_motion_planning_and_control" title="Click to go to the Keyword Index">
               Whole-Body Motion Planning and Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose an effective whole-body MPC controller for locomotion of humanoid robots. Our method generates motions using the full kinematics, allowing it to account for joint limits and to exploit upper-body motions to reject disturbances. Each MPC iteration solves a single QP that considers the interplay between dynamic and kinematic features of the robot. Thanks to our special formulation, we are able to perform a feasibility analysis, which opens the door to future enhancements of functionality and performance, e.g., step adaptation in complex environments. We demonstrate its effectiveness through a campaign of dynamic simulations aimed at highlighting how the joint limits and the use of the angular momentum through upper-body motions are fundamental for maximizing performance, robustness, and ultimately make the robot able to execute more challenging gaits.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t1_06">
             09:00-10:00, Paper FrPI6T1.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('672'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Integrating Model-Based Footstep Planning with Model-Free Reinforcement Learning for Dynamic Legged Locomotion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#369781" title="Click to go to the Author Index">
             Lee, Ho Jae
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#225837" title="Click to go to the Author Index">
             Hong, Seungwoo
            </a>
           </td>
           <td class="r">
            MIT (Massachusetts Institute of Technology)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106208" title="Click to go to the Author Index">
             Kim, Sangbae
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab672" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we introduce a control framework that combines model-based footstep planning with Reinforcement Learning (RL), leveraging desired footstep patterns derived from the Linear Inverted Pendulum (LIP) dynamics. Utilizing the LIP model, our method forward predicts robot states and determines the desired foot placement given the velocity commands. We then train an RL policy to track the foot placements without following the full reference motions derived from the LIP model. This partial guidance from the physics model allows the RL policy to integrate the predictive capabilities of the physics-informed dynamics and the adaptability characteristics of the RL controller without overfitting the policy to the template model. Our approach is validated on the MIT Humanoid, demonstrating that our policy can achieve stable yet dynamic locomotion for walking and turning. We further validate the adaptability and generalizability of our policy by extending the locomotion task to unseen, uneven terrain. During the hardware deployment, we have achieved forward walking speeds of up to 1.5 m/s on a treadmill and have successfully performed dynamic locomotion maneuvers such as 90-degree and 180-degree turns.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t1_07">
             09:00-10:00, Paper FrPI6T1.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2571'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Revisiting Reward Design and Evaluation for Robust Humanoid Standing and Walking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378723" title="Click to go to the Author Index">
             van Marum, Bart
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397763" title="Click to go to the Author Index">
             Shrestha, Aayam
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#203754" title="Click to go to the Author Index">
             Duan, Helei
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398157" title="Click to go to the Author Index">
             Dugar, Pranay
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#202399" title="Click to go to the Author Index">
             Dao, Jeremy
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286344" title="Click to go to the Author Index">
             Fern, Alan
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2571" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A necessary capability for humanoid robots is the ability to stand and walk while rejecting natural disturbances. Recent progress has been made using sim-to-real reinforcement learning (RL) to train such locomotion controllers, with approaches differing mainly in their reward functions. However, prior works lack a clear method to systematically test new reward functions and compare controller performance through repeatable experiments. This limits our understanding of the trade-offs between approaches and hinders progress. To address this, we propose a low-cost, quantitative benchmarking method to evaluate and compare the real-world performance of standing and walking (SaW) controllers on metrics like command following, disturbance recovery, and energy efficiency. We also revisit reward function design and construct a minimally constraining reward function to train SaW controllers. We experimentally verify that our benchmarking framework can identify areas for improvement, which can be systematically addressed to enhance the policies. We also compare our new controller to state-of-the-art controllers on the Digit humanoid robot. The results provide clear quantitative trade-offs among the controllers and suggest directions for future improvements to the reward functions and expansion of the benchmarks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t1_08">
             09:00-10:00, Paper FrPI6T1.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3140'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Bipedal Safe Navigation Over Uncertain Rough Terrain: Unifying Terrain Mapping and Locomotion Stability
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396689" title="Click to go to the Author Index">
             Muenprasitivej, Kasidit
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396859" title="Click to go to the Author Index">
             Jiang, Jesse
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#226703" title="Click to go to the Author Index">
             Shamsah, Abdulaziz
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#147487" title="Click to go to the Author Index">
             Coogan, Samuel
            </a>
           </td>
           <td class="r">
            Georgia Tech
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#158317" title="Click to go to the Author Index">
             Zhao, Ye
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3140" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We study the problem of bipedal robot navigation in complex environments with uncertain and rough terrain. In particular, we consider a scenario in which the robot is expected to reach a desired goal location by traversing an environment with uncertain terrain elevation. Such terrain uncertainties induce not only untraversable regions but also robot motion perturbations. Thus, the problems of terrain mapping and locomotion stability are intertwined. We evaluate three different kernels for Gaussian process (GP) regression to learn the terrain elevation. We also learn the motion deviation resulting from both the terrain as well as the discrepancy between the reduced-order Prismatic Inverted Pendulum Model used for planning and the full-order locomotion dynamics. We propose a hierarchical locomotion-dynamics-aware sampling-based navigation planner. The global navigation planner plans a series of local waypoints to reach the desired goal locations while respecting locomotion stability constraints. Then, a local navigation planner is used to generate a sequence of dynamically feasible footsteps to reach local waypoints. We develop a novel trajectory evaluation metric to minimize motion deviation and maximize information gain of the terrain elevation map. We evaluate the efficacy of our planning framework on Digit bipedal robot simulation in MuJoCo.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t1_09">
             09:00-10:00, Paper FrPI6T1.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3231'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Whleaper: A 10-DOF High-Performance Bipedal Wheeled Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370510" title="Click to go to the Author Index">
             Zhu, Yinglei
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370509" title="Click to go to the Author Index">
             He, SiXiao
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370555" title="Click to go to the Author Index">
             Qi, Zhenghao
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370516" title="Click to go to the Author Index">
             Yong, Zhuoyuan
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370738" title="Click to go to the Author Index">
             Qin, Yihua
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#178628" title="Click to go to the Author Index">
             Chen, Jianyu
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3231" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Wheel-legged robots combine the advantages of both wheeled robots and legged robots, offering versatile locomotion capabilities with excellent stability on challenging terrains and high efficiency on flat surfaces. However, existing wheel-legged robots typically have limited hip joint mobility compared to humans, which play a crucial role in locomotion. In this paper, we introduce Whleaper, a novel 10-degree-of-freedom (DOF) bipedal wheeled robot, with 3 DOFs at the hip of each leg. Its humanoid joint design enables adaptable motion in complex scenarios, ensuring stability and flexibility. This paper introduces the details of Whleaper, with a focus on innovative mechanical design, control algorithms and system implementation. Firstly, stability stems from the increased DOFs at the hip, which maximize motion range, enhance the attitude of contact between the feet and the ground. Secondly, the extra DOFs also augment its mobility capabilities. During walking or sliding, more complex movements can be adopted to execute obstacle avoidance tasks. Thirdly, we utilize two control algorithms to implement multimodal motion for walking and sliding. By controlling specific DOFs of the robot, we conducted a series of simulation and practical experiments, demonstrating that a high-DOF hip joint design can effectively enhance the stability and flexibility of wheel-legged robots. Whleaper shows its capability to perform actions such as squatting, obstacle avoidance sliding, and rapid turning in real-world scenarios.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t1_10">
             09:00-10:00, Paper FrPI6T1.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('663'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Physically Consistent Online Inertial Adaptation for Humanoid Loco-Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#246328" title="Click to go to the Author Index">
             Foster, James Paul
            </a>
           </td>
           <td class="r">
            University of West Florida
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#167359" title="Click to go to the Author Index">
             McCrory, Stephen
            </a>
           </td>
           <td class="r">
            Institute for Human and Machine Cognition
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#228000" title="Click to go to the Author Index">
             DeBuys, Christian
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#149808" title="Click to go to the Author Index">
             Bertrand, Sylvain
            </a>
           </td>
           <td class="r">
            Institute for Human and Machine Cognition
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#188443" title="Click to go to the Author Index">
             Griffin, Robert J.
            </a>
           </td>
           <td class="r">
            Institute for Human and Machine Cognition (IHMC)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab663" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_robot_systems" title="Click to go to the Keyword Index">
               Humanoid Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The ability to accomplish manipulation and locomotion tasks in the presence of significant time-varying external loads is a remarkable skill of humans that has yet to be replicated convincingly by humanoid robots. Such an ability will be a key requirement in the environments we envision deploying our robots: dull, dirty, and dangerous. External loads constitute a large model bias, which is typically unaccounted for. In this work, we enable our humanoid robot to engage in loco-manipulation tasks in the presence of significant model bias due to external loads. We propose an online estimation and control framework involving the combination of a physically consistent extended Kalman filter for inertial parameter estimation coupled to a whole-body controller. We showcase our results both in simulation and in hardware, where weights are mounted on Nadia's wrist links as a proxy for engaging in tasks where large external loads are applied to the robot.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t1_11">
             09:00-10:00, Paper FrPI6T1.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1060'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Feasible Region Construction by Polygon Merging for Continuous Bipedal Walking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390831" title="Click to go to the Author Index">
             Li, Chao
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#139013" title="Click to go to the Author Index">
             Chen, Xuechao
            </a>
           </td>
           <td class="r">
            Beijing Insititute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395296" title="Click to go to the Author Index">
             Hengbo, Qi
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology School of Mechatronical Engineer
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#216448" title="Click to go to the Author Index">
             Li, Qingqing
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372734" title="Click to go to the Author Index">
             Zhao, Qingrui
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338957" title="Click to go to the Author Index">
             Shi, Yongliang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#116950" title="Click to go to the Author Index">
             Yu, Zhangguo
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#252633" title="Click to go to the Author Index">
             Zhao, Lingxuan
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#117292" title="Click to go to the Author Index">
             Jiang, Zhihong
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1060" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_robot_systems" title="Click to go to the Keyword Index">
               Humanoid Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Feasible regions for continuous walking must provide necessary information for footstep planning, including surrounding landing areas and details about obstacles to be avoided during foot swing. However, the current frame lacks sufficient information to construct a feasible region needed at the current moment due to knee occlusion. To this end, this paper uses polygon merging to construct an information-complete feasible region. This polygon merging refers to merging polygons from the current frame and a specific previous frame. Since the polygon is more concise and efficient than point cloud for environmental representation, construction can be completed quickly without GPU acceleration. Experiments show that the proposed method successfully constructs informative feasible regions within the allowed time frame, enabling the robot to navigate stairs.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t1_12">
             09:00-10:00, Paper FrPI6T1.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1148'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Magnetic Tactile Sensor with Load Tolerance and Flexibility Using Frame Structures for Estimating Triaxial Contact Force Distribution of Humanoid
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#348984" title="Click to go to the Author Index">
             Hiraoka, Takuma
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#318884" title="Click to go to the Author Index">
             Kunita, Ren
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#165253" title="Click to go to the Author Index">
             Kojima, Kunio
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#245416" title="Click to go to the Author Index">
             Hiraoka, Naoki
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#348985" title="Click to go to the Author Index">
             Konishi, Masanori
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#224035" title="Click to go to the Author Index">
             Makabe, Tasuku
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291626" title="Click to go to the Author Index">
             Tang, Annan
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106350" title="Click to go to the Author Index">
             Okada, Kei
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106348" title="Click to go to the Author Index">
             Inaba, Masayuki
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1148" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_robot_systems" title="Click to go to the Keyword Index">
               Humanoid Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_networks" title="Click to go to the Keyword Index">
               Sensor Networks
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             For humanoid whole body contact motions, it is important to recognize the existence of whole body contacts and the contact forces. The challenges in recognizing the existence of whole body contacts and the contact forces in life-size humanoids are: 1) the measurement part with low mechanical strength must be tolerant of high load and 2) it is difficult to model thick elastic bodies with high impact tolerance and uneven sensor placements when applied to various shapes of the whole body. This paper proposes a method of constructing a load tolerant tactile sensor by separating the loaded part from the measuring part with magnetism and protecting the measuring part inside the frame of the robot. For modeling difficulties, this paper proposes learning the relationship between the change in the detected physical quantity due to deformation of the elastic body and the contact force distribution. This paper shows through experiments that the proposed tactile sensor based on a robot frame is load tolerant enough to support the weight of a life-sized humanoid, and that it can acquire contact force distribution and the robot is able to acclimate to external forces.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t1_13">
             09:00-10:00, Paper FrPI6T1.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1498'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Fly by Book: How to Train a Humanoid Robot to Fly an Airplane Using Large Language Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393823" title="Click to go to the Author Index">
             Kim, Hyungjoo
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology (KAIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285592" title="Click to go to the Author Index">
             Min, Sungjae
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology (KAIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#381132" title="Click to go to the Author Index">
             Kang, Gyuree
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology (KAIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392041" title="Click to go to the Author Index">
             Kim, Jihyeok
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104593" title="Click to go to the Author Index">
             Shim, David Hyunchul
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1498" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_robot_systems" title="Click to go to the Keyword Index">
               Humanoid Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#formal_methods_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Formal Methods in Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A pilot needs to manipulate various gadgets in the cockpit based on vast knowledge of rules and procedures while verbally communicating with air traffic controllers. While precision manipulation in the cockpit during the flight is already a difficult task, a far more difficult thing is how to make a robot learn all the knowledge needed to fly an airplane in accordance with all the rules and regulations. As a pioneering effort, this paper introduces LLM-PIBOT, which leverages the latest advances in Large Language Models (LLMs) to empower a humanoid pilot robot (PIBOT) to take the full authority of an airplane by understanding and executing complex procedures outlined in Pilot's Operating Handbooks (POHs). Unlike traditional rule-based methods, LLM-PIBOT system infers suitable flight procedures, employs an embedding process to accurately identify relevant procedures within documents, and structures the text-extracted flight tasks into tuples using our carefully crafted prompts. This approach enables PIBOT to adapt to the given POHs, generating and executing task plans in real-time in response to commands and situations. Experimental results show that LLM-PIBOT can comprehend and follow the complex procedures specified in the manuals and to fly the airplane on a full-scale simulator using the generated flight plans.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t1_14">
             09:00-10:00, Paper FrPI6T1.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1647'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Towards Designing a Low-Cost Humanoid Robot with Flex Sensors-Based Movement
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396858" title="Click to go to the Author Index">
             Al Omoush, Muhammad H.
            </a>
           </td>
           <td class="r">
            Dublin City University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396862" title="Click to go to the Author Index">
             Kishore, Sameer
            </a>
           </td>
           <td class="r">
            Middlesex University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396866" title="Click to go to the Author Index">
             Mehigan, Tracey
            </a>
           </td>
           <td class="r">
            Dublin City University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1647" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_robot_systems" title="Click to go to the Keyword Index">
               Humanoid Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#education_robotics" title="Click to go to the Keyword Index">
               Education Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#product_design__development_and_prototyping" title="Click to go to the Keyword Index">
               Product Design, Development and Prototyping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Humanoid robots have potential applications across diverse sectors, including education, healthcare, and customer service. This paper presents a project on designing and building a low-cost humanoid robot equipped with a flex sensor- based movement mechanism, highlighting its compatibility with Raspberry Pi and microcontrollers such as Arduino Uno and Nano. The project aims to investigate the robot's relevance and effectiveness within educational settings to showcase how a low- cost humanoid robot can potentially support the United Nations' fourth Sustainable Development Goal (UN SDG4) by improving access to quality education through innovative robotics solutions. The robot was tested in a cycle two school (covering Grades 5 to 8 (ages 10 to 13)) in Dubai, United Arab Emirates. It was integrated into math, science, and design technology classes to assess its functionality and efficiency. Surveys conducted among students and teachers showed a high level of acceptance towards the robot, with over 85% of respondents expressing positive attitudes about its presence and interaction in the classroom. However, teachers and students provided feedback concerning the robot's shape, capabilities, and movement mechanism. Teachers also appreciated the robot's alignment with the UN SDG4, stating its capability to support students learning and engagement. The authors highlighted the robot's potential to assist students with sensory challenges, such as hearing and vision impairments, and learning difficulties like dyslexia while emphasizing their commitment to enhancing its accessibility features for a more inclusive learning environment.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t1_15">
             09:00-10:00, Paper FrPI6T1.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2266'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Driving Style Alignment for LLM-Powered Driver Agent
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392538" title="Click to go to the Author Index">
             Yang, Ruoxuan
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392561" title="Click to go to the Author Index">
             Zhang, Xinyue
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392551" title="Click to go to the Author Index">
             Fernandez-Laaksonen, Anais
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392566" title="Click to go to the Author Index">
             Ding, Xin
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#311413" title="Click to go to the Author Index">
             Gong, Jiangtao
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2266" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_robot_systems" title="Click to go to the Keyword Index">
               Humanoid Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recently, LLM-powered driver agents have demonstrated considerable potential in the field of autonomous driving, showcasing human-like reasoning and decision-making abilities. However, current research on aligning driver agent behaviors with human driving styles remains limited, partly due to the scarcity of high-quality natural language data from human driving behaviors. To address this research gap, we propose a multi-alignment framework designed to align driver agents with human driving styles through demonstrations and feedback. Notably, we construct a natural language dataset of human driver behaviors through naturalistic driving experiments and post-driving interviews, offering high-quality human demonstrations for LLM alignment. The frameworkâ€™s effectiveness is validated through simulation experiments in the CARLA urban traffic simulator and further corroborated by human evaluations. Our research offers valuable insights into designing driving agents with diverse driving styles. The implementation of the framework and details of the dataset can be found at the link.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t1_16">
             09:00-10:00, Paper FrPI6T1.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2351'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              From CAD to URDF: Co-Design of a Jet-Powered Humanoid Robot Including CAD Geometry
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#306984" title="Click to go to the Author Index">
             Vanteddu, Punith Reddy
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196567" title="Click to go to the Author Index">
             Nava, Gabriele
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238258" title="Click to go to the Author Index">
             Bergonti, Fabio
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#251910" title="Click to go to the Author Index">
             L'Erario, Giuseppe
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#309972" title="Click to go to the Author Index">
             Paolino, Antonello
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#161571" title="Click to go to the Author Index">
             Pucci, Daniele
            </a>
           </td>
           <td class="r">
            Italian Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2351" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_robot_systems" title="Click to go to the Keyword Index">
               Humanoid Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#methods_and_tools_for_robot_system_design" title="Click to go to the Keyword Index">
               Methods and Tools for Robot System Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Co-design optimization strategies usually rely on simplified robot models extracted from CAD. While these models are useful for optimizing geometrical and inertial parameters for robot control, they might overlook important details essential for prototyping the optimized mechanical design. For instance, they may not account for mechanical stresses exerted on the optimized geometries and the complexity of assembly-level design. In this paper, we introduce a co-design framework aimed at improving both the control performance and mechanical design of our robot. Specifically, we identify the robot links that significantly influence control performance. The geometric characteristics of these links are parameterized and optimized using a multi-objective evolutionary algorithm to achieve optimal control performance. Additionally, an automated Finite Element Method (FEM) analysis is integrated into the framework to filter solutions not satisfying the required structural safety margin. We validate the framework by applying it to enhance the mechanical design for flight performance of the jet-powered humanoid robot iRonCub.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frpi6t2">
             <b>
              FrPI6T2
             </b>
            </a>
           </td>
           <td class="r">
            Room 2
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frpi6t2" title="Click to go to the Program at a Glance">
             <b>
              Soft and Flexible Robotics II
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#206342" title="Click to go to the Author Index">
             George Thuruthel, Thomas
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#126969" title="Click to go to the Author Index">
             Vazquez, Andres S.
            </a>
           </td>
           <td class="r">
            Universidad De Castilla La Mancha
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t2_01">
             09:00-10:00, Paper FrPI6T2.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('169'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robust-Adaptive Two-Loop Control for Robots with Mixed Rigid-Elastic Joints
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334787" title="Click to go to the Author Index">
             Hua, Minh Tuan
            </a>
           </td>
           <td class="r">
            University of Agder
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390078" title="Click to go to the Author Index">
             Sveen, Emil MÃ¼hlbradt
            </a>
           </td>
           <td class="r">
            University of Agder
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390079" title="Click to go to the Author Index">
             Schlanbusch, Siri Marte
            </a>
           </td>
           <td class="r">
            University of Agder
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#147409" title="Click to go to the Author Index">
             Sanfilippo, Filippo
            </a>
           </td>
           <td class="r">
            University of Agder
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab169" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In robotics, while rigid joints are common due to their accuracy and fast response ability, elastic joints are well-known for their safety when interacting with the environment. To harmonise the advantages of these joint types, robots with mixed rigid-elastic joints can be considered. In this paper, a robust-adaptive two-loop control algorithm is proposed to control this type of robot when there are uncertainties in system parameters. In the outer loop, a robust control algorithm is proposed to deal with the uncertainties in the dynamic parameters of the joint side, together with an adaptive controller for the rigid joints. In the inner loop, another robust control algorithm is proposed to handle the uncertainties in system parameters of the elastic jointâ€™s motor side, and a similar adaptive control algorithm is presented to manipulate the elastic joints' motors. The stability of the system is assured by Lyapunov's stability theory. Finally, simulation experiments are conducted to verify the proposed control algorithm.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t2_02">
             09:00-10:00, Paper FrPI6T2.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1160'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CFD-Enabled Approach for Optimizing CPG Control Network for Underwater Soft Robotic Fish
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#357939" title="Click to go to the Author Index">
             Wang, Yunfei
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375483" title="Click to go to the Author Index">
             Sun, Weiyuan
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#386009" title="Click to go to the Author Index">
             Tang, Wei
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375488" title="Click to go to the Author Index">
             Zhang, Xianrui
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#357943" title="Click to go to the Author Index">
             Yu, Zhenping
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375495" title="Click to go to the Author Index">
             Cao, Shunxiang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#181312" title="Click to go to the Author Index">
             Qu, Juntian
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1160" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Central Pattern Generators (CPG) nonlinear oscillation network is being increasingly used in the control of multijoint collaborative robots. The motion attitude of robots can be effectively adjusted by tuning parameters of the CPG neural network. However, the mapping from CPG parameters to motion attitude is relatively complicated. To improve the motion performance, an optimization method combining computational fluid dynamics (CFD) and CPG network is proposed. In this work, we design a three-joint biomimetic soft robot fish following the body structure of trevally and an improved CPG network based on the Hopf model is incorporated into the control system. Directly optimizing the swimming performance through experiments is time consuming and complex, a mode of first adjusting parameters on the simulation platform and then refining on the robot is usually adopted. Therefore, a CFD simulation platform using hydrodynamic solutions has been established to assist in analyzing the swimming effect after parameters optimization. Finally, the experimental results show that the swimming effect simulated by the CFD simulation platform is highly similar to the real test, and the swimming performance after the improved CPG network optimization has been significantly increased.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t2_03">
             09:00-10:00, Paper FrPI6T2.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1770'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design, Modelling, and Experimental Validation of a Soft Continuum Wrist Section Developed for a Prosthetic Hand
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351884" title="Click to go to the Author Index">
             Sulaiman, Shifa
            </a>
           </td>
           <td class="r">
            University of Naples, Federico II, Naples
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395383" title="Click to go to the Author Index">
             Menon, Mehul
            </a>
           </td>
           <td class="r">
            NIT DURGAPUR
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395391" title="Click to go to the Author Index">
             Schetter, Francesco
            </a>
           </td>
           <td class="r">
            University of Naples, Federico II, Naples
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#137686" title="Click to go to the Author Index">
             Ficuciello, Fanny
            </a>
           </td>
           <td class="r">
            UniversitÃ  Di Napoli Federico II
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1770" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft continuum sections are widely used in robotic mechanisms for achieving dexterous motions. However, most available designs of soft continuum sections cannot support payload during a motion. This paper presents a development of a novel soft robotic wrist section for a prosthetic hand named â€˜PRISMA Hand IIâ€™. Our research focuses on various phases of development of a soft continuum wrist section, that can support a substantial payload and maintain postures of the hand. Mechanical design, fabrication, and modelling strategies adopted for developing the wrist section are described. The design of the wrist section is constructed by assembling springs, discs, and tendons. The number and dimensions of springs and discs are optimised using static structural analysis. Kinematic modelling and dynamic modelling of the wrist section are carried out using Geometric Variable Strain (GVS) approach based on Cosserat rod theory and a generalised coordinate method respectively. The geometric formulations involved in Cosserat rod theory guaranteed accurate and quick computations considering deformation parameters. Dynamic modelling approach also enhanced performance of the wrist section reducing errors and computational time during real time implementations. This paper also discusses about a dynamic model based controller strategy for the wrist section and advantages of the proposed controller are proved using a comparative study with a kinematic model based PID controller. Experimental validations of motions of the fabricated wrist section employing the dynamic controller are also included in the paper.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t2_04">
             09:00-10:00, Paper FrPI6T2.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1936'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Theoretical Modeling and Bio-Inspired Trajectory Optimization of a Multiple-Locomotion Origami Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350885" title="Click to go to the Author Index">
             Zhu, Keqi
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319078" title="Click to go to the Author Index">
             Guo, Haotian
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#381069" title="Click to go to the Author Index">
             Yu, Wei
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#251336" title="Click to go to the Author Index">
             Sirag, Hassen Nigatu
            </a>
           </td>
           <td class="r">
            ZJU
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195536" title="Click to go to the Author Index">
             Li, Tong
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414188" title="Click to go to the Author Index">
             Dong, Ruihong
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#204350" title="Click to go to the Author Index">
             Dong, Huixu
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1936" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#biomimetics" title="Click to go to the Keyword Index">
               Biomimetics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent research on mobile robots has focused on increasing their adaptability to unpredictable and unstructured environments using soft materials and structures. However, the determination of key design parameters and control over these compliant robots are predominantly iterated through experiments, lacking a solid theoretical foundation. To improve their efficiency, this paper aims to provide mathematics modeling over two locomotion, crawling and swimming. Specifically, a dynamic model is first devised to reveal the influence of the contact surfacesâ€™ frictional coefficients on displacements in different motion phases. Besides, a swimming kinematics model is provided using coordinate transformation, based on which, we further develop an algorithm that systematically plans human-like swimming gaits, with maximum thrust obtained. The proposed algorithm is highly generalizable and has the potential to be applied in other soft robots with similar multiple joints. Simulation experiments have been conducted to illustrate the effectiveness of the proposed modeling.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t2_05">
             09:00-10:00, Paper FrPI6T2.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1985'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Fractional Order Modeling and Control of Hydrogel-Based Soft Pneumatic Bending Actuators
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#311357" title="Click to go to the Author Index">
             de la Morena, JesÃºs
            </a>
           </td>
           <td class="r">
            UCLM
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397487" title="Click to go to the Author Index">
             Redrejo LÃ³pez, David
            </a>
           </td>
           <td class="r">
            Universidad De Castilla-La Mancha
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#155924" title="Click to go to the Author Index">
             Ramos, Francisco
            </a>
           </td>
           <td class="r">
            University of Castilla-La Mancha
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102348" title="Click to go to the Author Index">
             Feliu, Vicente
            </a>
           </td>
           <td class="r">
            Escuela TÃ©cnica Superior De IngenierosIndustriales/Universidad D
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#126969" title="Click to go to the Author Index">
             Vazquez, Andres S.
            </a>
           </td>
           <td class="r">
            Universidad De Castilla La Mancha
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1985" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft pneumatic bending actuators (SPBAs) are commonly employed in soft robotics due to their unique characteristics, including safety, low weight, speed, and load capacity. However, the combination of pneumatics with soft materials causes SPBAs to exhibit nonlinearities and infinite degrees of freedom, complicating their dynamic modeling. In this work, we present how the dynamics of SPBAs can be adjusted to a fractional order model (FOM), showing an approach for their empirical identification. We also present a method for designing fractional order controllers (FOCs) for this type of actuators, based on the inversion of the empirical FOM. This modeling and control is applied to a modular SPBA made of a smart hydrogel, which endows the actuators with self-healing, self-adhesion, and self-sensing capabilities.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t2_06">
             09:00-10:00, Paper FrPI6T2.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2247'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Soft Robotic System Automatically Learns Precise Agile Motions without Model Information
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395419" title="Click to go to the Author Index">
             Bachhuber, Simon
            </a>
           </td>
           <td class="r">
            FAU Erlangen-NÃ¼rnberg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395237" title="Click to go to the Author Index">
             Pawluchin, Alexander
            </a>
           </td>
           <td class="r">
            Berliner Hochschule FÃ¼r Technik
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395449" title="Click to go to the Author Index">
             Pal, Arka
            </a>
           </td>
           <td class="r">
            Student
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#159942" title="Click to go to the Author Index">
             Boblan, Ivo
            </a>
           </td>
           <td class="r">
            Berliner Hochschule Fuer Technik
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196337" title="Click to go to the Author Index">
             Seel, Thomas
            </a>
           </td>
           <td class="r">
            Leibniz UniversitÃ¤t Hannover
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2247" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Many application domains, e.g., in medicine and manufacturing, can greatly benefit from pneumatic Soft Robots (SRs). However, the accurate control of SRs has remained a significant challenge to date, mainly due to their nonlinear dynamics and viscoelastic material properties. Conventional control design methods often rely on either complex system modeling or time-intensive manual tuning, both of which require significant amounts of human expertise and thus limit their practicality. In recent works, the data-driven method, Automatic Neural ODE Control (ANODEC) has been successfully used to -- fully automatically and utilizing only input-output data -- design controllers for various nonlinear systems in silico, and without requiring prior model knowledge or extensive manual tuning. In this work, we successfully apply ANODEC to automatically learn to perform agile, non-repetitive reference tracking motion tasks in a real-world SR and within a finite time horizon. To the best of the authors' knowledge, ANODEC achieves, for the first time, performant control of a SR with hysteresis effects from only 30 seconds of input-output data and without any prior model knowledge. We show that for multiple, qualitatively different and even out-of-training-distribution reference signals, a single feedback controller designed by ANODEC outperforms a manually tuned PID baseline consistently. Overall, this contribution not only further strengthens the validity of ANODEC, but it marks an important step towards more practical, easy-to-use SRs that can automatically learn to perform agile motions from minimal experimental interaction time.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t2_07">
             09:00-10:00, Paper FrPI6T2.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2560'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Human-Robot Interaction Control for Multi-Mode Exosuit with Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350105" title="Click to go to the Author Index">
             Huang, Kaizhen
            </a>
           </td>
           <td class="r">
            Nanjing University of Aeronautics and Astronautics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#221850" title="Click to go to the Author Index">
             Xu, Jiajun
            </a>
           </td>
           <td class="r">
            Nanjing University of Aeronautics and Astronautics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352751" title="Click to go to the Author Index">
             Zhang, Tianyi
            </a>
           </td>
           <td class="r">
            Nanjing University of Aeronautics and Astronaut
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393468" title="Click to go to the Author Index">
             Zhao, Mengcheng
            </a>
           </td>
           <td class="r">
            Nanjing University of Aeronautics and Astronautics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#252470" title="Click to go to the Author Index">
             Ji, Aihong
            </a>
           </td>
           <td class="r">
            Nanjing University of Aeronautics Ans Astronautics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160941" title="Click to go to the Author Index">
             Song, Guoli
            </a>
           </td>
           <td class="r">
            Shenyang Institute of Automation, Chinese Academy of SciencesA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104222" title="Click to go to the Author Index">
             Li, Y.F.
            </a>
           </td>
           <td class="r">
            City University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2560" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intention_recognition" title="Click to go to the Keyword Index">
               Intention Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft exoskeleton robots have promising potential in walking assistance with comfortable wearing experience. In this study, an exosuit equipped with a twisted string actuator (TSA) is developed to provide powerful driving force and diverse operating modes for hemiplegic patients in daily life. It is challenging to establish the human-robot coupling dynamic model due to the soft structure of the exosuit and tight coupling, precise control and effective assistance are difficult to guaranteed in current exosuits. Considering the impedance characteristics of human-robot interaction, an adaptive impedance control method based on reinforcement learning (RL) is proposed, where human motion intention is utilized to optimize impedance parameters and adjust the robot's operating mode. A nonlinear disturbance observer is proposed to compensate for the effects of model estimation errors, joint friction, and external disturbances. Experimental verification demonstrates the effectiveness and superiority of the robotic system.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t2_08">
             09:00-10:00, Paper FrPI6T2.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2639'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Predicting Interaction Shape of Soft Continuum Robots Using Deep Visual Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376574" title="Click to go to the Author Index">
             Huang, Yunqi
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#344761" title="Click to go to the Author Index">
             Alkayas, Abdulaziz Y.
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#272820" title="Click to go to the Author Index">
             Shi, Jialei
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#150250" title="Click to go to the Author Index">
             Renda, Federico
            </a>
           </td>
           <td class="r">
            Khalifa University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142097" title="Click to go to the Author Index">
             Wurdemann, Helge Arne
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#206342" title="Click to go to the Author Index">
             George Thuruthel, Thomas
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2639" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft continuum robots, characterized by their inherent compliance and dexterity, are increasingly pivotal in applications requiring delicate interactions with the environment such as the medical field. Despite their advantages, challenges persist in accurately modeling and controlling their shape during interactions with surrounding objects. This is because of the difficulty in modeling the large degrees of freedom in soft-bodied objects that become more active during interactions. In this study, we present a deep visual model to predict the interaction shapes of a soft continuum robot in contact with surrounding objects. By formulating this task as a forward-statics problem, the model uses the initial state images containing the object configuration and future actuation values to predict interactive state images of the robot under this actuation condition. We developed and tested the model in both simulated and physical environments, explored the model's predictive capabilities using monocular and binocular views, and tested the model's generalization ability on different datasets. Our results show that deep learning methods are a promising tool for solving the complex problem of predicting the shape of a soft continuum robot interacting with the environment, requiring no prior knowledge about the system dynamics and explicit mapping of the environment. This study paves the way for future explorations in robot-environment interaction modeling and the development of more adaptable interaction shape control strategies.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t2_09">
             09:00-10:00, Paper FrPI6T2.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2755'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Dynamic Tasks on a Large-Scale Soft Robot in a Handful of Trials
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#327275" title="Click to go to the Author Index">
             Zwane, Sicelukwanda Njabuliso Tunner
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383217" title="Click to go to the Author Index">
             Cheney, Daniel G.
            </a>
           </td>
           <td class="r">
            Brigham Young University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#293492" title="Click to go to the Author Index">
             Johnson, Curtis C
            </a>
           </td>
           <td class="r">
            Brigham Young University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#303920" title="Click to go to the Author Index">
             Luo, Yicheng
            </a>
           </td>
           <td class="r">
            UCL
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#133489" title="Click to go to the Author Index">
             Bekiroglu, Yasemin
            </a>
           </td>
           <td class="r">
            Chalmers University of Technology, University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#134229" title="Click to go to the Author Index">
             Killpack, Marc
            </a>
           </td>
           <td class="r">
            Brigham Young University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101413" title="Click to go to the Author Index">
             Deisenroth, Marc Peter
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2755" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft robots offer more flexibility, compliance, and adaptability than traditional rigid robots. They are also typically lighter and cheaper to manufacture. However, their use in real-world applications is limited due to modeling challenges and difficulties in integrating effective proprioceptive sensors. Large-scale soft robots (approx two meters in length) have greater modeling complexity due to increased inertia and related effects of gravity. Common efforts to ease these modeling difficulties such as assuming simple kinematic and dynamics models also limit the general capabilities of soft robots and are not applicable in tasks requiring fast, dynamic motion like throwing and hammering. To overcome these challenges, we propose a data-efficient Bayesian optimization-based approach for learning control policies for dynamic tasks on a large-scale soft robot. Our approach optimizes the task objective function directly from commanded pressures, without requiring approximate kinematics or dynamics as an intermediate step. We demonstrate the effectiveness of our approach through both simulated and real-world experiments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t2_10">
             09:00-10:00, Paper FrPI6T2.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2936'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design and Control of an Ultra-Slender Push-Pull Multisection Continuum Manipulator for In-Situ Inspection of Aeroengine
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397926" title="Click to go to the Author Index">
             Zhong, Weiheng
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123992" title="Click to go to the Author Index">
             Huang, Yuancan
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397987" title="Click to go to the Author Index">
             Hong, Da
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385293" title="Click to go to the Author Index">
             Shao, Nianfeng
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2936" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#engineering_for_robotic_systems" title="Click to go to the Keyword Index">
               Engineering for Robotic Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manufacturing__maintenance_and_supply_chains" title="Click to go to the Keyword Index">
               Manufacturing, Maintenance and Supply Chains
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Since the shape of industrial endoscopes is passively altered according to the contact around it, manual inspection approaches of aeroengines through the inspection ports have unreachable areas, and it's difficult to traverse multistage blades and inspect them simultaneously, which requires engine disassembly or the cooperation of multiple operators, resulting in efficiency decline and increased costs. To this end, this paper proposes a novel continuum manipulator with push-pull multisection structure which provides a potential solution for the disadvantages mentioned above due to its higher flexibility, passability, and controllability in confined spaces. The ultra-slender design combined with a tendon-driven mechanism makes the manipulator acquire enough workspace and more flexible postures while maintaining a light weight. Considering the coupling between the tendons in multisection, a innovative kinematics decoupling control method is implemented, which can realize real-time control in the case of limited computational resources. A prototype is built to validate the capabilities of mechatronic design and the performance of the control algorithm. The experimental results demonstrate the advantages of our continuum manipulator in the in-situ inspection of aeroengines' multistage blades, which has the potential to be a replacement solution for industrial endoscopes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t2_11">
             09:00-10:00, Paper FrPI6T2.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1384'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Origami Actuator with Tunable Limiting Layer for Reconfigurable Soft Robotic Grasping
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#181709" title="Click to go to the Author Index">
             Yang, Yang
            </a>
           </td>
           <td class="r">
            Nanjing University of Information Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396463" title="Click to go to the Author Index">
             Kejin, Zhu
            </a>
           </td>
           <td class="r">
            Nanjing University of Information Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380498" title="Click to go to the Author Index">
             Xie, Yuan
            </a>
           </td>
           <td class="r">
            Nanjing University of Information Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380496" title="Click to go to the Author Index">
             Yan, Shaoyang
            </a>
           </td>
           <td class="r">
            Nanjing University of Information Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191272" title="Click to go to the Author Index">
             Yi, Juan
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#171147" title="Click to go to the Author Index">
             Jiang, Pei
            </a>
           </td>
           <td class="r">
            Chongqing University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#328602" title="Click to go to the Author Index">
             Li, Yunquan
            </a>
           </td>
           <td class="r">
            South China University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#234284" title="Click to go to the Author Index">
             Zhang, Yazhan
            </a>
           </td>
           <td class="r">
            Peng Cheng National Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#181710" title="Click to go to the Author Index">
             Li, Yingtian
            </a>
           </td>
           <td class="r">
            Shenzhen Institutes of Advanced Technology, Chinese Academy of S
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1384" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a soft actuator inspired by origami and a tunable strain limiting layer, which is proposed for reconfigurable soft robotic grasping. Main structure of the actuator is based on Miura origami which generates extension under pressurized air while a limiting layer with tunable length enables the actuator with different motion patterns. By driving the limiting layer through a servo motor, the range of motion and trajectory of the actuator can be pre-programed and the gripperâ€™s grasping range will be affected accordingly. This paper discusses the design, fabrication, analysis and experimental verification of the actuator. Then grasping performance of the gripper under objects of different shapes, sizes, and weights is experimentally evaluated. The reconfigurable soft gripper can be applied as an end-effector to accomplish adaptive grasping tasks with various targets.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t2_12">
             09:00-10:00, Paper FrPI6T2.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2383'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A 'MAP' to Find High-Performing Soft Robot Designs: Traversing Complex Design Spaces Using MAP-Elites and Topology Optimization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#367763" title="Click to go to the Author Index">
             Xie, Yue
            </a>
           </td>
           <td class="r">
            University of Cambridge
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#187409" title="Click to go to the Author Index">
             Pinskier, Joshua
            </a>
           </td>
           <td class="r">
            CSIRO
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#251617" title="Click to go to the Author Index">
             Liow, Lois
            </a>
           </td>
           <td class="r">
            CSIRO
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#170783" title="Click to go to the Author Index">
             Howard, David
            </a>
           </td>
           <td class="r">
            CSIRO
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105049" title="Click to go to the Author Index">
             Iida, Fumiya
            </a>
           </td>
           <td class="r">
            University of Cambridge
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2383" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft robotics has emerged as the standard solution for grasping deformable objects, and has proven invaluable for mobile robotic exploration in extreme environments. However, despite this growth, there are no widely adopted computational design tools that produce quality, manufacturable designs. To advance beyond the diminishing returns of heuristic bio-inspiration, the field needs efficient tools to explore the complex, non-linear design spaces present in soft robotics, and find novel high-performing designs. In this work, we investigate a hierarchical design optimization methodology which combines the strengths of topology optimization and quality diversity optimization to generate diverse and high-performance soft robots by evolving the design domain. The method embeds variably sized void regions within the design domain and evolves their size and position, to facilitating a richer exploration of the design space and find a diverse set of high-performing soft robots. We demonstrate its efficacy on both benchmark topology optimization problems and soft robotic design problems, and show the method enhances grasp performance when applied to soft grippers. Our method provides a new framework to design parts in complex design domains, both soft and rigid.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t2_13">
             09:00-10:00, Paper FrPI6T2.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3345'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Pneumatic Bladder Links with Wide Range of Motion Joints for Articulated Inflatable Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#365585" title="Click to go to the Author Index">
             Uchiyama, Katsu
            </a>
           </td>
           <td class="r">
            Meiji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103555" title="Click to go to the Author Index">
             Niiyama, Ryuma
            </a>
           </td>
           <td class="r">
            Meiji University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3345" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Exploration of various applications is the frontier of research on inflatable robots. We proposed an articulated robots consisting of multiple pneumatic bladder links connected by rolling contact joints called Hillberry joints. The bladder link is made of a double-layered structure of tarpaulin sheet and polyurethane sheet, which is both airtight and flexible in shape. The integration of the Hilberry joint into an inflatable robot is also a new approach. The rolling contact joint allows wide range of motion of
             <span>
              Â±
             </span>
             150 degrees, the largest among the conventional inflatable joints. Using the proposed mechanism for inflatable robots, we demonstrated moving a 500 g payload with a 3-DoF arm and lifting 3.4 kg and 5 kg payloads with 2-DoF and 1-DoF arms, respectively. We also experimented with a single 3-DoF inflatable leg attached to a dolly to show that the proposed structure worked for legged locomotion.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t2_14">
             09:00-10:00, Paper FrPI6T2.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('964'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Bistable Valve for Electronics-Free Soft Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338358" title="Click to go to the Author Index">
             Kan, Longxin
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394483" title="Click to go to the Author Index">
             Lam, Jia Qing Joshua
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394479" title="Click to go to the Author Index">
             Qin, Zhihang
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394511" title="Click to go to the Author Index">
             Li, Keyi
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#233780" title="Click to go to the Author Index">
             Tang, Zhiqiang
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101847" title="Click to go to the Author Index">
             Laschi, Cecilia
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab964" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recently, there has been a notable shift towards electronics-free designs, which offer promising integration possibilities with soft robots, reducing reliance on traditional electronics. Despite numerous demonstrations showcasing logical control, contact sensors, and gait control, the conventional quake valve-based design is gradually struggling to meet the demands of electronics-free soft robots with increasingly complex functionalities. Integrating multiple tubes, channels, and valves has led to larger and bulkier overall systems. In this study, we introduce a simple yet powerful electronics-free pneumatic valve that excels in various aspects: it allows for flexible function configurations (operating individually, in pairs, or in larger groups), offers high-frequency synchronous reverse outputs, stores valve status, and ensures efficient maintenance. We believe that this work lays the groundwork for developing straightforward yet highly effective fully autonomous soft robots.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t2_15">
             09:00-10:00, Paper FrPI6T2.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('990'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Facile One-Step Injection Novel Composite Sensor for Robot Tactile Assistance
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393691" title="Click to go to the Author Index">
             Zhang, Yuyin
            </a>
           </td>
           <td class="r">
            Shanghai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394869" title="Click to go to the Author Index">
             Wang, Yue
            </a>
           </td>
           <td class="r">
            Shanghai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#169999" title="Click to go to the Author Index">
             Liu, Na
            </a>
           </td>
           <td class="r">
            Shanghai University, Shanghai, China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394859" title="Click to go to the Author Index">
             Zhong, Songyi
            </a>
           </td>
           <td class="r">
            Shanghai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#185024" title="Click to go to the Author Index">
             Li, Long
            </a>
           </td>
           <td class="r">
            Shanghai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#415890" title="Click to go to the Author Index">
             Xie, Xie
            </a>
           </td>
           <td class="r">
            Shanghai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285950" title="Click to go to the Author Index">
             Zhang, Quan
            </a>
           </td>
           <td class="r">
            Shanghai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#145495" title="Click to go to the Author Index">
             Yue, Tao
            </a>
           </td>
           <td class="r">
            Shanghai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101162" title="Click to go to the Author Index">
             Fukuda, Toshio
            </a>
           </td>
           <td class="r">
            Nagoya University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab990" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Tactile information is the research hotspot of wearable flexible sensors due to its importance and complexity. With the innovation of wearable technology and robotics in healthcare, researchers are increasingly integrating wearable flexible sensors on the front end of robots to reproduce the hand tactile manipulation of human tissues. Therefore, it is hoped to develop a thin-film sensor that can be deployed in a small area to assist robots in surgery and data collection of human tissues. Here we use a one-step injection method to fabricate a novel composite sensor based on liquid metal. By laminating multiple PDMS microfluidic layers, the two parameters of pressure and deformation are measured simultaneously in a decoupled manner. The sensor is small and thin, making it easy to integrate into fingers/robot fingers for assistance. The finger/robot finger exerts pressure on the sensor and the sensor deforms with the material to identify the hardness of the material being touched. Separate performance tests of the two sensors show that the strain and pressure functions are decoupled from each other, and their ratios can identify and classify the hardness of different touched materials (glass, PDMS and silicone). This novel composite sensor we proposed can assist robots in manipulating human tissues during medical surgeries. At the same time, its function in tactile information feedback also has broad applications in medical treatment, rehabilitation and services.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t2_16">
             09:00-10:00, Paper FrPI6T2.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3399'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Development of Permanent Magnet Elastomer-Based Tactile Sensor with Adjustable Compliance and Sensitivity
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#356767" title="Click to go to the Author Index">
             Abhyankar, Devesh
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#208722" title="Click to go to the Author Index">
             Wang, Yushi
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#295372" title="Click to go to the Author Index">
             Iwamoto, Yuhiro
            </a>
           </td>
           <td class="r">
            Nagoya Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100151" title="Click to go to the Author Index">
             Sugano, Shigeki
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114910" title="Click to go to the Author Index">
             Kamezaki, Mitsuhiro
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3399" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Tactile sensors are crucial in robotics as they enable robots to perceive and interact with their environment through touch, akin to the human sense of touch. Adjustable sensors that can adapt to various tasks by functional or structural modification have not been extensively explored. In terms of sensing adjustability of a sensor, two important aspects are the sensorâ€™s sensitivity and compliance. This paper proposes a novel design for an adjustable compliance and sensitivity sensor composed of a silicone base, a permanent magnetic elastomer (PME), and a printed circuit board (PCB) with magnetic transducers installed. Its adjustability is achieved by varying the pneumatic pressure. This paper presents the design, manufacturing process, and experimental characterization of such an adjustable compliance and sensitivity sensor. This paper thoroughly investigates how altering the pressure of the sensor influences its sensing properties. The results show that it can achieve adjustability in all three axes. For the current design, the sensitivity can be varied from 0.093 to 0.125 mT/N (34.41%), 0.089 to 0.13 mT/N (31.54%), and 0.169 to 0.45 mT/N (62.44%) in the X-, Y-, and Z-axis, respectively. The deformation it undertakes varies from 3.20 to 3.79 mm (18.44%), indicating the compliance change.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frpi6t3">
             <b>
              FrPI6T3
             </b>
            </a>
           </td>
           <td class="r">
            Room 3
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frpi6t3" title="Click to go to the Program at a Glance">
             <b>
              Cognitive Systems
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t3_01">
             09:00-10:00, Paper FrPI6T3.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1332'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Online Hand Movement Recognition System with EEG-EMG Fusion Using One-Dimensional Convolutional Neural Network
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384749" title="Click to go to the Author Index">
             Wang, Haozheng
            </a>
           </td>
           <td class="r">
            Nankai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384779" title="Click to go to the Author Index">
             Jia, Hao
            </a>
           </td>
           <td class="r">
            University of Vic Central University of Catalonia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#297805" title="Click to go to the Author Index">
             Sun, Zhe
            </a>
           </td>
           <td class="r">
            RIKEN
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#116345" title="Click to go to the Author Index">
             Duan, Feng
            </a>
           </td>
           <td class="r">
            Nankai University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1332" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#intention_recognition" title="Click to go to the Keyword Index">
               Intention Recognition
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_based_control" title="Click to go to the Keyword Index">
               Sensor-based Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Upper limb amputees face significant challenges in their daily lives due to the loss of hand or arm functionality. Researchers have developed upper limb prostheses to restore normal hand movements for them. Most hand movement recognition systems of prostheses use electromyography (EMG) as the input signal source, but ignore the interrelationship with electroencephalography (EEG), which may contain valuable movement-related information as well. In order to enhance the accuracy of hand movement classification, we proposed a hand movement recognition system based on a one-dimensional convolutional neural network (1D-CNN) that combines EEG and EMG as the input signal sources to increase the quantity of accessible information. In this work, we collected the EEG and EMG of five subjects during the hand movements and used a 1D-CNN based model to classify the preprocessed signals. The average accuracy of using EEG-EMG fusion is 96.59Â±2.63%, significantly higher than 74.99Â±8.24% of using single EEG and 90.31Â±7.16% of using single EMG. Then, we applied the model trained by offline experiment for online recognition, and controlled the Pepper robot to complete the corresponding hand movements. The average accuracy of online recognition can reach 93.00Â±4.85% by using majority voting method. The results indicate that the method of EEG-EMG fusion can effectively enhance the performance of hand movement recognition system, which promote the development of upper limb prostheses and contribute to the rehabilitation of upper limb amputees.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t3_02">
             09:00-10:00, Paper FrPI6T3.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2807'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Goal Estimation-Based Adaptive Shared Control for Brain-Machine Interfaces Remote Robot Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395940" title="Click to go to the Author Index">
             Muraoka, Tomoka
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195844" title="Click to go to the Author Index">
             Aoki, Tatsuya
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399287" title="Click to go to the Author Index">
             Hirata, Masayuki
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107751" title="Click to go to the Author Index">
             Taniguchi, Tadahiro
            </a>
           </td>
           <td class="r">
            Ritsumeikan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#176109" title="Click to go to the Author Index">
             Horii, Takato
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#111403" title="Click to go to the Author Index">
             Nagai, Takayuki
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2807" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#brain_machine_interfaces" title="Click to go to the Keyword Index">
               Brain-Machine Interfaces
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_factors_and_human_in_the_loop" title="Click to go to the Keyword Index">
               Human Factors and Human-in-the-Loop
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             To address these challenges, our method estimates the userâ€™s intended goal from their commands and uses this goal to generate auxiliary commands through the autonomous system that are both at a higher input frequency and more continuous.Furthermore, by defining the confidence level of the estimation, we adaptively calculated the weights for combining user and autonomous commands, thus achieving shared control. We conducted navigation experiments in both simulated environments and participant experiments in real environments including user ratings, using a pseudo-BMI setup. As a result, the proposed method significantly reduced obstacle collisions in all experiments. It markedly shortened path lengths under almost all conditions in simulations and, in participant experiments, especially when user inputs become more discrete and noisy (p&lt;0.01). Furthermore, under such challenging conditions, it was demonstrated that users could operate more easily, with greater confidence, and at a comfortable pace through this system.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t3_03">
             09:00-10:00, Paper FrPI6T3.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1269'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Voltage Regulation in Polymer Electrolyte Fuel Cell Systems Using Gaussian Process Model Predictive Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396097" title="Click to go to the Author Index">
             Li, Xiufei
            </a>
           </td>
           <td class="r">
            Lund University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396037" title="Click to go to the Author Index">
             Yang, Miao
            </a>
           </td>
           <td class="r">
            City University of HongKong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374195" title="Click to go to the Author Index">
             Zhang, Miao
            </a>
           </td>
           <td class="r">
            Tsinghua Shenzhen International Graduate School
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395975" title="Click to go to the Author Index">
             Qi, Yuanxin
            </a>
           </td>
           <td class="r">
            Lund University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#346702" title="Click to go to the Author Index">
             Li, Zhuowei
            </a>
           </td>
           <td class="r">
            The University of Nottingham, China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#411567" title="Click to go to the Author Index">
             Yu, Senbin
            </a>
           </td>
           <td class="r">
            Gala Sports
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#411556" title="Click to go to the Author Index">
             Yuantao, Wang
            </a>
           </td>
           <td class="r">
            Beijing University of Technologyï¼›Fengtai Technology (Beij
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#411564" title="Click to go to the Author Index">
             Shen, Linpeng
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#411549" title="Click to go to the Author Index">
             Li, Xiang
            </a>
           </td>
           <td class="r">
            Nantong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1269" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#cognitive_control_architectures" title="Click to go to the Keyword Index">
               Cognitive Control Architectures
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study introduces a novel approach utilizing Gaussian process model predictive control (MPC) to stabilize the output voltage of a polymer electrolyte fuel cell (PEFC) system by simultaneously regulating hydrogen and airflow rates. Two Gaussian process models are developed to capture PEFC dynamics, taking into account constraints including hydrogen pressure and input change rates, thereby aiding in mitigating errors inherent to PEFC predictive control. The dynamic performance of the physical model and Gaussian process MPC in constraint handling and system inputs is compared and analyzed. Simulation outcomes demonstrate that the proposed Gaussian process MPC effectively maintains the voltage at the target 48 V while adhering to safety constraints, even amidst workload disturbances ranging from 110-120 A.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t3_04">
             09:00-10:00, Paper FrPI6T3.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1373'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Roaming with Robots: Utilizing Artificial Curiosity in Global Path Planning for Autonomous Mobile Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#307735" title="Click to go to the Author Index">
             Spielbauer, Niklas
            </a>
           </td>
           <td class="r">
            FZI Forschungszentrum Informatik
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396402" title="Click to go to the Author Index">
             Laube, Till Jasper
            </a>
           </td>
           <td class="r">
            FZI Forschungszentrum Informatik
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#358047" title="Click to go to the Author Index">
             Oberacker, David
            </a>
           </td>
           <td class="r">
            FZI Forschungszentrum Informatik
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#132558" title="Click to go to the Author Index">
             Roennau, Arne
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#188556" title="Click to go to the Author Index">
             Dillmann, RÃ¼diger
            </a>
           </td>
           <td class="r">
            FZI - Forschungszentrum Informatik - Karlsruhe
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1373" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#cognitive_control_architectures" title="Click to go to the Keyword Index">
               Cognitive Control Architectures
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous Mobile Robots are used with increasing frequency in inspection and maintenance tasks completing fixed goal sequences. The downtime robots experience between goals offers an opportunity to gather additional environment information instead of resting. Uncertainty in the amount of downtime available rules out the definition of a pre-determined schedule set by an external operator. Instead, the robot itself should decide dynamically, what information it should gather before its next task begins. This results in a multi-objective optimization problem trying to maximize information gain while utilizing as much of the available time as possible. We propose a genetic algorithm to solve the presented optimization problem and introduce two different models for artificial curiosity used inside the fitness function for gathering as much information as possible. For planning the genetic algorithm utilizes a multi-map approach using information and obstacle maps. We evaluated our models in a pre-defined and pre-mapped Gazebo environment with a given information map and evaluated their performance against an information-agnostic coverage algorithm. In this work, we show that utilizing artificial curiosity in path planning can result in major information gains by effectively using downtime.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t3_05">
             09:00-10:00, Paper FrPI6T3.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2232'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ROBOVERINE: A Human-Inspired Neural Robotic Process Model of Active Visual Search and Scene Grammar in Naturalistic Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#227906" title="Click to go to the Author Index">
             Grieben, Raul
            </a>
           </td>
           <td class="r">
            Ruhr-UniversitÃ¤t Bochum
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397919" title="Click to go to the Author Index">
             Sehring, Stephan
            </a>
           </td>
           <td class="r">
            Ruhr-UniversitÃ¤t Bochum
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#186365" title="Click to go to the Author Index">
             TekÃ¼lve, Jan
            </a>
           </td>
           <td class="r">
            Ruhr-Universitaet Bochum
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#327892" title="Click to go to the Author Index">
             Spencer, John P.
            </a>
           </td>
           <td class="r">
            University of East Anglia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114952" title="Click to go to the Author Index">
             SchÃ¶ner, Gregor
            </a>
           </td>
           <td class="r">
            Ruhr University Bochum
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2232" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#cognitive_modeling" title="Click to go to the Keyword Index">
               Cognitive Modeling
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#neurorobotics" title="Click to go to the Keyword Index">
               Neurorobotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#bioinspired_robot_learning" title="Click to go to the Keyword Index">
               Bioinspired Robot Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present ROBOVERINE, a neural dynamic robotic active vision process model of selective visual attention and scene grammar in naturalistic environments. The model addresses significant challenges for cognitive robotic models of visual attention: combined bottom-up salience and top-down feature guidance, combined overt and covert attention, coordinate transformations, two forms of inhibition of return, finding objects outside of the camera frame, integrated space- and object-based analysis, minimally supervised few-shot continuous online learning for recognition and guidance templates, and autonomous switching between exploration and visual search. Furthermore, it incorporates a neural process account of scene grammar - prior knowledge about the relation between objects in the scene - to reduce the search space and increase search efficiency. The model also showcases the strength of bridging two frameworks: Deep Neural Networks for feature extractions and Dynamic Field Theory for cognitive operations.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t3_06">
             09:00-10:00, Paper FrPI6T3.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3490'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Interactive Reinforcement Learning from Natural Language Feedback
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#356166" title="Click to go to the Author Index">
             Tarakli, Imene
            </a>
           </td>
           <td class="r">
            Sheffield Hallam University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#229793" title="Click to go to the Author Index">
             Vinanzi, Samuele
            </a>
           </td>
           <td class="r">
            Sheffield Hallam University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#176120" title="Click to go to the Author Index">
             Di Nuovo, Alessandro
            </a>
           </td>
           <td class="r">
            Sheffield Hallam University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3490" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_factors_and_human_in_the_loop" title="Click to go to the Keyword Index">
               Human Factors and Human-in-the-Loop
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cognitive_modeling" title="Click to go to the Keyword Index">
               Cognitive Modeling
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Large Language Models (LLMs) are increasingly influential in advancing robotics. This paper introduces ECLAIR (Evaluative Corrective Guidance Language as Reinforcement), a novel framework that leverages LLMs to interpret and incorporate diverse natural language feedback into robotic learning. ECLAIR unifies various forms of human advice into actionable insights within a Reinforcement Learning context, enabling more efficient robot instruction. Experiments with real-world users demonstrate that ECLAIR accelerates the robot's learning process, aligning its policy closer to optimal from the outset and reducing the need for extensive human intervention. Additionally, ECLAIR effectively integrates multiple types of advice and adapts well to prompt modifications. It also supports multilingual instruction, broadening its applicability and fostering more inclusive human-robot interactions. Project website: https://sites.google.com/view/eclairiros
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t3_07">
             09:00-10:00, Paper FrPI6T3.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Synthetic Dataset Using Diffusion Model for Pixel-Level Dense Pose Estimation
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397831" title="Click to go to the Author Index">
             Wen, Jiaixiao
            </a>
           </td>
           <td class="r">
            South China University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397686" title="Click to go to the Author Index">
             Liu, Qiong
            </a>
           </td>
           <td class="r">
            South China University of Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t3_08">
             09:00-10:00, Paper FrPI6T3.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1225'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Contacts from Motion: Learning Discrete Features for Automatic Contact Detection and Estimation from Human Movements
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374083" title="Click to go to the Author Index">
             Miyake, Hibiki
            </a>
           </td>
           <td class="r">
            Tokyo University of Science
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114052" title="Click to go to the Author Index">
             Ayusawa, Ko
            </a>
           </td>
           <td class="r">
            National Institute of Advanced Industrial Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103364" title="Click to go to the Author Index">
             Sagawa, Ryusuke
            </a>
           </td>
           <td class="r">
            National Institute of Advanced Industrial Science AndTechnology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103117" title="Click to go to the Author Index">
             Yoshida, Eiichi
            </a>
           </td>
           <td class="r">
            Faculty of Advanced Engineering, Tokyo University of Science
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1225" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_and_humanoid_motion_analysis_and_synthesis" title="Click to go to the Keyword Index">
               Human and Humanoid Motion Analysis and Synthesis
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#modeling_and_simulating_humans" title="Click to go to the Keyword Index">
               Modeling and Simulating Humans
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a novel method for detecting and estimating contact forces only from human motions using machine learning techniques. Knowing the location of the contacts with the environment and the magnitude of the exerted force is critical for dynamic human motion analysis. However, their annotation is usually made manually from captured motion data especially in case of multiple contacts even if the data includes force measurement. Moreover, most existing human motion datasets do not include contact force. To overcome these bottlenecks, we introduce a network that leverages vector-quantized variational autoencoder (VQ-VAE) and self-attention that learns a small set of discrete feature values representing various contact states. These feature values, called contact codes, allow human motions to be converted to contact states and resulting forces. By applying an optimization for contact estimation with a reduced set of manual annotations, the existence of contacts can be automatically determined, which is essential information for dynamic analysis. We validated the effectiveness and potential usefulness of the proposed method with a human walking gait dataset, by converting the human motions into contact sequences and forces and applying the estimated contacts to dynamic motion analysis.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t3_09">
             09:00-10:00, Paper FrPI6T3.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1464'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Dual-Branch Graph Transformer Network for 3D Human Mesh Reconstruction from Video
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396206" title="Click to go to the Author Index">
             Tang, Tao
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#110768" title="Click to go to the Author Index">
             Liu, Hong
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310112" title="Click to go to the Author Index">
             You, Yingxuan
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396459" title="Click to go to the Author Index">
             Wang, Ti
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375390" title="Click to go to the Author Index">
             Li, Wenhao
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1464" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_and_humanoid_motion_analysis_and_synthesis" title="Click to go to the Keyword Index">
               Human and Humanoid Motion Analysis and Synthesis
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#modeling_and_simulating_humans" title="Click to go to the Keyword Index">
               Modeling and Simulating Humans
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_detection_and_tracking" title="Click to go to the Keyword Index">
               Human Detection and Tracking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Human mesh reconstruction (HMR) from monocular video plays an important role in human-robot interaction and collaboration. However, existing video-based human mesh reconstruction methods face a tradeoff between accurate reconstruction and smooth motion. These methods design networks based on either RNNs or attention mechanisms to extract local temporal correlations or global temporal dependencies, but the lack of complementary longterm information and local details limits their representation of the human body. To address this problem, we propose a Dual-branch Graph Transformer network for 3D human mesh Reconstruction from video, named DGTR. DGTR employs a dual-branch network including a Global Motion Attention (GMA) branch and a Local Details Refine (LDR) branch to parallelly extract long-term dependencies and local crucial information, helping model global human motion and local human details (e.g., local motion, tiny movement). Specifically, GMA utilizes a global transformer to model long-term human motion. LDR combines modulated graph convolutional networks and the transformer framework to aggregate local information in adjacent frames and extract crucial information of human details. Experiments demonstrate that our DGTR outperforms state-of-the-art video-based methods in reconstruction accuracy and maintains competitive motion smoothness. Moreover, DGTR utilizes fewer parameters and FLOPs, which validate the effectiveness and efficiency of the proposed DGTR. Code is publicly available at https://github.com/TangTao-PKU/DGTR.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t3_10">
             09:00-10:00, Paper FrPI6T3.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2348'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Predicting Long-Term Human Behaviors in Discrete Representations Via Physics-Guided Diffusion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277561" title="Click to go to the Author Index">
             Zhang, Zhitian
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#267596" title="Click to go to the Author Index">
             Li, Anjian
            </a>
           </td>
           <td class="r">
            Princeton University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#136950" title="Click to go to the Author Index">
             Lim, Angelica
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205553" title="Click to go to the Author Index">
             Chen, Mo
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2348" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_and_humanoid_motion_analysis_and_synthesis" title="Click to go to the Keyword Index">
               Human and Humanoid Motion Analysis and Synthesis
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intention_recognition" title="Click to go to the Keyword Index">
               Intention Recognition
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#modeling_and_simulating_humans" title="Click to go to the Keyword Index">
               Modeling and Simulating Humans
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Long-term human trajectory prediction is a challenging yet critical task in robotics and autonomous systems. Prior work that studied how to predict accurate short-term human trajectories with only unimodal features often failed in long-term prediction. Reinforcement learning provides a good solution for learning human long-term behaviors but can suffer from challenges in data efficiency and optimization. In this work, we propose a long-term human trajectory forecasting framework that leverages a guided diffusion model to generate diverse long-term human behaviors in a high-level latent action space, obtained via a hierarchical action quantization scheme using a VQ-VAE to discretize continuous trajectories and the available context. The latent actions are predicted by our guided diffusion model, which uses physics-inspired guidance at test time to constrain generated multimodal action distributions. Specifically, we use reachability analysis during the reverse denoising process to guide the diffusion steps toward physically feasible latent actions. We evaluate our framework on two publicly available human trajectory forecasting datasets: SFU-Store-Nav and JRDB, and extensive experimental results show that our framework achieves superior performance in long-term human trajectory forecasting.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t3_11">
             09:00-10:00, Paper FrPI6T3.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1194'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-View 2D to 3D Lifting Video-Based Optimization: A Robust Approach for Human Pose Estimation with Occluded Joint Prediction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395943" title="Click to go to the Author Index">
             Rato, Daniela
            </a>
           </td>
           <td class="r">
            University of Aveiro, Institute of Electronics and Informatics E
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#154460" title="Click to go to the Author Index">
             Oliveira, Miguel
            </a>
           </td>
           <td class="r">
            University of Aveiro
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101630" title="Click to go to the Author Index">
             Santos, Vitor
            </a>
           </td>
           <td class="r">
            University of Aveiro
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104177" title="Click to go to the Author Index">
             Sappa, Angel
            </a>
           </td>
           <td class="r">
            Computer Vision Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105267" title="Click to go to the Author Index">
             Raducanu, Bogdan
            </a>
           </td>
           <td class="r">
            Computer Vision Center
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1194" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_detection_and_tracking" title="Click to go to the Keyword Index">
               Human Detection and Tracking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_manufacturing" title="Click to go to the Keyword Index">
               Computer Vision for Manufacturing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the context of robotics, accurate 3D human pose estimation is essential for enhancing human-robot collaboration and interaction. This manuscript introduces a multi-view 2D to 3D lifting optimization-based method designed for video-based 3D human pose estimation, incorporating temporal information. Our technique addresses key challenges, namely robustness to 2D joint detection error, occlusions, and varying camera perspectives. We evaluate the performance of the algorithm through extensive experiments on the MPI-INF-3DHP dataset. Our method demonstrates very good robustness up to 25 pixels of 2D joint error and shows resilience in scenarios involving several occluded joints. Comparative analyses against existing 2D to 3D lifting and multi-view methods showcase good performance of our approach.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t3_12">
             09:00-10:00, Paper FrPI6T3.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('347'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Can Reasons Help Improve Pedestrian Intent Estimation? a Cross-Modal Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374038" title="Click to go to the Author Index">
             Khindkar, Vaishnavi
            </a>
           </td>
           <td class="r">
            IIIT Hyderabad
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#211605" title="Click to go to the Author Index">
             Balasubramanian, Vineeth
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology, Hyderabad
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#278895" title="Click to go to the Author Index">
             Arora, Chetan
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology, Delhi
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#297233" title="Click to go to the Author Index">
             Subramanian, Anbumani
            </a>
           </td>
           <td class="r">
            Intel / IIIT-Hyderabad
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106597" title="Click to go to the Author Index">
             Jawahar, C.V.
            </a>
           </td>
           <td class="r">
            IIIT, Hyderabad
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab347" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#intention_recognition" title="Click to go to the Keyword Index">
               Intention Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             With the increased importance of autonomous navigation systems has come an increasing need to protect the safety of Vulnerable Road Users (VRUs) such as pedestrians. Predicting pedestrian intent is one such challenging task, where prior work predicts the binary cross/no-cross intention with a fusion of visual and motion features. However, there has been no effort so far to hedge such predictions with human-understandable reasons. We address this issue by introducing a novel problem setting of exploring the intuitive reasoning behind a pedestrianâ€™s intent. In particular, we show that predicting the â€˜WHYâ€™ can be very useful in understanding the â€˜WHATâ€™. To this end, we propose a novel, reason-enriched PIE++ dataset consisting of multi-label textual explanations/reasons for pedestrian intent. (Explanations, in our context, refers to the interpretation of pedestrian intent and not model interpretability.) We also introduce a novel multi-task learning framework called MINDREAD, which leverages a cross-modal representation learning framework for predicting pedestrian intent as well as the reason behind the intent. Our comprehensive experiments show significant improvement of 5.6% and 7% in accuracy and F1-score for the task of intent prediction on the PIE++ dataset using MINDREAD. We also achieved a 4.4% improvement in accuracy on a commonly used JAAD dataset. Extensive evaluation using quantitative/qualitative metrics and user studies show the effectiveness of our approach
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t3_13">
             09:00-10:00, Paper FrPI6T3.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('365'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhanced Robotic Assistance for Human Activities through Human-Object Interaction Segment Prediction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#323328" title="Click to go to the Author Index">
             Wu, Yuankai
            </a>
           </td>
           <td class="r">
            TUM
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#373233" title="Click to go to the Author Index">
             Messaoud, Rayene
            </a>
           </td>
           <td class="r">
            TUM
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#168508" title="Click to go to the Author Index">
             Hildebrandt, Arne-Christoph
            </a>
           </td>
           <td class="r">
            Technische UniversitÃ¤t MÃ¼nchen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195626" title="Click to go to the Author Index">
             Baldini, Marco
            </a>
           </td>
           <td class="r">
            ABB AG
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352814" title="Click to go to the Author Index">
             Salihu, Driton
            </a>
           </td>
           <td class="r">
            Technical University Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352817" title="Click to go to the Author Index">
             Patsch, Constantin
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107651" title="Click to go to the Author Index">
             Steinbach, Eckehard
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab365" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_centered_automation" title="Click to go to the Keyword Index">
               Human-Centered Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intention_recognition" title="Click to go to the Keyword Index">
               Intention Recognition
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#humanoid_robot_systems" title="Click to go to the Keyword Index">
               Humanoid Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic assistance is a current research topic with high application value and multiple challenges. Assistive robots are used in various scenarios, such as production lines, operating tables, and elderly care. While providing effective assistance, most of the assistance tasks that current robots can perform are limited to predefined tasks. This limitation arises from the insufficiency of the current robot perception system to forecast future human activities. To address this issue, we propose a novel 2-stage robotic assistant for human activities through future human-object interaction (HOI) segment prediction. Unlike previous work focusing on predefined or short-term tasks, our robotic assistant can make predictions for future assistance according to human habits. In the first stage, we propose a visual-based human-object interaction segment prediction method to predict human activities, which enables the robotic system to infer human intention. Moreover, we define the robotic executable tasks as an interactive tuple to keep the robotic assistance normatively consistent with human activity. Meanwhile, a graph convolutional network with geometric features that can predict human-object interaction segments is proposed to provide target manipulation and target object for the assistive robot. In the second stage, we present a mobile task completion process including visual navigation, object localization and grasping. The perception stage is evaluated on the MPHOI dataset and custom-collected SPHOI dataset. Finally, we evaluate our comprehensive framework through real-time experimentation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t3_14">
             09:00-10:00, Paper FrPI6T3.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3077'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Aligning Learning with Communication in Shared Autonomy
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#344409" title="Click to go to the Author Index">
             Hoegerman, Joshua
            </a>
           </td>
           <td class="r">
            Virginia Polytechnic Institute and State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#332519" title="Click to go to the Author Index">
             Sagheb, Shahabedin
            </a>
           </td>
           <td class="r">
            Virginia Tech
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338970" title="Click to go to the Author Index">
             Christie, Benjamin
            </a>
           </td>
           <td class="r">
            Virginia Tech
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#187169" title="Click to go to the Author Index">
             Losey, Dylan
            </a>
           </td>
           <td class="r">
            Virginia Tech
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3077" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intention_recognition" title="Click to go to the Keyword Index">
               Intention Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Assistive robot arms can help humans by partially automating their desired tasks. Consider an adult with motor impairments controlling an assistive robot arm to eat dinner. The robot can reduce the number of human inputs â€” and how precise those inputs need to be â€” by recognizing what the human wants (e.g., a fork) and assisting for that task (e.g., moving towards the fork). Prior research has largely focused on learning the humanâ€™s task and providing meaningful assistance. But as the robot learns and assists, we also need to ensure that the human understands the robotâ€™s intent (e.g., does the human know the robot is reaching for a fork?). In this paper, we study the effects of communicating learned assistance from the robot back to the human operator. We do not focus on the specific interfaces used for communication. Instead, we develop experimental and theoretical models of a) how communication changes the way humans interact with assistive robot arms, and b) how robots can harness these changes to better align with the humanâ€™s intent. We first conduct online and in-person user studies where participants operate robots that provide partial assistance, and we measure how the humanâ€™s inputs change with and without communication. With communication, we find that humans are more likely to intervene when the robot incorrectly predicts their intent, and more likely to release control when the robot correctly understands their task. We then use these findings to modify an established robot learning algorithm so that the robot can correctly interpret the humanâ€™s inputs when communication is present. Our results from a second in-person user study suggest that this combination of communication and learning outperforms assistive systems that isolate either learning or communication.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t3_15">
             09:00-10:00, Paper FrPI6T3.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2704'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learned Sensor Fusion for Robust Human Activity Recognition in Challenging Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#368140" title="Click to go to the Author Index">
             Conway, Max
            </a>
           </td>
           <td class="r">
            University of Denver
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#199377" title="Click to go to the Author Index">
             Reily, Brian
            </a>
           </td>
           <td class="r">
            Army Research Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123373" title="Click to go to the Author Index">
             Reardon, Christopher M.
            </a>
           </td>
           <td class="r">
            University of Denver
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2704" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multi_modal_perception_for_hri" title="Click to go to the Keyword Index">
               Multi-Modal Perception for HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Human activity recognition is a vital area of robotics with significant real-world applications, from enhancing security and surveillance to improving healthcare and human-robot interaction. A critical challenge lies in bridging the gap between research models, which often assume ideal conditions, and the complexities of real-world environments. In practice, conditions can be far from perfect, including scenarios with poor lighting, adverse weather, or blurred views. In this paper, we present an innovative approach for robust activity recognition through learned sensor fusion, in which our recognition framework identifies a latent weighted combination of input modalities, enabling classifiers to capitalize on advantages provided by various sensors. In support of our work, we have released a dataset of human activities across multiple modalities with environmental degradation factors such as darkness, fog, and thermal blur. Our proposed approach identifies a weighted combination of modality representations derived from existing architectures. We show that our approach is able to achieve 24% higher classification performance than existing single-modality approaches. Our approach also attains comparable performance to modality fusion approaches in significantly reduced classification time. In real-world robotics applications, particularly those occurring in dangerous, degraded environments, this speed is critical.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t3_16">
             09:00-10:00, Paper FrPI6T3.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3402'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Human Orientation Estimation under Partial Observation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#313625" title="Click to go to the Author Index">
             Zhao, Jieting
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#320141" title="Click to go to the Author Index">
             Ye, Hanjing
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380174" title="Click to go to the Author Index">
             Zhan, Yu
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#313610" title="Click to go to the Author Index">
             Luan, Hao
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100155" title="Click to go to the Author Index">
             Zhang, Hong
            </a>
           </td>
           <td class="r">
            SUSTech
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3402" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robot_companions" title="Click to go to the Keyword Index">
               Robot Companions
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_centered_automation" title="Click to go to the Keyword Index">
               Human-Centered Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_detection_and_tracking" title="Click to go to the Keyword Index">
               Human Detection and Tracking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Reliable Human Orientation Estimation (HOE) from a monocular image is critical for autonomous agents to understand human intention. Significant progress has been made in HOE under full observation. However, the existing methods easily make a wrong prediction under partial observation and give it an unexpectedly high confidence. To solve the above problems, this study first develops a method called Part-HOE that estimates orientation from the visible joints of a target person so that it is able to handle partial observation. Subsequently, we introduce a confidence-aware orientation estimation method, enabling more accurate orientation estimation and reasonable confidence estimation under partial observation. The effectiveness of our method is validated on both public and custom-built datasets, and it shows great accuracy and reliability improvement in partial observation scenarios. In particular, we show in real experiments that our method can benefit the robustness and consistency of the Robot Person Following (RPF) task.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frpi6t4">
             <b>
              FrPI6T4
             </b>
            </a>
           </td>
           <td class="r">
            Room 4
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frpi6t4" title="Click to go to the Program at a Glance">
             <b>
              Robot Vision IV
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#109542" title="Click to go to the Author Index">
             Tanaka, Kanji
            </a>
           </td>
           <td class="r">
            University of Fukui
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#164571" title="Click to go to the Author Index">
             Patel, Amir
            </a>
           </td>
           <td class="r">
            University of Cape Town
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t4_01">
             09:00-10:00, Paper FrPI6T4.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2122'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Ultrafast Multi-Object Zooming System Based on Low-Latency Stereo Correspondence
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#322078" title="Click to go to the Author Index">
             Li, Qing
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#253702" title="Click to go to the Author Index">
             Hu, Shaopeng
            </a>
           </td>
           <td class="r">
            Hiroshima University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#202812" title="Click to go to the Author Index">
             Shimasaki, Kohei
            </a>
           </td>
           <td class="r">
            Hiroshima University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#111980" title="Click to go to the Author Index">
             Ishii, Idaku
            </a>
           </td>
           <td class="r">
            Hiroshima University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2122" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#surveillance_robotic_systems" title="Click to go to the Keyword Index">
               Surveillance Robotic Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we develop a multiple-object zoom- ing system which can capture clear images of different objects at an ultrafast speed. The system consists of a panoramic HFR stereo camera and a galvanometer-based reflective pan- tilt-zoom (PTZ) camera. In order to alleviate the impact of brightness, noise, and viewing angle in the image, we use the motion information of the object for stereo correspondence. According to the spatial positions of all objects obtained from HFR stereo correspondence, we can obtain the control voltage of the pan and tilt mirror of the galvanometer-based reflective PTZ camera through the mapping relationship. Then, PTZ camera captures clear images of multiple objects in a time-division multiplexed manner at an extremely fast speed. Experimental results show that we can distinguish multiple fast- moving people indoors in the HFR stereo camera and capture their high-definition facial images simultaneously.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t4_02">
             09:00-10:00, Paper FrPI6T4.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('137'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhanced Model Robustness to Input Corruptions by Per-Corruption Adaptation of Normalization Statistics
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389597" title="Click to go to the Author Index">
             Camuffo, Elena
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#318083" title="Click to go to the Author Index">
             Michieli, Umberto
            </a>
           </td>
           <td class="r">
            Samsung Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389598" title="Click to go to the Author Index">
             Milani, Simone
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391356" title="Click to go to the Author Index">
             Moon, Jijoong
            </a>
           </td>
           <td class="r">
            Samsung Research Korea
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#170089" title="Click to go to the Author Index">
             Ozay, Mete
            </a>
           </td>
           <td class="r">
            Samsung Research
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab137" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Developing a reliable vision system is a fundamental challenge for robotic technologies (e.g., indoor service robots and outdoor autonomous robots) which can ensure reliable navigation even in challenging environments such as adverse weather conditions (e.g., fog, rain), poor lighting conditions (e.g., over/under exposure), or sensor degradation (e.g., blurring, noise), and can guarantee high performance in safety-critical functions. Current solutions proposed to improve model robustness usually rely on generic data augmentation techniques or employ costly test-time adaptation methods. In addition, most approaches focus on addressing a single vision task (typically, image recognition) utilising synthetic data. In this paper, we introduce Per-corruption Adaptation of Normalization statistics (PAN) to enhance the model robustness of vision systems. Our approach entails three key components: (i) a corruption type identification module, (ii) dynamic adjustment of normalization layer statistics based on identified corruption type, and (iii) real-time update of these statistics according to input data. PAN can integrate seamlessly with any convolutional model for enhanced accuracy in several robot vision tasks. In our experiments, PAN obtains robust performance improvement on challenging real-world corrupted image datasets (e.g., OpenLoris, ExDark, ACDC), where most of the current solutions tend to fail. Moreover, PAN outperforms the baseline models by 20-30% on synthetic benchmarks in object recognition tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t4_03">
             09:00-10:00, Paper FrPI6T4.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('465'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Low-Cost, High-Speed, and Robust Bin Picking System for Factory Automation Enabled by a Non-Stop, Multi-View, and Active Vision Scheme
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#251668" title="Click to go to the Author Index">
             Fu, Xingdou
            </a>
           </td>
           <td class="r">
            OMRON Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#269758" title="Click to go to the Author Index">
             Miao, Lin
            </a>
           </td>
           <td class="r">
            Omron Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371390" title="Click to go to the Author Index">
             Ohnishi, Yasuhiro
            </a>
           </td>
           <td class="r">
            OMRON Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371335" title="Click to go to the Author Index">
             Hasegawa, Yuki
            </a>
           </td>
           <td class="r">
            OMRON Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#143070" title="Click to go to the Author Index">
             Suwa, Masaki
            </a>
           </td>
           <td class="r">
            OMRON Corporation
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab465" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_manufacturing" title="Click to go to the Keyword Index">
               Computer Vision for Manufacturing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Bin picking systems in factory automation usually face robustness issues caused by sparse and noisy 3D data of metallic objects. Utilizing multiple views, especially with a one-shot 3D sensor and â€œsensor on handâ€ configuration is getting more popularity due to its effectiveness, flexibility, and low cost. While moving the 3D sensor to acquire multiple views for 3D fusion, joint optimization, or active vision suffers from low-speed issues. That is because sensing is taken as a decoupled module from motion tasks and is not intentionally designed for a bin picking system. To address the problems, we designed a bin picking system, which tightly couples a multi-view, active vision scheme with motion tasks in a â€œsensor on handâ€ configuration. It not only speeds up the system by parallelizing the high-speed sensing scheme to the robot place action but also decides the next sensing path to maintain the continuity of the whole picking process. Unlike others focusing only on sensing evaluation, we also evaluated our design by picking experiments on 5 different types of objects without human intervention. Our experiments show the whole sensing scheme can be finished within 1.682 seconds (maximum) on CPU and the average picking complete rate is over 97.75%. Due to the parallelization with robot motion, the sensing scheme accounts for only 0.635 seconds in takt time on average.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t4_04">
             09:00-10:00, Paper FrPI6T4.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('745'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Every Dataset Counts: Scaling up Monocular 3D Object Detection with Joint Datasets Training
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276186" title="Click to go to the Author Index">
             Ma, Fulong
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339724" title="Click to go to the Author Index">
             Yan, Xiaoyang
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#365001" title="Click to go to the Author Index">
             Zhao, Guoyang
            </a>
           </td>
           <td class="r">
            HKUST(GZ)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370927" title="Click to go to the Author Index">
             Xu, Xiaojie
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology(Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#275161" title="Click to go to the Author Index">
             Liu, Yuxuan
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#182083" title="Click to go to the Author Index">
             Ma, Jun
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#125556" title="Click to go to the Author Index">
             Liu, Ming
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab745" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Monocular 3D object detection plays a crucial role in autonomous driving. However, existing monocular 3D detection algorithms depend on 3D labels derived from LiDAR measurements, which are costly to acquire for new datasets and challenging to deploy in novel environments. Specifically, this study investigates the pipeline for training a monocular 3D object detection model on a diverse collection of 3D and 2D datasets. The proposed framework comprises three components: (1) a robust monocular 3D model capable of functioning across various camera settings, (2) a selective-training strategy to accommodate datasets with differing class annotations, and (3) a pseudo 3D training approach using 2D labels to enhance detection performance in scenes containing only 2D labels. With this framework, we could train models on a joint set of various open 3D/2D datasets to obtain models with significantly stronger generalization capability and enhanced performance on new dataset with only 2D labels. We conduct extensive experiments on KITTI, nuScenes, ONCE, Cityscapes and BDD100K datasets to demonstrate the scaling ability of the proposed method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t4_05">
             09:00-10:00, Paper FrPI6T4.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('771'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Direct TPS-Based 3D Non-Rigid Motion Estimation on 3D Colored Point Cloud in Eye-In-Hand Configuration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#342430" title="Click to go to the Author Index">
             Cuau, LÃ©naÃ¯c
            </a>
           </td>
           <td class="r">
            LIRMM
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#226435" title="Click to go to the Author Index">
             Cavalcanti Santos, Joao
            </a>
           </td>
           <td class="r">
            University of Montpellier, LIRMM
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105369" title="Click to go to the Author Index">
             Poignet, Philippe
            </a>
           </td>
           <td class="r">
            LIRMM University of Montpellier CNRS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105086" title="Click to go to the Author Index">
             Zemiti, Nabil
            </a>
           </td>
           <td class="r">
            LIRMM, UniversitÃ© Montpellier II - CNRS UMR 5506
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab771" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, a method for 3D non-rigid motion estimation of a surface using an RGB-D camera in eye-in-hand configuration is presented. The eye-in-hand configuration eliminates errors typically associated with camera-end-effector calibration, and is thus desirable for task on moving surfaces such as bioprinting. However, its implementation is challenging since camera and surface of interest are moving, making mesh-based approaches unsuitable. Thus, the proposed method operates directly on point clouds, benefiting from accurate and simplified data processing. A point cloud contains both intensity and depth data, with the former used to estimate in-plane deformation and the latter to compute full 3D deformation. Surface deformation is modeled via a Thin Plate Spline model. The method accuracy is assessed at 0.1 mm accuracy in simulated datasets, rendering it suitable for precision tasks, and its feasibility is validated experimentally on a moving platform that deforms at a rate of 0.8 Hz with a 4 mm in-plane amplitude and a 20 mm elevation amplitude.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t4_06">
             09:00-10:00, Paper FrPI6T4.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1162'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              OW3Det: Toward Open-World 3D Object Detection for Autonomous Driving
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#347570" title="Click to go to the Author Index">
             Hu, Wenfei
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#301453" title="Click to go to the Author Index">
             Lin, Weikai
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#281161" title="Click to go to the Author Index">
             Fang, Hongyu
            </a>
           </td>
           <td class="r">
            Peking University, Beijing, China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#348175" title="Click to go to the Author Index">
             Wang, Yi
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#152071" title="Click to go to the Author Index">
             Luo, Dingsheng
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1162" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Despite their success in LIDAR object detection, modern detectors are vulnerable to uncommon instances and corner cases (e.g., a runaway tire) since they are closed-set and static. Networks under the closed-set setup only predict labels of seen classes, while static models suffer from catastrophic forgetting when gradually learning novel concepts. This motivates us to formulate the open-world 3D object detection task for autonomous driving, which aims to 1) tackle the closed-set issue by identifying unseen instances as unknown and 2) incrementally learn novel classes without forgetting previously obtained knowledge. To achieve the open-world objectives, we propose Open-World 3D Detector (OW3Det), the first framework for open-world 3D object detection. The OW3Det comprises a base detector, a self-supervised unknown identifier, and a knowledge-distillation-restricted incremental learner. Although knowledge distillation facilitates preserving memories, imposing penalties on areas containing unknown objects hinders the incremental learning process. We mitigate this hindrance by employing unknown-driven pivotal mask, which eliminates unnecessary restrictions on regions overlapping with novel instances. Abundant experiments and visualizations demonstrate that the proposed OW3Det attains state-of-the-art performance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t4_07">
             09:00-10:00, Paper FrPI6T4.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1239'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              FoveaCam++: Systems-Level Advances for Long Range Multi-Object High-Resolution Tracking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396067" title="Click to go to the Author Index">
             Zhang, Yuxuan
            </a>
           </td>
           <td class="r">
            University of Florida
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#181266" title="Click to go to the Author Index">
             Koppal, Sanjeev
            </a>
           </td>
           <td class="r">
            University of Florida
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1239" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#hardware_software_integration_in_robotics" title="Click to go to the Keyword Index">
               Hardware-Software Integration in Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             UAVs and other fast moving robots often need to keep track of distant objects. Conventional zoom cameras commit to a particular viewpoint, and carrying multiple zoom cameras for multi-object tracking is not feasible for power limited robotic systems. We present a dual camera setup that allows tracking of multiple targets at nearly 1km distance with high-resolution. Our setup includes a wide angle camera providing a conventional resolution view and a MEMS driven zoom camera that can query a specific region within the wide angle camera (WAC). We built and calibrated the two-camera system and implemented a real-time image fusion pipeline. We show multi-object tracking and stabilization in real world scenarios.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t4_08">
             09:00-10:00, Paper FrPI6T4.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1406'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robot Traversability Prediction: Towards Third-Person-View Extension of Walk2Map with Photometric and Physical Constraints
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#367929" title="Click to go to the Author Index">
             Tay Yu Liang, Jonathan
            </a>
           </td>
           <td class="r">
            University of Fukui
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109542" title="Click to go to the Author Index">
             Tanaka, Kanji
            </a>
           </td>
           <td class="r">
            University of Fukui
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1406" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Walk2Map has emerged as a promising data-driven method to generate indoor traversability maps based solely on pedestrian trajectories, offering great potential for indoor robot navigation. In this study, we investigate a novel approach, referred to as Walk2Map++, which involves replacing Walk2Mapâ€™s first-person sensor (i.e., IMU) with a human observing third-person view from the robotâ€™s onboard camera. However, human observation from a third-person camera is significantly ill-posed due to visual uncertainties resulting from occlusion, nonlinear perspective, depth ambiguity, and human-to-human interaction. To regularize the ill-posedness, we propose to integrate two types of constraints: photometric (i.e., occlusion ordering) and physical (i.e., collision avoidance). We demonstrate that these constraints can be effectively inferred from the interaction between past and present observations, human trackers, and object reconstructions. We depict the seamless integration of asynchronous map optimization events, like loop closure, into the real-time traversability map, facilitating incremental and efficient map refinement. We validate the efficacy of our enhanced methodology through rigorous fusion and comparison with established techniques, demonstrating its capability to advance traversability prediction in complex indoor environments. The code and datasets associated with this study will be made publicly available upon acceptance, facilitating further research and adoption in the field.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t4_09">
             09:00-10:00, Paper FrPI6T4.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1497'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Click to Grasp: Zero-Shot Precise Manipulation Via Visual Diffusion Descriptors
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380698" title="Click to go to the Author Index">
             Tsagkas, Nikolaos
            </a>
           </td>
           <td class="r">
            University of Edinburgh
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395981" title="Click to go to the Author Index">
             Rome, Jack A
            </a>
           </td>
           <td class="r">
            University of Edinburgh
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114132" title="Click to go to the Author Index">
             Ramamoorthy, Subramanian
            </a>
           </td>
           <td class="r">
            The University of Edinburgh
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238864" title="Click to go to the Author Index">
             Mac Aodha, Oisin
            </a>
           </td>
           <td class="r">
            University of Edinburgh
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#236901" title="Click to go to the Author Index">
             Lu, Chris Xiaoxuan
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1497" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Precise manipulation that is generalizable across scenes and objects remains a persistent challenge in robotics. Current approaches for this task heavily depend on having a significant number of training instances to handle objects with pronounced visual and/or geometric part ambiguities. Our work explores the grounding of fine-grained part descriptors for precise manipulation in a zero-shot setting by utilizing web-trained text-to-image diffusion-based generative models. We tackle the problem by framing it as a dense semantic part correspondence task. Our model returns a gripper pose for manipulating a specific part, using as reference a user-defined click from a source image of a visually different instance of the same object. We require no manual grasping demonstrations as we leverage the intrinsic object geometry and features. Practical experiments in a real-world tabletop scenario validate the efficacy of our approach, demonstrating its potential for advancing semantic-aware robotics manipulation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t4_10">
             09:00-10:00, Paper FrPI6T4.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1588'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Refining Airway Segmentation through Breakage Filling and Leakage Reduction Using Point Clouds
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394289" title="Click to go to the Author Index">
             Hu, Yan
            </a>
           </td>
           <td class="r">
            University of New South Wales
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396792" title="Click to go to the Author Index">
             Meijering, Erik
            </a>
           </td>
           <td class="r">
            University of New South Wales
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339638" title="Click to go to the Author Index">
             Song, Yang
            </a>
           </td>
           <td class="r">
            University of New South Wales
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1588" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Bronchoscopy reveals air passages and internal tissues for accurate diagnosis of various lung diseases. Robot-assisted bronchoscopy using an airway tree model can help path planning before surgery and navigation during surgery. In airway tree modeling, though volumetric deep learning methods have achieved good performance for airway segmentation, it remains a challenge due to the breakages and leakages. Some existing methods adopt post-processing using traditional methods like morphological and fuzzy connected algorithms. Also, some methods convert the volumetric data to point cloud format to refine segmentation. In this paper, we develop a new point cloud-based approach to refine volumetric segmentation. To address the breakage issue, we approach it as a regression problem of the branch extension direction and length. To tackle the leakage issue, we approach it as a segmentation task to eliminate leakages caused by breakage filling and from volumetric segmentation. Moreover, the direction information of branches is crucial for constructing the airway tree while point clouds do not naturally encode it. To introduce this information, we propose a directional feature aggregation, which first decomposes features of neighboring points based on their locations and aggregates decomposed features to aid the network in capturing the directional information effectively. Our proposed model has been evaluated on two public datasets, and the results show that our refinement can improve the volumetric segmentation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t4_11">
             09:00-10:00, Paper FrPI6T4.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1877'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Differentiable Fluid Physics Parameter Identification by Stirring and for Stirring
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#295593" title="Click to go to the Author Index">
             Xu, Wenqiang
            </a>
           </td>
           <td class="r">
            Shanghai Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379841" title="Click to go to the Author Index">
             Zheng, Dongzhe
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#347294" title="Click to go to the Author Index">
             Li, Yutong
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#314388" title="Click to go to the Author Index">
             Ren, Jieji
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#224610" title="Click to go to the Author Index">
             Lu, Cewu
            </a>
           </td>
           <td class="r">
            ShangHai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1877" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#calibration_and_identification" title="Click to go to the Keyword Index">
               Calibration and Identification
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Fluid interactions are crucial in daily tasks, with properties like density and viscosity being key parameters. The property states can be used as control signals for robot operation. While density estimation is simple, assessing viscosity, especially for different fluid types, is complex. This study introduces a novel differentiable fitting framework, DiffStir, tailored to identify key physics parameters through stirring. Then, given the estimated physics parameters, we can generate commands to guide the robotic stirring. Comprehensive experiments were conducted to validate the efficacy of DiffStir, showcasing its precision in parameter estimation when benchmarked against reported values in the literature. More experiments and videos can be found in the supplementary materials and on the website: url{https://diffstir.robotflow.ai}.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t4_12">
             09:00-10:00, Paper FrPI6T4.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2042'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhancing 3D Single Object Tracking with Efficient Point Cloud Segmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351740" title="Click to go to the Author Index">
             Yang, Yu Shi
            </a>
           </td>
           <td class="r">
            Nanjing University of Posts and Telecommunications
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#163781" title="Click to go to the Author Index">
             Fan, Baojie
            </a>
           </td>
           <td class="r">
            Nanjing University of Posts and Telecommunications
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397421" title="Click to go to the Author Index">
             Jiang, Yuyu
            </a>
           </td>
           <td class="r">
            Nanjing University of Posts and Telecommunications
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351744" title="Click to go to the Author Index">
             Zhou, Wuyang
            </a>
           </td>
           <td class="r">
            Nanjing University of Posts and Telecommunications
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#408560" title="Click to go to the Author Index">
             Chen, Dong
            </a>
           </td>
           <td class="r">
            Nanjing University of Posts and Telecommunications
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397601" title="Click to go to the Author Index">
             Xu, Hongxin
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2042" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             3D single object tracking (SOT) based on point cloud has attracted much attention due to its important role in machine vision and autonomous driving. Recently, textbf{M^2} -Track propose a two-stage tracking structure centered on motion, but they ignore the effect of segmentation errors in sparse point cloud scenarios, which hinder the ability of networks to accurately represent tracking targets. To solve the problems, we propose an efficient 3D single object tracker (Abbr. EST) that can effectively segment point cloud features. Firstly, the proposed fusion segmentation module makes up for the feature loss caused by the downsampling strategy and enhances the ability of the network to recognize foreground points. In addition, the global embedded module is used to further focus on the crucial features of the target. This module provides global information by using residual networks and adding background information. Numerous experiments conducted on KITTI and NuScenes benchmarks show that EST achieves superior point cloud tracking in both performance and efficiency.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t4_13">
             09:00-10:00, Paper FrPI6T4.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2376'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SwinMTL: A Shared Architecture for Simultaneous Depth Estimation and Semantic Segmentation from Monocular Camera Images
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396930" title="Click to go to the Author Index">
             Taghavi, Pardis
            </a>
           </td>
           <td class="r">
            Texas A&amp;M
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#130270" title="Click to go to the Author Index">
             Pandey, Gaurav
            </a>
           </td>
           <td class="r">
            Texas A&amp;M
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100144" title="Click to go to the Author Index">
             Langari, Reza
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2376" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This research paper presents an innovative multi-task learning framework that allows concurrent depth estimation and semantic segmentation using a single camera. The proposed approach is based on a shared encoder-decoder architecture, which integrates various techniques to improve the accuracy of the depth estimation and semantic segmentation task without compromising computational efficiency. Additionally, the paper incorporates an adversarial training component, employing a Wasserstein GAN framework with a critic network, to refine model's predictions. The framework is thoroughly evaluated on two datasets - the outdoor Cityscapes dataset and the indoor NYU Depth V2 dataset - and it outperforms existing state-of-the-art methods in both segmentation and depth estimation tasks. We also conducted ablation studies to analyze the contributions of different components, including pre-training strategies, the inclusion of critics, the use of logarithmic depth scaling, and advanced image augmentations, to provide a better understanding of the proposed framework.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t4_14">
             09:00-10:00, Paper FrPI6T4.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2510'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Monocular 3D Reconstruction of Cheetahs in the Wild
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#311600" title="Click to go to the Author Index">
             da Silva, Zico
            </a>
           </td>
           <td class="r">
            University of Cape Town
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397744" title="Click to go to the Author Index">
             Parkar, Zuhayr
            </a>
           </td>
           <td class="r">
            University of Cape Town
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#231772" title="Click to go to the Author Index">
             Muramatsu, Naoya
            </a>
           </td>
           <td class="r">
            University of Cape Town
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#141920" title="Click to go to the Author Index">
             Nicolls, Fred
            </a>
           </td>
           <td class="r">
            University of Cape Town
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#164571" title="Click to go to the Author Index">
             Patel, Amir
            </a>
           </td>
           <td class="r">
            University of Cape Town
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2510" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robotics_and_automation_in_life_sciences" title="Click to go to the Keyword Index">
               Robotics and Automation in Life Sciences
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a framework for monocular 3D reconstruction of cheetah movements, leveraging a combination of data-driven and physics-based modeling as well as trajectory optimization. Unlike traditional methods that rely solely on kinematics, our approach integrates dynamic motion principles, enhancing the plausibility and generalization of motion estimates. Validated on the cheetah running dataset, AcinoSet, we achieve mean per-joint position errors of 78.8 mm and 72.5 mm, showcasing significant advancements over the existing model used in AcinoSet. By addressing the challenge of absent ground truth data, this work not only advances animal motion capture techniques but also informs the development of bio-inspired robotic systems, offering a robust solution for accurately capturing complex animal locomotion in natural settings.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t4_15">
             09:00-10:00, Paper FrPI6T4.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2668'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Scalable Network and Adaptive Refinement Module for 6D Pose Estimation of Diverse Industrial Components
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#288169" title="Click to go to the Author Index">
             Qian, Kun
            </a>
           </td>
           <td class="r">
            University of Manchester
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#130792" title="Click to go to the Author Index">
             Erden, Mustafa Suphi
            </a>
           </td>
           <td class="r">
            Heriot-Watt University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105405" title="Click to go to the Author Index">
             Kong, Xianwen
            </a>
           </td>
           <td class="r">
            Heriot-Watt Universiy
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2668" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The estimation of the 6D pose of industrial components is essential for smart manufacturing. Especially for complex units that require intensive manual operations, such as a concentrator photovoltaics solar panel, accurate spatial localization provides visual aids for industrial automation. In this paper, we propose an accurate and scalable framework to address the dimensional variability of industrial components and tackle practical implementation issues. First, we use the scalable architecture EfficientNet as the backbone coupled with an enhanced feature pyramid network to estimate the objectâ€™s pose. By introducing vertical and horizontal connections of shallow layers, the feature extraction of small objects is optimized for better detection accuracy. Second, leveraging the reliable 2D detection results and geometry information, an adaptive pose refinement module is designed to adjust the estimated 6D pose. The scaling of the backbone network and the computational complexity of refined modules are uniformly adjusted via a shared hyperparameter, resulting in a globally scalable framework. In terms of the pose estimation accuracy, the effectiveness of the refinement module and the real-time performance, validations are conducted both on the LINEMOD dataset and our customized datasets comprising of objects from the industrial photovoltaic system. Additionally, to further illustrate the effectiveness of the proposed method, a precision parallel robot is employed to validate the accuracy of real-time object pose tracking.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t4_16">
             09:00-10:00, Paper FrPI6T4.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2957'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              AirShot: Efficient Few-Shot Detection for Autonomous Exploration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394707" title="Click to go to the Author Index">
             Wang, Zihan
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#290727" title="Click to go to the Author Index">
             Li, Bowen
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#200000" title="Click to go to the Author Index">
             Wang, Chen
            </a>
           </td>
           <td class="r">
            University at Buffalo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104304" title="Click to go to the Author Index">
             Scherer, Sebastian
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2957" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Few-shot object detection has drawn increasing attention in the field of robotic exploration, where robots are required to find unseen objects with a few online provided examples. Despite recent efforts have been made to yield online processing capabilities, slow inference speeds of low-powered robots fail to meet the demands of real-time detection-making them impractical for autonomous exploration. Existing methods still face performance and efficiency challenges, mainly due to unreliable features and exhaustive class loops. In this work, we propose a new paradigm AirShot, and discover that, by fully exploiting the valuable correlation map, AirShot can result in a more robust and faster few-shot object detection system, which is more applicable to robotics community. The core module Top Prediction Filter (TPF) can operate on multi-scale correlation maps in both the training and inference stages. During train- ing, TPF supervises the generation of a more representative correlation map, while during inference, it reduces looping iterations by selecting top-ranked classes, thus cutting down on computational costs with better performance. Surprisingly, this dual functionality exhibits general effectiveness and efficiency on various off-the-shelf models. Exhaustive experiments on COCO2017, VOC2014, and SubT datasets demonstrate that TPF can significantly boost the efficacy and efficiency of most off-the-shelf models, achieving up to 36.4% precision improve- ments along with 56.3% faster inference speed. Code and Data are at: https://github.com/ImNotPrepared/AirShot.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t4_17">
             09:00-10:00, Paper FrPI6T4.17
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2207'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RATE: Real-Time Asynchronous Feature Tracking with Event Cameras
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#253484" title="Click to go to the Author Index">
             Ikura, Mikihiro
            </a>
           </td>
           <td class="r">
            University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#218805" title="Click to go to the Author Index">
             Le Gentil, Cedric
            </a>
           </td>
           <td class="r">
            University of Technology Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219814" title="Click to go to the Author Index">
             MÃ¼ller, Marcus Gerhard
            </a>
           </td>
           <td class="r">
            German Aerospace Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413052" title="Click to go to the Author Index">
             Schuler, Florian
            </a>
           </td>
           <td class="r">
            German Aerospace Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102952" title="Click to go to the Author Index">
             Yamashita, Atsushi
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#137304" title="Click to go to the Author Index">
             Stuerzl, Wolfgang
            </a>
           </td>
           <td class="r">
            DLR, Institute of Robotics and Mechatronics
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2207" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Vision-based self-localization is a crucial technology for enabling autonomous robot navigation in GPS-deprived environments. However, standard frame cameras are subject to motion blur and suffer from a limited dynamic range. This research focuses on efficient feature tracking for self-localization by using event-based cameras. Such cameras do not provide regular snapshots of the environment but asynchronously collect events that correspond to a small delta of illumination in each pixel independently, thus addressing the issue of motion blur during fast motion and high dynamic range. Specifically, we propose a continuous real-time asynchronous event-based feature tracking pipeline, named RATE. This pipeline integrates (i) a corner detector node utilizing a time slice of the Surface of Active Events to initialize trackers continuously, along with (ii) a tracker node with a proposed tracking manager, consisting of a grid-based distributor to reduce redundant trackers and to remove feature tracks of poor quality. Evaluations using public datasets reveal that our method maintains a stable number of tracked features, and performs real-time tracking efficiently while maintaining or even improving tracking accuracy compared to state-of-the-art event-only tracking methods. Our ROS implementation is released as open-source: https://github.com/mikihiroikura/RATE
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frpi6t5">
             <b>
              FrPI6T5
             </b>
            </a>
           </td>
           <td class="r">
            Room 5
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frpi6t5" title="Click to go to the Program at a Glance">
             <b>
              Field Robotics
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t5_01">
             09:00-10:00, Paper FrPI6T5.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2977'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              PhysORD: A Neuro-Symbolic Approach for Physics-Infused Motion Prediction in Off-Road Driving
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#346049" title="Click to go to the Author Index">
             Zhao, Zhipeng
            </a>
           </td>
           <td class="r">
            University at Buffalo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#290727" title="Click to go to the Author Index">
             Li, Bowen
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#358477" title="Click to go to the Author Index">
             Du, Yi
            </a>
           </td>
           <td class="r">
            University at Buffalo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#311960" title="Click to go to the Author Index">
             Fu, Taimeng
            </a>
           </td>
           <td class="r">
            University at Buffalo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#200000" title="Click to go to the Author Index">
             Wang, Chen
            </a>
           </td>
           <td class="r">
            University at Buffalo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2977" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Motion prediction is critical for autonomous off-road driving, however, it presents significantly more challenges than on-road driving because of the complex interaction between the vehicle and the terrain. Traditional physics-based approaches encounter difficulties in accurately modeling dynamic systems and external disturbance. In contrast, data-driven neural networks require extensive datasets and struggle with explicitly capturing the fundamental physical laws, which can easily lead to poor generalization. By merging the advantages of both methods, neuro-symbolic approaches present a promising direction. These methods embed physical laws into neural models, potentially significantly improving generalization capabilities. However, no prior works were evaluated in real-world settings for off-road driving. To bridge this gap, we present PhysORD, a neural-symbolic approach integrating the conservation law, i.e., the Euler-Lagrange equation, into data-driven neural models for motion prediction in off-road driving. Our experiments showed that PhysORD can accurately predict vehicle motion and tolerate external disturbance by modeling uncertainties. It outperforms existing methods both in accuracy and efficiency and demonstrates data-efficient learning and generalization ability in long-term prediction.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t5_02">
             09:00-10:00, Paper FrPI6T5.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('68'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Kinetic-Energy-Optimal and Safety-Guaranteed Trajectory Planning for Bridge Inspection Robot Manipulator
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363422" title="Click to go to the Author Index">
             Zhang, Tianyu
            </a>
           </td>
           <td class="r">
            University of Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#224012" title="Click to go to the Author Index">
             Chang, Yong
            </a>
           </td>
           <td class="r">
            Chinese Academy of Sciences, Shenyang Institute of Automation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104816" title="Click to go to the Author Index">
             Wang, Hongguang
            </a>
           </td>
           <td class="r">
            Shenyang Institute of Automation, Chinese AcademyofSciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#386681" title="Click to go to the Author Index">
             Wang, Tianlong
            </a>
           </td>
           <td class="r">
            Shenyang Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab68" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Bridge inspections are essential for maintaining key infrastructure and preventing structural and functional failures. Nevertheless, traditional manual inspection techniques are plagued by laboriousness, high risk, and low efficiency. Although numerous automation inspection methods have been studied, inspection performance remains challenging. The main difficulties are redundant mechanisms, complex control, high energy consumption, and limited autonomy and safety. To address these problems, we are developing a small, lightweight, electrically-driven robotic manipulator for bridge inspection named the BIRM. Here, we propose a kinetic-energy-optimal and safety-guaranteed trajectory planning for BIRM. Compared with existing methods, it simultaneously addresses energy consumption and safety. The approach formulates a quadratic programming (QP) problem by considering the robot's kinetic energy as the objective function, and the augmented Lagrange multiplier (ALM) is applied to find the solution of the QP. The proposed method completely satisfies the joint position, velocity, and acceleration limits at the speed level while considering collision avoidance. In this paper, the collision detection strategy can achieve low-complexity computation through several structural parameters of the bridge, thereby quickly adapting to environmental changes. Through simulation experiments, we validate the effectiveness and superiority of the proposed method. Through physical experiments, we demonstrate the sustainability and safety of bridge inspections in the field.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t5_03">
             09:00-10:00, Paper FrPI6T5.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('488'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Proprioception Is All You Need: Terrain Classification for Boreal Forests
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354029" title="Click to go to the Author Index">
             LaRocque, Damien
            </a>
           </td>
           <td class="r">
            UniversitÃ© Laval
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#349367" title="Click to go to the Author Index">
             Guimont-Martin, William
            </a>
           </td>
           <td class="r">
            UniversitÃ© Laval
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391617" title="Click to go to the Author Index">
             Duclos, David-Alexandre
            </a>
           </td>
           <td class="r">
            UniversitÃ© Laval
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#110648" title="Click to go to the Author Index">
             GiguÃ¨re, Philippe
            </a>
           </td>
           <td class="r">
            UniversitÃ© Laval
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123399" title="Click to go to the Author Index">
             Pomerleau, Francois
            </a>
           </td>
           <td class="r">
            UniversitÃ© Laval
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab488" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#energy_and_environment_aware_automation" title="Click to go to the Keyword Index">
               Energy and Environment-Aware Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent works in field robotics highlighted the importance of resiliency against different types of terrains. Boreal forests, in particular, are home to many mobility-impeding terrains that should be considered for off-road autonomous navigation. Also, being one of the largest land biomes on Earth, boreal forests are an area where autonomous vehicles are expected to become increasingly common. In this paper, we address the issue of classifying boreal terrains by introducing BorealTC, a publicly available dataset for proprioceptive-based terrain classification (TC). Recorded with a Husky A200, our dataset contains 116 min of Inertial Measurement Unit (IMU), motor current, and wheel odometry data, focusing on typical boreal forest terrains, notably snow, ice, and silty loam. Combining our dataset with another dataset from the literature, we evaluate both a Convolutional Neural Network (CNN) and the novel state space model (SSM)-based Mamba architecture on a TC task. We show that while CNN outperforms Mamba on each separate dataset, Mamba achieves greater accuracy when trained on a combination of both. In addition, we demonstrate that Mamba's learning capacity is greater than a CNN for increasing amounts of data. We show that the combination of two TC datasets yields a latent space that can be interpreted with the properties of the terrains. We also discuss the implications of merging datasets on classification. Our source code and dataset are publicly available online: https://github.com/norlab-ulaval/BorealTC.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t5_04">
             09:00-10:00, Paper FrPI6T5.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('668'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              On Predicting Terrain Changes Induced by Mobile Robot Traversal
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#227038" title="Click to go to the Author Index">
             Pragr, Milos
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague, FEE
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#218032" title="Click to go to the Author Index">
             Bayer, Jan
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#130305" title="Click to go to the Author Index">
             Faigl, Jan
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab668" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Mobile robots operating in convoys have a limited view of the terrain to be traversed if it is occluded by the preceding vehicle. Furthermore, the preceding vehicle might change the terrain geometry and eventually significantly alter its traversability by driving over the terrain. When the following vehicles do not consider such changes, they can use spurious terrain appearance and geometry to decide whether to follow in the tracks of the previous vehicle or to avoid them since the preceding vehicle's tracks can make the terrain untraversable. We propose to predict the terrain changes induced by the robot traversal on the traversed terrain and thus support the decision-making of the following vehicles. The developed model projects the robot wheel footprint along the planned robot path and combines the projection with the terrain appearance and prior terrain elevation. The coupled model is used in a convolutional neural network that predicts the elevation after traversal. The footprint projection component is designed so that learned networks can be transferred to vehicles with different wheel footprints without relearning the model. The proposed model is verified using a dataset captured using a real, one-ton, six-wheel robot traversing rigid roads and vegetated fields.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t5_05">
             09:00-10:00, Paper FrPI6T5.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1915'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Real-Time Terrain Assessment and Bayesian-Based Path Planning for Off-Road Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352440" title="Click to go to the Author Index">
             Niu, Tianwei
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395907" title="Click to go to the Author Index">
             Yu, Shuwei
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351634" title="Click to go to the Author Index">
             Wang, Liang
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380004" title="Click to go to the Author Index">
             Yuan, Haoyu
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#214783" title="Click to go to the Author Index">
             Wang, Shoukun
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#214782" title="Click to go to the Author Index">
             Wang, Junzheng
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1915" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reactive_and_sensor_based_planning" title="Click to go to the Keyword Index">
               Reactive and Sensor-Based Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the context of unstructured and unknown environment, the autonomous navigation still faces many challenges, such as assessing rough terrain and deciding how to safely navigate complex terrain. In this work, we propose a robust and practical off-road navigation framework that has been successfully deployed on a vibroseis truck for land exploration. First, in degraded wild scenes, a tightly coupled lidar-GNSS-inertial fusion odometry and mapping framework is adopted to construct a local point cloud map around the vehicle in real-time and provide precise localization. Then, based on amplitude-frequency characteristic analysis and point cloud PCA, a multi-layer terrain assessment map containing terrain roughness, obstacles and slope information is obtained. Finally, combining Gaussian distribution based adaptive sampler and Bayesian sequentially updated proposal distribution, a local graph is efficiently built to obtain multiple path solutions under constrained conditions. Both simulations and field experiments show that the proposed navigation framework can decide how to travel on a flat road even in harsh terrain conditions, naturally suppressing frequent attitude angle changes and preventing vehicle accidents.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t5_06">
             09:00-10:00, Paper FrPI6T5.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2181'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              PARE: A Plane-Assisted Autonomous Robot Exploration Framework in Unknown and Uneven Terrain
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378255" title="Click to go to the Author Index">
             Xu, Pu
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378250" title="Click to go to the Author Index">
             Bai, Zhaoqiang
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379064" title="Click to go to the Author Index">
             Liu, Haoming
            </a>
           </td>
           <td class="r">
            Northeastern University(CN)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#121608" title="Click to go to the Author Index">
             Fang, Zheng
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2181" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Identifying traversable areas is a critical task for unmanned vehicles exploring safely through unstructured environments. In practice, the ambiguity in perceiving terrain traversability usually brings great challenges for autonomous exploration in unknown and uneven terrain, which often leads to conservative strategies or potential risk of vehicle damage, resulting in many unexplored areas in the environment. To that end, this paper proposes a plane-assisted autonomous robot exploration framework (PARE) to achieve maximum volume and safe autonomous exploration. The process is carried out by a three-step dual-layer framework: constructing a local tree using Plane-Assisted RRT* (PA-RRT*), calculating exploration gain based on terrain information, and maintaining a global search graph. Firstly, the planar feature metrics (flatness, sparsity, elevation variation, slope and slope variation) are introduced to determine the terrain traversability. Secondly, to completely explore the rugged environment, we propose a dual-layer exploration framework comprising local and global strategies. A local planner based on PA-RRT* is proposed to find the best path by evaluating the planar information and the volumetric gain within the local exploration tree. Meanwhile, a global planner constructed by graph is proposed to record unexplored nodes with high exploration gain from the local tree to ensure a high level of exploration volume. Extensive simulation and real-world experiments demonstrate that our method significantly outperforms existing frameworks, with an average improvement of more than 12% in exploration volume.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t5_07">
             09:00-10:00, Paper FrPI6T5.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2750'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Low-Cost Urban Localization with Magnetometer and LoRa Technology
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#323631" title="Click to go to the Author Index">
             Benham, Derek
            </a>
           </td>
           <td class="r">
            Brigham Young University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395061" title="Click to go to the Author Index">
             Palacios, Ashton
            </a>
           </td>
           <td class="r">
            Brigham Young University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395062" title="Click to go to the Author Index">
             Lundrigan, Philip
            </a>
           </td>
           <td class="r">
            Brigham Young University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#180889" title="Click to go to the Author Index">
             Mangelson, Joshua
            </a>
           </td>
           <td class="r">
            Brigham Young University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2750" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#networked_robots" title="Click to go to the Keyword Index">
               Networked Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             With the goal of developing low-cost and innovative perception and localization techniques for autonomous vehicles, this work explores a system that solely relies on a LoRa receiver and a magnetometer for agent localization within urban environments. Using the received signal strength from LoRa beacons distributed across a test area of 16,000 square meters, a model of expected RSSI values per beacon is estimated using Gaussian Process (GP) regression. Motion is estimated using a probabilistic signal similarity classifier, and localization is obtained via a particle filter. Our experiments demonstrate that our proposed system is able to estimate our location to within three meters RMSE when the agent is within the convex hull of prior data. In real-world scenarios, characterized by signal interference and environmental complexities, our approach highlights the potential of leveraging affordable technology such as LoRa receivers and magnetometers for robust and accurate location estimation in complex urban environments. The integration of low-cost LoRa devices, Gaussian Process regression, particle filtering and our novel signal similarity motion estimator offers a promising avenue for achieving cost-effective localization solutions without compromising accuracy or reliability.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t5_08">
             09:00-10:00, Paper FrPI6T5.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1891'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Side-Scan Sonar Based Landmark Detection for Underwater Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376984" title="Click to go to the Author Index">
             Hoff, Simon Andreas
            </a>
           </td>
           <td class="r">
            Norwegian University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376964" title="Click to go to the Author Index">
             Haraldstad, Vegard
            </a>
           </td>
           <td class="r">
            Norwegian University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376977" title="Click to go to the Author Index">
             Reitan Hogstad, BjÃ¸rnar
            </a>
           </td>
           <td class="r">
            Norwegian University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#134220" title="Click to go to the Author Index">
             Varagnolo, Damiano
            </a>
           </td>
           <td class="r">
            Norwegian University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1891" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose and analyze a pipeline to transform raw sonar data from underwater vehicles into actionable information for Simultaneous Localization and Mapping (SLAM) in real time. The pipeline encompasses three sequential steps, each building upon state-of-the-art algorithms from the existing literature: swath processing to preprocess the raw sonar data, with a primary focus on eliminating blind zones and noise re- duction; transformation of these swaths into probabilistic maps of the surroundings of the sonar; and finally, detection and classification of underwater landmarks from the probabilistic maps. Our work contributes by modifying algorithms from the literature to ensure computational efficiency and integrating them so that they operate in sequence, thereby furnishing valuable information for navigation purposes. Through validation with field data, we then discuss which scenarios may prove difficult for the individual stages of the proposed pipeline. We provide indications on whether each step may encounter challenges and discuss how this occurrence may affect the overall quality of the final result. This empirical discussion is useful for discerning the practical applicability of the proposed pipeline in real-world settings.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t5_09">
             09:00-10:00, Paper FrPI6T5.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1706'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Development of a Throwbot with Shock Absorption Structure
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396885" title="Click to go to the Author Index">
             Keum, Jaeyeong
            </a>
           </td>
           <td class="r">
            DGIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396889" title="Click to go to the Author Index">
             Kim, Jaemin
            </a>
           </td>
           <td class="r">
            DGIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396888" title="Click to go to the Author Index">
             Lee, Changgi
            </a>
           </td>
           <td class="r">
            DGIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#241740" title="Click to go to the Author Index">
             Lim, Seunghyun
            </a>
           </td>
           <td class="r">
            DGIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#317645" title="Click to go to the Author Index">
             Ju, Insung
            </a>
           </td>
           <td class="r">
            DGIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#206601" title="Click to go to the Author Index">
             Yun, Dongwon
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology (DGIST)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1706" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#product_design__development_and_prototyping" title="Click to go to the Keyword Index">
               Product Design, Development and Prototyping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#search_and_rescue_robots" title="Click to go to the Keyword Index">
               Search and Rescue Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this study, a throwing robot equipped with an shock absorbing structure, utilizing paired-Cross Flexural Hinge (p-CFH) and an airbag, was fabricated and validated to assess the effectiveness of its impact absorption mechanism. This robot was developed in anticipation of situations where direct human intervention for life rescue would be challenging. Throwing robots can be broadly categorized into ball type, wheel type, and hybrid type. The hybrid type combines the advantages of both: the ease of throwing from ball type, due to its low air resistance coefficient, and the versatile mobility of the wheel type in diverse environments. However, hybrid type throwing robots are more vulnerable to external impacts due to the complexity of their internal structure, resulting in a lower maximum drop height compared to wheel type robots. To address these challenges, this research proposes a the Throwbot that combines the easy throwing capability of ball type with the obstacle overcoming ability of the wheel type, while also addressing the low free fall height drawback inherent in hybrid types. To achieve this, we developed a Throwbot with a ball to wheel transform structure, p-CFH mechanism, and airbag based impact absorption system. Additionally, materials were selected based on simulation results to refine the Throw- bot. The performance of the proposed robot was evaluated through various assessments, including free fall experiments and obstacle overcoming tests. Through this research, the proposed Throwbot effectively addresses the shortcomings of existing throwing robots, establishing a novel approach to throwing robot design.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t5_10">
             09:00-10:00, Paper FrPI6T5.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('132'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Archie Jnr: A Robotic Platform for Autonomous Cane Pruning of Grapevines
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#170065" title="Click to go to the Author Index">
             Williams, Henry
            </a>
           </td>
           <td class="r">
            University of Auckland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353154" title="Click to go to the Author Index">
             Smith, David Anthony James
            </a>
           </td>
           <td class="r">
            University of Auckland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353167" title="Click to go to the Author Index">
             Shahabi, Jalil
            </a>
           </td>
           <td class="r">
            University of Auckland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339296" title="Click to go to the Author Index">
             Gee, Trevor
            </a>
           </td>
           <td class="r">
            The University of Auckland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#294011" title="Click to go to the Author Index">
             Qureshi, Ans
            </a>
           </td>
           <td class="r">
            University of Auckland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353143" title="Click to go to the Author Index">
             McGuinness, Benjamin John
            </a>
           </td>
           <td class="r">
            University of Waikato
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353150" title="Click to go to the Author Index">
             Harvey, Scott
            </a>
           </td>
           <td class="r">
            University of Waikato
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353180" title="Click to go to the Author Index">
             Downes, Catherine
            </a>
           </td>
           <td class="r">
            University of Waikato
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353148" title="Click to go to the Author Index">
             Jangali, Rahul
            </a>
           </td>
           <td class="r">
            The University of Waikato
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353141" title="Click to go to the Author Index">
             Black, Kale
            </a>
           </td>
           <td class="r">
            Black Box Technologies LTD
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#119307" title="Click to go to the Author Index">
             Lim, Shen Hin
            </a>
           </td>
           <td class="r">
            University of Waikato
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#269339" title="Click to go to the Author Index">
             Duke, Mike
            </a>
           </td>
           <td class="r">
            Waikato University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107803" title="Click to go to the Author Index">
             MacDonald, Bruce
            </a>
           </td>
           <td class="r">
            University of Auckland
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab132" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#agricultural_automation" title="Click to go to the Keyword Index">
               Agricultural Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robotics_and_automation_in_agriculture_and_forestry" title="Click to go to the Keyword Index">
               Robotics and Automation in Agriculture and Forestry
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Cane pruning grapevines is a complex manual task requiring expert vine assessment to determine which canes to prune. This paper presents Archie Jnr, which was developed to autonomously assess the structure of the vine and prune the lower-quality canes as an expert pruner would. The platform has been extensively evaluated in a real-world commercial vineyard using a three-cane pruning method. The results show the effectiveness of the vision system for generating accurate assessments of a vineâ€™s canes. The platform is also shown to be capable of successfully pruning 71.1% of the 311 total canes that required pruning across 25 vines.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t5_11">
             09:00-10:00, Paper FrPI6T5.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3210'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CAIS: Culvert Autonomous Inspection Robotic System
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256016" title="Click to go to the Author Index">
             Le, Chuong
            </a>
           </td>
           <td class="r">
            University of Nevada, Reno
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396022" title="Click to go to the Author Index">
             Walunj, Pratik
            </a>
           </td>
           <td class="r">
            University of Nevada Reno
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379325" title="Click to go to the Author Index">
             Nguyen, An
            </a>
           </td>
           <td class="r">
            University of Nevada, Reno
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398955" title="Click to go to the Author Index">
             Zhou, Yong
            </a>
           </td>
           <td class="r">
            University of Nevada, Reno
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#294797" title="Click to go to the Author Index">
             Nguyen, Thanh Binh
            </a>
           </td>
           <td class="r">
            TAMUCC
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#254430" title="Click to go to the Author Index">
             Nguyen, Thang
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University-Corpus Christi
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363381" title="Click to go to the Author Index">
             Netchaev, Anton
            </a>
           </td>
           <td class="r">
            USACE ERDC
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#119108" title="Click to go to the Author Index">
             La, Hung
            </a>
           </td>
           <td class="r">
            University of Nevada at Reno
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3210" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#service_robotics" title="Click to go to the Keyword Index">
               Service Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#software_hardware_integration_for_robot_systems" title="Click to go to the Keyword Index">
               Software-Hardware Integration for Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Culverts, essential components of drainage systems, require regular inspection to ensure optimal functionality. However, culvert inspections pose numerous challenges, including accessibility, manpower, defect localization, and reliance on superficial assessments. To address these challenges, we propose a novel Culvert Autonomous Inspection Robotic System (CAIS) equipped with advanced sensing and evaluation capabilities. Our solution integrates an RGBD camera, deep learning, lighting systems, and non-destructive evaluation (NDE) techniques to enable accurate and comprehensive condition assessments. We present a pioneering Partially Observable Markov Decision Process (POMDP) framework to resolve uncertainty in autonomous inspections, especially in confined and unstructured environments like culverts or tunnels. The framework outputs detailed 3D maps highlighting visual defects and NDE condition assessments, demonstrating consistent and reliable performance in both indoor and outdoor scenarios. Additionally, we provide an open-source implementation of our framework on GitHub, contributing to the advancement of autonomous inspection technology and fostering collaboration within the research community.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t5_12">
             09:00-10:00, Paper FrPI6T5.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('705'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Intelligent Fish Detection System with Similarity-Aware Transformer
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393578" title="Click to go to the Author Index">
             Li, Shengchen
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324459" title="Click to go to the Author Index">
             Zuo, Haobo
            </a>
           </td>
           <td class="r">
            University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160488" title="Click to go to the Author Index">
             Fu, Changhong
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393590" title="Click to go to the Author Index">
             Wang, Zhiyong
            </a>
           </td>
           <td class="r">
            Fishery Machinery and Instrument Research Institute, Chinese Aca
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393583" title="Click to go to the Author Index">
             Xu, Zhiqiang
            </a>
           </td>
           <td class="r">
            Fishery Machinery and Instrument Research Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab705" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#agricultural_automation" title="Click to go to the Keyword Index">
               Agricultural Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robotics_and_automation_in_agriculture_and_forestry" title="Click to go to the Keyword Index">
               Robotics and Automation in Agriculture and Forestry
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Fish detection in water-land transfer has significantly contributed to the fishery. However, manual fish detection in crowd-collaboration performs inefficiently and expensively, involving insufficient accuracy. To further enhance the water-land transfer efficiency, improve detection accuracy, and reduce labor costs, this work designs a new type of lightweight and plug-and-play edge intelligent vision system to automatically conduct fast fish detection with high-speed camera. Moreover, a novel similarity-aware vision Transformer for fast fish detection (FishViT) is proposed to onboard identify every single fish in a dense and similar group. Specifically, a novel similarity-aware multi-level encoder is developed to enhance multi-scale features in parallel, thereby yielding discriminative representations for varying-size fish. Additionally, a new soft-threshold attention mechanism is introduced, which not only effectively eliminates background noise from images but also accurately recognizes both the edge details and overall features of different similar fish. 85 challenging video sequences with high framerate and high-resolution are collected to establish a benchmark from real fish water-land transfer scenarios. Exhaustive evaluation conducted with this challenging benchmark has proved the robustness and effectiveness of FishViT with over 80 FPS. Real work scenario tests validate the practicality of the proposed method. The code and demo video are available at https://github.com/vision4robotics/FishViT.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t5_13">
             09:00-10:00, Paper FrPI6T5.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1633'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Calibration-Free Vision-Assisted Container Loading of RTG Cranes
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396945" title="Click to go to the Author Index">
             Yang, Jianbing
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#240150" title="Click to go to the Author Index">
             Wang, Yuanzhe
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396948" title="Click to go to the Author Index">
             Jiang, Hao
            </a>
           </td>
           <td class="r">
            Shanghai Zhenhua Heavy Industries Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396952" title="Click to go to the Author Index">
             Zhao, Bin
            </a>
           </td>
           <td class="r">
            Shanghai Zhenhua Heavy Industries Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396114" title="Click to go to the Author Index">
             Li, Yiming
            </a>
           </td>
           <td class="r">
            Shanghai Zhenhua Heavy Industries Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100565" title="Click to go to the Author Index">
             Wang, Danwei
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1633" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#engineering_for_robotic_systems" title="Click to go to the Keyword Index">
               Engineering for Robotic Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#automation_technologies_for_smart_cities" title="Click to go to the Keyword Index">
               Automation Technologies for Smart Cities
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Vision-assisted container loading of Rubber Tyred Gantry (RTG) cranes are facing two primary challenges. Firstly, the uncertainty inherent in Covolutional Neural Network (CNN) based detection hinders its direct application in the safety-critical operation of such heavy-duty machinery. Secondly, sensor calibration introduces additional complexities and errors into the system. However, existing studies have not adequately addressed these challenges. Motivated by this gap, this paper proposes an integrated approach for target detection and alignment control in container loading of RTG cranes. To ensure reliable target marker identification, a heuristic postprocessing algorithm is developed as a complement to CNN-based foreground segmentation, thereby ensuring safety during the container handling process. On this basis, a pixel-based control scheme is designed to align the container with the target markers, which eliminates the need for offline or online sensor calibrations. The proposed approach has been successfully implemented on a real RTG crane manufactured by Shanghai Zhenhua Heavy Industries Co., Ltd. (ZPMC) and validated at the Port of Ningbo, China. Experimental results demonstrate the superiority of the proposed approach over current manual operations in port industries, highlighting its potential for crane automation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t5_14">
             09:00-10:00, Paper FrPI6T5.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1212'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Online Tree Reconstruction and Forest Inventory on a Mobile Robotic System
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395791" title="Click to go to the Author Index">
             FreiÃŸmuth, Leonard
            </a>
           </td>
           <td class="r">
            Technical University Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#221792" title="Click to go to the Author Index">
             Mattamala, Matias
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191328" title="Click to go to the Author Index">
             Chebrolu, Nived
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#288304" title="Click to go to the Author Index">
             Schaefer, Simon
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#151104" title="Click to go to the Author Index">
             Leutenegger, Stefan
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#124863" title="Click to go to the Author Index">
             Fallon, Maurice
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1212" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robotics_and_automation_in_agriculture_and_forestry" title="Click to go to the Keyword Index">
               Robotics and Automation in Agriculture and Forestry
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Terrestrial laser scanning (TLS) is the standard technique used to create accurate point clouds for digital forest inventories. However, the measurement process is de- manding, requiring up to two days per hectare for data collection, significant data storage, as well as resource-heavy post-processing of 3D data. In this work, we present a real-time mapping and analysis system that enables online generation of forest inventories using mobile laser scanners that can be mounted e.g. on mobile robots. Given incrementally created and locally accurate submapsâ€”data payloadsâ€”our approach extracts tree candidates using a custom, Voronoi-inspired clus- tering algorithm. Tree candidates are reconstructed using an algorithm based on the Hough transform, which enables robust modeling of the tree stem. Further, we explicitly incorporate the incremental nature of the data collection by consistently updating the database using a pose graph LiDAR SLAM system. This enables us to refine our estimates of the tree traits if an area is revisited later during a mission. We demonstrate competitive accuracy to TLS or manual measurements using laser scanners that we mounted on backpacks or mobile robots operating in conifer, broad-leaf and mixed forests. Our results achieve RMSE of 1.93 cm, a bias of 0.65 cm and a standard deviation of 1.81 cm (averaged across these sequences)â€”with no post-processing required after the mission is complete.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t5_15">
             09:00-10:00, Paper FrPI6T5.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2707'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Roofus: Learning-Based Robotic Moisture Mapping on Flat Rooftops with Ground Penetrating Radar
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392813" title="Click to go to the Author Index">
             Lee, Kevin
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396820" title="Click to go to the Author Index">
             Lin, Wei-Heng
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396825" title="Click to go to the Author Index">
             Javed, Talha
            </a>
           </td>
           <td class="r">
            Building Diagnostic Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396823" title="Click to go to the Author Index">
             Madhusudhan, Sruti
            </a>
           </td>
           <td class="r">
            Building Diagnostic Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396826" title="Click to go to the Author Index">
             Sher, Bilal
            </a>
           </td>
           <td class="r">
            Building Diagnostic Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160443" title="Click to go to the Author Index">
             Feng, Chen
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2707" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robotics_and_automation_in_construction" title="Click to go to the Keyword Index">
               Robotics and Automation in Construction
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robust moisture detection is crucial for building maintenance and cost reduction. Current methods are often limited by the type of roofing material or are cumbersome and expensive. Ground Penetrating Radar (GPR) has shown promise in recent works in moisture detection due to its effectiveness across a broader range of materials, its compactness and lightweight nature, and its ability to image the subsurface. We introduce Roofus, an integrated robotic moisture detection system for flat rooftops, designed to overcome traditional method limitations. It combines a remotely controlled robot with deep learning GPR data processing and automatic map generation. Real-world data is collected and manually annotated for supervised learning. We investigate a novel approach to interpreting GPR data via deep learning using Transformer-based classifiers. LiDAR inertial odometry is employed to integrate multiple individual GPR scans into a holistic moisture map over the rooftop. When evaluated against existing methods such as infrared thermal imaging, electrical capacitance surveys, and nuclear moisture gauges, our system shows promising viability for industry application.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t5_16">
             09:00-10:00, Paper FrPI6T5.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('170'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Archie Snr: A Robotic Platform for Autonomous Apple Fruitlet Thinning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#170065" title="Click to go to the Author Index">
             Williams, Henry
            </a>
           </td>
           <td class="r">
            University of Auckland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#294011" title="Click to go to the Author Index">
             Qureshi, Ans
            </a>
           </td>
           <td class="r">
            University of Auckland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353154" title="Click to go to the Author Index">
             Smith, David Anthony James
            </a>
           </td>
           <td class="r">
            University of Auckland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339296" title="Click to go to the Author Index">
             Gee, Trevor
            </a>
           </td>
           <td class="r">
            The University of Auckland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353143" title="Click to go to the Author Index">
             McGuinness, Benjamin John
            </a>
           </td>
           <td class="r">
            University of Waikato
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353148" title="Click to go to the Author Index">
             Jangali, Rahul
            </a>
           </td>
           <td class="r">
            The University of Waikato
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353141" title="Click to go to the Author Index">
             Black, Kale
            </a>
           </td>
           <td class="r">
            Black Box Technologies LTD
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353150" title="Click to go to the Author Index">
             Harvey, Scott
            </a>
           </td>
           <td class="r">
            University of Waikato
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353180" title="Click to go to the Author Index">
             Downes, Catherine
            </a>
           </td>
           <td class="r">
            University of Waikato
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#119307" title="Click to go to the Author Index">
             Lim, Shen Hin
            </a>
           </td>
           <td class="r">
            University of Waikato
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390144" title="Click to go to the Author Index">
             Oliver, Richard
            </a>
           </td>
           <td class="r">
            Plant and Food Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#269339" title="Click to go to the Author Index">
             Duke, Mike
            </a>
           </td>
           <td class="r">
            Waikato University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107803" title="Click to go to the Author Index">
             MacDonald, Bruce
            </a>
           </td>
           <td class="r">
            University of Auckland
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab170" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robotics_and_automation_in_agriculture_and_forestry" title="Click to go to the Keyword Index">
               Robotics and Automation in Agriculture and Forestry
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Apple fruitlet thinning is critical in cultivating high-quality apples, requiring an expert workforce to manage the orchard. The thinning process requires precise mapping of fruitlet clusters across the tree branches to manage the desired load for each tree. This paper presents Archie Snr, which was developed to autonomously assess the current load of the tree and thin the excess apples as an expert thinner would. The platform has been extensively evaluated in a real-world commercial orchard. The results show the platform can generate an average load count accuracy of 82.1% with a recall of 93.3%. The system was then able to successfully thin 66.14% of the fruitlets from the canopy.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frpi6t6">
             <b>
              FrPI6T6
             </b>
            </a>
           </td>
           <td class="r">
            Room 6
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frpi6t6" title="Click to go to the Program at a Glance">
             <b>
              Learning V
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#352058" title="Click to go to the Author Index">
             Wang, Yang
            </a>
           </td>
           <td class="r">
            Shanghaitech University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t6_01">
             09:00-10:00, Paper FrPI6T6.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2987'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Neural Kinodynamic Planning: Learning for Kinodynamic Tree Expansion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237502" title="Click to go to the Author Index">
             Lai, Tin
            </a>
           </td>
           <td class="r">
            University of Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238613" title="Click to go to the Author Index">
             Zhi, Weiming
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142053" title="Click to go to the Author Index">
             Hermans, Tucker
            </a>
           </td>
           <td class="r">
            University of Utah
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101688" title="Click to go to the Author Index">
             Ramos, Fabio
            </a>
           </td>
           <td class="r">
            University of Sydney, NVIDIA
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2987" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#learning_from_experience" title="Click to go to the Keyword Index">
               Learning from Experience
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We integrate neural networks into kinodynamic motion planning and present the Learning for KinoDynamic Tree Expansion (L4KDE) method. Tree-based planning approaches, such as rapidly exploring random tree (RRT), are the dominant approach to finding globally optimal plans in continuous state-space motion planning. Central to these approaches is tree expansion, the procedure in which new nodes are added to an ever-expanding tree. We study the kinodynamic variants of tree-based planning, where we have known system dynamics and kinematic constraints. In the interest of quickly selecting nodes to connect newly sampled coordinates, existing methods typically cannot optimise the finding of nodes that have a low cost to transition to sampled coordinates. Instead, they use metrics like Euclidean distance between coordinates as a heuristic for selecting candidate nodes to connect to the search tree. We propose L4KDE to address this issue. L4KDE uses a neural network to predict transition costs between queried states, which can be efficiently computed in batch, providing much higher quality estimates of transition cost compared to commonly used heuristics while maintaining almost-surely asymptotic optimality guarantee. We empirically demonstrate the significant performance improvement provided by L4KDE on a variety of challenging system dynamics, with the ability to generalise across different instances of the same model class and in conjunction with a suite of modern tree-based motion planners.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t6_02">
             09:00-10:00, Paper FrPI6T6.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('444'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Unsupervised Multiple Proactive Behavior Learning of Mobile Robots for Smooth and Safe Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#309043" title="Click to go to the Author Index">
             Srisuchinnawong, Arthicha
            </a>
           </td>
           <td class="r">
            University of Southern Denmark and Vidyasirimedhi Institute of S
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#346567" title="Click to go to the Author Index">
             Baech, Jonas
            </a>
           </td>
           <td class="r">
            Danish Technological Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372528" title="Click to go to the Author Index">
             Hyzy, Marek Piotr
            </a>
           </td>
           <td class="r">
            Technical University of Denmark, Lungby
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#210467" title="Click to go to the Author Index">
             Kounalakis, Tsampikos
            </a>
           </td>
           <td class="r">
            Danish Technological Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#180541" title="Click to go to the Author Index">
             Boukas, Evangelos
            </a>
           </td>
           <td class="r">
            Technical University of Denmark
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#120785" title="Click to go to the Author Index">
             Manoonpong, Poramate
            </a>
           </td>
           <td class="r">
            Vidyasirimedhi Institute of Science and Technology (VISTEC)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab444" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensorimotor_learning" title="Click to go to the Keyword Index">
               Sensorimotor Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#bioinspired_robot_learning" title="Click to go to the Keyword Index">
               Bioinspired Robot Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             While different control approaches have been developed for smooth and safe navigation in service applications, they are limited by the needs for model-based assumptions, true training target/reward function, and/or large sample data. To overcome these limitations, this study proposes a model-free neural control architecture with a generic plug-and-play online Multiple Proactive Behavior Learning (MPL) module. The MPL adapts robot neural control policy in an online unsupervised manner with small sample data by correlating its sensory inputs to a local planner command. As a result, it allows a mobile robot to autonomously and quickly learn and balance various proactive behaviors related to smooth motion and collision avoidance. It also compensates for the limited planning update rates and the planning model mismatch of an arbitrary local motion planner. Compared with existing control approaches without the MPL, our control architecture with the MPL leads to (1) a 10% improvement in the smoothness of robot motion and 30% fewer collisions in a narrow static environment, and (2) trading motion smoothness for up to 70% fewer collisions in an unknown dynamic environment. Taken together, this study also demonstrates how to apply model-free neural control with unsupervised learning to existing model-based control (e.g., local motion planner) for efficient proactive behavior learning and control of mobile robots.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t6_03">
             09:00-10:00, Paper FrPI6T6.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1035'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              NFPDE: Normalizing Flow-Based Parameter Distribution Estimation for Offline Adaptive Domain Randomization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191764" title="Click to go to the Author Index">
             Takano, Rin
            </a>
           </td>
           <td class="r">
            NEC Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376427" title="Click to go to the Author Index">
             Takaya, Kei
            </a>
           </td>
           <td class="r">
            NEC Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#257120" title="Click to go to the Author Index">
             Oyama, Hiroyuki
            </a>
           </td>
           <td class="r">
            NEC Corporation
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1035" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Reinforcement learning with domain randomization (DR) has been proposed as a promising approach for learning robust policies to environmental changes. However, for DR to work well in real-world environments, it is necessary to design appropriate DR distributions for model parameters. This paper proposes Normalizing Flow-based Parameter Distribution Estimation (NFPDE), a new estimation method for DR distributions. NFPDE models the target distribution by a flow-based generative model using normalizing flow and estimates the target distribution based on an offline dataset collected a priori in the target environment. Through numerical experiments on the OpenAI gym environment, we show that NFPDE can estimate the target distribution more accurately and efficiently than the previous estimation methods. We also show that the estimated DR distributions can improve the robustness of trained policies.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t6_04">
             09:00-10:00, Paper FrPI6T6.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1489'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              The Power of Input: Benchmarking Zero-Shot Sim-To-Real Transfer of Reinforcement Learning Control Policies for Quadrotor Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#275357" title="Click to go to the Author Index">
             Dionigi, Alberto
            </a>
           </td>
           <td class="r">
            University of Perugia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#150020" title="Click to go to the Author Index">
             Costante, Gabriele
            </a>
           </td>
           <td class="r">
            University of Perugia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142369" title="Click to go to the Author Index">
             Loianno, Giuseppe
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1489" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the last decade, data-driven approaches have become popular choices for quadrotor control, thanks to their ability to facilitate the adaptation to unknown or uncertain flight conditions. Among the different data-driven paradigms, Deep Reinforcement Learning (DRL) is currently one of the most explored. However, the design of DRL agents for Micro Aerial Vehicles (MAVs) remains an open challenge. While some works have studied the output configuration of these agents (i.e., what kind of control to compute), there is no general consensus on the type of input data these approaches should employ. Multiple works simply provide the DRL agent with full state information, without questioning if this might be redundant and unnecessarily complicate the learning process, or pose superfluous constraints on the availability of such information in real platforms. In this work, we provide an in-depth benchmark analysis of different configurations of the observation space. We optimize multiple DRL agents in simulated environments with different input choices and study their robustness and their sim-to-real transfer capabilities with zero-shot adaptation. We believe that the outcomes and discussions presented in this work supported by extensive experimental results could be an important milestone in guiding future research on the development of DRL agents for aerial robot tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t6_05">
             09:00-10:00, Paper FrPI6T6.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1996'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Tube-GAN: A Novel Virtual Tube Generation Method for Unmanned Aerial Swarms Based on Generative Adversarial Network
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353767" title="Click to go to the Author Index">
             Zhai, Shixun
            </a>
           </td>
           <td class="r">
            North Automatic Control Technology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397478" title="Click to go to the Author Index">
             Zhang, Kaige
            </a>
           </td>
           <td class="r">
            Utah State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397415" title="Click to go to the Author Index">
             Nan, Bo
            </a>
           </td>
           <td class="r">
            North Automatic Control Technology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397679" title="Click to go to the Author Index">
             Sun, Yanwen
            </a>
           </td>
           <td class="r">
            North Automatic Control Technology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#358616" title="Click to go to the Author Index">
             Fu, Qianyi
            </a>
           </td>
           <td class="r">
            Leeds/Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1996" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Virtual tube is a two-dimensional or three-dimensional strip or tubular area similar to RSFC (Relative Safe Flight Corridor), which can provide smooth, feasible, and safe space for UAV swarm in environments with dense obstacles. In order to address the problem that current virtual tube planning methods are mainly based on complex heuristic algorithm with consuming time complexity, we modify the model architecture by introducing generative adversarial network (GAN), and propose a Tube-GAN model. Tube-GAN takes the key point prompt image and obstacle environment image as inputs, and outputs the image of the virtual tube, which transforms the optimization problem into an image generation problem, leveraging the performance of computational efficiency for the construction of virtual tube. The experimental results demonstrate that the proposed Tube-GAN model can quickly generate virtual tube in random environments (less than 25ms), providing a new direction for the construction of virtual tube in real-time.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t6_06">
             09:00-10:00, Paper FrPI6T6.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2174'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Repairing Neural Networks for Safety in Robotic Systems Using Predictive Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#239233" title="Click to go to the Author Index">
             Majd, Keyvan
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#239454" title="Click to go to the Author Index">
             Clark, Geoffrey
            </a>
           </td>
           <td class="r">
            ASU
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103644" title="Click to go to the Author Index">
             Fainekos, Georgios
            </a>
           </td>
           <td class="r">
            Toyota NA-R&amp;D
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#130054" title="Click to go to the Author Index">
             Ben Amor, Heni
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2174" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#neural_and_fuzzy_control" title="Click to go to the Keyword Index">
               Neural and Fuzzy Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a new method for safety-aware robot learning, focusing on repairing policies using predictive models. Our method combines behavioral cloning with neural network repair in a two-step supervised learning framework. It first learns a policy from expert demonstrations and then applies repair subject to predictive models to enforce safety constraints. The predictive models can encompass various aspects relevant to robot learning applications, such as proprioceptive states and collision likelihood. Our experimental results demonstrate that the learned policy successfully adheres to a predefined set of safety constraints on two applications: mobile robot navigation, and real-world lower-leg prostheses. Additionally, we have shown that our method effectively reduces repeated interaction with the robot, leading to substantial time savings during the learning process.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t6_07">
             09:00-10:00, Paper FrPI6T6.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2579'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Performing Efficient and Safe Deformable Package Transport Operations Using Suction Cups
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#304593" title="Click to go to the Author Index">
             Shukla, Rishabh
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324230" title="Click to go to the Author Index">
             Yu, Zeren
            </a>
           </td>
           <td class="r">
            Covariant.ai
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398309" title="Click to go to the Author Index">
             Moode, Samrudh
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291782" title="Click to go to the Author Index">
             Manyar, Omey Mohan
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#212074" title="Click to go to the Author Index">
             Wang, Fan
            </a>
           </td>
           <td class="r">
            Amazon Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205606" title="Click to go to the Author Index">
             Mayya, Siddharth
            </a>
           </td>
           <td class="r">
            Amazon Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107914" title="Click to go to the Author Index">
             Gupta, Satyandra K.
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2579" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Suction cups are popular for picking and transporting packages in warehouse applications. To maximize throughput, high transport speeds are desired. Many packages are deformable and may detach from the suction cups due to inertial loading if trajectories use excessive velocities. This paper introduces a novel methodology that analyzes package deformation through its curvature at the package-suction cup contact interface to generate a Factor-of-Safety (FOS) score for each waypoint in a given trajectory. By maintaining the FOS above a predetermined threshold, the trajectory planner is able to generate transport trajectories that are both safe and time-optimized. Experimental results show the method's efficacy, demonstrating a 21.92% reduction in transport times compared to a conservative trajectory generation. Our FOS predictor identified trajectories that ensured safe package transport with 100% accuracy across all 627 real-world experiments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t6_08">
             09:00-10:00, Paper FrPI6T6.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('890'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Dynamic Modeling of Robotic Fish Considering Background Flow Using Koopman Operators
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352055" title="Click to go to the Author Index">
             Lin, Xiaozhu
            </a>
           </td>
           <td class="r">
            ShanghaiTech University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285160" title="Click to go to the Author Index">
             Liu, Song
            </a>
           </td>
           <td class="r">
            ShanghaiTech University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#187991" title="Click to go to the Author Index">
             Liu, Chengyuan
            </a>
           </td>
           <td class="r">
            Loughborough Univeristy
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352058" title="Click to go to the Author Index">
             Wang, Yang
            </a>
           </td>
           <td class="r">
            Shanghaitech University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab890" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic Fish is increasingly employed in various aquatic application, where modelling and controlling their dynamic behaviour are crucial. Despite considerable efforts in robotic fish dynamic modeling, controllers based on existing models cannot perform satisfactorily in non-stationary flow environments. The main reason is that the nonlinear and two-way coupled nature of the interaction between background flow and robotic fish dynamics underscores a significant challenge in integrating the influence of background flow on robotic fish behavior, a topic that remains relatively under-explored in existing literature. To this end, we propose a novel approach for dynamic modeling of robotic fish considering background flow using Koopman operators, namely Flow-Aware Robot-Fish Modeling (FARM). Specifically, we first collect motion data of the robotic fish in different background flow fields, and then obtain a linear approximation (dynamic model) of nonlinear dynamics through carefully selected lifted functions. The obtained model can provide the next state at the given current state, control input, and average flow velocity of the background flow field. We evaluate the accuracy of the obtained model by evaluating the RMSE of predicted motion trajectories and real trajectories in different flow field environments. The results indicate that the FARM is highly promising in obtain reliable dynamic model, and obtained model can achieve comparable prediction accuracy even in unseen flow field environments with rough flow map for activity region. This lays a solid foundation for the motion control of robotic fish in different background flow fields.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t6_09">
             09:00-10:00, Paper FrPI6T6.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1000'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Data-Driven Force Observer for Human-Robot Interaction with Series Elastic Actuators Using Gaussian Processes
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#312668" title="Click to go to the Author Index">
             Tesfazgi, Samuel
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395043" title="Click to go to the Author Index">
             KeÃŸler, Markus
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196002" title="Click to go to the Author Index">
             Trigili, Emilio
            </a>
           </td>
           <td class="r">
            Scuola Superiore Sant'Anna
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#312181" title="Click to go to the Author Index">
             Lederer, Armin
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107646" title="Click to go to the Author Index">
             Hirche, Sandra
            </a>
           </td>
           <td class="r">
            Technische UniversitÃ¤t MÃ¼nchen
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1000" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#wearable_robotics" title="Click to go to the Keyword Index">
               Wearable Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Ensuring safety and adapting to the user's behavior are of paramount importance in physical human-robot interaction. Thus, incorporating elastic actuators in the robot's mechanical design has become popular, since it offers intrinsic compliance and additionally provide a coarse estimate for the interaction force by measuring the deformation of the elastic components. While observer-based methods have been shown to improve these estimates, they rely on accurate models of the system, which are challenging to obtain in complex operating environments. In this work, we overcome this issue by learning the unknown dynamics components using Gaussian process (GP) regression. By employing the learned model in a Bayesian filtering framework, we improve the estimation accuracy and additionally obtain an observer that explicitly considers local model uncertainty in the confidence measure of the state estimate. Furthermore, we derive guaranteed estimation error bounds, thus, facilitating the use in safety-critical applications. We demonstrate the effectiveness of the proposed approach experimentally in a human-exoskeleton interaction scenario.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t6_10">
             09:00-10:00, Paper FrPI6T6.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3161'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Guiding Reinforcement Learning with Incomplete System Dynamics
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#323086" title="Click to go to the Author Index">
             Wang, Shuyuan
            </a>
           </td>
           <td class="r">
            University of British Columbia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#314366" title="Click to go to the Author Index">
             Duan, Jingliang
            </a>
           </td>
           <td class="r">
            University of Science and Technology Beijing
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#295324" title="Click to go to the Author Index">
             Lawrence, Nathan P.
            </a>
           </td>
           <td class="r">
            University of British Columbia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#410795" title="Click to go to the Author Index">
             Loewen, Philip D
            </a>
           </td>
           <td class="r">
            University of British Columbia, Vancouver
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#411226" title="Click to go to the Author Index">
             Forbes, Michael
            </a>
           </td>
           <td class="r">
            Honeywell
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384796" title="Click to go to the Author Index">
             Gopaluni, Bhushan
            </a>
           </td>
           <td class="r">
            University of British Columbia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#252939" title="Click to go to the Author Index">
             Zhang, Lixian
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3161" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Model-free reinforcement learning (RL) is inher- ently a reactive method, operating under the assumption that it starts with no prior knowledge of the system and entirely depends on trial-and-error for learning. This approach faces several challenges, such as poor sample efficiency, generaliza- tion, and the need for well-designed reward functions to guide learning effectively. On the other hand, controllers based on complete system dynamics do not require data. This paper addresses the intermediate situation where there is not enough model information for complete controller design, but there is enough to suggest that a model-free approach is not the best approach either. By carefully decoupling known and unknown information about the system dynamics, we obtain an embedded controller guided by our partial model and thus improve the learning efficiency of an RL-enhanced approach. A modular design allows us to deploy mainstream RL algorithms to refine the policy. Simulation results show that our method signifi- cantly improves sample efficiency compared with standard RL methods on continuous control tasks, and also offers enhanced performance over traditional control approaches. Experiments on a real ground vehicle also validate the performance of our method, including generalization and robustness.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t6_11">
             09:00-10:00, Paper FrPI6T6.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('56'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Agile Locomotion on Risky Terrains
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#308697" title="Click to go to the Author Index">
             Zhang, Chong
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285817" title="Click to go to the Author Index">
             Rudin, Nikita
            </a>
           </td>
           <td class="r">
            ETH Zurich, NVIDIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286476" title="Click to go to the Author Index">
             Hoeller, David
            </a>
           </td>
           <td class="r">
            ETH Zurich, NVIDIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114045" title="Click to go to the Author Index">
             Hutter, Marco
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab56" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensorimotor_learning" title="Click to go to the Keyword Index">
               Sensorimotor Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Quadruped robots have shown remarkable mobility on various terrains through reinforcement learning. Yet, in the presence of sparse footholds and risky terrains such as stepping stones and balance beams, which require precise foot placement to avoid falls, model-based approaches are often used. In this paper, we show that end-to-end reinforcement learning can also enable the robot to traverse risky terrains with dynamic motions. To this end, our approach involves training a generalist policy for agile locomotion on disorderly and sparse stepping stones before transferring its reusable knowledge to various more challenging terrains by finetuning specialist policies from it. Given that the robot needs to rapidly adapt its velocity on these terrains, we formulate the task as a navigation task instead of the commonly used velocity tracking which constrains the robot's behavior and propose an exploration strategy to overcome sparse rewards and achieve high robustness. We validate our proposed method through simulation and real-world experiments on an ANYmal-D robot achieving peak forward velocity of &gt;= 2.5 m/s on sparse stepping stones and narrow balance beams. Video: youtu.be/Z5X0J8OH6z4
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t6_12">
             09:00-10:00, Paper FrPI6T6.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('613'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Sensorimotor Attention and Language-Based Regressions in Shared Latent Variables for Integrating Robot Motion Learning and LLM
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#203755" title="Click to go to the Author Index">
             Suzuki, Kanata
            </a>
           </td>
           <td class="r">
            Fujitsu Limited
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101828" title="Click to go to the Author Index">
             Ogata, Tetsuya
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab613" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensorimotor_learning" title="Click to go to the Keyword Index">
               Sensorimotor Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_experience" title="Click to go to the Keyword Index">
               Learning from Experience
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In recent years, studies have been actively conducted on combining large language models (LLM) and robotics; however, most have not considered end-to-end feedback in the robot-motion generation phase. The prediction of deep neural networks must contain errors, it is required to update the trained model to correspond to the real environment to generate robot motion adaptively. This study proposes an integration method that connects the robot-motion learning model and LLM using shared latent variables. When generating robot motion, the proposed method updates shared parameters based on prediction errors from both sensorimotor attention points and task language instructions given to the robot. This allows the model to search for latent parameters appropriate for the robot task efficiently. Through simulator experiments on multiple robot tasks, we demonstrated the effectiveness of our proposed method from two perspectives: position generalization and language instruction generalization abilities.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t6_13">
             09:00-10:00, Paper FrPI6T6.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1288'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GeRM: A Generalist Robotic Model with Mixture-Of-Experts for Quadruped Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389395" title="Click to go to the Author Index">
             Song, Wenxuan
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334849" title="Click to go to the Author Index">
             Zhao, Han
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391285" title="Click to go to the Author Index">
             Ding, Pengxiang
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391284" title="Click to go to the Author Index">
             Cui, Can
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#192153" title="Click to go to the Author Index">
             Lyu, Shangke
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389415" title="Click to go to the Author Index">
             Fan, YaNing
            </a>
           </td>
           <td class="r">
            Hebei University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#267934" title="Click to go to the Author Index">
             Wang, Donglin
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1288" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#perception_action_coupling" title="Click to go to the Keyword Index">
               Perception-Action Coupling
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-task robot learning holds significant importance in tackling diverse and complex scenarios. However, current approaches are hindered by performance issues and difficulties in collecting training datasets. In this paper, we propose GeRM (Generalist Robotic Model). We utilize offline reinforcement learning to optimize data utilization strategies to learn from both demonstrations and sub-optimal data, thus surpassing the limitations of human demonstrations. Thereafter, we employ a transformer-based VLA network to process multi-modal inputs and output actions. By introducing the Mixture-of-Experts structure, GeRM allows faster inference speed with higher whole model capacity, and thus resolves the issue of limited RL parameters, enhancing model performance in multi-task learning while controlling computational costs. Through a series of experiments, we demonstrate that GeRM outperforms other methods across all tasks, while also validating its efficiency in both training and inference processes. Additionally, we uncover its potential to acquire emergent skills. Additionally, we contribute the QUARD-Auto dataset, collected automatically to support our training approach and foster advancements in multi-task quadruped robot learning. This work presents a new paradigm for reducing the cost of collecting robot data and driving progress in the multi-task learning community.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t6_14">
             09:00-10:00, Paper FrPI6T6.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2708'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Feeling Optimistic? Ambiguity Attitudes for Online Decision Making
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#272062" title="Click to go to the Author Index">
             Beard, Jared
            </a>
           </td>
           <td class="r">
            West Virginia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#312432" title="Click to go to the Author Index">
             Butts, R. Michael
            </a>
           </td>
           <td class="r">
            West Virginia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#146498" title="Click to go to the Author Index">
             Gu, Yu
            </a>
           </td>
           <td class="r">
            West Virginia University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2708" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#probability_and_statistical_methods" title="Click to go to the Keyword Index">
               Probability and Statistical Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Due to the complexity of many decision making problems, tree search algorithms often have inadequate information to produce accurate transition models. This results in ambiguities (uncertainties for which there are multiple plausible models). Faced with ambiguities, robust methods have been used to produce safe solutionsâ€”often by maximizing the lower bound over the set of plausible transition models. However, they often overlook how much the representation of uncertainty can impact how a decision is made. This work introduces the Ambiguity Attitude Graph Search (AAGS), advocating for more comprehensive representations of ambiguities in decision making. Additionally, AAGS allows users to adjust their ambiguity attitude (or preference), promoting exploration and improving usersâ€™ ability to control how an agent should respond when faced with a set of plausible alternatives. Simulation in a dynamic sailing environment shows how environments with high entropy transition models can lead robust methods to fail. Results further demonstrate how adjusting ambiguity attitudes better fulfills objectives while mitigating this failure mode of robust approaches. Because this approach is a generalization of the robust framework, these results further demonstrate how algorithms focused on ambiguity have applicability beyond safety-critical systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t6_15">
             09:00-10:00, Paper FrPI6T6.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('321'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Offline Meta-Reinforcement Learning with Evolving Gradient Agreement
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391117" title="Click to go to the Author Index">
             Chen, Jiaxing
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391918" title="Click to go to the Author Index">
             Yuan, Weilin
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391461" title="Click to go to the Author Index">
             Chen, Shaofei
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391508" title="Click to go to the Author Index">
             Liu, Furong
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391503" title="Click to go to the Author Index">
             Ma, Ao
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391572" title="Click to go to the Author Index">
             Hu, Zhenzhen
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391505" title="Click to go to the Author Index">
             Li, Peng
            </a>
           </td>
           <td class="r">
            National University of Defence Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab321" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#evolutionary_robotics" title="Click to go to the Keyword Index">
               Evolutionary Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_experience" title="Click to go to the Keyword Index">
               Learning from Experience
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Meta-Reinforcement Learning (Meta-RL) is a machine learning paradigm aimed at learning reinforcement learning policies that can quickly adapt to unseen tasks with few-shot data. Nevertheless, applying Meta-RL to real-world applications faces challenges due to the cost of data acquisition. To address this problem, offline Meta-RL has emerged as a promising solution, focusing on learning policies from pre-collected data that can effectively and rapidly adapt to unseen tasks. In this paper, we propose a new offline Meta-RL method called Meta-Actor-Critic with Evolving Gradient Agreement (MACEGA). MACEGA utilizes an evolutionary approach to estimate meta-gradients conductive to generalization across unseen tasks. During meta-training, gradient evolution is utilized to meta-update the value network and policies. Moreover, we use gradient agreement as an optimization objective for meta-learning, thereby enhancing the generalization ability of the meta-policy. We experimentally demonstrate the robustness of MACEGA in handling offline data quality. Furthermore, extensive experiments on various benchmarks provide empirical evidence that MACEGA outperforms previous state-of-the-art methods in generalizing to unseen tasks, thus demonstrating its potential for real-world applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t6_16">
             09:00-10:00, Paper FrPI6T6.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3349'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Stein Movement Primitives for Adaptive Multi-Modal Trajectory Generation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399102" title="Click to go to the Author Index">
             Zeya, Yin
            </a>
           </td>
           <td class="r">
            Univeristy of Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237502" title="Click to go to the Author Index">
             Lai, Tin
            </a>
           </td>
           <td class="r">
            University of Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#315585" title="Click to go to the Author Index">
             Khan, Subhan
            </a>
           </td>
           <td class="r">
            The University of Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363448" title="Click to go to the Author Index">
             Jacob, Jayadeep
            </a>
           </td>
           <td class="r">
            The University of Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397077" title="Click to go to the Author Index">
             Li, Yong Hui
            </a>
           </td>
           <td class="r">
            Univeristy of Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101688" title="Click to go to the Author Index">
             Ramos, Fabio
            </a>
           </td>
           <td class="r">
            University of Sydney, NVIDIA
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3349" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#learning_from_experience" title="Click to go to the Keyword Index">
               Learning from Experience
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#probabilistic_inference" title="Click to go to the Keyword Index">
               Probabilistic Inference
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Probabilistic Movement Primitives (ProMPs) and their variants are powerful methods for robots to learn complex tasks from human demonstrations, where motion trajectories are represented as stochastic processes with Gaussian assumptions. However, despite being computationally efficient, this method has limited expressivity in capturing the diversity found in human demonstrations, which are typically characterised by the multi- modality of motions. For example, when picking up an object partially obscured by an obstacle, some individuals may opt to go to the right while others may choose the left side of the object. In this paper, we introduce Stein Movement Primitives (SMPs), a novel approach to probabilistic movement primitives. We formulate motion primitive adaptation as non-parametric probabilistic inference using Stein Variational Gradient Descent (SVGD), thus not constraining our method to any posterior distribution assumption and enabling direct representation of the multi-modality in human demonstrations. We illustrate how our method can adapt robot motion to different scenarios for collision avoidance and adaptation to new tasks without being restricted to single modal assumptions. Experimentally, we demonstrate our approach on several domain adaptation problems using the LASA dataset and with a real robotic arm.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frpi6t7">
             <b>
              FrPI6T7
             </b>
            </a>
           </td>
           <td class="r">
            Room 7
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frpi6t7" title="Click to go to the Program at a Glance">
             <b>
              Optimal Control in Robotics
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#209027" title="Click to go to the Author Index">
             Tortora, Stefano
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t7_01">
             09:00-10:00, Paper FrPI6T7.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1106'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Toward Control of Wheeled Humanoid Robots with Unknown Payloads: Equilibrium Point Estimation Via Real-To-Sim Adaptation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#222498" title="Click to go to the Author Index">
             Baek, DongHoon
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#217956" title="Click to go to the Author Index">
             Sim, Youngwoo
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#321869" title="Click to go to the Author Index">
             Purushottam, Amartya
            </a>
           </td>
           <td class="r">
            University of Illinois, Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#192737" title="Click to go to the Author Index">
             Gupta, Saurabh
            </a>
           </td>
           <td class="r">
            UIUC
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#159651" title="Click to go to the Author Index">
             Ramos, Joao
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1106" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#transfer_learning" title="Click to go to the Keyword Index">
               Transfer Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Model-based controllers using a linearized model around the systemâ€™s equilibrium point is a common approach in the control of a wheeled humanoid due to their less computational load and ease of stability analysis. However, controlling a wheeled humanoid robot while it lifts an unknown object presents significant challenges, primarily due to the lack of knowledge in object dynamics. This paper presents a framework designed for predicting the new equilibrium point explicitly to control a wheeled-legged robot with unknown dynamics.We estimated the total mass and center of mass of the system from its response to initially unknown dynamics, then calculated the new equilibrium point accordingly. To avoid using additional sensors (e.g., force torque sensor) and reduce the effort of obtaining expensive real data, a data-driven approach is utilized with a novel real-to-sim adaptation. A more accurate nonlinear dynamics model, offering a closer representation of real-world physics, is injected into a rigid-body simulation for real-to-sim adaptation. The nonlinear dynamics model parameters were optimized using Particle Swarm Optimization. The efficacy of this framework was validated on a physical wheeled inverted pendulum, a simplified model of a wheeledlegged robot. The experimental results indicate that employing a more precise analytical model with optimized parameters significantly reduces the gap between simulation and reality, thus improving the efficiency of a model-based controller in controlling a wheeled robot with unknown dynamics.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t7_02">
             09:00-10:00, Paper FrPI6T7.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2356'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CLIPSwarm: Generating Drone Shows from Text Prompts with Vision-Language Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#278155" title="Click to go to the Author Index">
             Pueyo, Pablo
            </a>
           </td>
           <td class="r">
            Universidad De Zaragoza
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#117412" title="Click to go to the Author Index">
             Montijano, Eduardo
            </a>
           </td>
           <td class="r">
            Universidad De Zaragoza
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104884" title="Click to go to the Author Index">
             Murillo, Ana Cristina
            </a>
           </td>
           <td class="r">
            University of Zaragoza
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106233" title="Click to go to the Author Index">
             Schwager, Mac
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2356" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#art_and_entertainment_robotics" title="Click to go to the Keyword Index">
               Art and Entertainment Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces CLIPSwarm, a new algorithm designed to automate the modeling of swarm drone formations based on natural language. The algorithm begins by enriching a provided word, to compose a text prompt that serves as input to an iterative approach to find the formation that best matches the provided word. The algorithm iteratively refines formations of robots to align with the textual description, employing different steps for â€œexplorationâ€ and â€œexploitationâ€. Our framework is currently evaluated on simple formation targets, limited to con- tour shapes. A formation is visually represented through alpha-shape contours and the most representative color is automatically found for the input word. To measure the similarity between the description and the visual representation of the formation, we use CLIP [1], encoding text and images into vectors and assessing their similarity. Subsequently, the algorithm rearranges the formation to visually represent the word more effectively, within the given constraints of available drones. Control actions are then assigned to the drones, ensuring robotic behavior and collision-free movement. Experimental results demonstrate the systemâ€™s efficacy in accurately modeling robot formations from natural language descriptions. The algorithmâ€™s versatility is showcased through the execution of drone shows in photorealistic simulation with varying shapes. We refer the reader to the supplementary video for a visual reference of the results.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t7_03">
             09:00-10:00, Paper FrPI6T7.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3362'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robust Two-View Geometry Estimation with Implicit Differentiation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394995" title="Click to go to the Author Index">
             Pyatov, Vladislav
            </a>
           </td>
           <td class="r">
            Skolkovo Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395927" title="Click to go to the Author Index">
             Koshelev, Iaroslav
            </a>
           </td>
           <td class="r">
            AI Foundation and Algorithm Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394996" title="Click to go to the Author Index">
             Lefkimmiatis, Stamatios
            </a>
           </td>
           <td class="r">
            MTS AI
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3362" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computational_geometry" title="Click to go to the Keyword Index">
               Computational Geometry
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a novel two-view geometry estimation framework which is based on a differentiable robust loss function fitting. We propose to treat the robust fundamental matrix estimation as an implicit layer, which allows us to avoid backpropagation through time and significantly improves the numerical stability. To take full advantage of the information from the feature matching stage we incorporate learnable weights that depend on the matching confidences. In this way our solution brings together feature extraction, matching and two-view geometry estimation in a unified end-to-end trainable pipeline. We evaluate our approach on the camera pose estimation task in both outdoor and indoor scenarios. The experiments on several datasets show that the proposed method outperforms both classic and learning-based state-of-the-art methods by a large margin. The project webpage is available at: https://github.com/VladPyatov/ihls
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t7_04">
             09:00-10:00, Paper FrPI6T7.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('617'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robustifying Model-Based Locomotion by Zero-Order Stochastic Nonlinear Model Predictive Control with Guard Saltation Matrix
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285000" title="Click to go to the Author Index">
             Katayama, Sotaro
            </a>
           </td>
           <td class="r">
            Sony Group Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195618" title="Click to go to the Author Index">
             Takasugi, Noriaki
            </a>
           </td>
           <td class="r">
            Sony Group Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392018" title="Click to go to the Author Index">
             Kaneko, Mitsuhisa
            </a>
           </td>
           <td class="r">
            Sony Global Manufacturing &amp; Operations Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#307293" title="Click to go to the Author Index">
             Nagatsuka, Norio
            </a>
           </td>
           <td class="r">
            Sony Interactive Entertainment
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#295379" title="Click to go to the Author Index">
             Kinoshita, Masaya
            </a>
           </td>
           <td class="r">
            Sony Group Corporation
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab617" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_contact_whole_body_motion_planning_and_control" title="Click to go to the Keyword Index">
               Multi-Contact Whole-Body Motion Planning and Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a stochastic/robust nonlinear model predictive control (NMPC) to enhance the robustness of model-based legged locomotion against contact uncertainties. We integrate the contact uncertainties into the covariance propagation of stochastic/robust NMPC framework by leveraging the guard saltation matrix and an extended Kalman filter-like covariance update. We achieve fast stochastic/robust NMPC computation by utilizing the zero-order algorithm with additional improvements in computational efficiency concerning the feedback gains. We conducted numerical experiments and demonstrate that the proposed method can accurately forecast future state covariance and generate trajectories that satisfies constraints even in the presence of the contact uncertainties. Hardware experiments on the perceptive locomotion of a wheeled-legged robot were also carried out, validating the feasibility of the proposed method in a real-world system with limited on-board computation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t7_05">
             09:00-10:00, Paper FrPI6T7.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2038'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Momentum-Aware Trajectory Optimisation Using Full-Centroidal Dynamics and Implicit Inverse Kinematics
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378783" title="Click to go to the Author Index">
             Papatheodorou, Aristotelis
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#199930" title="Click to go to the Author Index">
             Merkt, Wolfgang Xaver
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#257119" title="Click to go to the Author Index">
             Mitchell, Alexander Luis
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123323" title="Click to go to the Author Index">
             Havoutis, Ioannis
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2038" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The current state-of-the-art gradient-based optimisation frameworks are able to produce impressive dynamic manoeuvres such as linear and rotational jumps. However, these methods, which optimise over the full rigid-body dynamics of the robot, often require precise foothold locations apriori, while real time performance is not guaranteed without elaborate regularisation and tuning of the cost function. In contrast, we investigate the advantages of a task-space optimisation framework, with special focus on acrobatic motions. Our proposed formulation exploits the systemâ€™s high-order nonlinearities, such as the nonholonomy of the angular momentum, in order to produce feasible, high acceleration manoeuvres. By leveraging the full-centroidal dynamics of the quadruped ANYmal C and directly optimising its footholds and contact forces, the framework is capable of producing efficient motion plans with low computational overhead. Finally, we deploy our proposed framework on the ANYmal C platform, and demonstrate its true capabilities through real-world experiments, with the successful execution of high-acceleration motions, such as linear and rotational jumps. Extensive analysis of these shows that the robotâ€™s dynamics can be exploited to surpass its hardware limitations of having a high mass and low-torque limits.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t7_06">
             09:00-10:00, Paper FrPI6T7.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2589'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Model Predictive Control for Frenet-Cartesian Trajectory Tracking of a Tricycle Kinematic Automated Guided Vehicle
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398331" title="Click to go to the Author Index">
             Subash, Akash John
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398357" title="Click to go to the Author Index">
             Kloeser, Daniel
            </a>
           </td>
           <td class="r">
            Ek Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#344313" title="Click to go to the Author Index">
             Frey, Jonathan
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#325309" title="Click to go to the Author Index">
             Reiter, Rudolf
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101488" title="Click to go to the Author Index">
             Diehl, Moritz
            </a>
           </td>
           <td class="r">
            Univ. of Heidelberg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#155957" title="Click to go to the Author Index">
             Bohlmann, Karsten
            </a>
           </td>
           <td class="r">
            Eberhard-Karls-UniversitÃ¤t TÃ¼bingen
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2589" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#embedded_systems_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Embedded Systems for Robotic and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work proposes an optimal control scheme for a trajectory-tracking Automated Guided Vehicle considering motion and collision constraints in a warehouse environment. We outline how the simpler obstacle avoidance constraints in the Cartesian Coordinate Frame (CCF) can be retained, while projecting the tricycle kinematics to the Frenet Coordinate Frame (FCF) for track progress. The Nonlinear Model Pre- dictive Control (NMPC) scheme is subsequently implemented using acados and its real-time feasibility is demonstrated in simulation and aboard a test vehicle at a warehouse.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t7_07">
             09:00-10:00, Paper FrPI6T7.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2881'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Ensuring Joint Constraints of Torque-Controlled Robot Manipulators under Bounded Jerk
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237548" title="Click to go to the Author Index">
             Ko, Dongwoo
            </a>
           </td>
           <td class="r">
            POSTECH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#341926" title="Click to go to the Author Index">
             Kim, Jonghyeok
            </a>
           </td>
           <td class="r">
            POSTECH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100095" title="Click to go to the Author Index">
             Chung, Wan Kyun
            </a>
           </td>
           <td class="r">
            POSTECH
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2881" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes an optimization-based control framework for the torque-controlled robot, which can satisfy the joint position, velocity, and acceleration constraints under a bounded jerk. The optimization filter is incorporated as a module to modify the nominal controller output to ensure joint constraints. To formulate the optimization problem as a QP, the torque optimization problem is converted to the jerk optimization problem using the augmented state, and the constraints are reformulated to be affine in the jerk. Here, the viable constraints are derived using the time-optimal braking policy to guarantee the feasibility of the QP. The proposed method was validated in simulation and with a 6-DOF robot manipulator.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t7_08">
             09:00-10:00, Paper FrPI6T7.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2894'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Collaboration Strategies for Two Heterogeneous Pursuers in a Pursuit-Evasion Game Using Deep Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397074" title="Click to go to the Author Index">
             Zhong, Zhanping
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397130" title="Click to go to the Author Index">
             Dong, Zhuoning
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#270301" title="Click to go to the Author Index">
             Duan, Xiaoming
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#247284" title="Click to go to the Author Index">
             He, Jianping
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2894" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#agent_based_systems" title="Click to go to the Keyword Index">
               Agent-Based Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We investigate a pursuit-evasion game taking place in an unbounded three-dimensional space, where a flexible pursuer with hybrid dynamics collaborates with a fast pursuer and aims to capture a flexible evader within a finite time. The key feature of this problem lies in the hybrid dynamics of the flexible pursuer, which can change its dynamics once during the game and switch to a fast pursuer with increased speed but lower maneuverability. To address this challenge, we devise a hybrid strategy based on the soft actor-critic framework, tailored specifically for the flexible pursuer, which encompasses both maneuvering and switch tactics. We introduce a switch factor to the input of the actor network and incorporate switch actions to further expand the action space. These additions enable the flexible pursuer to execute maneuvering actions and determine a moment to switch to a fast pursuer. The reward function is designed to account for related angle, altitude, speed, and sparse reward. Through extensive ablation experiments conducted in a simulated environment, we demonstrate the efficacy of our algorithm in facilitating the learning of hybrid strategies for the flexible pursuer, resulting in significantly improved capture rates compared to alternative methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t7_09">
             09:00-10:00, Paper FrPI6T7.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3069'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Adaptive Trajectory Database Learning for Nonlinear Control with Hybrid Gradient Optimization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#234186" title="Click to go to the Author Index">
             Tseng, Kuan-Yu
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286992" title="Click to go to the Author Index">
             Zhang, Mengchao
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123478" title="Click to go to the Author Index">
             Hauser, Kris
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114982" title="Click to go to the Author Index">
             Dullerud, Geir E.
            </a>
           </td>
           <td class="r">
            University of Illinois
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3069" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#continual_learning" title="Click to go to the Keyword Index">
               Continual Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_experience" title="Click to go to the Keyword Index">
               Learning from Experience
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a novel experience-based technique, called EHGO, for sample-efficient adaptive control of nonlinear systems in the presence of dynamical modeling errors. The starting point for EHGO is a database seeded with many trajectories optimized under a reference estimate of real system dynamics. When executed on the real system, these trajectories will be suboptimal due to errors in the reference dynamics. The approach then leverages a hybrid gradient optimization technique, GRILC, which observes executed trajectories and computes gradients from the reference model to refine the control policy without requiring an explicit model of the real system. In past work, GRILC was applied in a restrictive setting in which a robot executes multiple rollouts from identical start states. In this paper, we show how to leverage a database to enable GRILC to operate across a wide envelope of possible start states in different iterations. The database is used to balance between start state proximity and recentness-of-experience via a learned distance metric to generate good initial guesses. Experiments on three dynamical systems (pendulum, car, drone) show that the proposed approach adapts quickly to online experience even when the reference model has significant errors. In these examples EHGO generates near-optimal solutions within hundreds of epochs of real execution, which can be orders of magnitude more sample efficient than reinforcement learning techniques.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t7_10">
             09:00-10:00, Paper FrPI6T7.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3185'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Bi-Level Trajectory Optimization on Uneven Terrains with Differentiable Wheel-Terrain Interaction Model
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#226239" title="Click to go to the Author Index">
             Manoharan, Amith
            </a>
           </td>
           <td class="r">
            University of Tartu
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310720" title="Click to go to the Author Index">
             Sharma, Aditya
            </a>
           </td>
           <td class="r">
            Robotics Research Center, IIIT Hyderabad
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398997" title="Click to go to the Author Index">
             Belsare, Himani
            </a>
           </td>
           <td class="r">
            International Institute of Information Technology, Hyderabad
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#223018" title="Click to go to the Author Index">
             Pal, Kaustab
            </a>
           </td>
           <td class="r">
            International Institute of Information Technology, Hyderabad
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102906" title="Click to go to the Author Index">
             Krishna, Madhava
            </a>
           </td>
           <td class="r">
            IIIT Hyderabad
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123110" title="Click to go to the Author Index">
             Singh, Arun Kumar
            </a>
           </td>
           <td class="r">
            University of Tartu
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3185" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Navigation of wheeled vehicles on uneven terrain necessitates going beyond the 2D approaches for trajectory planning. Specifically, it is essential to incorporate the full 6dof variation of vehicle pose and its associated stability cost in the planning process. To this end, most recent works aim to learn a neural network model to predict vehicle evolution. However, such approaches are data-intensive and fraught with generalization issues.
             <p>
              In this paper, we present a purely model-based approach that just requires the digital elevation information of the terrain. Specifically, we express the wheel-terrain interaction and 6dof pose prediction as a non-linear least squares (NLS) problem. As a result, trajectory planning can be viewed as a bi-level optimization. The inner optimization layer predicts the pose on the terrain along a given trajectory, while the outer layer deforms the trajectory itself to reduce the stability and kinematic costs of the pose.
              <p>
               We improve the state-of-the-art in the following respects. First, we show that our NLS-based pose prediction closely matches the output of a high-fidelity physics engine. This result, coupled with the fact that we can query gradients of the NLS solver, makes our pose predictor a differentiable wheel-terrain interaction model. We further leverage this differentiability to efficiently solve the proposed bi-level trajectory optimization problem. Finally, we perform extensive experiments and comparisons with a baseline to showcase the effectiveness of our approach in obtaining smooth, stable trajectories.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t7_11">
             09:00-10:00, Paper FrPI6T7.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3276'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Disturbance-Aware Model Predictive Control of Underactuated Robotics Systems
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398450" title="Click to go to the Author Index">
             Kim, Jiwon
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#149446" title="Click to go to the Author Index">
             Kim, Min Jun
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3276" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             While robust model predictive control (MPC) has been studied extensively in recent decades, addressing unmatched disturbances in underactuated robotic systems is still challenging. In this paper, we propose a method to enhance the robustness of the MPC through the online estimation of disturbances using a nonlinear disturbance observer (NDOB). We call this method disturbance-aware MPC (DA-MPC), because the proposed method explicitly utilizes the estimated disturbance in the future prediction. We provide a performance analysis of the NDOB, establishing the boundedness between the predicted and real states. The main advantages of the DA-MPC include its applicability to real-time control and its compatibility with off-the-shelf optimal control problem (OCP) solvers. We demonstrate the application of the proposed method using an underactuated quadrotor system. The simulation validation shows the effectiveness of the proposed method compared to L1-adaptive MPC, which is one of the state-of-the-art robust MPC methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t7_12">
             09:00-10:00, Paper FrPI6T7.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1661'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Fast Online Omnidirectional Quadrupedal Jumping Framework Via Virtual-Model Control and Minimum Jerk Trajectory Generation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237789" title="Click to go to the Author Index">
             Yue, Linzhu
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339847" title="Click to go to the Author Index">
             Zhang, Lingwei
            </a>
           </td>
           <td class="r">
            Hong Kong Centre for Logistics Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#272143" title="Click to go to the Author Index">
             Song, Zhitao
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339968" title="Click to go to the Author Index">
             Zhang, Hongbo
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#245787" title="Click to go to the Author Index">
             Dong, Jinhu
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339864" title="Click to go to the Author Index">
             Zeng, Xuanqi
            </a>
           </td>
           <td class="r">
            Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100055" title="Click to go to the Author Index">
             Liu, Yunhui
            </a>
           </td>
           <td class="r">
            Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1661" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Exploring the limits of quadruped robot agility, particularly in the context of rapid and real-time planning and execution of omnidirectional jump trajectories, presents significant challenges due to the complex dynamics involved, especially when considering significant impulse contacts. This paper introduces a new framework to enable fast, omnidirectional jumping capabilities for quadruped robots. Utilizing minimum jerk technology, the proposed framework efficiently generates jump trajectories that exploit its analytical solutions, ensuring numerical stability and dynamic compatibility with minimal computational resources. The virtual model control is employed to formulate a Quadratic Programming (QP) optimization problem to accurately track the Center of Mass (CoM) trajectories during the jump phase. In contrast, whole-body control strategies facilitate precise and compliant landing motion. The framework's efficacy is demonstrated through its implementation on an enhanced version of the open-source textit{Mini Cheetah} robot. Omnidirectional jumpsâ€”including forward, backward, and other directionalâ€”were successfully executed, showcasing the robot's capability to perform rapid and consecutive jumps with an average trajectory generation and tracking solution time of merely 50 microseconds.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t7_13">
             09:00-10:00, Paper FrPI6T7.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1394'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Adaptive Feedforward Super-Twisting Sliding Mode Control of Parallel Kinematic Manipulators with Real-Time Experiments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#218721" title="Click to go to the Author Index">
             Saied, Hussein
            </a>
           </td>
           <td class="r">
            Univesity of Montpellier, LIRMM
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#117709" title="Click to go to the Author Index">
             Chemori, Ahmed
            </a>
           </td>
           <td class="r">
            LIRMM, University of Montpellier, CNRS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#116064" title="Click to go to the Author Index">
             Bouri, Mohamed
            </a>
           </td>
           <td class="r">
            EPFL
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102309" title="Click to go to the Author Index">
             El Rafei, Maher
            </a>
           </td>
           <td class="r">
            Lebanese University, Faculty of Engineering, CRSI
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#178616" title="Click to go to the Author Index">
             Francis, Clovis
            </a>
           </td>
           <td class="r">
            Lebanese University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1394" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#parallel_robots" title="Click to go to the Keyword Index">
               Parallel Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we propose a novel adaptive feedforward super-twisting sliding mode control algorithm to resolve the tracking control problem of parallel manipulators. The proposed control scheme includes three main terms, (i) the standard super-twisting algorithm, (ii) an adaptive feedforward dynamic model, and (iii) a feedback term to ensure stability. The proposed controller provides robustness towards uncertainties and disturbances, less sensitive to measurement noise, and allows dynamic parameters adaptation of the manipulator while executing a certain task. Real-time experiments are conducted on a 3-DOF non-redundant Delta parallel robot, including two main scenarios, (i) nominal case, and (ii) robustness towards operating acceleration changes. The relevance of the proposed controller is verified experimentally in both scenarios and compared with two other controllers from the literature, including the standard and the feedforward super-twisting sliding mode control algorithms.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t7_14">
             09:00-10:00, Paper FrPI6T7.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('215'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SoftMAC: Differentiable Soft Body Simulation with Forecast-Based Contact Model and Two-Way Coupling with Articulated Rigid Bodies and Clothes
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371657" title="Click to go to the Author Index">
             Liu, Min
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354078" title="Click to go to the Author Index">
             Yang, Gang
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352769" title="Click to go to the Author Index">
             Luo, Siyuan
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#217322" title="Click to go to the Author Index">
             Shao, Lin
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab215" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Differentiable physics simulation provides an avenue to tackle previously intractable challenges through gradient-based optimization, thereby greatly improving the efficiency of solving robotics-related problems. To apply differentiable simulation in diverse robotic manipulation scenarios, a key challenge is to integrate various materials in a unified framework. We present SoftMAC, a differentiable simulation framework that couples soft bodies with articulated rigid bodies and clothes. SoftMAC simulates soft bodies with the continuum-mechanics-based Material Point Method (MPM). We provide a novel forecast-based contact model for MPM, which effectively reduces penetration without introducing other artifacts like unnatural rebound. To couple MPM particles with deformable and non-volumetric clothes meshes, we also propose a penetration tracing algorithm that reconstructs the signed distance field in local area. Diverging from previous works, SoftMAC simulates the complete dynamics of each modality and incorporates them into a cohesive system with an explicit and differentiable coupling mechanism. The feature empowers SoftMAC to handle a broader spectrum of interactions, such as soft bodies serving as manipulators and engaging with underactuated systems. We conducted comprehensive experiments to validate the effectiveness and accuracy of the proposed differentiable pipeline in downstream robotic manipulation applications. Supplementary materials are available on our project website at https://damianliumin.github.io/SoftMAC.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t7_15">
             09:00-10:00, Paper FrPI6T7.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3108'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Task-Based Design and Policy Co-Optimization for Tendon-Driven Underactuated Kinematic Chains
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#313075" title="Click to go to the Author Index">
             Islam, Sharfin
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237254" title="Click to go to the Author Index">
             He, Zhanpeng
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#110328" title="Click to go to the Author Index">
             Ciocarlie, Matei
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3108" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#underactuated_robots" title="Click to go to the Keyword Index">
               Underactuated Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Underactuated manipulators reduce the number of bulky motors, thereby enabling compact and mechanically robust designs. However, fewer actuators than joints means that the manipulator can only access a specific manifold within the joint space, which is particular to a given hardware configuration and can be low-dimensional and/or discontinuous. Determining an appropriate set of hardware parameters for this class of mechanisms, therefore, is difficult - even for traditional task-based co-optimization methods. In this paper, our goal is to implement a task-based design and policy co-optimization method for underactuated, tendon-driven manipulators. We first formulate a general model for an underactuated, tendon-driven transmission. We then use this model to co-optimize a three-link, two-actuator kinematic chain using reinforcement learning. We demonstrate that our optimized tendon transmission and control policy can be transferred reliably to physical hardware with real-world reaching experiments.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frpi6t8">
             <b>
              FrPI6T8
             </b>
            </a>
           </td>
           <td class="r">
            Room 8
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frpi6t8" title="Click to go to the Program at a Glance">
             <b>
              Robot Motion Planning V
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#156679" title="Click to go to the Author Index">
             Quattrini Li, Alberto
            </a>
           </td>
           <td class="r">
            Dartmouth College
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t8_01">
             09:00-10:00, Paper FrPI6T8.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2824'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Search-Based Strategy for Spatio-Temporal Environmental Property Restoration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379533" title="Click to go to the Author Index">
             Docena, Amel Nestor
            </a>
           </td>
           <td class="r">
            Dartmouth College
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#156679" title="Click to go to the Author Index">
             Quattrini Li, Alberto
            </a>
           </td>
           <td class="r">
            Dartmouth College
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2824" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#environment_monitoring_and_management" title="Click to go to the Keyword Index">
               Environment Monitoring and Management
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper addresses the spatio-temporal areas restoration problem: a robot, with limited battery life, deployed in a known environment, needs to persistently plan a schedule to visit areas of interest and charge its battery as needed. The goal is to restore the areas' temporal properties that decay over timeâ€”--such as air quality--â€”so that the time the measured property values are below a certain threshold is minimized. This problem is different from typical problems solved in the area of monitoring a spatio-temporal environment. A related problem is the orienteering problem, where a robot visits nodes to maximize the profit collected at each visited node within a time budget frame. That problem is NP-hard. The typical formulation considers static profit, while we consider a time-varying one. Given look-ahead time window or schedule length, we formulate the problem as an optimization search problem with a temporal objective, and devise a heuristic function that enables finding solutions in polynomial time. The heuristic evaluates the discounted opportunity costs of a visitâ€”a concept borrowed from economics. We then develop a greedy algorithm that takes the immediate feasible visit that minimizes this heuristic. This strategy addresses a primary limitation of a recent approach in applications where being able to revisit highly urgent areas within the time window of the schedule is critical. We provide a theoretical analysis on lower and upper bounds for the problem. Extensive experimental results with a robotic simulator show that our method is able to keep the areas in the environment above the threshold better than other methods and closer to the optimal. This work can enable high-impact applications, such as environmental preservation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t8_02">
             09:00-10:00, Paper FrPI6T8.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('823'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Elliptical K-Nearest Neighbors - Path Optimization Via Coulomb's Law and Invalid Vertices in C-Space Obstacles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370306" title="Click to go to the Author Index">
             Zhang, Liding
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195330" title="Click to go to the Author Index">
             Bing, Zhenshan
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372916" title="Click to go to the Author Index">
             Zhang, Yu
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#266688" title="Click to go to the Author Index">
             Cai, Kuanqi
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#296908" title="Click to go to the Author Index">
             Chen, Lingyun
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#212176" title="Click to go to the Author Index">
             Wu, Fan
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108317" title="Click to go to the Author Index">
             Haddadin, Sami
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105608" title="Click to go to the Author Index">
             Knoll, Alois
            </a>
           </td>
           <td class="r">
            Tech. Univ. Muenchen TUM
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab823" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Path planning has long been an important and active research area in robotics. To address challenges in high-dimensional motion planning, this study introduces the Force Direction Informed Trees (FDIT*), a sampling-based planner designed to enhance speed and cost-effectiveness in pathfinding. FDIT* builds upon the state-of-the-art informed sampling planner, the Effort Informed Trees (EIT*), by capitalizing on often-overlooked information in invalid vertices. It incorporates principles of physical force, particularly Coulomb's law. This approach proposes the elliptical k-nearest neighbors search method, enabling fast convergence navigation and avoiding high solution cost or infeasible paths by exploring more problem-specific search-worthy areas. It demonstrates benefits in search efficiency and cost reduction, particularly in confined, high-dimensional environments. It can be viewed as an extension of nearest neighbors search techniques. Fusing invalid vertex data with physical dynamics facilitates force-direction-based search regions, resulting in an improved convergence rate to the optimum. FDIT* outperforms existing single-query, sampling-based planners on the tested problems in R^4 to R^16 and has been demonstrated on a real-world mobile manipulation task.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t8_03">
             09:00-10:00, Paper FrPI6T8.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3128'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              EMPOWER: Embodied Multi-Role Open-Vocabulary Planning with Online Grounding and Execution
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398132" title="Click to go to the Author Index">
             Argenziano, Francesco
            </a>
           </td>
           <td class="r">
            Sapienza University of Rome
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#360561" title="Click to go to the Author Index">
             Brienza, Michele
            </a>
           </td>
           <td class="r">
            Sapienza University of Rome
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#229349" title="Click to go to the Author Index">
             Suriani, Vincenzo
            </a>
           </td>
           <td class="r">
            University of Basilicata
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#137880" title="Click to go to the Author Index">
             Nardi, Daniele
            </a>
           </td>
           <td class="r">
            Sapienza University of Rome
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#166479" title="Click to go to the Author Index">
             Bloisi, Domenico
            </a>
           </td>
           <td class="r">
            International University of Rome UNINT
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3128" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Task planning for robots in real-life settings presents significant challenges. These challenges stem from three primary issues: the difficulty in identifying grounded sequences of steps to achieve a goal; the lack of a standardized mapping between high-level actions and low-level commands; and the challenge of maintaining low computational overhead given the limited resources of robotic hardware. We introduce EMPOWER, a framework designed for open-vocabulary online grounding and planning for embodied agents aimed at addressing these issues. By leveraging efficient pre-trained foundation models and a multi-role mechanism, EMPOWER demonstrates notable improvements in grounded planning and execution. Quantitative results highlight the effectiveness of our approach, achieving an average success rate of 0.73 across six different real-life scenarios using a TIAGo robot.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t8_04">
             09:00-10:00, Paper FrPI6T8.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('262'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Extended Tree Search for Robot Task and Motion Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#206972" title="Click to go to the Author Index">
             Ren, Tianyu
            </a>
           </td>
           <td class="r">
            Technische UniversitÃ¤t Darmstadt
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#168538" title="Click to go to the Author Index">
             Chalvatzaki, Georgia
            </a>
           </td>
           <td class="r">
            Technische UniversitÃ¤t Darmstadt
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104326" title="Click to go to the Author Index">
             Peters, Jan
            </a>
           </td>
           <td class="r">
            Technische UniversitÃ¤t Darmstadt
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab262" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#service_robotics" title="Click to go to the Keyword Index">
               Service Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Integrated Task and Motion Planning (TAMP) offers opportunities for achieving generalized autonomy in robots but also poses challenges. It involves searching in both symbolic task space and high-dimensional motion space, while also addressing geometrically infeasible actions within its hierarchical process. We introduce a novel TAMP decision- making framework, utilizing an extended decision tree for both symbolic task planning and high-dimensional motion variable binding. Employing top-k planning, we generate a skeleton space with diverse candidate plans, seamlessly integrating it with motion variable spaces into an extended decision space. Subsequently, Monte-Carlo Tree Search (MCTS) is utilized to maintain a balance between exploration and exploitation at decision nodes, ultimately yielding optimal solutions. Our approach combines symbolic top-k planning with concrete mo- tion variable binding, leveraging MCTS for proven optimality, resulting in a powerful algorithm for handling combinatorial complexity in long-horizon manipulation tasks. Empirical eval- uations demonstrate the algorithmâ€™s effectiveness in diverse, challenging robot tasks, in comparison with its most competitive baseline method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t8_05">
             09:00-10:00, Paper FrPI6T8.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('356'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              HPHS: Hierarchical Planning Based on Hybrid Frontier Sampling for Unknown Environments Exploration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391788" title="Click to go to the Author Index">
             Long, Shijun
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350814" title="Click to go to the Author Index">
             Li, Ying
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195500" title="Click to go to the Author Index">
             Wu, Chenming
            </a>
           </td>
           <td class="r">
            Baidu Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205361" title="Click to go to the Author Index">
             Xu, Bin
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#317533" title="Click to go to the Author Index">
             Fan, Wei
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab356" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#search_and_rescue_robots" title="Click to go to the Keyword Index">
               Search and Rescue Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Rapid sampling from the environment to acquire available frontier points and timely incorporating them into subsequent planning to reduce fragmented regions are critical to improve the efficiency of autonomous exploration. We propose HPHS, a fast and effective method for autonomous exploration of unknown environments. In this work, we quickly sample hybrid frontier points directly from the LiDAR data and the local map around the robot, and exploit hierarchical planning strategy to provide the robot with a global perspective. The hierarchical planning framework divides the environment into multiple subregions and arranges the order of access to them by evaluating the revenue of each subregion. The combination of the frontier point sampling method and hierarchical planning strategy reduces the complexity of the planning problem and mitigates the issue of region remnants during the exploration process. Detailed simulation and real world experiments demonstrate the effectiveness and efficiency of our approach in various aspects. The source code will be released to benefit the further research.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t8_06">
             09:00-10:00, Paper FrPI6T8.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1155'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Robot Multi-Goal Mission Planning in Terrains of Varying Energy Consumption
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354185" title="Click to go to the Author Index">
             Herynek, JÃ¡chym
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#133832" title="Click to go to the Author Index">
             Edelkamp, Stefan
            </a>
           </td>
           <td class="r">
            Computer Science &amp; Artificial Intelligence Center Faculty of Ele
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1155" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper considers planning missions for a fleet of robots with limited energy. Each robot has size, heading, and velocity and its motion is described by non-linear differential equations. The dynamics of movements, existing obstacles, multiple robots, and waypoints are additional challenges, as the combined task and motion planning procedure prevents collisions. On their long-term missions, robots have to visit several waypoints in a cost-minimizing manner to satisfy the overall mission task. The robots consume energy and have to be recharged. The framework guides expanding a motion tree via a state projection to a discrete problem, whose solutions serve as search heuristics. Our experiments highlight that despite all these challenges, even sizable problem tasks can be solved even for complex environments
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t8_07">
             09:00-10:00, Paper FrPI6T8.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1198'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Framework for Neurosymbolic Goal-Conditioned Continual Learning for Open World Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378310" title="Click to go to the Author Index">
             Lorang, Pierrick
            </a>
           </td>
           <td class="r">
            AIT Austrian Institute of Technology GmbH - Tufts University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276858" title="Click to go to the Author Index">
             Goel, Shivam
            </a>
           </td>
           <td class="r">
            Tufts University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277268" title="Click to go to the Author Index">
             Shukla, Yash
            </a>
           </td>
           <td class="r">
            Tufts University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#164522" title="Click to go to the Author Index">
             Zips, Patrik
            </a>
           </td>
           <td class="r">
            AIT Austrian Institute of Technology GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104328" title="Click to go to the Author Index">
             Scheutz, Matthias
            </a>
           </td>
           <td class="r">
            Tufts University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1198" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#continual_learning" title="Click to go to the Keyword Index">
               Continual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In dynamic open-world environments, agents continually face new challenges due to sudden and unpredictable novelties, hindering Task and Motion Planning (TAMP) in autonomous systems. We introduce a novel TAMP architecture that integrates symbolic planning with reinforcement learning to enable autonomous adaptation in such environments, operating without human guidance. Our approach employs symbolic goal representation within a goal-oriented learning framework, coupled with planner-guided goal identification, effectively managing abrupt changes where traditional reinforcement learning, re-planning, and hybrid methods fall short. Through sequential novelty injections in our experiments, we assess our method's adaptability to continual learning scenarios. Extensive simulations conducted in a robotics domain corroborate the superiority of our approach, demonstrating faster convergence to higher performance compared to traditional methods. The success of our framework in navigating diverse novelty scenarios within a continuous domain underscores its potential for critical real-world applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t8_08">
             09:00-10:00, Paper FrPI6T8.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1415'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Stage Monte Carlo Tree Search for Non-Monotone Object Rearrangement Planning in Narrow Confined Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335370" title="Click to go to the Author Index">
             Ren, Hanwen
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#201200" title="Click to go to the Author Index">
             Qureshi, Ahmed H.
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1415" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Non-monotone object rearrangement planning in confined spaces such as cabinets and shelves is a widely occurring but challenging problem in robotics. Both the robot motion and the available regions for object relocation are highly constrained because of the limited space. This work proposes a Multi-Stage Monte Carlo Tree Search (MS-MCTS) method to solve non-monotone object rearrangement planning problems in confined spaces. Our approach decouples the complex problem into simpler subproblems using an object stage topology. A subgoal-focused tree expansion algorithm that jointly considers the high-level planning and the low-level robot motion is designed to reduce the search space and better guide the search process. By fitting the task into the MCTS paradigm, our method generates short object rearrangement sequences by balancing exploration and exploitation. The experiments demonstrate that our method outperforms the existing methods in terms of the planning time, the number of steps, the object moving distance and the gripper moving distance. Moreover, we deploy our MS-MCTS to a real-world robot system and verify its performance in different scenarios.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t8_09">
             09:00-10:00, Paper FrPI6T8.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2040'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LLM^3: Large Language Model-Based Task and Motion Planning with Motion Failure Reasoning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#220064" title="Click to go to the Author Index">
             Wang, Shu
            </a>
           </td>
           <td class="r">
            UCLA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#235820" title="Click to go to the Author Index">
             Han, Muzhi
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191567" title="Click to go to the Author Index">
             Jiao, Ziyuan
            </a>
           </td>
           <td class="r">
            Beijing Institute for General Artificial Intelligence
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#233455" title="Click to go to the Author Index">
             Zhang, Zeyu
            </a>
           </td>
           <td class="r">
            Beijing Institute for General Artificial Intelligence
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291151" title="Click to go to the Author Index">
             Wu, Ying Nian
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#170029" title="Click to go to the Author Index">
             Zhu, Song-Chun
            </a>
           </td>
           <td class="r">
            UCLA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196468" title="Click to go to the Author Index">
             Liu, Hangxin
            </a>
           </td>
           <td class="r">
            Beijing Institute for General Artificial Intelligence (BIGAI)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2040" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Conventional Task and Motion Planning (TAMP)approaches rely on manually designed interfaces connecting symbolic task planning with continuous motion generation. These domain-specific and labor-intensive modules are limited in addressing emerging tasks in real-world settings. Here, we present LLM^3, a novel LLM-based TAMP framework featuring a domain-independent interface. Specifically, we leverage the powerful reasoning and planning capabilities of pre-trained LLM to propose symbolic action sequences and select continuous action parameters for motion planning. Crucially, LLM^3 incorporates motion planning feedback through prompting, allowing the LLM to iteratively refine its proposals by reasoning about motion failure. Consequently, LLM^3 interfaces between task planning and motion planning, alleviating the intricate design process of handling domain-specific messages between them. Through a series of simulations in a box-packing domain, we quantitatively demonstrate the effectiveness of LLM^3 in solving TAMP problems and the efficiency in selecting action parameters. Ablation studies underscore the significant contribution of motion failure reasoning to the success of LLM^3. Furthermore, we conduct qualitative experiments on a physical manipulator, demonstrating the practical applicability of our approach in real-world settings.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t8_11">
             09:00-10:00, Paper FrPI6T8.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2237'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              StratXplore: Strategic Novelty-Seeking and Instruction-Aligned Exploration for Vision and Language Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#346795" title="Click to go to the Author Index">
             Gopinathan, Muraleekrishna
            </a>
           </td>
           <td class="r">
            Edith Cowan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#125090" title="Click to go to the Author Index">
             Abu-Khalaf, Jumana
            </a>
           </td>
           <td class="r">
            Edith Cowan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375658" title="Click to go to the Author Index">
             Suter, David
            </a>
           </td>
           <td class="r">
            Edith Cowan University, School of Science, Centre of AI and Mach
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#180892" title="Click to go to the Author Index">
             Masek, Martin
            </a>
           </td>
           <td class="r">
            ECU
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2237" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Embodied navigation requires robots to understand and interact with the environment based on given tasks. Vision-Language Navigation (VLN) is an embodied navigation task, where a robot navigates within a previously seen and unseen environment, based on linguistic instruction and visual inputs. VLN agents need access to both local and global action spaces; former for immediate decision making and the latter for recovering from navigational mistakes. Prior VLN agents rely only on instruction-viewpoint alignment for local and global decision making and back-track to a previously visited viewpoint, if the instruction and its current viewpoint mismatches. These methods are prone to mistakes, due to the complexity of the instruction and partial observability of the environment. We posit that, back-tracking is sub-optimal and agent that is aware of its mistakes can recover efficiently. For optimal recovery, exploration should be extended to unexplored viewpoints (or frontiers). The optimal frontier is a recently observed but unexplored viewpoint that aligns with the instruction and is novel. We introduce a memory-based and mistake-aware path planning strategy for VLN agents, called StratXplore, that presents global and local action planning to select the optimal frontier for path correction. The proposed method collects all past actions and viewpoint features during navigation and then selects the optimal frontier suitable for recovery. Experimental results show this simple yet effective strategy improves the success rate on two VLN datasets with different task complexities.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t8_12">
             09:00-10:00, Paper FrPI6T8.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2767'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Efficient Target Singulation with Multi-Fingered Gripper Using Propositional Logic
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#320179" title="Click to go to the Author Index">
             Kim, Hyojeong
            </a>
           </td>
           <td class="r">
            Korea Institute of Science and Technology (KIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#364101" title="Click to go to the Author Index">
             Jo, Jeong Yong
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#116455" title="Click to go to the Author Index">
             Lim, Myo-Taeg
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109726" title="Click to go to the Author Index">
             Kim, ChangHwan
            </a>
           </td>
           <td class="r">
            Korea Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2767" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             When multiple tablewares are closely packed on a table, rearranging obstacles to make space is necessary to grasp the target, often called target singulation. Due to the nature of handling fragile tablewares (i.e. plates, bowls), we make a few assumptions for the target singulation problem. First, tableware is grasped with a multi-fingered gripper; second, rearrangement is based on prehensile motions like pick-and- place. Under these assumptions, we aim to generate a relocation plan that guarantees global optimality. Furthermore, if any relocation plan cannot singulate the target, we aim to determine it quickly. Therefore, we propose a search method that utilizes the relationship between the object and its nearby obstacles expressed in propositional logic. We define the problem as determining logical entailment (i.e., whether the target can be singulated) and expand the search tree from the target while generating an optimal relocation plan. We demonstrate the performance of our algorithm by increasing the number of objects and validate the plan in a simulation environment.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t8_13">
             09:00-10:00, Paper FrPI6T8.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2919'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Reactive Temporal Logic-Based Planning and Control for Interactive Robotic Tasks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379306" title="Click to go to the Author Index">
             Savvas Sadiq Ali, Farhad Nawaz
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#360030" title="Click to go to the Author Index">
             Peng, Shaoting
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#298188" title="Click to go to the Author Index">
             Lindemann, Lars
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#151054" title="Click to go to the Author Index">
             Figueroa, Nadia
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#121906" title="Click to go to the Author Index">
             Matni, Nikolai
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2919" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#formal_methods_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Formal Methods in Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robots interacting with humans must be safe, reactive and adapt online to unforeseen environmental and task changes. Achieving these requirements concurrently is a challenge as interactive planners lack formal safety guarantees, while safe motion planners lack flexibility to adapt. To tackle this, we propose a modular control architecture that generates both safe and reactive motion plans for human-robot interaction by integrating temporal logic-based discrete task level plans with continuous Dynamical System (DS)-based motion plans. We formulate a reactive temporal logic formula that enables users to define task specifications through structured language, and propose a planning algorithm at the task level that generates a sequence of desired robot behaviors while being adaptive to environmental changes. At the motion level, we incorporate control Lyapunov functions and control barrier functions to compute stable and safe continuous motion plans for two types of robot behaviors: (i) complex, possibly periodic motions given by autonomous DS and (ii) time-critical tasks specified by Signal Temporal Logic~(STL). Our methodology is demonstrated on the Franka robot arm performing wiping tasks on a whiteboard and a mannequin that is compliant to human interactions and adaptive to environmental changes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t8_14">
             09:00-10:00, Paper FrPI6T8.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1216'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              NLNS-MASPF for Solving Multi-Agent Scheduling and Path-Finding
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353782" title="Click to go to the Author Index">
             Park, Heemang
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#325437" title="Click to go to the Author Index">
             Ahn, Kyuree
            </a>
           </td>
           <td class="r">
            Omelet
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#325410" title="Click to go to the Author Index">
             Park, Jinkyoo
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1216" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we propose a novel method, NLNS-MASPF, to solve the Multi-Agent Scheduling and Pathfinding (MASPF) problem. The problem exhibits a bi-level structure, consisting of High-level Scheduling and Low-level Pathfinding. Our method applies a graph neural network in the high-level scheduling process and utilizes a MAPF solver with a schedule segmenting technique in the low-level pathfinding process. Through these approaches, NLNS-MASPF has experimentally demonstrated superior performance compared to the previous state-of-the-art MASPF algorithm, LNS-PBS, in solving the MASPF problem.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t8_15">
             09:00-10:00, Paper FrPI6T8.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1747'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DoReMi: Grounding Language Model by Detecting and Recovering from Plan-Execution Misalignment
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#341977" title="Click to go to the Author Index">
             Guo, Yanjiang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352359" title="Click to go to the Author Index">
             Wang, Yen-Jen
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378900" title="Click to go to the Author Index">
             Zha, Lihan
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#178628" title="Click to go to the Author Index">
             Chen, Jianyu
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1747" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Large language models (LLMs) encode a vast amount of semantic knowledge and possess remarkable understanding and reasoning capabilities. Previous work has explored how to ground LLMs in robotic tasks to generate feasible and executable textual plans. However, low-level execution in the physical world may deviate from the high-level textual plan due to environmental perturbations or imperfect controller design. In this paper, we propose textbf{DoReMi}, a novel language model grounding framework that enables immediate Detection and Recovery from Misalignments between plan and execution. Specifically, we leverage LLMs to play a dual role, aiding not only in high-level planning but also generating constraints that can indicate misalignment during execution. Then vision language models (VLMs) are utilized to detect constraint violations continuously. Our pipeline can monitor the low-level execution and enable timely recovery if certain plan-execution misalignment occurs. Experiments on various complex tasks including robot arms and humanoid robots demonstrate that our method can lead to higher task success rates and shorter task completion times.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t8_16">
             09:00-10:00, Paper FrPI6T8.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2817'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Sequential Discrete Action Selection Via Blocking Conditions and Resolutions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398604" title="Click to go to the Author Index">
             Merz Hoffmeister, Liam
            </a>
           </td>
           <td class="r">
            Yale University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106996" title="Click to go to the Author Index">
             Scassellati, Brian
            </a>
           </td>
           <td class="r">
            Yale
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195948" title="Click to go to the Author Index">
             Rakita, Daniel
            </a>
           </td>
           <td class="r">
            Yale University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2817" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we introduce a strategy that frames the sequential action selection problem for robots in terms of resolving blocking conditions, i.e., situations that impede progress on an action en route to a goal. This strategy allows a robot to make one-at-a-time decisions that take in pertinent contextual information and swiftly adapt and react to current situations. We present a first instantiation of this strategy that combines a state-transition graph and a zero-shot Large Language Model (LLM).	The state-transition graph tracks which previously attempted actions are currently blocked and which candidate actions may resolve existing blocking conditions. This information from the state-transition graph is used to automatically generate a prompt for the LLM, which then uses the given context and set of possible actions to select a single action to try next. This selection process is iterative, with each chosen and executed action further refining the state-transition graph, continuing until the agent either fulfills the goal criteria or encounters a termination condition.	We demonstrate the effectiveness of our approach by comparing it to various LLM and traditional task-planning methods in a testbed of simulation experiments. We discuss the implications of our work based on our results.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t8_17">
             09:00-10:00, Paper FrPI6T8.17
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3125'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SMART-LLM: Smart Multi-Agent Robot Task Planning Using Large Language Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#226469" title="Click to go to the Author Index">
             Kannan, Shyam Sundar
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#243484" title="Click to go to the Author Index">
             Venkatesh, L.N Vishnunandan
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#164680" title="Click to go to the Author Index">
             Min, Byung-Cheol
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3125" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we introduce SMART-LLM, an innovative framework designed for embodied multi-robot task planning. SMART-LLM: Smart Multi-Agent Robot Task Planning using Large Language Models (LLMs), harnesses the power of LLMs to convert high-level task instructions provided as input into a multi-robot task plan. It accomplishes this by executing a series of stages, including task decomposition, coalition formation, and task allocation, all guided by programmatic LLM prompts within the few-shot prompting paradigm. We create a benchmark dataset designed for validating the multi-robot task planning problem, encompassing four distinct categories of high-level instructions that vary in task complexity. Our evaluation experiments span both simulation and real-world scenarios, demonstrating that the proposed model can achieve promising results for generating multi-robot task plans. The experimental videos, code, and datasets from the work can be found at https://sites.google.com/view/smart-llm/.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frpi6t9">
             <b>
              FrPI6T9
             </b>
            </a>
           </td>
           <td class="r">
            Room 9
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frpi6t9" title="Click to go to the Program at a Glance">
             <b>
              Telerobotics and Teleoperation
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#115196" title="Click to go to the Author Index">
             Piater, Justus
            </a>
           </td>
           <td class="r">
            University of Innsbruck
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t9_01">
             09:00-10:00, Paper FrPI6T9.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('120'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Local Linearity Is All You Need (in Data Driven Teleoperation)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291199" title="Click to go to the Author Index">
             Przystupa, Michael
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#373704" title="Click to go to the Author Index">
             Gidel, Gauthier
            </a>
           </td>
           <td class="r">
            UniversitÃ© De MontrÃ©al
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#143233" title="Click to go to the Author Index">
             Taylor, Matthew
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106699" title="Click to go to the Author Index">
             Jagersand, Martin
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#115196" title="Click to go to the Author Index">
             Piater, Justus
            </a>
           </td>
           <td class="r">
            University of Innsbruck
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#216431" title="Click to go to the Author Index">
             Tosatto, Samuele
            </a>
           </td>
           <td class="r">
            University of Innsbruck
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab120" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             One of the critical aspects of assistive robotics is to provide a control system of a high-dimensional robot from a low-dimensional user input (i.e. a 2D joystick). Data-driven teleoperation seeks to provide an intuitive user interface called an action map to map the low dimensional input to robot velocities from human demonstrations. Action maps are machine learning models trained on robotic demonstration data to map user input directly to desired movements as opposed to aspects of robot pose (â€œmove to cup or pour contentâ€ vs. â€œmove along x- or y-axisâ€). Many works have investigated nonlinear action maps with multi-layer perceptrons, but recent work suggests that local-linear neural approximations provide better control of the system. However, local linear models assume actions exist on a linear subspace and may not capture nuanced motions in training data. In this work, we hypothesize that local-linear neural networks are effective because they make the action map odd w.r.t. the user input, enhancing the intuitiveness of the controller. Based on this assumption, we propose two nonlinear means of encoding odd behavior that do not constrain the action map to a local linear function. However, our analysis reveals that these models effectively behave like local linear models for relevant mappings between user joysticks and robot movements. We support this claim in simulation, and show on a realworld use case that there is no statistical benefit of using non-linear maps, according to the users experience. These negative results suggest that further investigation into model architectures beyond local linear models may offer diminishing returns for improving user experience in data-driven teleoperation systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t9_02">
             09:00-10:00, Paper FrPI6T9.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('433'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GELLO: A General, Low-Cost, and Intuitive Teleoperation Framework for Robot Manipulators
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#233715" title="Click to go to the Author Index">
             Wu, Shiyao
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#204951" title="Click to go to the Author Index">
             Shentu, Yide
            </a>
           </td>
           <td class="r">
            University of California -- Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379028" title="Click to go to the Author Index">
             Yi, Zhongke
            </a>
           </td>
           <td class="r">
            Covariant
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#234074" title="Click to go to the Author Index">
             Lin, Xingyu
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107568" title="Click to go to the Author Index">
             Abbeel, Pieter
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab433" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#bimanual_manipulation" title="Click to go to the Keyword Index">
               Bimanual Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Humans can teleoperate robots to accomplish complex manipulation tasks. Imitation learning has emerged as a powerful framework that leverages human teleoperated demonstrations to teach robots new skills. However, the performance of the learned policies is bottlenecked by the quality, scale, and variety of the demonstration data. In this paper, we aim to lower the barrier to collecting large and high-quality human demonstration data by proposing a GEneraL framework for building LOw-cost and intuitive teleoperation systems for robotic manipulation (GELLO). Given a target robot arm, we build a GELLO controller device that has the same kinematic structure as the target arm, leveraging 3D-printed parts and economical off-the-shelf motors. GELLO is easy to build and intuitive to use. Through an extensive user study, we show that GELLO enables more reliable and efficient demonstration collection compared to other cost efficient teleoperation devices commonly used in the imitation learning literature such as virtual reality controllers and 3D spacemouses. We further demonstrate the capabilities of GELLO for performing complex bi-manual and contact-rich manipulation tasks. To make GELLO accessible to everyone, we have designed and built GELLO systems for 3 commonly used robotic arms: Franka, UR5, and xArm. All software and hardware are open-sourced and can be found on our website: https://wuphilipp.github.io/gello/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t9_03">
             09:00-10:00, Paper FrPI6T9.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('592'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Real-Time Dexterous Telemanipulation with an End-Effect-Oriented Learning-Based Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392478" title="Click to go to the Author Index">
             Wang, Haoyang
            </a>
           </td>
           <td class="r">
            Oklahoma State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#120483" title="Click to go to the Author Index">
             Bai, He
            </a>
           </td>
           <td class="r">
            Oklahoma State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#178583" title="Click to go to the Author Index">
             Zhang, Xiaoli
            </a>
           </td>
           <td class="r">
            Colorado School of Mines
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#293539" title="Click to go to the Author Index">
             Jung, Yunsik
            </a>
           </td>
           <td class="r">
            Colorado School of Mines
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237053" title="Click to go to the Author Index">
             Bowman, Michael
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277262" title="Click to go to the Author Index">
             Tao, Lingfeng
            </a>
           </td>
           <td class="r">
            Oklahoma State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab592" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Dexterous telemanipulation is crucial in advancing human-robot systems, especially in tasks requiring precise and safe manipulation. However, it faces significant challenges due to the physical differences between human and robotic hands, the dynamic interaction with objects, and the indirect control and perception of the remote environment. Current approaches predominantly focus on mapping the human hand onto robotic counterparts to replicate motions, which exhibits a critical oversight: it often neglects the physical interaction with objects and relegates the interaction burden to the human to adapt and make laborious adjustments in response to the indirect and counter-intuitive observation of the remote environment. This work develops an End-Effects-Oriented Learning-based Dexterous Telemanipulation (EFOLD) framework to address telemanipulation tasks. EFOLD models telemanipulation as a Markov Game, introducing multiple end-effect features to interpret the human operator's commands during interaction with objects. These features are used by a Deep Reinforcement Learning policy to control the robot and reproduce such end effects. EFOLD was evaluated with real human subjects and two end-effect extraction methods for controlling a virtual Shadow Robot Hand in telemanipulation tasks. EFOLD achieved real-time control capability with low command following latency (delay&lt;0.11s) and highly accurate tracking (MSE&lt;0.084 rad).
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t9_04">
             09:00-10:00, Paper FrPI6T9.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('794'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Development of a Bilateral Control Teleoperation System for Bipedal Humanoid Robot Utilizing Foot Sole Haptics Feedback
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#344470" title="Click to go to the Author Index">
             Shen, Yang
            </a>
           </td>
           <td class="r">
            Faculty of Science and Engineering, Waseda University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394027" title="Click to go to the Author Index">
             Kanazawa, Masanobu
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394030" title="Click to go to the Author Index">
             Mori, Kazuki
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#344471" title="Click to go to the Author Index">
             Isono, Ryu
            </a>
           </td>
           <td class="r">
            Faculty of Science and Engineering, Waseda University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353057" title="Click to go to the Author Index">
             Nakazawa, Yuri
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102287" title="Click to go to the Author Index">
             Takanishi, Atsuo
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#140460" title="Click to go to the Author Index">
             Otani, Takuya
            </a>
           </td>
           <td class="r">
            Shibaura Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab794" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#haptics_and_haptic_interfaces" title="Click to go to the Keyword Index">
               Haptics and Haptic Interfaces
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#humanoid_robot_systems" title="Click to go to the Keyword Index">
               Humanoid Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Teleoperating bipedal humanoid robots presents unique challenges, including decreased stability and reduced operator presence. This paper addresses these challenges by proposing a method that leverages the operator's inherent sense of stability by feedback from a sole haptics display to operate a bipedal humanoid robot. We developed a bilateral control system that integrates a device replicating sole haptics feedback and provides the operator with feedback on changes in the robotâ€™s center of gravity. We conducted operating experiments in the forward-backward direction to evaluate its effectiveness and investigate the effectiveness of sole haptics on robot operation. The results demonstrate that operating with both vision and sole haptics feedback significantly reduces the robot's fall rate by over 56% when disturbances are applied, compared to using only vision feedback. Moreover, operators reported a 21% higher sense of presence with both vision and sole haptics feedback compared to using only vision feedback.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t9_05">
             09:00-10:00, Paper FrPI6T9.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1261'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Immersive Human-In-The-Loop Control: Real-Time 3D Surface Meshing and Physics Simulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#342454" title="Click to go to the Author Index">
             Akturk, Sait
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376406" title="Click to go to the Author Index">
             Valentine, Justin
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#342451" title="Click to go to the Author Index">
             Ahmad, Junaid
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106699" title="Click to go to the Author Index">
             Jagersand, Martin
            </a>
           </td>
           <td class="r">
            University of Alberta
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1261" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#virtual_reality_and_interfaces" title="Click to go to the Keyword Index">
               Virtual Reality and Interfaces
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces the TactiMesh Teleoperator Interface (TTI), a novel predictive visual and haptic system designed explicitly for human-in-the-loop robot control using a head-mounted display (HMD). By employing simultaneous localization and mapping (SLAM) in tandem with a space carving method (CARV), TTI creates a real-time 3D surface mesh of remote environments from an RGB camera mounted on a Barrett WAM arm. The generated mesh is integrated into a physics simulator, featuring a digital twin of the WAM robot arm to create a virtual environment. In this virtual environment, TTI provides haptic feedback directly in response to the operatorâ€™s movements, eliminating the problem with delayed response from the haptic follower robot. Furthermore, texturing the 3D mesh with keyframes from SLAM allows the operator to control the viewpoint of their Head Mounted Dis- play (HMD) independently of the arm-mounted robot camera, giving a better visual immersion and improving manipulation speed. Incorporating predictive visual and haptic feedback significantly improves tele-operation in applications such as search and rescue, inspection, and remote maintenance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t9_06">
             09:00-10:00, Paper FrPI6T9.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1928'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              6D Variable Virtual Fixtures for Telemanipulated Insertion Tasks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#322340" title="Click to go to the Author Index">
             Schwarz, Stephan Andreas
            </a>
           </td>
           <td class="r">
            Chemnitz University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105723" title="Click to go to the Author Index">
             Thomas, Ulrike
            </a>
           </td>
           <td class="r">
            Chemnitz University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1928" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#safety_in_hri" title="Click to go to the Keyword Index">
               Safety in HRI
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Telemanipulation enables humans to perform tasks in dangerous environments without exposing them to any risk. The COVID-19 pandemic sadly showed, that these environments can also include the treatment and interaction with infected patients. Since human-robot interactions demand for low interaction forces yet high precision, telemanipulation often results in a high mental workload for the operator. To overcome this, we present a virtual guidance approach to perform telemanipulated insertion tasks. A nasopharyngeal swap sampling procedure is taken as use case. We extend our previously presented approach by adding an additional position fixture, introducing distance-dependent variable stiffness values and guaranteeing stability using energy tanks. Based on RGB-D data, the operator is guided towards a desirable insertion line while approaching the nostril. The distance-dependent stiffness values increase the smoothness of the fixture. Since variable stiffness values can result in unstable behavior, energy tanks for the fixtures are introduced. Experiments show the improvements compared to our previous approach. Further, a comparison between guided and unguided samplings performed by an expert user gives a first impression of the improvements resulting from the fixture.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t9_07">
             09:00-10:00, Paper FrPI6T9.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2327'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Evaluation of Predictive Display for Teleoperated Driving Using CARLA Simulator
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#367855" title="Click to go to the Author Index">
             Kashwani, Fatima
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#333626" title="Click to go to the Author Index">
             Hassan, Bilal
            </a>
           </td>
           <td class="r">
            Khalifa University, Abu Dhabi
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380019" title="Click to go to the Author Index">
             Kong, Peng-Yong
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#267359" title="Click to go to the Author Index">
             Khonji, Majid
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101631" title="Click to go to the Author Index">
             Dias, Jorge
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2327" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Before the world-wide deployment of autonomous vehicles, it is essential to implement intermediate solutions with partial autonomy. One such solution is the use of vehicle teleoperation, the act of controlling a vehicle from a distance. In real time applications of teleoperation, it is often pertinent to use augmented reality components within the teleoperator view, which are referred to as a predictive display. In this work, we evaluate our predictive display method, which is a guiding path based on the free space in the environment. The path is generated based on our Dual Transformer Network (DTNet), which uses both object detection and lane semantic segmentation to define the free space in the environment. While the model has previously performed well on image data, it is necessary to observe its accuracy in the presence of time delay and packet loss, to assess its performance in a real-time setting. Thus, in this work, we use CARLA simulator to compare the detected free space on the teleoperator side to the true free space on the vehicle side across different values of time delay and packet loss. Under optimal network conditions, our model yielded a remarkable 87.9% DSC score and 81.3% IoU score. Defining our minimum performance threshold as 80% DSC and 70% IoU, we conclude that our model can effectively mitigate the challenges of time delay below 100ms and packet loss below 1%, both of which represent substantial tolerances.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t9_08">
             09:00-10:00, Paper FrPI6T9.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2388'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              User-Customizable Shared Control for Robot Teleoperation Via Virtual Reality
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#246859" title="Click to go to the Author Index">
             Luo, Rui
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#226883" title="Click to go to the Author Index">
             Zolotas, Mark
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378917" title="Click to go to the Author Index">
             Moore, Drake
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#129456" title="Click to go to the Author Index">
             Padir, Taskin
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2388" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_factors_and_human_in_the_loop" title="Click to go to the Keyword Index">
               Human Factors and Human-in-the-Loop
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#virtual_reality_and_interfaces" title="Click to go to the Keyword Index">
               Virtual Reality and Interfaces
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Shared control can ease and enhance a human operator's ability to teleoperate robots, particularly for intricate tasks demanding fine control over multiple degrees of freedom. However, the arbitration process dictating how much autonomous assistance to administer in shared control can confuse novice operators and impede their understanding of the robot's behavior. To overcome these adverse side-effects, we propose a novel formulation of shared control that enables operators to tailor the arbitration to their unique capabilities and preferences. Unlike prior approaches to customizable shared control where users could indirectly modify the latent parameters of the arbitration function by issuing a feedback command, we instead make these parameters observable and directly editable via a virtual reality (VR) interface. We present our user-customizable shared control method for a teleoperation task in SE(3), known as the buzz wire game. A user study is conducted with participants teleoperating a robotic arm in VR to complete the game. The experiment spanned two weeks per subject to investigate longitudinal trends. Our findings reveal that users allowed to interactively tune the arbitration parameters across trials generalize well to adaptations in the task, exhibiting improvements in precision and fluency over direct teleoperation and conventional shared control.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t9_09">
             09:00-10:00, Paper FrPI6T9.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2426'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Exploring Cognitive Load Dynamics in Human-Machine Interaction for Teleoperation: A User-Centric Perspective on Remote Operation System Design
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398029" title="Click to go to the Author Index">
             GarcÃ­a CÃ¡rdenas, Juan JosÃ©
            </a>
           </td>
           <td class="r">
            ENSTA - Institute Polytechinique De Paris
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#290413" title="Click to go to the Author Index">
             Hei, Xiaoxuan
            </a>
           </td>
           <td class="r">
            ENSTA Paris, Institut Polytechnique De Paris
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106757" title="Click to go to the Author Index">
             Tapus, Adriana
            </a>
           </td>
           <td class="r">
            ENSTA Paris, Institut Polytechnique De Paris
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2426" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_factors_and_human_in_the_loop" title="Click to go to the Keyword Index">
               Human Factors and Human-in-the-Loop
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#design_and_human_factors" title="Click to go to the Keyword Index">
               Design and Human Factors
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Teleoperated robots, especially in hazardous environments, integrate human cognition with machine efficiency, but can increase cognitive load, causing stress and reducing task performance and safety. This study examines the impact of the information available to the operator on cognitive load, physiological responses (e.g., GSR, blinking, facial temperature), and performance during teleoperation in three conditions: C1 - in presence, C2 - remote with Visual feedback, and C3 - remote with telepresence robot. The findings from our user study involving 20 participants show that information availability significantly impacts perceived cognitive load, as evidenced by the differences observed between conditions in our analysis. Furthermore, the results indicated that blinking rates varied significantly among the conditions. The results also underline that individuals with higher error scores on the spatial orientation test (SOT), reflecting lower spatial ability, are more likely to experience failure in conditions 2 and 3. The results show that information availability significantly affects cognitive load and teleoperation performance, especially depth perception of the robot's actions. Additionally, the thermal and GSR data findings indicate an increase in stress and anxiety levels when operators perform conditions 2 and 3, thus corroborating an increase in the user's cognitive load.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t9_10">
             09:00-10:00, Paper FrPI6T9.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2504'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Deep Learning-Based Delay Compensation Framework for Teleoperated Wheeled Rovers on Soft Terrains
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366425" title="Click to go to the Author Index">
             Abubakar, Ahmad
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#328150" title="Click to go to the Author Index">
             Zweiri, Yahya
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366427" title="Click to go to the Author Index">
             Yakubu, Mubarak
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#367371" title="Click to go to the Author Index">
             Alhammadi, Ruqqayya
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366423" title="Click to go to the Author Index">
             Mohiuddin, Mohammed
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377969" title="Click to go to the Author Index">
             Haddad, Abdel Gafoor
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101631" title="Click to go to the Author Index">
             Dias, Jorge
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#360178" title="Click to go to the Author Index">
             Seneviratne, Lakmal
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2504" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The difficulties posed by terrain-induced slippage for wheeled rovers traversing soft terrains are critical to ensuring safe and precise mobility. While bilateral teleoperation systems offer a promising solution to this issue, the inherent network-induced delays hinder the fidelity of the closed-loop integration, potentially compromising teleoperator system controls, and resulting in poor command-tracking performance. This work introduces a new model-free predictor framework based on deep learning designed to improve prediction performance and effectively compensate for large network delays in teleoperated wheeled rovers. Our approach employs the Recurrent Neural Network (RNN) to achieve a significant improvement in modeling complexity and prediction accuracy. Particularly, our framework consists of two distinct predictors, each tailored to the forward and backward coupling variables of the teleoperated wheeled rover. Human-in-the-loop experiments were conducted to validate the effectiveness of the developed framework in compensating for the delays encountered by teleoperated wheeled rovers coupled with terrain-induced slippage. The results confirm the improved prediction accuracy of the framework. This improvement is evidenced by improved performance and transparency metrics, which lead to better command-tracking performance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t9_11">
             09:00-10:00, Paper FrPI6T9.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2534'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Optimization Based Scheme for Real-Time Transfer of Human Arm Motion to Robot Arm
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378184" title="Click to go to the Author Index">
             Yang, Zhelin
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#341897" title="Click to go to the Author Index">
             Bien, Seongjin
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339117" title="Click to go to the Author Index">
             Nertinger, Simone
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#239366" title="Click to go to the Author Index">
             Naceri, Abdeldjallil
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108317" title="Click to go to the Author Index">
             Haddadin, Sami
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2534" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Performing human-like motion is crucial for service humanoid robots. Real-time motion retargeting allows clear observation of the robot's pose and provides instant feedback during human demonstrator actions. This paper presents an optimization-based real-time anthropomorphic motion retargeting framework for transferring human arm motion to a robot arm. The framework is generic, applicable to both spherical-rotational-spherical (SRS) and non-SRS robot arms. We introduce the normalized normal vector of the arm plane as an anthropomorphic criterion within our framework. The method is validated on a service humanoid robot, with both static and dynamic evaluations. The statistical analysis show that our method maintains strong anthropomorphic features while ensuring accurate wrist pose tracking.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t9_12">
             09:00-10:00, Paper FrPI6T9.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2554'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Tetherless Soft Robotic Wearable Haptic Human Machine Interface for Robot Teleoperation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#233211" title="Click to go to the Author Index">
             Thakur, Shilpa
            </a>
           </td>
           <td class="r">
            Worcester Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398056" title="Click to go to the Author Index">
             Diaz Armas, Nathalia
            </a>
           </td>
           <td class="r">
            University of Massachusetts Lowell
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398116" title="Click to go to the Author Index">
             Adegite, Joseph
            </a>
           </td>
           <td class="r">
            Worcester Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383172" title="Click to go to the Author Index">
             Pandey, Ritwik
            </a>
           </td>
           <td class="r">
            Worcester Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398242" title="Click to go to the Author Index">
             Mead, Joey
            </a>
           </td>
           <td class="r">
            University of Massachusetts Lowell
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383176" title="Click to go to the Author Index">
             Rao, Pratap
            </a>
           </td>
           <td class="r">
            Worcester Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108473" title="Click to go to the Author Index">
             Onal, Cagdas
            </a>
           </td>
           <td class="r">
            WPI
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2554" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#haptics_and_haptic_interfaces" title="Click to go to the Keyword Index">
               Haptics and Haptic Interfaces
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work describes the development, demonstration, and performance evaluation study of a wearable human machine interface (HMI) for robotic teleoperation. We present a novel tetherless HMI in the form of a backpack, body-worn 3-D arm motion capture sensors, finger flexion sensors, and haptic feedback muscles embedded in a glove. The system is integrated in a complete teleoperation framework, enabling users to be immersed in a remote environment through virtual reality headgear, facilitating intuitive manipulation of an industrial articulated arm. The designed HMI measures the kinematic configuration of the userâ€™s arm, hand and fingers using multiple inertial measurement units (IMUs) and capacitive sensors respectively. Subsequently, the captured data is channeled into the teleoperation software stack. The gripping forces experienced at the robotâ€™s end-effector are acquired using a custom three-dimensional Hall-effect magnetic sensor. The system simultaneously renders the kinesthetic and tactile feedback on the userâ€™s fingers through custom designed pneumatically actuated soft robotic haptic muscles. The efficacy of the HMI and the teleoperation system was tested and evaluated by conducting user study experiments, which showed 31.4% faster teleoperation vs. a keypad controller and 60% less gripping force exerted when the haptics were enabled. The findings of the pilot study guided the design and prototype development of a printed electronics based stretchable sleeve and glove motion capture unit to improve the portability, ergonomics and user experience of the HMI.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frpi6t10">
             <b>
              FrPI6T10
             </b>
            </a>
           </td>
           <td class="r">
            Room 10
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frpi6t10" title="Click to go to the Program at a Glance">
             <b>
              Simultaneous Localization and Mapping (SLAM) VI
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#205136" title="Click to go to the Author Index">
             Yue, Yufeng
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#289521" title="Click to go to the Author Index">
             Kornilova, Anastasiia
            </a>
           </td>
           <td class="r">
            Skolkovo Institute of Science and Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t10_01">
             09:00-10:00, Paper FrPI6T10.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3315'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              PS-Loc: Robust LiDAR Localization with Prior Structural Reference
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340531" title="Click to go to the Author Index">
             Li, Rui
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338644" title="Click to go to the Author Index">
             Zhao, Wentao
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#312315" title="Click to go to the Author Index">
             Deng, Tianchen
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335698" title="Click to go to the Author Index">
             Yanbo, Wang
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122983" title="Click to go to the Author Index">
             Wang, Jingchuan
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3315" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Prior structural reference like floor plan is readily accessible in indoor scene, which exhibits the potential of improving localization quality without the requirements of a previously-built high-precision map. This paper introduces a novel optimal transport-based framework for prior structural reference-based localization, aiming to improve the robustness for the robot localization. Leveraging the spacial relations of structures, a matching method based on optimal transport theory is proposed and it improves the robustness of matching results in dynamic scene and rapid rotation conditions. Additionally, this paper handles metric inaccuracies in the known structural reference by implementing an prior guided plane adjustment-based updating strategy. This strategy combines prior and observational information to jointly optimize the structural information within a sliding window. The performance of the framework is validated through real-world experiments, demonstrating superior accuracy and robustness to disturbances from dynamic occlusion and rapid rotation compared to common state-of-the-art SLAM and localization methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t10_02">
             09:00-10:00, Paper FrPI6T10.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('533'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Backpropagation-Based Analytical Derivatives of EKF Covariance for Active Sensing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391031" title="Click to go to the Author Index">
             Benhamou, Jonas
            </a>
           </td>
           <td class="r">
            Mines Paris/Safran
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#124754" title="Click to go to the Author Index">
             Bonnabel, Silvere
            </a>
           </td>
           <td class="r">
            Mines ParisTech
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371241" title="Click to go to the Author Index">
             Chapdelaine, Camille
            </a>
           </td>
           <td class="r">
            Safran SA
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab533" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reactive_and_sensor_based_planning" title="Click to go to the Keyword Index">
               Reactive and Sensor-Based Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             To enhance accuracy of robot state estimation, active sensing (or perception-aware) methods seek trajectories that maximize the information gathered by the sensors. To this aim, one possibility is to seek trajectories that minimize the (estimation error) covariance matrix output by an extended Kalman filter (EKF), w.r.t. its control inputs over a given horizon. However, this is computationally demanding. In this article, we derive novel backpropagation analytical formulas for the derivatives of the covariance matrices of an EKF w.r.t. all its inputs. We then leverage the obtained analytical gradients as an enabling technology to derive perception-aware optimal motion plans.	Simulations validate the approach, showcasing improvements in execution time, notably over PyTorch's automatic differentiation. Experimental results on a real vehicle	also support the method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t10_03">
             09:00-10:00, Paper FrPI6T10.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1053'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              EgoVM: Achieving Precise Ego-Localization Using Lightweight Vectorized Maps
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366971" title="Click to go to the Author Index">
             He, Yuzhe
            </a>
           </td>
           <td class="r">
            Baidu
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#252887" title="Click to go to the Author Index">
             Liang, Shuang
            </a>
           </td>
           <td class="r">
            Baidu
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366970" title="Click to go to the Author Index">
             Rui, XiaoFei
            </a>
           </td>
           <td class="r">
            BAIDU
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#296111" title="Click to go to the Author Index">
             Cai, Chengying
            </a>
           </td>
           <td class="r">
            Baidu
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#218917" title="Click to go to the Author Index">
             Wan, Guowei
            </a>
           </td>
           <td class="r">
            Baidu
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1053" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurate and reliable ego-localization is critical for autonomous driving. In this paper, we present EgoVM, an end-to-end localization network that achieves comparable localization accuracy to prior state-of-the-art methods, but uses lightweight vectorized maps instead of heavy point-based maps. To begin with, we extract BEV features from online multi-view images and LiDAR point cloud. Then, we employ a set of learnable semantic embeddings to encode the semantic types of map elements and supervise them with semantic segmentation, to make their feature representation consistent with BEV features. After that, we feed map queries, composed of learnable semantic embeddings and coordinates of map elements, into a transformer decoder to perform cross-modality matching with BEV features. Finally, we adopt a robust histogram-based pose solver to estimate the optimal pose by searching exhaustively over candidate poses. We comprehensively validate the effectiveness of our method using both the nuScenes dataset and a newly collected dataset. The experimental results show that our method achieves centimeter-level localization accuracy, and outperforms existing methods using vectorized maps by a large margin. Furthermore, our model has been extensively tested in a large fleet of autonomous vehicles under various challenging urban scenes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t10_04">
             09:00-10:00, Paper FrPI6T10.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('830'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Deep Sensor Fusion with Constraint Safety Bounds for High Precision Localization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374273" title="Click to go to the Author Index">
             Schmidt, Sebastian
            </a>
           </td>
           <td class="r">
            BMW
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374411" title="Click to go to the Author Index">
             Stumpp, Ludwig
            </a>
           </td>
           <td class="r">
            AppliedAI Initiative GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374468" title="Click to go to the Author Index">
             Valverde Garrro, Diego
            </a>
           </td>
           <td class="r">
            BMW
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#325206" title="Click to go to the Author Index">
             GÃ¼nnemann, Stephan
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab830" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In mobile robotics, particularly in autonomous driving, localization is one of the key challenges for navigation and planning. For safe operation in the open world where vulnerable participants are present, precise and guaranteed safe localization is required. While current classical fusion approaches are safe due to provably bounded closed-form formulation, their situation-adaptivity is limited. In contrast, data-driven approaches are situation-adaptive based on the underlying training data but unbounded and unsafe. In our work, we propose a novel data-driven but provably bounded sensor fusion and apply it to mobile robotic localization. In extensive experiments using an autonomous driving test vehicle, we show that our fusion method outperforms other safe fusion approaches.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t10_05">
             09:00-10:00, Paper FrPI6T10.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1636'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LCP-Fusion: A Neural Implicit SLAM with Enhanced Local Constraints and Computable Prior
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#381480" title="Click to go to the Author Index">
             Wang, Jiahui
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#302001" title="Click to go to the Author Index">
             Deng, Yinan
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#128868" title="Click to go to the Author Index">
             Yang, Yi
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205136" title="Click to go to the Author Index">
             Yue, Yufeng
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1636" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recently the dense Simultaneous Localization and Mapping (SLAM) based on neural implicit representation has shown impressive progress in hole filling and high-fidelity mapping. Nevertheless, existing methods either heavily rely on known scene bounds or suffer inconsistent reconstruction due to drift in potential loop-closure regions, or both, which can be attributed to the inflexible representation and lack of local constraints. In this paper, we present LCP-Fusion, a neural implicit SLAM system with enhanced local constraints and computable prior, which takes the sparse voxel octree structure containing feature grids and SDF priors as hybrid scene representation, enabling the scalability and robustness during mapping and tracking. To enhance the local constraints, we propose a novel sliding window selection strategy based on visual overlap to address the loop-closure, and a practical warping loss to constrain relative poses. Moreover, we estimate SDF priors as coarse initialization for implicit features, which brings additional explicit constraints and robustness, especially when a light but efficient adaptive early ending is adopted. Experiments demonstrate that our method achieve better localization accuracy and reconstruction consistency than existing RGB-D implicit SLAM, especially in challenging real scenes (ScanNet) as well as self-captured scenes with unknown scene bounds. The code is available at https://github.com/laliwang/LCP-Fusion.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t10_06">
             09:00-10:00, Paper FrPI6T10.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3194'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Long-Term Map-Maintenance in Changing Environments Using Ray-Bundle-Impact-Factor Estimation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390832" title="Click to go to the Author Index">
             Breitfuss, Matthias
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#368252" title="Click to go to the Author Index">
             Geimer, Marcus
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#138775" title="Click to go to the Author Index">
             Gruber, Christoph Johannes
            </a>
           </td>
           <td class="r">
            Self-Employed
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3194" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robotics_and_automation_in_construction" title="Click to go to the Keyword Index">
               Robotics and Automation in Construction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Ensuring an accurate and robust localization is one of the most significant problems in the field of mobile robotics. In this context, map-based localization methods utilizing 3D LiDARS for environmental perception are widely used. Even if there exist multiple promising techniques in this field, the majority of approaches can only guarantee an accurate and robust operation if there is no deviation between the map and the real surroundings. Consequently, state of the art localization methods frequently suffer from unreliable results or even complete failure in the case of changing environments. In this paper, we propose an efficient technique for a precise and robust maintenance of localization maps through realtime incorporation of 3D LiDAR scans. Our map update procedure is based on a novel way of estimating the interference between laserbeams and map contents, denoted as Ray-Bundle-Impact-Factor (RBIF). Our technique additionally solves the widespread problem of disruptive hole creation caused by discretization effects. Experiments on real-world as well as synthetic data demonstrate the precision and stability of our method under various challenging conditions and evaluate our approach in comparison to multiple SOTA map maintenance algorithms.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t10_07">
             09:00-10:00, Paper FrPI6T10.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3213'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DeepMIF: Deep Monotonic Implicit Fields for Large-Scale LiDAR 3D Mapping
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395085" title="Click to go to the Author Index">
             Yilmaz, Kutay
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#178676" title="Click to go to the Author Index">
             Niessner, Matthias
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#289521" title="Click to go to the Author Index">
             Kornilova, Anastasiia
            </a>
           </td>
           <td class="r">
            Skolkovo Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277787" title="Click to go to the Author Index">
             Artemov, Alexey
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3213" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recently, significant progress has been achieved in sensing real large-scale outdoor 3D environments, particularly by using modern acquisition equipment such as LiDAR sensors. Unfortunately, they are fundamentally limited in their ability to produce dense, complete 3D scenes. To address this issue, recent learning-based methods integrate neural implicit representations and optimizable feature grids to approximate surfaces of 3D scenes. However, naively fitting samples along raw LiDAR rays leads to noisy 3D mapping results due to the nature of sparse, conflicting LiDAR measurements. Instead, in this work we depart from fitting LiDAR data exactly, instead letting the network optimize a non-metric monotonic implicit field defined in 3D space. To fit our field, we design a learning system integrating a monotonicity loss that enables optimizing neural monotonic fields and leverages recent progress in large-scale 3D mapping. Our algorithm achieves high-quality dense 3D mapping performance as cap- tured by multiple quantitative and perceptual measures and visual results obtained for Mai City, Newer College, and KITTI benchmarks. The code of our approach is publicly available at https://github.com/artonson/deepmif.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t10_08">
             09:00-10:00, Paper FrPI6T10.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3264'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MM-Gaussian: 3D Gaussian-Based Multi-Modal Fusion for Localization and Reconstruction in Unbounded Scenes
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397915" title="Click to go to the Author Index">
             Wu, Chenyang
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#231281" title="Click to go to the Author Index">
             Duan, Yifan
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376912" title="Click to go to the Author Index">
             Zhang, Xinran
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375012" title="Click to go to the Author Index">
             Sheng, Yu
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#148006" title="Click to go to the Author Index">
             Ji, Jianmin
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291452" title="Click to go to the Author Index">
             Zhang, Yanyong
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3264" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Localization and mapping are critical tasks for various applications such as autonomous vehicles and robotics. The challenges posed by outdoor environments present particular complexities due to their unbounded characteristics. In this work, we present MM-Gaussian, a LiDAR-camera multi-modal fusion system for localization and mapping in unbounded scenes. Our approach is inspired by the recently developed 3D Gaussians, which demonstrate remarkable capabilities in achieving high rendering quality and fast rendering speed. Specifically, our system fully utilizes the geometric structure information provided by solid-state LiDAR to address the problem of inaccurate depth encountered when relying solely on visual solutions in unbounded, outdoor scenarios. Additionally, we utilize 3D Gaussian point clouds, with the assistance of pixel-level gradient descent, to fully exploit the color information in photos, thereby achieving realistic rendering effects.To further bolster the robustness of our system, we designed a relocalization module, which assists in returning to the correct trajectory in the event of a localization failure. Experiments conducted in multiple scenarios demonstrate the effectiveness of our method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t10_09">
             09:00-10:00, Paper FrPI6T10.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1233'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Large-Scale Indoor Mapping with Failure Detection and Recovery in SLAM
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196858" title="Click to go to the Author Index">
             Rahman, Sharmin
            </a>
           </td>
           <td class="r">
            Amazon
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#187264" title="Click to go to the Author Index">
             DiPietro, Robert
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390810" title="Click to go to the Author Index">
             Kedarisetti, Dharanish
            </a>
           </td>
           <td class="r">
            Amazon
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395052" title="Click to go to the Author Index">
             Kulathumani, Vinod
            </a>
           </td>
           <td class="r">
            Amazon
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1233" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#failure_detection_and_recovery" title="Click to go to the Keyword Index">
               Failure Detection and Recovery
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper addresses the failure detection and recovery problem in visual-inertial based Simultaneous Localization and Mapping (SLAM) systems for large-scale indoor environments. Camera and Inertial Measurement Unit (IMU) are popular choices for SLAM in many robotics tasks (e.g., navigation) due to their complementary sensing capabilities and low cost. However, vision has inherent challenges even in well-lit scenes, including motion blur, lack of features, or even accidental camera blockage. These failures can cause drifts to accumulate over time and can severely impact the scalability of existing solutions to large areas. To address these issues, we propose an automatic map generation service with (i) a failure detection method based on visual feature tracking quality using a health tracker which identifies and discards faulty measurements and (ii) a continuous session merging approach in SLAM. Taken together, this allows us to handle erroneous data without any manual intervention, and allows us to scale to extremely large spaces. The proposed system has been validated on benchmark datasets. Also, experimental results on multiple custom large-scale grocery stores, each between 1700 m^2 to 3700 m^2, and duration 60 to 80 minutes, are presented. Our approach shows the lowest error in all large-scale SLAM cases when compared with state-of-the-art visual-inertial SLAM packages, which often produce highly erroneous trajectories or lose track. Additionally, we provide dense 3D reconstruction with the presence of a depth camera by simply registering the point cloud from RGB-D image with respect to the SLAM generated trajectory -- and the quality of the reconstruction illustrates the efficacy of our proposed method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t10_10">
             09:00-10:00, Paper FrPI6T10.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1490'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Active Loop Closure for OSM-Guided Robotic Mapping in Large-Scale Urban Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396671" title="Click to go to the Author Index">
             Gao, Wei
            </a>
           </td>
           <td class="r">
            University of Macau
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237428" title="Click to go to the Author Index">
             Sun, Zezhou
            </a>
           </td>
           <td class="r">
            Nanjing University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376539" title="Click to go to the Author Index">
             Zhao, Mingle
            </a>
           </td>
           <td class="r">
            University of Macau
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#259738" title="Click to go to the Author Index">
             Xu, Chengzhong
            </a>
           </td>
           <td class="r">
            University of Macau
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#204275" title="Click to go to the Author Index">
             Kong, Hui
            </a>
           </td>
           <td class="r">
            University of Macau
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1490" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#view_planning_for_slam" title="Click to go to the Keyword Index">
               View Planning for SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The autonomous mapping of large-scale urban scenes presents significant challenges for autonomous robots. To mitigate the challenges, global planning, such as utilizing prior GPS trajectories from OpenStreetMap (OSM), is often used to guide the autonomous navigation of robots for mapping. However, due to factors like complex terrain, unexpected body movement, and sensor noise, the uncertainty of the robot's pose estimates inevitably increases over time, ultimately leading to the failure of robotic mapping. To address this issue, we propose a novel active loop closure procedure, enabling the robot to actively re-plan the previously planned GPS trajectory. The method can guide the robot to re-visit the previous places where the loop-closure detection can be performed to trigger the back-end optimization, effectively reducing errors and uncertainties in pose estimation. The proposed active loop closure mechanism is implemented and embedded into a real-time OSM-guided robot mapping framework. Empirical results on several large-scale outdoor scenarios demonstrate its effectiveness and promising performance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t10_11">
             09:00-10:00, Paper FrPI6T10.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1080'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MOE: A Dense LiDAR Moving Event Dataset, Detection Benchmark and LeaderBoard
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#284178" title="Click to go to the Author Index">
             Chen, Zhiming
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#387851" title="Click to go to the Author Index">
             Fang, Haozhe
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#387479" title="Click to go to the Author Index">
             Chen, Jiapeng
            </a>
           </td>
           <td class="r">
            The Individual Researcher
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100161" title="Click to go to the Author Index">
             Wang, Michael Yu
            </a>
           </td>
           <td class="r">
            Mywang@gbu.edu.cn
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#294459" title="Click to go to the Author Index">
             Yu, Hongyu
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1080" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_slam" title="Click to go to the Keyword Index">
               Data Sets for SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#big_data_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Big Data in Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Detecting moving events produced by moving objects is a crucial task in the realms of autonomous driving and mobile robots. Moving objects have the potential to create ghost artifacts in mapped environments and pose risks to autonomous navigation. LiDAR serves as a vital sensor for autonomous systems due to its ability to provide dense and precise range measurements. However, existing LiDAR datasets often lack sufficient discussion on the motion labeling of moving objects, containing only a limited representation of moving entities within a single scene. Furthermore, the methodologies for Moving Event Detection (MED) on LiDAR sensors have not been comprehensively explored or evaluated. To address these gaps, this study focuses on constructing a diverse LiDAR moving event dataset encompassing multiple scenes with a high density of moving objects. A thorough review of current MED techniques is conducted, followed by the establishment of a performance benchmark based on evaluating these methods using our dataset. Additionally, part sequences of the dataset are utilized to host an online MED competition, aimed at fostering collaboration within the research community and advancing related studies.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t10_12">
             09:00-10:00, Paper FrPI6T10.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1319'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              I-ASM: Iterative Acoustic Scene Mapping for Enhanced Robot Auditory Perception in Complex Indoor Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334429" title="Click to go to the Author Index">
             Fu, Linya
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334427" title="Click to go to the Author Index">
             He, Yuanzheng
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334426" title="Click to go to the Author Index">
             Wang, Jiang
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334425" title="Click to go to the Author Index">
             Qiao, Xu
            </a>
           </td>
           <td class="r">
            Department of Mechanical and Energy Engineering, Southern Univer
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237433" title="Click to go to the Author Index">
             Kong, He
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1319" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robot_audition" title="Click to go to the Keyword Index">
               Robot Audition
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper addresses the challenge of acoustic scene mapping (ASM) in complex indoor environments with multiple sound sources. Unlike existing methods that rely on prior data association or SLAM frameworks, we propose a novel particle filter-based iterative framework, termed I-ASM, for ASM using a mobile robot equipped with a microphone array and LiDAR. I-ASM harnesses an innovative â€œimplicit associationâ€ to align sound sources with Direction of Arrival (DoA) observations without requiring explicit pairing, thereby streamlining the mapping process. Given inputs including an occupancy map, DoA estimates from various robot positions, and corresponding robot pose data, I-ASM performs multi-source mapping through an iterative cycle of ``Filtering-Clustering-Implicit Associating''. The proposed framework has been tested in real-world scenarios with up to 10 concurrent sound sources, demonstrating its robustness against missing and false DoA estimates while achieving high-quality ASM results. To benefit the community, we open-source all the codes and data at https://github.com/AISLAB-sustech/Acoustic-Scene-Mapping
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t10_13">
             09:00-10:00, Paper FrPI6T10.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1806'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              TivNe-SLAM: Dynamic Mapping and Tracking Via Time-Varying Neural Radiance Fields
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#373670" title="Click to go to the Author Index">
             Duan, Chengyao
            </a>
           </td>
           <td class="r">
            Yunnan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#267273" title="Click to go to the Author Index">
             Yang, Zhiliu
            </a>
           </td>
           <td class="r">
            Yunnan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1806" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Previous attempts to integrate Neural Radiance Fields (NeRF) into the Simultaneous Localization and Mapping (SLAM) framework either rely on the assumption of static scenes or require the ground truth camera poses, which impedes their application in real-world scenarios. This paper proposes a time-varying representation to track and reconstruct the dynamic scenes. Firstly, two processes, a tracking process and a mapping process, are maintained simultaneously in our framework. In the tracking process, all input images are uniformly sampled and then progressively trained in a self-supervised paradigm. In the mapping process, we leverage motion masks to distinguish dynamic objects from the static background, and sample more pixels from dynamic areas. Secondly, the parameter optimization for both processes is comprised of two stages: the first stage associates time with 3D positions to convert the deformation field to the canonical field. The second stage associates time with the embeddings of the canonical field to obtain colors and a Signed Distance Function (SDF). Lastly, we propose a novel keyframe selection strategy based on the overlapping rate. Our approach is evaluated on two synthetic datasets and one real-world dataset, and the experiments validate that our method achieves competitive results in both tracking and mapping when compared to existing state-of-the-art NeRF-based dynamic SLAM systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t10_14">
             09:00-10:00, Paper FrPI6T10.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1993'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RCAL: A Lightweight Road Cognition and Automated Labeling System for Autonomous Driving Scenarios
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396300" title="Click to go to the Author Index">
             Chen, Jiancheng
            </a>
           </td>
           <td class="r">
            Li Auto
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396260" title="Click to go to the Author Index">
             Yu, Chao
            </a>
           </td>
           <td class="r">
            Li Auto
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#288915" title="Click to go to the Author Index">
             Wang, Huayou
            </a>
           </td>
           <td class="r">
            Li Auto
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396440" title="Click to go to the Author Index">
             Liu, Kun
            </a>
           </td>
           <td class="r">
            Li Auto
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397566" title="Click to go to the Author Index">
             Zhan, Yifei
            </a>
           </td>
           <td class="r">
            Li Auto
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#410945" title="Click to go to the Author Index">
             Lang, Xianpeng
            </a>
           </td>
           <td class="r">
            Li Auto
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#288916" title="Click to go to the Author Index">
             Xue, Changliang
            </a>
           </td>
           <td class="r">
            Li Auto
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1993" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Vectorized reconstruction and topological cognition of road structures are crucial for autonomous vehicles to handle complex scenes. Traditional frameworks rely heavily on high-definition (HD) maps, which place significant demands on storage, computation, and manual labor. To overcome these limitations, we introduce a lightweight Road Cognition and Automated Labeling (RCAL) system. It leverages lightweight road data captured from mass-produced vehicles to vectorize road elements and cognize their topology. RCAL compiles multi-trip data on cloud servers for enhanced accuracy and coverage, addressing the limitations of single-trip data. In the field of element extraction, we proposed a pivotal point priority sampling strategy that can balance the contradiction between road scale and processing efficiency. Additionally, traffic flow is utilized to enhance the accuracy of road topology cognition. With its impressive automation, reliability, and efficiency, RCAL stands as an advanced solution in the field.	Our evaluations on the intersection dataset from the real world confirm that RCAL not only achieves comparable precision to traditional HD map labeling systems but also substantially reducing resource costs.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t10_15">
             09:00-10:00, Paper FrPI6T10.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2820'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              AutoInst: Automatic Instance-Based Segmentation of LiDAR 3D Scans
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395119" title="Click to go to the Author Index">
             Perauer, Cedric
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375656" title="Click to go to the Author Index">
             Zhang, Haifan
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395278" title="Click to go to the Author Index">
             Heidrich, Laurenz Adrian
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#178676" title="Click to go to the Author Index">
             Niessner, Matthias
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#289521" title="Click to go to the Author Index">
             Kornilova, Anastasiia
            </a>
           </td>
           <td class="r">
            Skolkovo Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277787" title="Click to go to the Author Index">
             Artemov, Alexey
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2820" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recently, progress in acquisition equipment such as LiDAR sensors has enabled sensing increasingly spacious outdoor 3D environments. Making sense of such 3D acquisitions requires fine-grained scene understanding, such as constructing instance-based 3D scene segmentations. Commonly, a neural network is trained for this task; however, this requires access to a large, densely annotated dataset, which is widely known to be challenging to obtain. To address this issue, in this work we propose to predict instance segmentations for 3D scenes in an unsupervised way, without relying on ground-truth annotations. To this end, we construct a learning framework consisting of two components: (1) a pseudo-annotation scheme for generating initial unsupervised pseudo-labels; and (2) a self-training algorithm for instance segmentation to fit robust, accurate instances from initial noisy proposals. To enable generating 3D instance mask proposals, we construct a weighted proxy-graph by connecting 3D points with edges integrating multi-modal image- and point-based self-supervised features, and perform graph- cuts to isolate individual pseudo-instances. We then build on a state-of-the-art point-based architecture and train a 3D instance segmentation model, resulting in significant refinement of initial proposals. To scale to arbitrary complexity 3D scenes, we design our algorithm to operate on local 3D point chunks and construct a merging step to generate scene-level instance segmentations. Experiments on the challenging SemanticKITTI benchmark demonstrate the potential of our approach, where it attains 13.3% higher Average Precision and 9.1% higher F1 score compared to the best-performing baseline. The code is publicly available at https://github.com/artonson/autoinst.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t10_16">
             09:00-10:00, Paper FrPI6T10.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('271'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Visual Timing for Sound Source Depth Estimation in the Wild
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336856" title="Click to go to the Author Index">
             Sun, Wei
            </a>
           </td>
           <td class="r">
            UT AUSTIN
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391601" title="Click to go to the Author Index">
             Qiu, Lili
            </a>
           </td>
           <td class="r">
            UT Austin
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab271" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Inspired by the flash-to-bang theory, we develop FBDepth, the first passive audio-visual depth estimation framework. It is based on the difference between the time-of-flight (ToF) of the light and the sound. We formulate sound source depth estimation as an audio-visual event localization task for collision events. To approach decimeter-level depth accuracy, we design a coarse-to-fine pipeline to push the temporary localization accuracy from event-level to millisecond-level by aligning audio-visual correspondence and manipulating optical flow. FBDepth feeds the estimated visual timestamp together with the audio clip and objects visual features to regress the source depth. We use a mobile phone to collect	3.6K+ video clips with 24 different objects at up to 65m. FBDepth shows superior performance especially at a long range compared to monocular and stereo methods.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frpi6t11">
             <b>
              FrPI6T11
             </b>
            </a>
           </td>
           <td class="r">
            Room 11
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frpi6t11" title="Click to go to the Program at a Glance">
             <b>
              Safety for Robots
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#101975" title="Click to go to the Author Index">
             Althoefer, Kaspar
            </a>
           </td>
           <td class="r">
            Queen Mary University of London
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t11_01">
             09:00-10:00, Paper FrPI6T11.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1613'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              TacLink-Integrated Robot Arm Toward Safe Human-Robot Interaction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#278785" title="Click to go to the Author Index">
             Luu, Quan
            </a>
           </td>
           <td class="r">
            Japan Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#204668" title="Click to go to the Author Index">
             Albini, Alessandro
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#140995" title="Click to go to the Author Index">
             Maiolino, Perla
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122439" title="Click to go to the Author Index">
             Ho, Van
            </a>
           </td>
           <td class="r">
            Japan Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1613" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent developments in vision-based tactile sensing offer a simple means to enable robots to perceive touch interactions. However, existing sensors are primarily designed for small-scale applications like robotic hands, lacking research on their integration for large-sized robot bodies that can be leveraged for safe human-robot interactions. This paper explores the utilization of the previously-developed vision-based tactile sensing link (called TacLink) with soft skin as a safety control mechanism, which can serve as an alternative to conventional rigid robot links and impact observers. We characterize the behavior of a robot integrated with the soft TacLink in response to collisions, particularly employing a reactive control strategy. The controller is primarily driven by tactile force information acquired from the soft TacLink sensor through a data-driven sim2real learning method. Compared with a standard rigid link, the results obtained from collision experiments also confirm the advantages of our "soft" solution in impact resilience and in facilitating controls that are difficult to achieve with a stiff robot body. This study can act as a benchmark for assessing the efficiency of soft tactile-sensitive skins in reactive collision responses and open new safety standards for soft skin-based collaborative robots in human-robot interaction scenarios.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t11_02">
             09:00-10:00, Paper FrPI6T11.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1590'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Fixing Symbolic Plans with Reinforcement Learning in Object-Based Action Spaces
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291553" title="Click to go to the Author Index">
             Thierauf, Christopher
            </a>
           </td>
           <td class="r">
            Woods Hole Oceanographic Institution
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104328" title="Click to go to the Author Index">
             Scheutz, Matthias
            </a>
           </td>
           <td class="r">
            Tufts University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1590" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#failure_detection_and_recovery" title="Click to go to the Keyword Index">
               Failure Detection and Recovery
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Abstractâ€” Reinforcement learning techniques are widely used when robots have to learn new tasks but they typically operate on action spaces defined by the joints of the robot. We present a contrasting approach where actions spaces are the trajectories of objects in the environment, requiring robots to discover events such as object changes and behaviors that must occur to accomplish the task. We show that this allows robots to learn faster, to learn semantic representations that can be communicated to humans, and to learn in a manner that does not depend on the robot itself, enabling low-cost policy transfer between different types of robots. Our demonstrations can be replicated using provided source code.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t11_03">
             09:00-10:00, Paper FrPI6T11.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('315'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Online Efficient Safety-Critical Control for Mobile Robots in Unknown Dynamic Multi-Obstacle Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372916" title="Click to go to the Author Index">
             Zhang, Yu
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391800" title="Click to go to the Author Index">
             Tian, Guangyao
            </a>
           </td>
           <td class="r">
            Technische UniversitÃ¤t MÃ¼nchen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#337488" title="Click to go to the Author Index">
             Wen, Long
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334712" title="Click to go to the Author Index">
             Yao, Xiangtong
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370306" title="Click to go to the Author Index">
             Zhang, Liding
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195330" title="Click to go to the Author Index">
             Bing, Zhenshan
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#158922" title="Click to go to the Author Index">
             He, Wei
            </a>
           </td>
           <td class="r">
            University of Science and Technology Beijing
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105608" title="Click to go to the Author Index">
             Knoll, Alois
            </a>
           </td>
           <td class="r">
            Tech. Univ. Muenchen TUM
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab315" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes a LiDAR-based goal-seeking and exploration framework, addressing the efficiency of online obstacle avoidance in unstructured environments populated with static and moving obstacles. This framework addresses two significant challenges associated with traditional dynamic control barrier functions (D-CBFs): their online construction and the diminished real-time performance caused by utilizing multiple D-CBFs. To tackle the first challenge, the framework's perception component begins with clustering point clouds via the DBSCAN algorithm, followed by encapsulating these clusters with the minimum bounding ellipses (MBEs) algorithm to create elliptical representations. By comparing the current state of MBEs with those stored from previous moments, the differentiation between static and dynamic obstacles is realized, and the Kalman filter is utilized to predict the movements of the latter. Such analysis facilitates the D-CBF's online construction for each MBE. To tackle the second challenge, we introduce buffer zones, generating Type-II D-CBFs online for each identified obstacle. Utilizing these buffer zones as activation areas substantially reduces the number of D-CBFs that need to be activated. Upon entering these buffer zones, the system prioritizes safety, autonomously navigating safe paths, and hence referred to as the exploration mode. Exiting these buffer zones triggers the system's transition to goal-seeking mode. We demonstrate that the system's states under this framework achieve safety and asymptotic stabilization. Experimental results in simulated and real-world environments have validated our framework's capability, allowing a LiDAR-equipped mobile robot to efficiently and safely reach the desired location within dynamic environments containing multiple obstacles.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t11_04">
             09:00-10:00, Paper FrPI6T11.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('796'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safe Reinforcement Learning Via Hierarchical Adaptive Chance-Constraint Safeguards
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#311560" title="Click to go to the Author Index">
             Chen, Zhaorun
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#368073" title="Click to go to the Author Index">
             Zhao, Zhuokai
            </a>
           </td>
           <td class="r">
            University of Chicago
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379756" title="Click to go to the Author Index">
             He, Tairan
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276132" title="Click to go to the Author Index">
             Chen, BinHao
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394053" title="Click to go to the Author Index">
             Zhao, Xuhao
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142453" title="Click to go to the Author Index">
             Gong, Liang
            </a>
           </td>
           <td class="r">
            Shanghai  Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#135074" title="Click to go to the Author Index">
             Liu, Chengliang
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab796" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
             </span>
             <br/>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t11_05">
             09:00-10:00, Paper FrPI6T11.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1078'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Adaptive Splitting of Reusable Temporal Monitors for Rare Traffic Violations
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#282332" title="Click to go to the Author Index">
             Innes, Craig
            </a>
           </td>
           <td class="r">
            University of Edinburgh
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114132" title="Click to go to the Author Index">
             Ramamoorthy, Subramanian
            </a>
           </td>
           <td class="r">
            The University of Edinburgh
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1078" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#hybrid_logical_dynamical_planning_and_verification" title="Click to go to the Keyword Index">
               Hybrid Logical/Dynamical Planning and Verification
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous Vehicles (AVs) are often tested in simulation to estimate the probability they violate safety specifications. Two common issues arise when using existing techniques to produce this estimation: If violations are rare, Monte-Carlo sampling can fail to produce efficient estimates; if simulation horizons are too long, importance samplers (which learn distributions from past simulations) can fail to converge. This paper addresses both issues by interleaving rare-event sampling techniques with online specification monitoring algorithms. We use importance splitting to decompose simulations into partial trajectories, then calculate the distance of those partial trajectories to failure by leveraging robustness metrics from Signal Temporal Logic (STL). By caching those partial robustness metric values, we can efficiently re-use computations across multiple sampling stages. Our experiments on an interstate lane-change scenario show our method is viable for testing simulated AV-pipelines, efficiently estimating failure probabilities for STL specifications based on real traffic rules. We produce better estimates than Monte-Carlo and importance sampling in fewer simulations.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t11_06">
             09:00-10:00, Paper FrPI6T11.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1574'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Interruptive Language Control of Bipedal Locomotion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#313158" title="Click to go to the Author Index">
             Malik, Ashish
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#187769" title="Click to go to the Author Index">
             Lee, Stefan
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286344" title="Click to go to the Author Index">
             Fern, Alan
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1574" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We study the problem of natural language-based control of dynamic bipedal locomotion from the perspective of operational robustness and hardware safety. Existing work on natural language-based robot control has focused on episodic command execution for stable robot platforms, such as fixed-based manipulators in table-top scenarios. These scenarios feature non-overlapping phases of instruction and execution, with execution mishaps usually posing no threat to the robot safety. This allows for non-trivial failure rates to be acceptable. In contrast, our work involves indistinguishable instruction and execution stages for a dynamically unstable robot where execution failures can harm the robot. For example, interrupting a bipedal robot with a new instruction in certain states may cause it to fall. Our first contribution is to design and train a natural language based controller for the bipedal robot Cassie that can take in new language commands at any time. Our second contribution is to introduce a protocol for evaluating the robustness to interruptions of such controllers and evaluating the learned controller in simulation under different interruption distributions. Our third contribution is to learn a detector for interruptions that are likely to lead to failure and to integrate that detector into a failure mitigation strategy. Overall, our results show that interruptions can lead to non-trivial failure rates for the original controller and that the proposed mitigation strategy can help to significantly reduce that rate.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t11_07">
             09:00-10:00, Paper FrPI6T11.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1618'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safe Offline-To-Online Multi-Agent Decision Transformer: A Safety Conscious Sequence Modeling Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396171" title="Click to go to the Author Index">
             Shah, Aamir Bader
            </a>
           </td>
           <td class="r">
            University of Houston
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396902" title="Click to go to the Author Index">
             Wen, Yu
            </a>
           </td>
           <td class="r">
            University of Houston
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396907" title="Click to go to the Author Index">
             Chen, Jiefu
            </a>
           </td>
           <td class="r">
            University of Houston
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396908" title="Click to go to the Author Index">
             Wu, Xuqing
            </a>
           </td>
           <td class="r">
            University of Houston
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396910" title="Click to go to the Author Index">
             Fu, Xin
            </a>
           </td>
           <td class="r">
            University of Houston
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1618" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce the Safe Offline-to-Online Multi-Agent Decision Transformer (SO2-MADT), an innovative framework that revolutionizes safety considerations in Multi-agent Reinforcement Learning (MARL) through a novel sequence modeling approach. Leveraging the dynamic capabilities inherent in Decision Transformers, our methodology seamlessly incorporates safety protocols as a cornerstone element, ensuring secure operations throughout both the offline pre-training phase and the adaptive online fine-tuning phase. At the core of our framework lie two pivotal innovations: the Safety-To-Go (STG) token, embedding safety at a macro level, and the Agent Prioritization Module (APM), facilitating explicit credit assignment at a micro level. Through extensive testing against the challenging environments of the StarCraft Multi-Agent Challenge (SMAC) and Multi-agent MuJoCo, our SO2-MADT not only excels in offline pre-training but also demonstrates superior performance during online fine-tuning, without any degradation in performance. The implications of our work provide a pathway for deployment in critical real-world applications where safety is paramount and non-negotiable. The code is available at https://github.com/shahaamirbader/SO2-MADT.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t11_08">
             09:00-10:00, Paper FrPI6T11.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3024'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Differential-Algebraic Equation Control Barrier Function for Flexible Link Manipulator
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#328711" title="Click to go to the Author Index">
             Park, Younghwa
            </a>
           </td>
           <td class="r">
            Maersk Mc-Kinney Moller Institute, University of Southern Denmar
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#211661" title="Click to go to the Author Index">
             Sloth, Christoffer
            </a>
           </td>
           <td class="r">
            University of Southern Denmark
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3024" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#underactuated_robots" title="Click to go to the Keyword Index">
               Underactuated Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a control barrier function (CBF) for systems described by differential-algebraic equations, and applies the method to guarantee the safety of a two-link flexible-link manipulator. The two main contributions of the paper are: a) an extension of CBFs to systems governed by differential-algebraic equations; b) a framework simulation of flexible-link robots in a floating frame of reference formulation (FFRF) finite element method (FEM). Numerical simulations demonstrate the minimally invasive safety control of a flexible two-link manipulator with position constraints through CBF quadratic programming without converting the differential-algebraic equations to a control-affine system.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t11_09">
             09:00-10:00, Paper FrPI6T11.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1447'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MIXED-SENSE: A Mixed Reality Sensor Emulation Framework for Test and Evaluation of UAVs against False Data Injection Attacks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350519" title="Click to go to the Author Index">
             Pant, Kartik Anand
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#358669" title="Click to go to the Author Index">
             Lin, Li-Yu
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395511" title="Click to go to the Author Index">
             Kim, Jaehyeok
            </a>
           </td>
           <td class="r">
            Purdue University - West Lafayette
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#381044" title="Click to go to the Author Index">
             Sribunma, Worawis
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#145535" title="Click to go to the Author Index">
             Goppert, James
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#151833" title="Click to go to the Author Index">
             Hwang, Inseok
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1447" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#virtual_reality_and_interfaces" title="Click to go to the Keyword Index">
               Virtual Reality and Interfaces
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a high-fidelity Mixed Reality sensor emulation framework for testing and evaluating the resilience of Unmanned Aerial Vehicles (UAVs) against false data injection (FDI) attacks. The proposed approach can be utilized to assess the impact of FDI attacks, benchmark attack detector performance, and validate the effectiveness of mitigation/reconfiguration strategies in single-UAV and UAV swarm operations. Our Mixed Reality framework leverages high-fidelity simulations of Gazebo and a Motion Capture system to emulate proprioceptive (e.g., GNSS) and exteroceptive (e.g., camera) sensor measurements in real-time. We propose an empirical approach to faithfully recreate signal characteristics such as latency and noise in these measurements. Finally, we illustrate the efficacy of our proposed framework through a Mixed Reality experiment consisting of an emulated GNSS attack on an actual UAV, which (i)demonstrates the impact of false data injection attacks on GNSS measurements and (ii) validates a mitigation strategy utilizing a distributed camera network developed in our previous work. Our open-source implementation is available at https://github.com/CogniPilot/mixed_sense
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t11_10">
             09:00-10:00, Paper FrPI6T11.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1703'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safe Multi-Agent Reinforcement Learning for Bimanual Dexterous Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#332034" title="Click to go to the Author Index">
             Zhan, Weishu
            </a>
           </td>
           <td class="r">
            Dartmouth College
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394064" title="Click to go to the Author Index">
             Chin, Peter
            </a>
           </td>
           <td class="r">
            Dartmouth College
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1703" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#bimanual_manipulation" title="Click to go to the Keyword Index">
               Bimanual Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Bimanual dexterous manipulation in robotics, essential for a wide range of applications, addresses the critical challenge of balancing intricate operational capabilities with assured safety and reliability. While Safe Reinforcement Learning is integral to the robustness of robotic systems, the area of safe multi-agent reinforcement learning (MARL), cooperative control of multiple robots has been scarcely studied. In this study, we explore MARL for safe cooperative control with multiple robot hands. Each robot must follow individual and collective safety guidelines to ensure safe team actions. However, the non-stationarity inherent in current algorithms hinders the precise updating of strategies to satisfy these safety constraints effectively. In this paper, we propose Multi-Agent Constrained Proximal Advantage Optimization (MACPAO), which considers the sequence of agent updates and integrates non-stationarity into sequential update schemes. This algorithm ensures consistent improvement in both rewards and adherence to safety constraints in each iteration. We tested MACPAO on various tasks with safety constraints and demonstrated that it outperforms other MARL algorithms in balancing reward enhancement and safety compliance. Supplementary materials and code are available at the provided link https://github.com/YONEX4090/MultiSafeHand.git.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t11_11">
             09:00-10:00, Paper FrPI6T11.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2883'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CBFkit: A Control Barrier Function Toolbox for Robotics Applications
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335349" title="Click to go to the Author Index">
             Black, Mitchell
            </a>
           </td>
           <td class="r">
            MIT Lincoln Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103644" title="Click to go to the Author Index">
             Fainekos, Georgios
            </a>
           </td>
           <td class="r">
            Toyota NA-R&amp;D
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#175460" title="Click to go to the Author Index">
             Hoxha, Bardh
            </a>
           </td>
           <td class="r">
            Toyota Research Institute of North America
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378628" title="Click to go to the Author Index">
             Okamoto, Hideki
            </a>
           </td>
           <td class="r">
            Toyota Motor North America
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#119485" title="Click to go to the Author Index">
             Prokhorov, Danil
            </a>
           </td>
           <td class="r">
            Toyota Tech Center
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2883" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#control_architectures_and_programming" title="Click to go to the Keyword Index">
               Control Architectures and Programming
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#formal_methods_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Formal Methods in Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces CBFkit, a Python/ROS toolbox for safe robotics planning and control under uncertainty. The toolbox provides a general framework for designing control barrier functions for mobility systems within both deterministic and stochastic environments. It can be connected to the ROS open-source robotics middleware, allowing for the setup of multi-robot applications, encoding of environments and maps, and integrations with predictive motion planning algorithms. Additionally, it offers multiple CBF variations and algorithms for robot control. The CBFKit is demonstrated on the Toyota Human Support Robot (HSR) in both simulation and in physical experiments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t11_12">
             09:00-10:00, Paper FrPI6T11.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2367'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RECOVER: A Neuro-Symbolic Framework for Failure Detection and Recovery
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395935" title="Click to go to the Author Index">
             Cornelio, Cristina
            </a>
           </td>
           <td class="r">
            Samsung AI
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#234176" title="Click to go to the Author Index">
             Diab, Mohammed
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2367" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#failure_detection_and_recovery" title="Click to go to the Keyword Index">
               Failure Detection and Recovery
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recognizing failures during task execution and implementing recovery procedures is challenging in robotics. Traditional approaches rely on the availability of extensive data or a tight set of constraints, while more recent approaches leverage large language models (LLMs) to verify task steps and replan accordingly. However, these methods often operate offline, necessitating scene resets and incurring in high costs. This paper introduces RECOVER, a neuro-symbolic framework for online failure identification and recovery. By integrating ontologies, logical rules, and LLM-based planners, RECOVER exploits symbolic information to enhance the ability of LLMs to generate recovery plans and also to decrease the associated costs. In order to demonstrate the capabilities of our method in a simulated kitchen environment, we introduce ONTOTHOR, an ontology describing the AI2Thor simulator setting. Empirical evaluation shows that ONTOTHORâ€™s logical rules accurately detect all failures in the analyzed tasks, and that RECOVER considerably outperforms, for both failure detection and recovery, a baseline method reliant solely on LLMs. Supplementary material, including the ONTOTHOR ontology, is available at: https://recover-ontothor.github.io.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t11_13">
             09:00-10:00, Paper FrPI6T11.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1248'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hybrid Continuum-Eversion Robot: Precise Navigation and Decontamination in Nuclear Environments Using Vine Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#357163" title="Click to go to the Author Index">
             Al-Dubooni, Mohammed
            </a>
           </td>
           <td class="r">
            Queen Mary University of London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#236010" title="Click to go to the Author Index">
             Wong, Cuebong
            </a>
           </td>
           <td class="r">
            National Nuclear Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101975" title="Click to go to the Author Index">
             Althoefer, Kaspar
            </a>
           </td>
           <td class="r">
            Queen Mary University of London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1248" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft growing vine robots show great potential for navigation and decontamination tasks in the nuclear industry. This paper introduces a novel hybrid continuum-eversion robot designed to address certain challenges in relation to navigating and operating within pipe networks and enclosed remote vessels. The hybrid robot combines the flexibility of a soft eversion robot with the precision of a continuum robot at its tip, allowing for controlled steering and movement in hard to access and/or complex environments. The design enables the delivery of sensors, liquids, and aerosols to remote areas, supporting remote decontamination activities.
             <p>
              This paper outlines the design and construction of the robot and the methods by which it achieves selective steering. We also include a comprehensive review of current related work in eversion robotics, as well as other steering devices and actuators currently under research, which underpin this novel active steering approach. This is followed by an experimental evaluation that demonstrates the robotâ€™s real-world capabilities in delivering liquids and aerosols to remote locations. The experiments reveal successful outcomes, with over 95% success in precision spraying tests. The paper concludes by discussing future work alongside limitations in the current design, ultimately showcasing its potential as a solution for remote decontamination operations in the nuclear industry.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t11_14">
             09:00-10:00, Paper FrPI6T11.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2935'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RoboGuardZ: A Scalable Zero-Shot Framework for Zero-Day Malware Detection in Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#278740" title="Click to go to the Author Index">
             Kaur, Upinder
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#341701" title="Click to go to the Author Index">
             Celik, Berkay
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101960" title="Click to go to the Author Index">
             Voyles, Richard
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2935" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#engineering_for_robotic_systems" title="Click to go to the Keyword Index">
               Engineering for Robotic Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The ubiquitous deployment of robots across diverse domains, from industrial automation to personal care, underscores their critical role in modern society. However, this growing dependence has also revealed security vulnerabilities. An attack vector involves the deployment of malicious software (malware) on robots, which can cause harm to robots themselves, users, and even the surrounding environment. Machine learning approaches, particularly supervised ones, have shown promise in malware detection by building intricate models to identify known malicious code patterns. However, these methods are inherently limited in detecting unseen or zero-day malware variants as they require regularly updated massive datasets that might be unavailable to robots. To address this challenge, we introduce RoboGuardZ, a novel malware detection framework based on zero-shot learning for robots. This approach allows RoboGuardZ to identify unseen malware by establishing relationships between known malicious code and benign behaviors, allowing detection even before the code executes on the robot. To ensure practical deployment in resource-constrained robotic hardware, we employ a unique parallel structured pruning and quantization strategy that compresses the RoboGuardZ detection model by 37.4% while maintaining its accuracy. This strategy reduces the size of the model and computational demands, making it suitable for real-world robotic systems. We evaluated RoboGuardZ on a recent dataset containing real-world binary executables from multi-sensor autonomous car controllers. The framework was deployed on two popular robot embedded hardware platforms. Our results demonstrate an average detection accuracy of 94.25% and a low false negative rate of 5.8% with a minimal latency of 20 ms, which demonstrates its effectiveness and practicality.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t11_15">
             09:00-10:00, Paper FrPI6T11.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2966'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RoboCop: A Robust Zero-Day Cyber-Physical Attack Detection Framework for Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#278740" title="Click to go to the Author Index">
             Kaur, Upinder
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#341701" title="Click to go to the Author Index">
             Celik, Berkay
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101960" title="Click to go to the Author Index">
             Voyles, Richard
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2966" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#embedded_systems_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Embedded Systems for Robotic and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Zero-day vulnerabilities pose a significant challenge to robot cyber-physical systems (CPS). Attackers can exploit software vulnerabilities in widely-used robotics software, such as the Robot Operating System (ROS), to manipulate robot behavior, compromising both safety and operational effectiveness. The hidden nature of these vulnerabilities requires strong defense mechanisms to guarantee the safety and dependability of robotic systems. In this paper, we introduce RoboCop, a cyber-physical attack detection framework designed to protect robots from zero-day threats. RoboCop leverages static software features in the pre-execution analysis along with runtime state monitoring to identify attack patterns and deviations that signal attacks, thus ensuring the robot's operational integrity. We evaluated RoboCop on the F1-tenth autonomous car platform. It achieves a 93% detection accuracy against a variety of zero-day attacks targeting sensors, actuators, and controller logic. Importantly, in on-robot deployments, it identifies attacks in less than 7 seconds with a 12% computational overhead.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t11_16">
             09:00-10:00, Paper FrPI6T11.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1158'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Collision Detection between Smooth Convex Bodies Via Riemannian Optimization Framework
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395769" title="Click to go to the Author Index">
             An, Seoki
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319698" title="Click to go to the Author Index">
             Lee, Somang
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#274086" title="Click to go to the Author Index">
             Lee, Jeongmin
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395770" title="Click to go to the Author Index">
             Park, Sunkyung
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104207" title="Click to go to the Author Index">
             Lee, Dongjun
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1158" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computational_geometry" title="Click to go to the Keyword Index">
               Computational Geometry
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#contact_modeling" title="Click to go to the Keyword Index">
               Contact Modeling
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Collision detection is a fundamental problem across various fields such as robotics, physical simulation, and computer graphics. While numerous studies have provided efficient solutions, based on the well-known Gilbert, Johnson, and Keerthi (GJK) algorithm and Expanding Polytope Algorithm (EPA), existing methods utilizing GJK-EPA often struggle with smooth strictly convex shapes like ellipsoids. This paper proposes a novel approach to the collision detection problem converting it to a problem compatible with an unconstrained Riemannian optimization problem. Moreover, we presents a specific method of solving the problem based on twice differentiable support functions and the Riemannian trust region (RTR) method. The method exhibits fast and robust convergence rate, leveraging the well-established theory of Riemannian optimization. In addition, it offers the capability to compute derivatives of resultant contact features. The evaluation studies comparing our method to GJK-EPA method are done with pre-defined primitive shapes. Additionally, a test result with several more complex shapes is demonstrated exhibiting the method's effectiveness and applicability.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frpi6t12">
             <b>
              FrPI6T12
             </b>
            </a>
           </td>
           <td class="r">
            Room 12
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frpi6t12" title="Click to go to the Program at a Glance">
             <b>
              Sensor Fusion for Robots
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#162950" title="Click to go to the Author Index">
             Kim, Jinwhan
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t12_01">
             09:00-10:00, Paper FrPI6T12.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2693'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Case Study on Visual-Audio-Tactile Cross-Modal Retrieval
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377410" title="Click to go to the Author Index">
             Wojcik, Jagoda
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285049" title="Click to go to the Author Index">
             Jiang, Jiaqi
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377420" title="Click to go to the Author Index">
             Wu, Jiacheng
            </a>
           </td>
           <td class="r">
            Kingâ€™s College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#165900" title="Click to go to the Author Index">
             Luo, Shan
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2693" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Cross-Modal Retrieval (CMR), which retrieves relevant items from one modality (e.g., audio) given a query in another modality (e.g., visual), has undergone significant advancements in recent years. This capability is crucial for robots to integrate and interpret information across diverse sensory inputs. However, the retrieval space in existing robotic CMR approaches often consists of only one modality, which limits the robotâ€™s performance. In this paper, we propose a novel CMR model that incorporates three different modalities, i.e., visual, audio and tactile, for enhanced multi-modal object retrieval, named as VAT-CMR. In this model, multi-modal representations are first fused to provide a holistic view of object features. To mitigate the semantic gaps between representations of different modalities, a dominant modality is then selected during the classification training phase to improve the distinctiveness of the representations, so as to improve the retrieval performance. To evaluate our proposed approach, we conducted a case study and the results demonstrate that our VAT-CMR model surpasses competing approaches. Further, our proposed dominant modality selection significantly enhances cross-retrieval accuracy.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t12_02">
             09:00-10:00, Paper FrPI6T12.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('167'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ASY-VRNet: Waterway Panoptic Driving Perception Model Based on Asymmetric Fair Fusion of Vision and 4D mmWave Radar
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389634" title="Click to go to the Author Index">
             Guan, Runwei
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#330006" title="Click to go to the Author Index">
             Yao, Shanliang
            </a>
           </td>
           <td class="r">
            XJTLU
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389739" title="Click to go to the Author Index">
             Man, Ka Lok
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong-Liverpool University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375541" title="Click to go to the Author Index">
             Zhu, Xiaohui
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong-Liverpool University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377042" title="Click to go to the Author Index">
             Yue, Yong
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong-Liverpool University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389729" title="Click to go to the Author Index">
             Smith, Jeremy
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#303425" title="Click to go to the Author Index">
             Lim, Eng Gee
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong-Liverpool University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389831" title="Click to go to the Author Index">
             Yue, Yutao
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab167" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Panoptic Driving Perception (PDP) is critical for the autonomous navigation of Unmanned Surface Vehicles (USVs). A PDP model typically integrates multiple tasks, necessitating the simultaneous and robust execution of various perception tasks to facilitate downstream path planning. The fusion of visual and radar sensors is currently acknowledged as a robust and cost-effective approach. However, most existing research has primarily focused on fusing visual and radar features dedicated to object detection or utilizing a shared feature space for multiple tasks, neglecting the individual representation differences between various tasks. To address this gap, we propose a pair of Asymmetric Fair Fusion (AFF) modules with favorable explainability designed to efficiently interact with independent features from both visual and radar modalities, tailored to the specific requirements of object detection and semantic segmentation tasks. The AFF modules treat image and radar maps as irregular point sets and transform these features into a crossed-shared feature space for multitasking, ensuring equitable treatment of vision and radar point cloud features. Leveraging AFF modules, we propose a novel and efficient PDP model, ASY-VRNet, which processes image and radar features based on irregular super-pixel point sets. Additionally, we propose an effective multi-task learning method specifically designed for PDP models. Compared to other lightweight models, ASY-VRNet achieves state-of-the-art performance in object detection, semantic segmentation, and drivable-area segmentation on the WaterScenes benchmark. Our project is publicly available at https://github.com/GuanRunwei/ASY-VRNet.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t12_03">
             09:00-10:00, Paper FrPI6T12.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('250'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              KLILO: Kalman Filter Based LiDAR-Inertial-Leg Odometry for Legged Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#311096" title="Click to go to the Author Index">
             Xu, Shaohang
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#337326" title="Click to go to the Author Index">
             Zhang, Wentao
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#152107" title="Click to go to the Author Index">
             Zhu, Lijun
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab250" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a Kalman filter based LiDAR-Inertial-Leg Odometry (KLILO) system for legged robots to navigate in challenging environments. In particular, we employ the iterated error-state extended Kalman filter framework on manifolds to fuse measurements from the inertial measurement unit (IMU), LiDAR, joint encoders, and contact force sensors in a tightly coupled manner. To assess the performance of KLILO, we build a dataset that encompasses intricate environments with challenging conditions such as dynamic objects and deformable terrains. The results demonstrate that our algorithm can provide efficient and reliable localization in all tests. It exhibits an average improvement of around 40% in positioning accuracy compared to the baselines. Furthermore, we validate KLILO in a challenging navigation task on a real robot, where the LiDAR encounters ineffective measurements.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t12_04">
             09:00-10:00, Paper FrPI6T12.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('413'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              AnytimeFusion: Parameter-Free RGB Camera-Radar Sensor Fusion Algorithm in Complex Maritime Situations
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#362339" title="Click to go to the Author Index">
             Shin, Yeongha
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#150694" title="Click to go to the Author Index">
             Kim, Hanguen
            </a>
           </td>
           <td class="r">
            Seadronix Corp
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#162950" title="Click to go to the Author Index">
             Kim, Jinwhan
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab413" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Determining the position of obstacles is crucial for unmanned vehicles, and, to achieve this, cameras and radar sensors are widely utilized. However, establishing correlation between two or more sensors proves challenging in the dynamically changing maritime environment. To solve these issues, we propose the AnytimeFusion algorithm. The key innovation of AnytimeFusion lies in the utilization of a parameter-free method that does not require accurate sensor alignment and calibration. The algorithm consists of the following four stages. First, calibration targets are selected in the maritime environment based on segmentation images. Second, radar and camera data are pre-fused to model the correlation of azimuth information. After completing the auto-calibration stages, Inverse Perspective Mapping (IPM) is employed to integrate the coordinate systems of the two sensors. To determine the parameters for this integration, optimization based on the Particle Swarm Optimization (PSO) method is employed. Finally, an Error Polygon for the positions of the camera and radar is generated, and sensor fusion is carried out based on this information. We validated our method through experiments conducted on real ships in complex maritime environments, achieving an average accuracy of 95.7%.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t12_05">
             09:00-10:00, Paper FrPI6T12.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('418'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Implicit Neural Fusion of RGB and Far-Infrared 3D Imagery for Invisible Scenes
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392366" title="Click to go to the Author Index">
             Li, Xiangjie
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#323262" title="Click to go to the Author Index">
             Xie, Shuxiang
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#254363" title="Click to go to the Author Index">
             Sakurada, Ken
            </a>
           </td>
           <td class="r">
            National Institute of Advanced Industrial Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103364" title="Click to go to the Author Index">
             Sagawa, Ryusuke
            </a>
           </td>
           <td class="r">
            National Institute of Advanced Industrial Science AndTechnology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#112375" title="Click to go to the Author Index">
             Oishi, Takeshi
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab418" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Optical sensors, such as the Far Infrared (FIR) sensor, have demonstrated advantages over traditional imaging. For example, 3D reconstruction in the FIR field captures the heat distribution of a scene that is invisible to RGB, aiding various applications like gas leak detection. However, less texture information and challenges in acquiring FIR frames hinder the reconstruction process. Given that implicit neural representations (INRs) can integrate geometric information across different sensors, we propose Implicit Neural Fusion (INF) of RGB and FIR for 3D reconstruction of invisible scenes in the FIR field. Our method first obtains a neural density field of objects from RGB frames. Then, with the trained object density field, a separate neural density field of gases is optimized using limited view inputs of FIR frames. Our method not only demonstrates outstanding reconstruction quality in the FIR field through extensive experiments but also can isolate the geometric information of the invisible, offering a new dimension of scene understanding.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t12_06">
             09:00-10:00, Paper FrPI6T12.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('426'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Audio-Visual Traffic Light State Detection for Urban Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392533" title="Click to go to the Author Index">
             Gupta, Sagar
            </a>
           </td>
           <td class="r">
            Deakin University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#147002" title="Click to go to the Author Index">
             Cosgun, Akansel
            </a>
           </td>
           <td class="r">
            Monash University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab426" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a multimodal traffic light state detection using vision and sound, from the viewpoint of a quadruped robot navigating in urban settings. This is a challenging problem because of the visual occlusions and noise from robot locomotion. Our method combines features from raw audio with the ratios of red and green pixels within bounding boxes, identified by established vision-based detectors. The fusion method aggregates features across multiple frames in a given timeframe, increasing robustness and adaptability. Results show that our approach effectively addresses the challenge of visual occlusion and surpasses the performance of single-modality solutions when the robot is in motion. This study serves as a proof of concept, highlighting the significant, yet often overlooked, potential of multi-modal perception in robotics.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t12_07">
             09:00-10:00, Paper FrPI6T12.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('753'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Accurately Tracking Relative Positions of Moving Trackers Based on UWB Ranging and Inertial Sensing without Anchors
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378630" title="Click to go to the Author Index">
             Armani, Rayan
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256450" title="Click to go to the Author Index">
             Holz, Christian
            </a>
           </td>
           <td class="r">
            ETH ZÃ¼rich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab753" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_networks" title="Click to go to the Keyword Index">
               Sensor Networks
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a tracking system for relative positioning that can operate on entirely moving tracking nodes without the need for stationary anchors. Each node embeds a 9-DOF magnetic and inertial measurement unit and a single-antenna ultra-wideband radio. We introduce a multi-stage filtering pipeline through which our system estimates the relative layout of all tracking nodes within the group. The key novelty of our method is the integration of a custom Extended Kalman filter (EKF) with a refinement step via multidimensional scaling (MDS). Our method integrates the MDS output back into the EKF, thereby creating a dynamic feedback loop for more robust estimates. We complement our method with UWB ranging protocol that we designed to allow tracking nodes to opportunistically join and leave the group. In our evaluation with constantly moving nodes, our system estimated relative positions with an error of 10.2cm (in 2D) and 21.7cm (in 3D), including obstacles that occluded the line of sight between tracking nodes. Our approach requires no external infrastructure, making it particularly suitable for operation in environments where stationary setups are impractical.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t12_08">
             09:00-10:00, Paper FrPI6T12.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('803'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Bridging Language, Vision and Action: Multimodal VAEs in Robotic Manipulation Tasks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#225977" title="Click to go to the Author Index">
             Sejnova, Gabriela
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#225899" title="Click to go to the Author Index">
             Vavrecka, Michal
            </a>
           </td>
           <td class="r">
            Czech Technical University CIIRC
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#165953" title="Click to go to the Author Index">
             Stepanova, Karla
            </a>
           </td>
           <td class="r">
            Czech Technical University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab803" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we focus on unsupervised vision-language-action mapping in the area of robotic manipulation. Recently, multiple approaches employing pre-trained large language and vision models have been proposed for this task. However, they are computationally demanding and require careful fine-tuning of the produced output. A more lightweight alternative would be the implementation of multimodal Variational Autoencoders (VAEs) which can extract the latent features of the data and integrate them into a joint representation, as has been demonstrated mostly on image-image or image-text data for the state-of-the-art models. Here, we explore whether and how multimodal VAEs can be employed in unsupervised robotic manipulation tasks in a simulated environment. Based on the results obtained, we propose a model-invariant training alternative that improves the models' performance in a simulator by up to 55%. Moreover, we systematically evaluate the challenges raised by individual tasks, such as object or robot position variability, number of distractors, or task length. Our work thus also sheds light on the potential benefits and limitations of using the current multimodal VAEs for unsupervised learning of robotic motion trajectories based on vision and language.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t12_09">
             09:00-10:00, Paper FrPI6T12.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('882'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Adaptive Visual-Aided 4D Radar Odometry through Transformer-Based Feature Fusion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392956" title="Click to go to the Author Index">
             Zhang, Yuanfan
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#373023" title="Click to go to the Author Index">
             Xiao, Renxiang
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#236090" title="Click to go to the Author Index">
             Hong, Ziyang
            </a>
           </td>
           <td class="r">
            Heriot-Watt University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#280111" title="Click to go to the Author Index">
             Hu, Liang
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#294276" title="Click to go to the Author Index">
             Liu, Jie
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab882" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multimodal sensor fusion has been successfully utilized in many odometry and localization methods as it increases both estimate accuracy and robustness in application scenarios. To address the challenge of odometry under varying-weather conditions, we propose a novel visual 4D radar fusion based odometry in an unsupervised deep learning approach. In our method, we adopt transformer-based cascaded decoders to facilitate efficient feature extraction of images and radar point clouds. Considering that radars are weather-agnostic and information-rich cameras are susceptible to adverse weathers, we deliberately introduce an adaptive feature fusion strategy via the attention mechanism, in which the attention shifts dynamically to adapt to changing weather conditions based on the amount of information content in image features. Through extensive comparative experiments, our method surpasses different state-of-the-art single-modal odometry estimation methods. Our code and trained model will be released publicly.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t12_10">
             09:00-10:00, Paper FrPI6T12.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1361'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              VIRUS-NeRF - Vision, InfraRed and UltraSonic Based Neural Radiance Fields
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396247" title="Click to go to the Author Index">
             Schmid, Nicolaj
            </a>
           </td>
           <td class="r">
            EPFL
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285803" title="Click to go to the Author Index">
             von Einem, Cornelius
            </a>
           </td>
           <td class="r">
            ETH ZÃ¼rich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122912" title="Click to go to the Author Index">
             Cadena Lerma, Cesar
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100088" title="Click to go to the Author Index">
             Siegwart, Roland
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396372" title="Click to go to the Author Index">
             Hruby, Lorenz
            </a>
           </td>
           <td class="r">
            Filics GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#234191" title="Click to go to the Author Index">
             Tschopp, Florian
            </a>
           </td>
           <td class="r">
            Voliro AG
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1361" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous mobile robots are an increasingly integral part of modern factory and warehouse operations. Obstacle detection, avoidance and path planning are critical safety-relevant tasks, which are often solved using expensive LiDAR sensors and depth cameras. We propose to use costeffective low-resolution ranging sensors, such as ultrasonic and infrared time-of-flight sensors by developing VIRUS-NeRF - Vision, InfraRed, and UltraSonic based Neural Radiance Fields. Building upon Instant Neural Graphics Primitives with a Multiresolution Hash Encoding (Instant-NGP), VIRUS-NeRF incorporates depth measurements from ultrasonic and infrared sensors and utilizes them to update the occupancy grid used for ray marching. Experimental evaluation in 2D demonstrates that VIRUS-NeRF achieves comparable mapping performance to LiDAR point clouds regarding coverage. Notably, in small environments, its accuracy aligns with that of LiDAR measurements, while in larger ones, it is bounded by the utilized ultrasonic sensors. An in-depth ablation study reveals that adding ultrasonic and infrared sensors is highly effective when dealing with sparse data and low view variation. Further, the proposed occupancy grid of VIRUS-NeRF improves the mapping capabilities and increases the training speed by 46% compared to Instant-NGP. Overall, VIRUS-NeRF presents a promising approach for cost-effective local mapping in mobile robotics, with potential applications in safety and navigation tasks. The code can be found at https://github.com/ethz-asl/virus_nerf.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t12_11">
             09:00-10:00, Paper FrPI6T12.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1418'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Monocular Event-Inertial Odometry with Adaptive Decay-Based Time Surface and Polarity-Aware Tracking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352700" title="Click to go to the Author Index">
             Tang, Kai
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#293969" title="Click to go to the Author Index">
             Lang, Xiaolei
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324369" title="Click to go to the Author Index">
             Ma, Yukai
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391888" title="Click to go to the Author Index">
             Huang, Yuehao
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#325876" title="Click to go to the Author Index">
             Li, Laijian
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122966" title="Click to go to the Author Index">
             Liu, Yong
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#246892" title="Click to go to the Author Index">
             Lv, Jiajun
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1418" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_inertial_slam" title="Click to go to the Keyword Index">
               Visual-Inertial SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we propose a monocular event-inertial odometry that incorporates an adaptive decay kernel-based time surface with a polarity-aware tracking method. Event cameras have garnered considerable attention because of their advantages over traditional cameras in low power consumption, high dynamic range, and no motion blur. To extract texture information from asynchronous events, our odometry implements the Time Surface based on adaptive decay, and the adaptive decay can adapt to the dynamic characteristics of the event stream and enhance the representation of environmental textures. Moreover, polarity-weighted time surfaces suffer from event polarity shifts in the motion direction change. To mitigate its adverse effects on feature tracking, we optimize the tracking process by incorporating an additional polarity-inverted time surface to enhance the robustness. We compare our method with visual-intertial and event-inertial odometry methods in terms of accuracy. Additionally, we conduct ablation experiments on both decays, parameter settings and the polarity-aware tracking method. The experimental results demonstrate better performance over the state-of-the-art methods, along with competitive outcomes across various datasets.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t12_12">
             09:00-10:00, Paper FrPI6T12.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1437'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DCSANet: Dual Cross-Channel and Spatial Attention Make RGB-T Object Detection Better
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396582" title="Click to go to the Author Index">
             Lan, Xiaoxiong
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396598" title="Click to go to the Author Index">
             Liu, Shenghao
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374423" title="Click to go to the Author Index">
             Zhang, Zhiyong
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375031" title="Click to go to the Author Index">
             Qiu, Changzhen
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1437" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multimodal image pairs can make object detection more reliable in challenging environments, so RGB-T object detection has gained extensive attention over the past decade. To alleviate the complementarity of the visible and thermal modality, we propose a novel lightweight Feature Enhancement-fusion Module (FEM), which is composed of the Channel Enhancement-fusion Unit (CEU) and Spatial Enhancement-fusion Unit (SEU) by extending the attention mechanism to operate on two modalities. CEU is used to exploit the complementarity and alleviate the data imbalance by combining internal and global channel attention. Additionally, SEU is utilized to guide the model to pay more attention to the regions of interest. By incorporating FEM, enhanced and fused features are obtained, leading to improved performance. The effectiveness and generalizability of FEM are validated by two public datasets and our proposed DCSANet achieves competitive performance while maintaining high speed (+%7.0 on LLVIP and +1.2% on FLIR in mAP). Moreover, we conducted ablation experiments to verify the effectiveness of the proposed operators.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t12_13">
             09:00-10:00, Paper FrPI6T12.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Advanced Liquid and Dust Detection Sensor Setup and Algorithm Based on YOLO and Feature Extraction for Commercial Autonomous Cleaning Robots
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392671" title="Click to go to the Author Index">
             Jung, Dae-Hwan
            </a>
           </td>
           <td class="r">
            Samsung Electronics Company, Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276434" title="Click to go to the Author Index">
             Hong, Hyun Seok
            </a>
           </td>
           <td class="r">
            Samsung Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393935" title="Click to go to the Author Index">
             Park, Sahng-Gyu
            </a>
           </td>
           <td class="r">
            Samsung Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393934" title="Click to go to the Author Index">
             Lee, Yeongrok
            </a>
           </td>
           <td class="r">
            Samsung Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#112925" title="Click to go to the Author Index">
             Lee, Woosub
            </a>
           </td>
           <td class="r">
            Samsung
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t12_14">
             09:00-10:00, Paper FrPI6T12.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1973'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Error-State Kalman Filter Based Visual-Inertial Odometry Using Orientation Measurement on Unit Quaternion Group
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397169" title="Click to go to the Author Index">
             Chang, Chao-Wei
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102410" title="Click to go to the Author Index">
             Lian, Feng-Li
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1973" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_inertial_slam" title="Click to go to the Keyword Index">
               Visual-Inertial SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The inaccessibility of data from standard sensor suites on closed-platform unmanned aerial vehicles (UAVs) has been a hindrance to developing a compatible visual-inertial odometry (VIO). Despite the advance of recent VIO research, these works often emphasize fusing detailed sensor models with available sensor data at a relatively high frequency. To address this issue, in this paper, we derive an innovation signal for an orientation measurement model on the unit quaternion group S^3 based on the error-state Kalman filter (ESKF) framework. Leveraging the error-state formulation, the innovation signal directly exploits the geometric error representation on S^3 instead of treating unit quaternions as R^4 vectors. Flight experiments on a small commercial UAV (Fig. 1) have been carried out to compare the performance of the proposed ESKF with quaternion measurements on S^3 (ESKF-Q) against the original ESKF framework. Experimental results demonstrate that while both representations of unit quaternion measurements in ESKF framework improve orientation estimates with unperturbed orientation measurement model, only the proposed ESKF-Q exhibits convergent state estimates in the presence of uncertainties in the orientation measurement model.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t12_15">
             09:00-10:00, Paper FrPI6T12.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2785'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Real-Time Truly-Coupled Lidar-Inertial Motion Correction and Spatiotemporal Dynamic Object Detection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#218805" title="Click to go to the Author Index">
             Le Gentil, Cedric
            </a>
           </td>
           <td class="r">
            University of Technology Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#184933" title="Click to go to the Author Index">
             Falque, Raphael
            </a>
           </td>
           <td class="r">
            University of Technology Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103428" title="Click to go to the Author Index">
             Vidal-Calleja, Teresa A.
            </a>
           </td>
           <td class="r">
            University of Technology Sydney
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2785" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Over the past decade, lidars have become a cornerstone of robotics state estimation and perception thanks to their ability to provide accurate geometric information about their surroundings in the form of 3D scans. Unfortunately, most of nowadays lidars do not take snapshots of the environment but sweep the environment over a period of time (typically around 100 ms). Such a rolling-shutter-like mechanism introduces motion distortion into the collected lidar scan, thus hindering downstream perception applications. In this paper, we present a novel method for motion distortion correction of lidar data by tightly coupling lidar with Inertial Measurement Unit (IMU) data. The motivation of this work is a map-free dynamic object detection based on lidar. The proposed lidar data undistortion method relies on continuous preintegrated of IMU measurements that allow parameterising the sensorsâ€™ continuous 6-DoF trajectory using solely eleven discrete state variables (biases, initial velocity, and gravity direction). The undistortion consists of feature-based distance minimisation of point-to-line and point-to-plane residuals in a non-linear least-square formulation. Given undistorted geometric data over a short temporal window, the proposed pipeline computes the spatiotemporal normal vector of each of the lidar points. The temporal component of the normals is a proxy for the corresponding pointâ€™s velocity, therefore allowing for learning-free dynamic object classification without the need for registration in a global reference frame. We demonstrate the soundness of the proposed method and its different components using public datasets and compare them with state-of-the-art lidar-inertial state estimation and dynamic object detection algorithms.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t12_16">
             09:00-10:00, Paper FrPI6T12.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2994'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Accurate and Efficient Loop Closure Detection with Deep Binary Image Descriptor and Augmented Point Cloud Registration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377488" title="Click to go to the Author Index">
             Wang, Jialiang
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#193655" title="Click to go to the Author Index">
             Gao, Zhi
            </a>
           </td>
           <td class="r">
            Temasek Laboratories @ NUS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335326" title="Click to go to the Author Index">
             Lin, Zhipeng
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378929" title="Click to go to the Author Index">
             Zhou, Zhiyu
            </a>
           </td>
           <td class="r">
            Wuhan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398751" title="Click to go to the Author Index">
             Wang, Xiaonan
            </a>
           </td>
           <td class="r">
            ZG Technology Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398759" title="Click to go to the Author Index">
             Cheng, Jianhua
            </a>
           </td>
           <td class="r">
            ZG Technology Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377634" title="Click to go to the Author Index">
             Zhang, Hao
            </a>
           </td>
           <td class="r">
            Wuhan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#341800" title="Click to go to the Author Index">
             Liu, Xinyi
            </a>
           </td>
           <td class="r">
            Wuhan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#171587" title="Click to go to the Author Index">
             Chen, Ben M.
            </a>
           </td>
           <td class="r">
            Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2994" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Loop Closure Detection (LCD) is an essential component of Simultaneous Localization and Mapping (SLAM), helping to correct drift errors, facilitate map merging, or both by identifying previously observed scenes. Despite its importance, traditional LCD algorithms based on single sensor such as camera or LiDAR exhibit degraded performance in challenging scenarios due to their inherent limitations. To address this issue, we propose a novel LCD method based on camera-LiDAR fusion, exploiting the rich textural information from cameras and the accurate geometric data from LiDAR to ensure robustness and speed in challenging environments. Specifically, we first employ deep hashing learning to encode deep image features into binary image descriptor for extremely fast loop candidate (LC) retrieval. Then, LiDAR points are augmented with image color for accurate geometric verification. Finally, we incorporate a spatial-temporal consistency check that mandates an LC to have consistently matched neighbors to be accepted as true. Our method is extensively verified and compared with state-of-the-art methods on various public datasets and our own data, encompassing both indoor and outdoor environments. Experimental results demonstrate that our method obtains the best performance, increasing the maximum recall rate at 100% precision by a significant margin of 20% while operating in real-time at an average speed of 30 fps.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi6t12_17">
             09:00-10:00, Paper FrPI6T12.17
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3007'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Event-Intensity Stereo with Cross-Modal Fusion and Contrast
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#348955" title="Click to go to the Author Index">
             Wang, Yuanbo
            </a>
           </td>
           <td class="r">
            Dalian University of Technolory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375214" title="Click to go to the Author Index">
             Qu, Shanglai
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397730" title="Click to go to the Author Index">
             Meng, Tianyu
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398670" title="Click to go to the Author Index">
             Cui, Yan
            </a>
           </td>
           <td class="r">
            China Germany Artificial Intelligence Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#297585" title="Click to go to the Author Index">
             Piao, Haiyin
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276968" title="Click to go to the Author Index">
             Wei, Xiaopeng
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276961" title="Click to go to the Author Index">
             Yang, Xin
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3007" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             For binocular stereo, traditional cameras excel in capturing fine details and texture information but are limited in terms of dynamic range and their ability to handle rapid motion. On the other hand, event cameras provide pixel-level intensity changes with low latency and a wide dynamic range, albeit at the cost of less detail in their output. It is natural to leverage the strengths of both modalities. We solve this problem by introducing a cross-modal fusion module that learns a visual representation from both sensor inputs. Additionally, we extract and compare dense event-intensity stereo pair features by contrasting â€œpairs of event-intensity pairs from different views and different modalities and different timestampsâ€. This provides the flexibility in masking hard negatives and enables networks to effectively combine event-intensity signals within a contrastive learning framework, leading to an improved matching accuracy and facilitating more accurate estimation of disparity. Experimental results validate the effectiveness of our model and the improvement of disparity estimation accuracy.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frat1">
             <b>
              FrAT1
             </b>
            </a>
           </td>
           <td class="r">
            Room 1
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frat1" title="Click to go to the Program at a Glance">
             <b>
              SLAM V
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat1_01">
             10:00-10:15, Paper FrAT1.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3138'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              EverySync: An Open Hardware Time Synchronization Sensor Suite for Common Sensors in SLAM
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363277" title="Click to go to the Author Index">
             Wu, Xuankang
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377444" title="Click to go to the Author Index">
             Sun, Haoxiang
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363239" title="Click to go to the Author Index">
             Wu, Rongguang
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#121608" title="Click to go to the Author Index">
             Fang, Zheng
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3138" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#software_hardware_integration_for_robot_systems" title="Click to go to the Keyword Index">
               Software-Hardware Integration for Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-sensor fusion systems have been widely applied in various fields, including mobile robot, simultaneous localization and mapping (SLAM), and autonomous driving. For a tightly coupled multi-sensor fusion system, strict time synchronization between sensors will improve the accuracy of the system. However, there is currently a lack of open-source and general-purpose hardware synchronization systems for Cameras, IMUs, LiDARs, GNSS/RTK in the academic community. Therefore, we propose EverySync, an open hardware time synchronization system to address this gap. The synchronization accuracy of the system was evaluated through multiple experiments, achieving an accuracy of less than 1 ms. And, real-world experiments proved that hardware time synchronization improves the accuracy of the SLAM system. This open-source system is available on GitHub.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat1_02">
             10:15-10:30, Paper FrAT1.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('332'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Point-Line Features Fusion Method for Fast and Robust Monocular Visual-Inertial Initialization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391146" title="Click to go to the Author Index">
             Xie, Guoqiang
            </a>
           </td>
           <td class="r">
            Sichuan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392028" title="Click to go to the Author Index">
             Chen, Jie
            </a>
           </td>
           <td class="r">
            Sichuan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391897" title="Click to go to the Author Index">
             Tang, Tianhang
            </a>
           </td>
           <td class="r">
            Sichuan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391895" title="Click to go to the Author Index">
             Chen, Zeyu
            </a>
           </td>
           <td class="r">
            Sichuan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391953" title="Click to go to the Author Index">
             Lei, Ling
            </a>
           </td>
           <td class="r">
            Sichuan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#170160" title="Click to go to the Author Index">
             Liu, Yiguang
            </a>
           </td>
           <td class="r">
            Sichuan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab332" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_inertial_slam" title="Click to go to the Keyword Index">
               Visual-Inertial SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Fast and robust initialization is essential for highly accurate monocular visual-inertial odometer (VIO), but at present majority of initialization methods rely only on point features, unstable in low texture and blurring situations. Therefore, we propose a novel point-line features fusion method for monocular visual-inertial initialization, as line features are more stable and provide richer geometric information than point features: 1) a closed-form line features initialization method is presented, and combined with point features to obtain a more integrated and robust linear system; 2) a monocular depth network is adopted to provide learned affine-invariant depth map, requiring only one prior depth map for the first frame, which can improve performance under low-parallax scenarios; 3) we can easily use RANSAC to reject outliers in solving linear system based on our formulation. Moreover, line feature re-projection residual is added to visual-inertial bundle adjustment (VI-BA) to obtain more accurate initial parameters. The proposed method is more accurate and robust than state-of-the-art methods due to the line features, especially under extreme low-parallax scenarios, and extensive experiments on popular datasets have confirmed, 0.5s initialization window on EuRoC MAV, 0.3s initialization window on TUM-VI, while the standard method normally waits for a window of 2s.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat1_03">
             10:30-10:45, Paper FrAT1.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1097'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              NVINS: Robust Visual Inertial Navigation Fused with NeRF-Augmented Camera Pose Regressor and Uncertainty Quantification
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#337592" title="Click to go to the Author Index">
             Han, Juyeop
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291945" title="Click to go to the Author Index">
             Lao Beyer, Lukas
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#211997" title="Click to go to the Author Index">
             Cavalheiro, Guilherme
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#124153" title="Click to go to the Author Index">
             Karaman, Sertac
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1097" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_inertial_slam" title="Click to go to the Keyword Index">
               Visual-Inertial SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#probabilistic_inference" title="Click to go to the Keyword Index">
               Probabilistic Inference
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In recent years, Neural Radiance Fields (NeRF) have emerged as a powerful tool for 3D reconstruction and novel view synthesis. However, the computational cost of NeRF rendering and degradation in quality due to the presence of artifacts pose significant challenges for its application in real-time and robust robotic tasks, especially on embedded systems. This paper introduces a novel framework that integrates NeRF-derived localization information with Visual-Inertial Odometry (VIO) to provide a robust solution for robotic navigation in a real-time. By training an absolute pose regression network with augmented image data rendered from a NeRF and quantifying its uncertainty, our approach effectively counters positional drift and enhances system reliability. We also establish a mathematically sound foundation for combining visual inertial navigation with camera localization neural networks, considering uncertainty under a Bayesian framework. Experimental validation in the photorealistic simulation environment demonstrates significant improvements in accuracy compared to a conventional VIO approach.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat1_04">
             10:45-11:00, Paper FrAT1.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3265'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Online Refractive Camera Model Calibration in Visual Inertial Odometry
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#273163" title="Click to go to the Author Index">
             Singh, Mohit
            </a>
           </td>
           <td class="r">
            NTNU: Norwegian University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#132933" title="Click to go to the Author Index">
             Alexis, Kostas
            </a>
           </td>
           <td class="r">
            NTNU - Norwegian University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3265" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_inertial_slam" title="Click to go to the Keyword Index">
               Visual-Inertial SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a general refractive camera model and online co-estimation of odometry and the refractive index of an unknown media. This enables operation in diverse and varying refractive fluids, given only the camera calibration in air. The refractive index is estimated online as a state variable of a monocular visual-inertial odometry framework in an iterative formulation using the proposed camera model. The method was verified on data collected using an underwater robot traversing inside a pool. The evaluations demonstrate convergence to the ideal refractive index for water despite significant perturbations in the initialization. Simultaneously, the approach enables on-par visual-inertial odometry performance in refractive media without prior knowledge of the refractive index or requirement of medium-specific camera calibration.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frat2">
             <b>
              FrAT2
             </b>
            </a>
           </td>
           <td class="r">
            Room 2
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frat2" title="Click to go to the Program at a Glance">
             <b>
              Neurorobotics
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#238075" title="Click to go to the Author Index">
             Anil Meera, Ajith
            </a>
           </td>
           <td class="r">
            Radboud University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat2_01">
             10:00-10:15, Paper FrAT2.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('826'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Confidence-Aware Decision-Making and Control for Tool Selection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238075" title="Click to go to the Author Index">
             Anil Meera, Ajith
            </a>
           </td>
           <td class="r">
            Radboud University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#154539" title="Click to go to the Author Index">
             Lanillos, Pablo
            </a>
           </td>
           <td class="r">
            Donders Institute for Brain, Cognition and Behavior, Radboud Uni
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab826" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#neurorobotics" title="Click to go to the Keyword Index">
               Neurorobotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cognitive_modeling" title="Click to go to the Keyword Index">
               Cognitive Modeling
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cognitive_control_architectures" title="Click to go to the Keyword Index">
               Cognitive Control Architectures
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Self-reflecting about our performance (e.g., how confident we are) before doing a task is essential for decision making, such as selecting the most suitable tool or choosing the best route to drive. While this form of awareness (thinking about our performance or metacognitive performance) is well-known in humans, robots still lack this cognitive ability. This reflective monitoring can enhance their embodied decision power, robustness and safety. Here, we take a step in this direction by introducing a mathematical framework that allows robots to use their control self-confidence to make better-informed decisions. We derive a mathematical closed-form expression for control confidence for dynamic systems (i.e., the posterior inverse covariance of the control action). This control confidence seamlessly integrates within an objective function for decision making, that balances the: i) performance for task completion, ii) control effort, and iii) self-confidence. To evaluate our theoretical account, we framed the decision-making within the tool selection problem, where the agent has to select the best robot arm for a particular control task. The statistical analysis of the numerical simulations with randomized 2DOF arms shows that using control confidence during tool selection improves both real task performance, and the reliability of the tool for performance under unmodelled perturbations (e.g., external forces). Furthermore, our results indicate that control confidence is an early indicator of performance and thus, it can be used as a heuristic for making decisions when computation power is restricted or decision-making is intractable. Overall, we show the advantages of using confidence-aware decision-making and control scheme for dynamic systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat2_02">
             10:15-10:30, Paper FrAT2.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('875'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Environment Transformer and Policy Optimization for Model-Based Offline Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#317462" title="Click to go to the Author Index">
             Wang, Pengqin
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#288834" title="Click to go to the Author Index">
             Zhu, Meixin
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142354" title="Click to go to the Author Index">
             Shen, Shaojie
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab875" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#environment_monitoring_and_management" title="Click to go to the Keyword Index">
               Environment Monitoring and Management
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#long_term_interaction" title="Click to go to the Keyword Index">
               Long term Interaction
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Interacting with the actual environment to acquire data is often costly and time-consuming in robotic tasks. Model-based offline reinforcement learning (RL) provides a feasible solution. On the one hand, it eliminates the requirements of interaction with the actual environment. On the other hand, it learns the transition dynamics and reward function from the offline datasets and generates simulated rollouts to accelerate training. Previous model-based offline RL methods adopt probabilistic ensemble neural networks (NN) to model aleatoric uncertainty and epistemic uncertainty. However, this results in a great increase in training time and computing resource requirements. Furthermore, these methods are easily disturbed by the accumulative errors of the environment dynamics models when simulating long-term rollouts. To solve the above problems, we propose an uncertainty-aware sequence modeling architecture called Environment Transformer. It models the probability distribution of the environment dynamics and reward function to capture aleatoric uncertainty and treats epistemic uncertainty as a learnable noise parameter. Benefiting from the accurate modeling of the transition dynamics and reward function, Environment Transformer can be combined with arbitrary planning, dynamics programming, or policy optimization algorithms for offline RL. In this case, we perform Conservative Q-Learning (CQL) to learn a conservative Q-function. Through simulation experiments, we demonstrate that our method achieves or exceeds state-of-the-art performance in widely studied offline RL benchmarks. Moreover, we show that Environment Transformer's simulated rollout quality, sample efficiency, and long-term rollout simulation capability are superior to those of previous model-based offline RL methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat2_03">
             10:30-10:45, Paper FrAT2.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2458'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning to Recover from Plan Execution Errors During Robot Manipulation: A Neuro-Symbolic Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#341508" title="Click to go to the Author Index">
             Kalithasan, Namasivayam
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology, Delhi
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#342071" title="Click to go to the Author Index">
             Tuli, Arnav
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology, Delhi
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#342179" title="Click to go to the Author Index">
             Bindal, Vishal
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology, Delhi
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#342036" title="Click to go to the Author Index">
             Singh, Himanshu Gaurav
            </a>
           </td>
           <td class="r">
            University of California Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#342116" title="Click to go to the Author Index">
             Singla, Parag
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology, Delhi
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#132742" title="Click to go to the Author Index">
             Paul, Rohan
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology Delhi
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2458" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#failure_detection_and_recovery" title="Click to go to the Keyword Index">
               Failure Detection and Recovery
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Automatically detecting and recovering from failures is an important but challenging problem for autonomous robots. Most of the recent work on learning to plan from demonstrations lacks the ability to detect and recover from errors in the absence of an explicit state representation and/or a (sub-) goal check function. We propose an approach (blending learning with symbolic search) for automated error discovery and recovery, without needing annotated data of failures. Central to our approach is a neuro-symbolic state representation, in the form of dense scene graph, structured based on the objects present within the environment. This enables efficient learning of the transition function and a discriminator that not only identifies failures but also localizes them facilitating fast re-planning via computation of heuristic distance function. We also present an anytime version of our algorithm, where instead of recovering to the last correct state, we search for a sub-goal in the original plan minimizing the total distance to the goal given a re-planning budget. Experiments on a physics simulator with a variety of simulated failures show the effectiveness of our approach compared to existing baselines, both in terms of efficiency as well as accuracy of our recovery mechanism.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat2_04">
             10:45-11:00, Paper FrAT2.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1335'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MLPER: Multi-Level Prompts for Adaptively Enhancing Vision-Language Emotion Recognition
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390724" title="Click to go to the Author Index">
             Gao, Yu
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#343672" title="Click to go to the Author Index">
             Ren, Weihong
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology (Shenzhen)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372097" title="Click to go to the Author Index">
             Xu, Xinglong
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology(Shenzhen)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396310" title="Click to go to the Author Index">
             Wang, Yan
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385193" title="Click to go to the Author Index">
             Wang, Zhiyong
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#112147" title="Click to go to the Author Index">
             Liu, Honghai
            </a>
           </td>
           <td class="r">
            Portsmouth University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1335" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#gesture__posture_and_facial_expressions" title="Click to go to the Keyword Index">
               Gesture, Posture and Facial Expressions
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#emotional_robotics" title="Click to go to the Keyword Index">
               Emotional Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the fields of robotics, vision-based Emotion Recognition (ER) has achieved significant progress, but it still faces the challenge of poor generalization ability under unconstrained conditions (e.g., occlusions and pose variations). In this work, we propose MLPER model, which introduces Vision-Language Model for Emotion Recognition to learn discriminative representations adaptively. Specifically, different from typically leveraging a hand-crafted prompt (e.g., â€œa photo of a [class] personâ€), we first establish Multi-Level Prompts from three aspects: facial expression, human posture and situational condition using large language models, like ChatGPT. Correspondingly, we extract the visual tokens from three levels: the face, body, and context. Further, to achieve fine-grained alignment on each level, we adopt textual tokens from the positive and the hard negative to query visual tokens, predicting whether a pair of image and text is matched. Experimental results demonstrate that our MLPER model outperforms the state-of-the-art methods on several ER benchmarks, especially under the conditions of occlusions and pose variations.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frat3">
             <b>
              FrAT3
             </b>
            </a>
           </td>
           <td class="r">
            Room 3
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frat3" title="Click to go to the Program at a Glance">
             <b>
              Cooperative Manipulation
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#178939" title="Click to go to the Author Index">
             Hamaya, Masashi
            </a>
           </td>
           <td class="r">
            OMRON SINIC X Corporation
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#210962" title="Click to go to the Author Index">
             Park, J. hyeon
            </a>
           </td>
           <td class="r">
            Samsung Electronics
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat3_01">
             10:00-10:15, Paper FrAT3.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('916'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hierarchical Action Chunking Transformer: Learning Temporal Multimodality from Demonstrations with Fast Imitation Behavior
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#210962" title="Click to go to the Author Index">
             Park, J. hyeon
            </a>
           </td>
           <td class="r">
            Samsung Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#373319" title="Click to go to the Author Index">
             Choi, Wonhyuk
            </a>
           </td>
           <td class="r">
            SAMSUNG Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#298480" title="Click to go to the Author Index">
             Hong, Sunpyo
            </a>
           </td>
           <td class="r">
            Samsung Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#179146" title="Click to go to the Author Index">
             Seo, Hoseong
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#218844" title="Click to go to the Author Index">
             Ahn, Joonmo
            </a>
           </td>
           <td class="r">
            Samsung Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#159880" title="Click to go to the Author Index">
             Ha, Changsu
            </a>
           </td>
           <td class="r">
            Samsung Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#298475" title="Click to go to the Author Index">
             Han, Heungwoo
            </a>
           </td>
           <td class="r">
            Samsung Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106548" title="Click to go to the Author Index">
             Kwon, Junghyun
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab916" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#bimanual_manipulation" title="Click to go to the Keyword Index">
               Bimanual Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Behavioral cloning from human demonstrations has succeeded in programming a robot to generate fine-grained motion, but it is still challenging to learn multimodal trajectories such as with various speeds. This restricts the use of a robot dataset collected by multiusers because the different proficiency of robot operators makes the dataset have diverse distributions of speed. To tackle this issue, we develop Hierarchical Action Chunking Transformer with Vector-quantization (HACT-Vq) to efficiently learn temporal multimodality in addition to fine-grained motion. The proposed hierarchical model consists of a high-level policy to make planning for a latent subgoal and style, and a low-level policy to predict an action chunk conditioned with the latent subgoal and style. The latent subgoal and style are trained as discrete representations so that high-level policy can efficiently learn multimodal distributions of demonstrations and retrieve the mode of fast behavior. In experiments, we set up bimanual robots in both simulation and real-world environments, and collected demonstrations with various speeds. The proposed model with the quantized subgoal and style showed the highest success rates with fast imitation behavior. Our code is available at textit{https://github.com/SamsungLabs/hierarchical-act.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat3_02">
             10:15-10:30, Paper FrAT3.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1448'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Dynamic Manipulation of Deformable Objects Using Imitation Learning with Adaptation to Hardware Constraints
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391856" title="Click to go to the Author Index">
             Hannus, Eric
            </a>
           </td>
           <td class="r">
            Aalto University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#266640" title="Click to go to the Author Index">
             Nguyen Le, Tran
            </a>
           </td>
           <td class="r">
            Aalto University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#211191" title="Click to go to the Author Index">
             Blanco-Mulero, David
            </a>
           </td>
           <td class="r">
            Institut De RobÃ²tica I InformÃ tica Industrial, CSIC-UPC
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105044" title="Click to go to the Author Index">
             Kyrki, Ville
            </a>
           </td>
           <td class="r">
            Aalto University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1448" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#bimanual_manipulation" title="Click to go to the Keyword Index">
               Bimanual Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dual_arm_manipulation" title="Click to go to the Keyword Index">
               Dual Arm Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Imitation Learning (IL) is a promising paradigm for learning dynamic manipulation of deformable objects since it does not depend on difficult-to-create accurate simulations of such objects. However, the translation of motions demonstrated by a human to a robot is a challenge for IL, due to differences in the embodiments and the robotâ€™s physical limits. These limits are especially relevant in dynamic manipulation where high velocities and accelerations are typical. To address this problem, we propose a framework that first maps a dynamic demonstration into a motion that respects the robotâ€™s constraints using a constrained Dynamic Movement Primitive. Second,the resulting object state is further optimized by quasi-static refinement motions to optimize task performance metrics. This allows both efficiently altering the object state by dynamic motions and stable small-scale refinements. We evaluate the framework in the challenging task of bag opening, designing the system BILBO: Bimanual dynamic manipulation using Imitation Learning for Bag Opening. Our results show that BILBO can successfully open a wide range of crumpled bags, using a demonstration with a single bag. See supplementary material at https://sites.google.com/view/bilbo-bag.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat3_03">
             10:30-10:45, Paper FrAT3.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1120'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Variable Compliance Control from a Few Demonstrations for Bimanual Robot with Haptic Feedback Teleoperation System
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372695" title="Click to go to the Author Index">
             Kamijo, Tatsuya
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#165436" title="Click to go to the Author Index">
             Beltran-Hernandez, Cristian Camilo
            </a>
           </td>
           <td class="r">
            OMRON SINIC X Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#178939" title="Click to go to the Author Index">
             Hamaya, Masashi
            </a>
           </td>
           <td class="r">
            OMRON SINIC X Corporation
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1120" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dual_arm_manipulation" title="Click to go to the Keyword Index">
               Dual Arm Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Automating dexterous, contact-rich manipulation tasks using rigid robots is a significant challenge in robotics. Rigid robots, defined by their actuation through position commands, face issues of excessive contact forces due to their inability to adapt to contact with the environment, potentially causing damage. While compliance control schemes have been introduced to mitigate these issues by controlling forces via external sensors, they are hampered by the need for fine-tuning task-specific controller parameters. Learning from Demonstrations (LfD) offers an intuitive alternative, allowing robots to learn manipulations through observed actions. In this work, we introduce a novel system to enhance the teaching of dexterous, contact-rich manipulations to rigid robots. Our system is twofold: firstly, it incorporates a teleoperation interface utilizing Virtual Reality (VR) controllers, designed to provide an intuitive and cost-effective method for task demonstration with haptic feedback. Secondly, we present Comp-ACT (Compliance Control via Action Chunking with Transformers), a method that leverages the demonstrations to learn variable compliance control from a few demonstrations. Our methods have been validated across various complex contact-rich manipulation tasks using single-arm and bimanual robot setups in simulated and real-world environments, demonstrating the effectiveness of our system in teaching robots dexterous manipulations with enhanced adaptability and safety. Code available at https://github.com/omron-sinicx/CompACT
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat3_04">
             10:45-11:00, Paper FrAT3.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('957'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Agent Behavior Retrieval: Retrieval-Augmented Policy Training for Cooperative Push Manipulation by Mobile Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#343456" title="Click to go to the Author Index">
             Kuroki, So
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#274687" title="Click to go to the Author Index">
             Nishimura, Mai
            </a>
           </td>
           <td class="r">
            Omron Sinic X
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#347321" title="Click to go to the Author Index">
             Kozuno, Tadashi
            </a>
           </td>
           <td class="r">
            Omron Sinic X
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab957" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Due to the complex interactions between agents, learning multi-agent control policy often requires a prohibitive amount of data. This paper aims to enable multi-agent systems to effectively utilize past memories to adapt to novel collaborative tasks in a data-efficient fashion. We propose the Multi-Agent Coordination Skill Database, a repository for storing a collection of coordinated behaviors associated with key vectors distinctive to them. Our Transformer-based skill encoder effectively captures spatio-temporal interactions that contribute to coordination and provides a unique skill representation for each coordinated behavior. By leveraging only a small number of demonstrations of the target task, the database enables us to train the policy using a dataset augmented with the retrieved demonstrations. Experimental evaluations demonstrate that our method achieves a significantly higher success rate in push manipulation tasks compared with baseline methods like few-shot imitation learning. Furthermore, we validate the effectiveness of our retrieve-and-learn framework in a real environment using a team of wheeled robots.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frat4">
             <b>
              FrAT4
             </b>
            </a>
           </td>
           <td class="r">
            Room 4
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frat4" title="Click to go to the Program at a Glance">
             <b>
              Underactuated Robots
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#150250" title="Click to go to the Author Index">
             Renda, Federico
            </a>
           </td>
           <td class="r">
            Khalifa University of Science and Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat4_01">
             10:00-10:15, Paper FrAT4.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1364'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              On Performing Non-Prehensile Rolling Manipulations: Stabilizing Synchronous Motions of Butterfly Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#167057" title="Click to go to the Author Index">
             Surov, Maksim
            </a>
           </td>
           <td class="r">
            Arrival R&amp;D
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#139871" title="Click to go to the Author Index">
             Pchelkin, Stepan
            </a>
           </td>
           <td class="r">
            Huawei
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109377" title="Click to go to the Author Index">
             Shiriaev, Anton
            </a>
           </td>
           <td class="r">
            Norwegian University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#134482" title="Click to go to the Author Index">
             Gusev, Sergei V.
            </a>
           </td>
           <td class="r">
            St. Petersburg State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109126" title="Click to go to the Author Index">
             Freidovich, Leonid
            </a>
           </td>
           <td class="r">
            UmeÃ¥ University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1364" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#underactuated_robots" title="Click to go to the Keyword Index">
               Underactuated Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The paper explores the challenging task of performing a non-prehensile manipulation of several balls synchronously rolling on the curved hands of Butterfly robots. Each Butterfly robot represents a standard benchmark hardware setup, comprising a DC motor rotating a butterfly-shaped frame in a vertical plane, with a ball moving freely upon it, equipped with integrated computer vision, communication, programmable control, and computation interfaces.
             <p>
              The combined dynamics of the considered system, consisting of N (2 or more) such robots, is inherently underactuated, characterized by N active and N passive degrees of freedom, as well as N independent unilateral constraints that model the interactions between the frames and the balls, assuming no slipping.
              <p>
               We focus on designing a model-based centralized feedback controller to achieve synchronized rotations of the balls. We assume the accuracy of our mathematical model and the feasibility of implementing a discretized digital controller with a small sampling time. Without rigorous analysis, we will experimentally check robustness to various inevitable challenges such as noises, disturbances, uncertainties, and communication delays. Hence, our concentration lies in designing an orbitally stabilizing controller for the underactuated models.
               <p>
                The primary contribution is proposing one set of transverse coordinates, enabling transverse-linearization-based controller design, accompanied by pertinent closed-loop system analysis tools, thereby enhancing the efficacy of solving the manipulation task.
                <p>
                 Analytical and model-based arguments are validated through successful simulations and experiments conducted on two Butterfly robots, thereby emphasizing the validity and practicality of the proposed approach.
                </p>
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat4_02">
             10:15-10:30, Paper FrAT4.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3359'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Dynamic Walking on Highly Underactuated Point Foot Humanoids: Closing the Loop between HZD and HLIP
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#381172" title="Click to go to the Author Index">
             Ghansah, Adrian
            </a>
           </td>
           <td class="r">
            California Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#201505" title="Click to go to the Author Index">
             Kim, Jeeseop
            </a>
           </td>
           <td class="r">
            Caltech
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#287869" title="Click to go to the Author Index">
             Li, Kejun
            </a>
           </td>
           <td class="r">
            California Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#134049" title="Click to go to the Author Index">
             Ames, Aaron
            </a>
           </td>
           <td class="r">
            Caltech
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3359" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#underactuated_robots" title="Click to go to the Keyword Index">
               Underactuated Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#whole_body_motion_planning_and_control" title="Click to go to the Keyword Index">
               Whole-Body Motion Planning and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Realizing bipedal locomotion on humanoid robots with point feet is especially challenging due to their highly underactuated nature, high degrees of freedom, and hybrid dynamics resulting from impacts. With the goal of addressing this challenging problem, this paper develops a control framework for realizing dynamic locomotion and implements it on a novel point foot humanoid: ADAM. To this end, we close the loop between Hybrid Zero Dynamics (HZD) and Hybrid linear inverted pendulum (HLIP) based step length regulation. To leverage the full-order hybrid dynamics of the robot, walking gaits are first generated offline by utilizing HZD. These trajectories are stabilized online through the use of a HLIP based regulator. Finally, the planned trajectories are mapped into the full-order system by using a task space controller incorporating inverse kinematics. The proposed method is verified through numerical simulations and hardware experiments on the humanoid robot ADAM marking the first humanoid point foot walking. Moreover, we experimentally demonstrate the robustness of the realized walking via the ability to track a desired reference speed, robustness to pushes, and locomotion on uneven terrain.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat4_03">
             10:30-10:45, Paper FrAT4.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1991'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Reinforcement Learning Control for Autonomous Hydraulic Material Handling Machines with Underactuated Tools
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#323216" title="Click to go to the Author Index">
             Spinelli, Filippo Alberto
            </a>
           </td>
           <td class="r">
            ETH ZÃ¼rich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#270333" title="Click to go to the Author Index">
             Egli, Pascal Arturo
            </a>
           </td>
           <td class="r">
            RSL, ETHZ
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256647" title="Click to go to the Author Index">
             Nubert, Julian
            </a>
           </td>
           <td class="r">
            ETH ZÃ¼rich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310196" title="Click to go to the Author Index">
             Nan, Fang
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396546" title="Click to go to the Author Index">
             Bleumer, Thilo
            </a>
           </td>
           <td class="r">
            Liebherr Hydraulikbagger GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397547" title="Click to go to the Author Index">
             Goegler, Patrick
            </a>
           </td>
           <td class="r">
            Liebherr Hydraulikbagger GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397538" title="Click to go to the Author Index">
             Brockes, Stephan
            </a>
           </td>
           <td class="r">
            Liebherr Hydraulikbagger GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397542" title="Click to go to the Author Index">
             Hofmann, Ferdinand
            </a>
           </td>
           <td class="r">
            Liebherr Hydraulikbagger GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114045" title="Click to go to the Author Index">
             Hutter, Marco
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1991" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robotics_and_automation_in_construction" title="Click to go to the Keyword Index">
               Robotics and Automation in Construction
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#hydraulic_pneumatic_actuators" title="Click to go to the Keyword Index">
               Hydraulic/Pneumatic Actuators
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The precise and safe control of heavy material handling machines presents numerous challenges due to the hard-to-model hydraulically actuated joints and the need for collision-free trajectory planning with a free-swinging end-effector tool. In this work, we propose an RL-based controller that commands the cabin joint and the arm simultaneously. It is trained in a simulation combining data-driven modeling techniques with first-principles modeling. On the one hand, we employ a neural network model to capture the highly nonlinear dynamics of the upper carriage turn hydraulic motor, incorporating explicit pressure prediction to handle delays better. On the other hand, we model the arm as velocity-controllable and the free-swinging end-effector tool as a damped pendulum using first principles. This combined model enhances our simulation environment, enabling the training of RL controllers that can be directly transferred to the real machine. Designed to reach steady-state Cartesian targets, the RL controller learns to leverage the hydraulic dynamics to improve accuracy, maintain high speeds, and minimize end-effector tool oscillations. Our controller, tested on a mid-size prototype material handler, is more accurate than an inexperienced operator and causes fewer tool oscillations. It demonstrates competitive performance even compared to an experienced professional driver.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat4_04">
             10:45-11:00, Paper FrAT4.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1967'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Motion Primitives Planning for Center-Articulated Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395817" title="Click to go to the Author Index">
             Hu, Jiangpeng
            </a>
           </td>
           <td class="r">
            ETH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#287076" title="Click to go to the Author Index">
             Yang, Fan
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310196" title="Click to go to the Author Index">
             Nan, Fang
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114045" title="Click to go to the Author Index">
             Hutter, Marco
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1967" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reactive_and_sensor_based_planning" title="Click to go to the Keyword Index">
               Reactive and Sensor-Based Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous navigation across unstructured terrains, including forests and construction areas, faces unique challenges due to intricate obstacles and the element of the unknown. Lacking pre-existing maps, these scenarios necessitate a motion planning approach that combines agility with efficiency. Critically, it must also incorporate the robot's kinematic constraints to navigate more effectively through complex environments. This work introduces a novel planning method for center-articulated vehicles (CAV), leveraging motion primitives within a receding horizon planning framework using onboard sensing. The approach commences with the offline creation of motion primitives, generated through forward simulations that reflect the distinct kinematic model of center-articulated vehicles. These primitives undergo evaluation through a heuristic-based scoring function, facilitating the selection of the most suitable path for real-time navigation. To account for disturbances, we develop a pose-stabilizing controller, tailored to the kinematic specifications of center-articulated vehicles. During experiments, our method demonstrates a 67% improvement in SPL (Success Rate weighted by Path Length) performance over existing strategies. Furthermore, its efficacy was validated through real-world experiments conducted with a tree harvester vehicle - SAHA.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frat5">
             <b>
              FrAT5
             </b>
            </a>
           </td>
           <td class="r">
            Room 5
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frat5" title="Click to go to the Program at a Glance">
             <b>
              Robust and Adaptive Control II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#198353" title="Click to go to the Author Index">
             Kumar, Shivesh
            </a>
           </td>
           <td class="r">
            DFKI GmbH
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat5_01">
             10:00-10:15, Paper FrAT5.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3055'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Grow-To-Shape Control of Variable Length Continuum Robots Via Adaptive Visual Servoing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#257254" title="Click to go to the Author Index">
             Gandhi, Abhinav
            </a>
           </td>
           <td class="r">
            Worceser Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#283193" title="Click to go to the Author Index">
             Chiang, Shou-Shan
            </a>
           </td>
           <td class="r">
            Worcester Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108473" title="Click to go to the Author Index">
             Onal, Cagdas
            </a>
           </td>
           <td class="r">
            WPI
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122725" title="Click to go to the Author Index">
             Calli, Berk
            </a>
           </td>
           <td class="r">
            Worcester Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3055" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_servoing" title="Click to go to the Keyword Index">
               Visual Servoing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we propose an adaptive eye-to-hand vision-based control methodology, which enables a closed-loop grow-to-shape capability for variable length continuum manipulators in 2D. Our method utilizes shape features of the continuum robot, i.e. module curvature and length, which are obtained from the image. Our adaptive control algorithm servos the robot to converge and track the desired values of these features in the image space without the need of a robot model. As a result the robot starts from a minimum length configuration and grows into a given desired shape, always staying on the course of the desired shape. We believe that this approach unlocks capabilities for variable length continuum robots by leveraging their actuation redundancy and avoiding obstacles while carrying out object manipulation or inspection tasks in cluttered and constrained environments. We perform experiments in simulations and on a real robot to assess the performance of our visual servoing algorithm. Our experimental results demonstrate the controllers ability to accurately converge the current features to their references, for a variety of desired shapes in the image, while ensuring a smooth tracking response. We also present some proof of concept results demonstrating the effectiveness of this technique for controlling the robot in constrained environments. Markedly, this is the first successful demonstration for automatic grow-to-shape control using visual feedback for variable length continuum manipulators.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat5_02">
             10:15-10:30, Paper FrAT5.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3391'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Feasibility-Guided Safety-Aware Model Predictive Control for Jump Markov Linear Systems
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378547" title="Click to go to the Author Index">
             Laouar, Zakariya
            </a>
           </td>
           <td class="r">
            University of Colorado
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#245344" title="Click to go to the Author Index">
             Ho, Qi Heng
            </a>
           </td>
           <td class="r">
            University of Colorado Boulder
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399173" title="Click to go to the Author Index">
             Mazouz, Rayan
            </a>
           </td>
           <td class="r">
            University of Colorado Boulder
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399194" title="Click to go to the Author Index">
             Becker, Tyler
            </a>
           </td>
           <td class="r">
            University of Colorado Boulder
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191745" title="Click to go to the Author Index">
             Sunberg, Zachary
            </a>
           </td>
           <td class="r">
            University of Colorado
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3391" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we present a controller framework that synthesizes control policies for Jump Markov Linear Systems subject to stochastic mode switches and imperfect mode estimation. Our approach builds on safe and robust methods for Model Predictive Control (MPC), but in contrast to existing approaches that either optimize without regard to feasibility or utilize soft constraints that increase computational requirements, we employ a safe and robust control approach informed by the feasibility of the optimization problem. We formulate and encode finite horizon safety for multiple model systems in our MPC design using Control Barrier Functions (CBFs). When subject to inaccurate hybrid state estimation, our feasibility-guided MPC generates a control policy that is maximally robust to uncertainty in the system's modes. We evaluate our approach on an orbital rendezvous problem and a six degree-of-freedom hexacopter under several scenarios and benchmarks to demonstrate the utility of the framework. Results indicate that the proposed technique of maximizing the robustness horizon, and the use of CBFs for safety awareness, improve the overall safety and performance of MPC for Jump Markov Linear Systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat5_03">
             10:30-10:45, Paper FrAT5.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3507'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Adaptive Stochastic Nonlinear Model Predictive Control with Look-Ahead Deep Reinforcement Learning for Autonomous Vehicle Motion Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398581" title="Click to go to the Author Index">
             Zarrouki, Baha
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398574" title="Click to go to the Author Index">
             Wang, Chenyang
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#268360" title="Click to go to the Author Index">
             Betz, Johannes
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3507" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Propagating uncertainties through nonlinear system dynamics in the context of Stochastic Nonlinear Model Predictive Control (SNMPC) is challenging, especially for high-dimensional systems requiring real-time control and operating under time-variant uncertainties such as autonomous vehicles. In this work, we propose an Adaptive SNMPC (aSNMPC) driven by Deep Reinforcement Learning (DRL) to optimize uncertainty handling, constraints robustification, feasibility, and closed-loop performance. To this end, our SNMPC uses Polynomial Chaos Expansion (PCE) for efficient uncertainty propagation, limits its propagation time through an Uncertainty Propagation Horizon (UPH), and transforms nonlinear chance constraints into robustified deterministic ones. We conceive a DRL agent to proactively anticipate upcoming control tasks and to dynamically reduce conservatism by determining the most suitable constraints robustification factor kappa, and to enhance feasibility by choosing optimal UPH length T_u. We analyze the trained DRL agent's decision-making process and highlight its ability to learn context-dependent optimal parameters. We showcase the enhanced robustness and feasibility of our DRL-driven aSNMPC through the real-time motion control task of an autonomous passenger vehicle when confronted with significant time-variant disturbances while achieving a minimum solution frequency of 110Hz. The code used in this research is publicly accessible as open-source software: https://github.com/bzarr/TUM-CONTROL
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat5_04">
             10:45-11:00, Paper FrAT5.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2760'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Accelerating Model Predictive Control for Legged Robots through Distributed Optimization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286825" title="Click to go to the Author Index">
             Amatucci, Lorenzo
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277908" title="Click to go to the Author Index">
             Turrisi, Giulio
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#266110" title="Click to go to the Author Index">
             Bratta, Angelo
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#153776" title="Click to go to the Author Index">
             Barasuol, Victor
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108792" title="Click to go to the Author Index">
             Semini, Claudio
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2760" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#whole_body_motion_planning_and_control" title="Click to go to the Keyword Index">
               Whole-Body Motion Planning and Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a novel approach to enhance Model Predictive Control (MPC) for legged robots through Distributed Optimization. Our method focuses on decomposing the robot dynamics into smaller, parallelizable subsystems, and utilizing the Alternating Direction Method of Multipliers (ADMM) to ensure consensus among them. Each subsystem is managed by its own Optimal Control Problem, with ADMM facilitating consistency between their optimizations. This approach not only decreases the computational time but also allows for effective scaling with more complex robot configurations, facilitating the integration of additional subsystems such as articulated arms on a quadruped robot. We demonstrate, through numerical evaluations, the convergence of our approach on two systems with increasing complexity. In addition, we showcase that our approach converges towards the same solution when compared to a state-of-the-art centralized whole-body MPC implementation. Moreover, we quantitatively compare the computational efficiency of our method to the centralized approach, revealing up to a 75% reduction in computational time. Overall, our approach offers a promising avenue for accelerating MPC solutions for legged robots, paving the way for more effective utilization of the computational performance of modern hardware. Accompanying video at https://youtu.be/Yar4W-Vlh2A. The related code can be found at https://github.com/iit-DLSLab/DWMPC.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frat6">
             <b>
              FrAT6
             </b>
            </a>
           </td>
           <td class="r">
            Room 6
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frat6" title="Click to go to the Program at a Glance">
             <b>
              Aerial Systems: Applications III
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#142369" title="Click to go to the Author Index">
             Loianno, Giuseppe
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat6_01">
             10:00-10:15, Paper FrAT6.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('224'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Det-Recon-Reg: An Intelligent Framework towards Automated Large-Scale Infrastructure Inspection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351220" title="Click to go to the Author Index">
             Yang, Guidong
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#289427" title="Click to go to the Author Index">
             Zhang, Jihan
            </a>
           </td>
           <td class="r">
            Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351216" title="Click to go to the Author Index">
             Zhao, Benyun
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#341805" title="Click to go to the Author Index">
             Gao, Chuanxiang
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375342" title="Click to go to the Author Index">
             Huang, Yijun
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319735" title="Click to go to the Author Index">
             Wen, Junjie
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391025" title="Click to go to the Author Index">
             Li, Qingxiang
            </a>
           </td>
           <td class="r">
            The Chineses University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#275702" title="Click to go to the Author Index">
             Tang, Haoyun (Jerry)
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351227" title="Click to go to the Author Index">
             Chen, Xi
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#171587" title="Click to go to the Author Index">
             Chen, Ben M.
            </a>
           </td>
           <td class="r">
            Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab224" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visual inspection plays a predominant role in inspecting infrastructure surface. However, the generalization of existing visual inspection systems to large-scale real-world scenes remains challenging. In this paper, we introduce Det-Recon-Reg, an intelligent framework separating the complex inspection procedure into three stages: Detect, Reconstruct, and Register. For defect detection (Detect), we present the first high-resolution defect dataset tailored for large-scale defect detection. Based on the dataset, we evaluate the most effective real-time object detection algorithms and push the boundary by proposing CUBIT-Net for real-world defect inspection. For infrastructure reconstruction (Reconstruct), we propose a learning-based multi view stereo (MVS) network to adapt to large-scale scenes, taking as input the multi-view images and outputting the point cloud reconstruction, where its performance has been validated on the standard MVS datasets, including BlendedMVS, DTU, and Tanks and Temples datasets. For defect localization (Register), we propose an effective registration method based on the geographic information system that registers the detected defects onto the reconstructed infrastructure model to establish a global reference for maintenance measures. The real-world experiments verify the effectiveness and efficiency of our proposed framework. Dataset, code, and appendix are available on our project page.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat6_02">
             10:15-10:30, Paper FrAT6.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('654'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Kinodynamic Motion Planning for a Team of Multirotors Transporting a Cable-Suspended Payload in Cluttered Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#365857" title="Click to go to the Author Index">
             Wahba, Khaled
            </a>
           </td>
           <td class="r">
            Technical University of Berlin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#212772" title="Click to go to the Author Index">
             Ortiz-Haro, Joaquim
            </a>
           </td>
           <td class="r">
            TU Berlin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102561" title="Click to go to the Author Index">
             Toussaint, Marc
            </a>
           </td>
           <td class="r">
            TU Berlin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#183179" title="Click to go to the Author Index">
             Hoenig, Wolfgang
            </a>
           </td>
           <td class="r">
            TU Berlin
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab654" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#nonholonomic_motion_planning" title="Click to go to the Keyword Index">
               Nonholonomic Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose a motion planner for cable-driven payload transportation using multiple unmanned aerial vehicles (UAVs) in an environment cluttered with obstacles. Our planner is kinodynamic, i.e., it considers the full dynamics model of the transporting system including actuation constraints. Due to the high dimensionality of the planning problem, we use a hierarchical approach where we first solve the geometric motion planning using a sampling-based method with a novel sampler, followed by constrained trajectory optimization that considers the full dynamics of the system. Both planning stages consider inter-robot and robot/obstacle collisions. We demonstrate in a software-in-the-loop simulation and real flight experiments that there is a significant benefit in kinodynamic motion planning for such payload transport systems with respect to payload tracking error and energy consumption compared to the standard methods of planning for the payload alone. Notably, we observe a significantly higher success rate in scenarios where the team formation changes are needed to move through tight spaces.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat6_03">
             10:30-10:45, Paper FrAT6.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2455'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Long-Horizon Predictions for Quadrotor Dynamics
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#307959" title="Click to go to the Author Index">
             Rao, Pratyaksh
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#320007" title="Click to go to the Author Index">
             Saviolo, Alessandro
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398240" title="Click to go to the Author Index">
             Castiglione Ferrari, Tommaso
            </a>
           </td>
           <td class="r">
            Technology Innovation Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142369" title="Click to go to the Author Index">
             Loianno, Giuseppe
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2455" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurate modeling of system dynamics is crucial for achieving high-performance planning and control of robotic systems. Although existing data-driven approaches represent a promising approach for modeling dynamics, their accuracy is limited to a short prediction horizon, overlooking the impact of compounding prediction errors over longer prediction horizons. Strategies to mitigate these cumulative errors remain underexplored. To bridge this gap, in this paper, we study the key design choices for efficiently learning long-horizon prediction dynamics for quadrotors. Specifically, we analyze the impact of multiple architectures, historical data, and multi-step loss formulation. We show that sequential modeling techniques showcase their advantage in minimizing compounding errors compared to other types of solutions. Furthermore, we propose a novel decoupled dynamics learning approach, which further simplifies the learning process while also enhancing the approach modularity. Extensive experiments and ablation studies on real-world quadrotor data demonstrate the versatility and precision of the proposed approach. Our outcomes offer several insights and methodologies for enhancing long-term predictive accuracy of learned quadrotor dynamics for planning and control.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat6_04">
             10:45-11:00, Paper FrAT6.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3755'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design of an Adaptive Lightweight LiDAR to Decouple Robot-Camera Geometry (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#211518" title="Click to go to the Author Index">
             Chen, Yuyang
            </a>
           </td>
           <td class="r">
            University at Buffalo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#239395" title="Click to go to the Author Index">
             Wang, Dingkang
            </a>
           </td>
           <td class="r">
            University of Florida
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285524" title="Click to go to the Author Index">
             Thomas, Lenworth
            </a>
           </td>
           <td class="r">
            University of Florida
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106419" title="Click to go to the Author Index">
             Dantu, Karthik
            </a>
           </td>
           <td class="r">
            University of Buffalo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#181266" title="Click to go to the Author Index">
             Koppal, Sanjeev
            </a>
           </td>
           <td class="r">
            University of Florida
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3755" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#sensor_based_control" title="Click to go to the Keyword Index">
               Sensor-based Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#adaptive_sensor_design" title="Click to go to the Keyword Index">
               Adaptive Sensor Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A fundamental challenge in robot perception is the coupling of the sensor pose and robot pose. This has led to research in active vision where robot pose is changed to reorient the sensor to areas of interest for perception. Further, egomotion such as jitter, and external effects such as wind and others affect perception requiring additional effort in software such as image stabilization. This effect is particularly pronounced in micro-air vehicles and micro-robots who typically are lighter and subject to larger jitter but do not have the computational capability to perform stabilization in real-time. We present a novel microelectromechanical (MEMS) mirror LiDAR system to change the field of view of the LiDAR independent of the robot motion. Our design has the potential for use on small, low-power systems where the expensive components of the LiDAR can be placed external to the small robot. We show the utility of our approach in simulation and on prototype hardware mounted on a UAV. We believe that this LiDAR and its compact movable scanning design provide mechanisms to decouple robot and sensor geometry allowing us to simplify robot perception. We also demonstra
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frat7">
             <b>
              FrAT7
             </b>
            </a>
           </td>
           <td class="r">
            Room 7
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frat7" title="Click to go to the Program at a Glance">
             <b>
              Medical Robotics IV
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#100111" title="Click to go to the Author Index">
             Arai, Fumihito
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#120785" title="Click to go to the Author Index">
             Manoonpong, Poramate
            </a>
           </td>
           <td class="r">
            Vidyasirimedhi Institute of Science and Technology (VISTEC)
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat7_01">
             10:00-10:15, Paper FrAT7.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2184'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Single Protoplasts Pickup System Combining Brightfield and Confocal Images
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397884" title="Click to go to the Author Index">
             Ando, Daito
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#155140" title="Click to go to the Author Index">
             Turan, Bilal
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#321896" title="Click to go to the Author Index">
             Amaya, Satoshi
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397970" title="Click to go to the Author Index">
             Ukai, Yuko
            </a>
           </td>
           <td class="r">
            Nagoya University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397952" title="Click to go to the Author Index">
             Sato, Yoshikatsu
            </a>
           </td>
           <td class="r">
            Nagoya University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100111" title="Click to go to the Author Index">
             Arai, Fumihito
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2184" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#biological_cell_manipulation" title="Click to go to the Keyword Index">
               Biological Cell Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#automation_at_micro_nano_scales" title="Click to go to the Keyword Index">
               Automation at Micro-Nano Scales
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a system that picks up protoplasts produced by removing the surrounding cell wall of root cells while preserving their positional information. The fundamental concept of this system involves scanning the root tip over time using a confocal microscopy to measure the positional information of each cell. Then, the protoplast pickup is conducted after switching to a brightfield microscopy to ensure the certainty of pickup. The system measures the position of single protoplasts, adjusts the position of the pipette using a 3-axis micromanipulator, and picks up the target protoplast using a microfluidic pump driven by a piezoelectric actuator. To automate this pickup process, we achieved calibration of the system. The fully automatic 3D calibration of the pipette tip was achieved, allowing 3D micromanipulation under the microscope with an accuracy of 3.1 um in the XY-plane. Furthermore, by implementing multiple functions such as automatic detection of protoplasts, the process of protoplast pickup has been achieved.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat7_02">
             10:15-10:30, Paper FrAT7.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2773'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SuPerPM: A Surgical Perception Framework Based on Deep Point Matching Learned from Physical Constrained Simulation Data
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#266752" title="Click to go to the Author Index">
             Lin, Shan
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340557" title="Click to go to the Author Index">
             Miao, Albert
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374710" title="Click to go to the Author Index">
             Alabiad, Ali
            </a>
           </td>
           <td class="r">
            University of California San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#179568" title="Click to go to the Author Index">
             Liu, Fei
            </a>
           </td>
           <td class="r">
            University of Tennessee Knoxville
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375760" title="Click to go to the Author Index">
             Wang, Kaiyuan
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#257296" title="Click to go to the Author Index">
             Lu, Jingpei
            </a>
           </td>
           <td class="r">
            University of California San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#234261" title="Click to go to the Author Index">
             Richter, Florian
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#137547" title="Click to go to the Author Index">
             Yip, Michael C.
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2773" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A major source of endoscopic tissue tracking errors during deformations stems from wrong data association between observed sensor measurements with previously tracked scene. To mitigate this issue, we present a surgical perception framework, SuPerPM, that leverages learning-based non-rigid point cloud matching for data association, thus accommodating larger deformations than previous approaches which relied on Iterative Closest Point (ICP) for point associations. The learning models typically require training data with ground truth point cloud correspondences, which is challenging or even impractical to collect in surgical environments. Thus, for tuning the learning model, we gather endoscopic data of soft tissue being manipulated by a surgical robot and then establish correspondences between point clouds at different time points to serve as ground truth. This was achieved by employing a position-based dynamics (PBD) simulation to ensure that the correspondences adhered to physical constraints. The proposed framework is demonstrated on several challenging surgical datasets that are characterized by large deformations, achieving superior performance over advanced surgical scene tracking algorithms.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat7_03">
             10:30-10:45, Paper FrAT7.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3376'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Towards Design and Development of a Soft Pressure Sensing Sleeve for Performing Safe Colonoscopic Procedures
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378944" title="Click to go to the Author Index">
             Rafiee Javazm, Mohammad
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398865" title="Click to go to the Author Index">
             Kiehler, Sonika
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#306862" title="Click to go to the Author Index">
             Kara, Ozdemir Can
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#190490" title="Click to go to the Author Index">
             Alambeigi, Farshid
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3376" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, with the goal of enhancing the safety of current colonoscopic procedures and providing the pressure and location of the contact between the colonoscope and the colon's surface, we propose design and development of a unique Soft Pressure Sensing Sleeve (SPSS). SPSS can seamlessly be integrated with the existing colonoscopic devices and would not change the existing diagnosis workflow. The pressure sensing of SPSS is performed based on the resistance change of a liquid metal (i.e., Gallium) embedded into several micro-channels located within SPSS's deformable sleeve when it interacts with the colon surface. To demonstrate functionality of the SPSS, without loss of generality, in this paper, we designed and fabricated a SPSS with 4 sensing regions. We also proposed and experimentally evaluated an empirical calibration function for this sensor. Results demonstrate high accuracy (RMSE=2.45 and mean absolute error &lt; 3%) of the proposed calibration function compared with the evaluation experiments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat7_04">
             10:45-11:00, Paper FrAT7.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('943'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Online Adaptive Impedance Control with Gravity Compensation for an Interactive Lower-Limb Exoskeleton
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#345391" title="Click to go to the Author Index">
             Janna, Run
            </a>
           </td>
           <td class="r">
            Vidyasirimedhi Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#345638" title="Click to go to the Author Index">
             Tarapongnivat, Kanut
            </a>
           </td>
           <td class="r">
            Vidyasirimedhi Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336241" title="Click to go to the Author Index">
             Sricom, Natchaya
            </a>
           </td>
           <td class="r">
            VISTEC
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336236" title="Click to go to the Author Index">
             Akkawutvanich, Akkawutvanich
            </a>
           </td>
           <td class="r">
            Vidyasirimedhi Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#136856" title="Click to go to the Author Index">
             Xiong, Xiaofeng
            </a>
           </td>
           <td class="r">
            University of Southern Denmark
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#120785" title="Click to go to the Author Index">
             Manoonpong, Poramate
            </a>
           </td>
           <td class="r">
            Vidyasirimedhi Institute of Science and Technology (VISTEC)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab943" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#compliance_and_impedance_control" title="Click to go to the Keyword Index">
               Compliance and Impedance Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             While lower-limb exoskeletons have been increasingly used for gait assistance and rehabilitation, most of them continue to function as assistive devices, with the exoskeleton-user relationship as a leader and follower. This limits the user's ability to interactively contribute to gait control. Therefore, this study proposes an interactive user-exoskeleton control strategy aiming to translate the exoskeletons into interactive compliant companion devices with the exoskeleton-user relationship as collaborators. This control strategy is implemented through online adaptive impedance control with gravity compensation (OAIC-GC). It relies solely on internal pose feedback (joint position), rather than external sensors such as electromyography, torque, or force, as utilized in other assist-as-needed (AAN) control methods. The OAIC-GC can automatically capture the mechanical impedance dynamics of the user's lower limbs during walking, and thus facilitate adaptive, versatile, and personalized gait assistance. It is evaluated using a real lower-limb exoskeleton system with six degrees of freedom (DOFs) across different users engaging in various activities. These activities include symmetrical and asymmetrical walking on a split-belt treadmill at different speeds, as well as walking up stairs. The results indicate a significant improvement in the exoskeleton's performance in terms of adaptability and movement smoothness under all activities when compared to traditional control. The proposed control reduces joint assistance torque across all exoskeleton joints, enhancing user interaction and comfort. This enables users to actively control their gait patterns, enabling the exoskeleton to operate in an interactive assist-as-needed (IAAN) mode.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frat8">
             <b>
              FrAT8
             </b>
            </a>
           </td>
           <td class="r">
            Room 8
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frat8" title="Click to go to the Program at a Glance">
             <b>
              Mapping II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#224374" title="Click to go to the Author Index">
             Verdoja, Francesco
            </a>
           </td>
           <td class="r">
            Aalto University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat8_01">
             10:00-10:15, Paper FrAT8.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('312'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Bayesian Floor Field: Transferring People Flow Predictions across Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#224374" title="Click to go to the Author Index">
             Verdoja, Francesco
            </a>
           </td>
           <td class="r">
            Aalto University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#166253" title="Click to go to the Author Index">
             Kucner, Tomasz Piotr
            </a>
           </td>
           <td class="r">
            Aalto University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105044" title="Click to go to the Author Index">
             Kyrki, Ville
            </a>
           </td>
           <td class="r">
            Aalto University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab312" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#service_robotics" title="Click to go to the Keyword Index">
               Service Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Mapping people dynamics is a crucial skill for robots, because it enables them to coexist in human-inhabited environments. However, learning a model of people dynamics is a time consuming process which requires observation of large amount of people moving in an environment. Moreover, approaches for mapping dynamics are unable to transfer the learned models across environments: each model is only able to describe the dynamics of the environment it has been built in. However, the impact of architectural geometry on people's movement can be used to anticipate their patterns of dynamics, and recent work has looked into learning maps of dynamics from occupancy. So far however, approaches based on trajectories and those based on geometry have not been combined. In this work we propose a novel Bayesian approach to learn people dynamics able to combine knowledge about the environment geometry with observations from human trajectories. An occupancy-based deep prior is used to build an initial transition model without requiring any observations of pedestrian; the model is then updated when observations become available using Bayesian inference. We demonstrate the ability of our model to increase data efficiency and to generalize across real large-scale environments, which is unprecedented for maps of dynamics.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat8_02">
             10:15-10:30, Paper FrAT8.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('460'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Leveraging GNSS and Onboard Visual Data from Consumer Vehicles for Robust Road Network Estimation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#184469" title="Click to go to the Author Index">
             Opra, IstvÃ¡n BalÃ¡zs
            </a>
           </td>
           <td class="r">
            Woven by Toyota / University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#242575" title="Click to go to the Author Index">
             Le Dem, Betty
            </a>
           </td>
           <td class="r">
            Woven by Toyota
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#157591" title="Click to go to the Author Index">
             Walls, Jeffrey
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375677" title="Click to go to the Author Index">
             Lukarski, Dimitar
            </a>
           </td>
           <td class="r">
            Woven by Toyota
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101642" title="Click to go to the Author Index">
             Stachniss, Cyrill
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab460" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Maps are essential for diverse applications, such as vehicle navigation and autonomous robotics. Both require spatial models for effective route planning and localization. This paper addresses the challenge of road graph construction for autonomous vehicles. Despite recent advances, creating a road graph remains labor-intensive and has yet to achieve full automation. The goal of this paper is to generate such graphs automatically and accurately. Modern cars are equipped with onboard sensors used for today's advanced driver assistance systems like lane keeping. We propose using global navigation satellite system (GNSS) traces and basic image data acquired from these standard sensors in consumer vehicles to estimate road-level maps with minimal effort. We exploit the spatial information in the data by framing the problem as a road centerline semantic segmentation task using a convolutional neural network. We also utilize the data's time series nature to refine the neural network's output by using map matching. We implemented and evaluated our method using a fleet of real consumer vehicles, only using the deployed onboard sensors. Our evaluation demonstrates that our approach not only matches existing methods on simpler road configurations but also significantly outperforms them on more complex road geometries and topologies. This work received the 2023 Woven by Toyota Invention Award.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat8_03">
             10:30-10:45, Paper FrAT8.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1189'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Refractive COLMAP: Refractive Structure-From-Motion Revisited
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393197" title="Click to go to the Author Index">
             She, Mengkun
            </a>
           </td>
           <td class="r">
            Kiel University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395910" title="Click to go to the Author Index">
             SeegrÃ¤ber, Felix
            </a>
           </td>
           <td class="r">
            Kiel University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#239284" title="Click to go to the Author Index">
             Nakath, David
            </a>
           </td>
           <td class="r">
            University Kiel
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#156748" title="Click to go to the Author Index">
             Koeser, Kevin
            </a>
           </td>
           <td class="r">
            University of Kiel
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1189" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we present a complete refractive Structure-from-Motion (RSfM) framework for underwater 3D reconstruction using refractive camera setups (for both, flat- and dome-port underwater housings). Despite notable achievements in refractive multi-view geometry over the past decade, a robust, complete and publicly available solution for such tasks is not available at present, and often practical applications have to resort to approximating refraction effects by the intrinsic (distortion) parameters of a pinhole camera model. To fill this gap, we have integrated refraction considerations throughout the entire SfM process within the state-of-the-art, open-source SfM framework COLMAP. Numerical simulations and reconstruction results on synthetically generated but photo-realistic images with ground truth validate that enabling refraction does not compromise accuracy or robustness as compared to in-air reconstructions. Finally, we demonstrate the capability of our approach for large-scale refractive scenarios using a dataset consisting of nearly 6000 images. The implementation is released as open-source at: https://cau-git.rz.uni-kiel.de/inf-ag-koeser/colmap_underwa ter.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat8_04">
             10:45-11:00, Paper FrAT8.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1204'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Evaluation and Deployment of LiDAR-Based Place Recognition in Dense Forests
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395819" title="Click to go to the Author Index">
             Oh, Haedam
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191328" title="Click to go to the Author Index">
             Chebrolu, Nived
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#221792" title="Click to go to the Author Index">
             Mattamala, Matias
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395791" title="Click to go to the Author Index">
             FreiÃŸmuth, Leonard
            </a>
           </td>
           <td class="r">
            Technical University Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#124863" title="Click to go to the Author Index">
             Fallon, Maurice
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1204" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robotics_and_automation_in_agriculture_and_forestry" title="Click to go to the Keyword Index">
               Robotics and Automation in Agriculture and Forestry
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Many LiDAR place recognition systems have been developed and tested specifically for urban driving scenarios. Their performance in natural environments such as forests and woodlands have been studied less closely. In this paper, we analyze the capabilities of four different LiDAR place recognition systems, both handcrafted and learning-based methods, using LiDAR data collected with a handheld device and legged robot in dense forest environments. In particular, we focused on evaluating localization where there is significant transnational and orientation difference between corresponding LiDAR scan pairs. This is particularly important for forest survey systems where the sensor or robot does not follow a defined road or path. Extending our analysis we then incorporated the best performing approach, Logg3dNet, into a full 6-DoF pose estimation system---introducing several verification layers for precise registration. We demonstrated the performance of our methods in three operational modes: online SLAM, offline multi-mission SLAM map merging, and relocalization into a prior map. We evaluated these modes using data captured in forests from three different countries, achieving 80 % of correct loop closures candidates with baseline distances up to 5m, and 60 % up to 10m. Video at: https://youtu.be/86l-oxjwmjY
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frat9">
             <b>
              FrAT9
             </b>
            </a>
           </td>
           <td class="r">
            Room 9
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frat9" title="Click to go to the Program at a Glance">
             <b>
              Optimization and Optimal Control
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#103188" title="Click to go to the Author Index">
             Kyriakopoulos, Kostas
            </a>
           </td>
           <td class="r">
            New York University - Abu Dhabi
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat9_01">
             10:00-10:15, Paper FrAT9.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2013'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Centroidal State Estimation Based on the Koopman Embedding for Dynamic Legged Locomotion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#321462" title="Click to go to the Author Index">
             Khorshidi, Shahram
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#337011" title="Click to go to the Author Index">
             Elnagdi, Murad
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113220" title="Click to go to the Author Index">
             Bennewitz, Maren
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2013" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we introduce a novel approach to centroidal state estimation, which plays a crucial role in predictive model-based control strategies for dynamic legged locomotion. Our approach uses the Koopman operator theory to transform the robot's complex nonlinear dynamics into a linear system, by employing dynamic mode decomposition and deep learning for model construction. We evaluate both models on their linearization accuracy and capability to capture both fast and slow dynamic system responses. We then select the most suitable model for estimation purposes, and integrate it within a moving horizon estimator. This estimator is formulated as a convex quadratic program to facilitate robust, real-time centroidal state estimation. Through extensive simulation experiments on a quadruped robot executing various dynamic gaits, our data-driven framework outperforms conventional Extended Kalman Filtering technique based on nonlinear dynamics. Our estimator addresses challenges posed by force/torque measurement noise in highly dynamic motions and accurately recovers the centroidal states, demonstrating the adaptability and effectiveness of the Koopman-based linear representation for complex locomotive behaviors. Importantly, our model based on dynamic mode decomposition, trained with two locomotion patterns (trot and jump), successfully estimates the centroidal states for a different motion (bound) without retraining.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat9_02">
             10:15-10:30, Paper FrAT9.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2352'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Perfecting Periodic Trajectory Tracking: Model Predictive Control with a Periodic Observer
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380344" title="Click to go to the Author Index">
             Pabon, Luis
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256648" title="Click to go to the Author Index">
             KÃ¶hler, Johannes
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#337273" title="Click to go to the Author Index">
             Alora, John Irvin
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398090" title="Click to go to the Author Index">
             Eberhard, Patrick Benito
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#180368" title="Click to go to the Author Index">
             Carron, Andrea
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#197975" title="Click to go to the Author Index">
             Zeilinger, Melanie N.
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123466" title="Click to go to the Author Index">
             Pavone, Marco
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2352" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In Model Predictive Control (MPC), discrepancies between the actual system and the predictive model can lead to substantial tracking errors and significantly degrade performance and reliability. While such discrepancies can be alleviated with more complex models, this often complicates controller design and implementation. By leveraging the fact that many trajectories of interest are periodic, we show that perfect tracking is possible when incorporating a simple observer that estimates and compensates for periodic disturbances. We present the design of the observer and the accompanying tracking MPC scheme, proving that their combination achieves zero tracking error asymptotically, regardless of the complexity of the unmodelled dynamics. We validate the effectiveness of our method, demonstrating asymptotically perfect tracking on a high-dimensional soft robot with nearly 10,000 states and a fivefold reduction in tracking errors compared to a baseline MPC on small-scale autonomous race car experiments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat9_03">
             10:30-10:45, Paper FrAT9.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2471'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Pose Graph Optimization Over Planar Unit Dual Quaternions: Improved Accuracy with Provably Convergent Riemannian Optimization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398257" title="Click to go to the Author Index">
             Warke, William
            </a>
           </td>
           <td class="r">
            University of Florida
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#298969" title="Click to go to the Author Index">
             Ramos, J Humberto
            </a>
           </td>
           <td class="r">
            University of Florida
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#298973" title="Click to go to the Author Index">
             Ganesh, Prashant
            </a>
           </td>
           <td class="r">
            EpiSys Science Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#153930" title="Click to go to the Author Index">
             Brink, Kevin
            </a>
           </td>
           <td class="r">
            AFRL
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285421" title="Click to go to the Author Index">
             Hale, Matthew
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2471" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             It is common in pose graph optimization (PGO) algorithms to assume that noise in the translations and rotations of relative pose measurements is uncorrelated. However, existing work shows that in practice these measurements can be highly correlated, which leads to degradation in the accuracy of PGO solutions that rely on this assumption. Therefore, in this paper we develop a novel algorithm derived from a realistic, correlated model of relative pose uncertainty, and we quantify the resulting improvement in the accuracy of the solutions we obtain relative to state-of-the-art PGO algorithms. Our approach utilizes Riemannian optimization on the planar unit dual quaternion (PUDQ) manifold, and we prove that it converges to first-order stationary points of a Lie-theoretic maximum likelihood objective. Then we show experimentally that, compared to state-of-the-art PGO algorithms, this algorithm produces estimation errors that are lower by 10% to 25% across several orders of magnitude of correlated noise levels and graph sizes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat9_04">
             10:45-11:00, Paper FrAT9.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2832'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Probabilistic Homotopy Optimization for Dynamic Motion Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277969" title="Click to go to the Author Index">
             Chignoli, Matthew
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398623" title="Click to go to the Author Index">
             Pardis, Shayan
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106208" title="Click to go to the Author Index">
             Kim, Sangbae
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2832" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#humanoid_robot_systems" title="Click to go to the Keyword Index">
               Humanoid Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a homotopic approach to solving challenging, optimization-based motion planning problems. The approach uses Homotopy Optimization, which, unlike standard continuation methods for solving homotopy problems, solves a sequence of constrained optimization problems rather than a sequence of nonlinear systems of equations. The insight behind our proposed algorithm is formulating the discovery of this sequence of optimization problems as a search problem in a multidimensional homotopy parameter space. Our proposed algorithm, the Probabilistic Homotopy Optimization algorithm, switches between solve and sample phases, using solutions to easy problems as initial guesses to more challenging problems. We analyze how our algorithm performs in the presence of common challenges to homotopy methods, such as bifurcation, folding, and disconnectedness of the homotopy solution manifold. Finally, we demonstrate its utility via a case study on two dynamic motion planning problems: the cart-pole and the MIT Humanoid.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frat10">
             <b>
              FrAT10
             </b>
            </a>
           </td>
           <td class="r">
            Room 10
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frat10" title="Click to go to the Program at a Glance">
             <b>
              Deep Learning for Perception
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#390916" title="Click to go to the Author Index">
             Jayasuriya, Suren
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat10_01">
             10:00-10:15, Paper FrAT10.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1724'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DarkGS: Learning Neural Illumination and 3D Gaussians Relighting for Robotic Exploration in the Dark
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#266906" title="Click to go to the Author Index">
             Zhang, Tianyi
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396946" title="Click to go to the Author Index">
             Huang, Kaining
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238613" title="Click to go to the Author Index">
             Zhi, Weiming
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#118789" title="Click to go to the Author Index">
             Johnson-Roberson, Matthew
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1724" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#calibration_and_identification" title="Click to go to the Keyword Index">
               Calibration and Identification
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Humans have the remarkable ability to construct consistent mental models of an environment, even under limited or varying levels of illumination. We wish to endow robots with this same capability. In this paper, we tackle the challenge of constructing a photorealistic scene representation under poorly illuminated conditions and with a moving light source. We approach the task of modeling illumination as a learning problem, and utilize the developed illumination model to aid in scene reconstruction. We introduce an innovative framework that uses a data-driven approach, Neural Light Simulators (NeLiS), to model and calibrate the camera-light system. Furthermore, we present DarkGS, a method that applies NeLiS to create a relightable 3D Gaussian scene model capable of real-time, photorealistic rendering from novel viewpoints. We show the applicability and robustness of our proposed simulator and system in a variety of real-world environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat10_02">
             10:15-10:30, Paper FrAT10.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2605'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              NeuralFloors++: Consistent Street-Level Scene Generation from BEV Semantic Maps
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#302584" title="Click to go to the Author Index">
             Musat, Valentina
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196040" title="Click to go to the Author Index">
             De Martini, Daniele
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#179163" title="Click to go to the Author Index">
             Gadd, Matthew
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105828" title="Click to go to the Author Index">
             Newman, Paul
            </a>
           </td>
           <td class="r">
            Oxford University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2605" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Learning autonomous driving capabilities requires diverse and realistic training data. This has led to exploring generative techniques as an alternative to real-world data collection. In this paper we propose a method for synthesising photo-realistic urban driving scenes, along with semantic, instance and depth ground-truth. Our model relies on Bird's Eye View (BEV) representations due to their compositionality and scene content control capabilities, reducing the need for traditional simulators. We employ a two-stage process: first, a 3D scene representation is extracted from BEV semantic, instance and style maps using a neural field. After rendering the semantic, instance, depth and style maps from a ground-view perspective, a second stage based on a diffusion model is used to generate the photo-realistic scene. We extend our prior work - NeuralFloors, to include multiple-view outputs, style manipulation for finer control at the object level through instance-wise style maps and cross-frame consistency via auto-regressive training. The proposed system is evaluated extensively on the KITTI-360 dataset, showing improved realism and semantic alignment for generated images.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat10_03">
             10:30-10:45, Paper FrAT10.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3377'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              PathFinder: Attention-Driven Dynamic Non-Line-Of-Sight Tracking with a Mobile Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#255965" title="Click to go to the Author Index">
             Kannapiran, Shenbagaraj
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391403" title="Click to go to the Author Index">
             Chandran, Sreenithy
            </a>
           </td>
           <td class="r">
            Arizona State University, USA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390916" title="Click to go to the Author Index">
             Jayasuriya, Suren
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102710" title="Click to go to the Author Index">
             Berman, Spring
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3377" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The study of non-line-of-sight (NLOS) imaging is growing due to its many potential applications, including rescue operations and pedestrian detection by self-driving cars. However, implementing NLOS imaging on a moving camera remains an open area of research. Existing NLOS imaging methods rely on time-resolved detectors and laser configurations that require precise optical alignment, making it difficult to deploy them in dynamic environments. This work proposes a data-driven approach to NLOS imaging, PathFinder, that can be used with a standard RGB camera mounted on a small, power-constrained mobile robot, such as an aerial drone. Our experimental pipeline is designed to accurately estimate the 2D trajectory of a person who moves in a Manhattan-world environment while remaining hidden from the cameraâ€™s field- of-view. We introduce a novel approach to process a sequence of dynamic successive frames in a line-of-sight (LOS) video using an attention-based neural network that performs inference in real-time. The method also includes a preprocessing selection metric that analyzes images from a moving camera which contain multiple vertical planar surfaces, such as walls and building facades, and extracts planes that return maximum NLOS information. We validate the approach on in-the-wild scenes using a drone for video capture, thus demonstrating low-cost NLOS imaging in dynamic capture environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat10_04">
             10:45-11:00, Paper FrAT10.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('324'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Text3DAug â€“ Prompted Instance Augmentation for LiDAR Perception
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391904" title="Click to go to the Author Index">
             Reichardt, Laurenz
            </a>
           </td>
           <td class="r">
            HS Mannheim
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391958" title="Click to go to the Author Index">
             Uhr, Luca
            </a>
           </td>
           <td class="r">
            Hochschule Mannheim
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#209038" title="Click to go to the Author Index">
             WasenmÃ¼ller, Oliver
            </a>
           </td>
           <td class="r">
            Mannheim University of Applied Sciences
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab324" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             LiDAR data of urban scenarios poses unique challenges, such as heterogeneous characteristics and inherent class imbalance. Therefore, large-scale datasets are necessary to apply deep learning methods. Instance augmentation has emerged as an efficient method to increase dataset diversity. However, current methods require the time-consuming curation of 3D models or costly manual data annotation. To overcome these limitations, we propose Text3DAug, a novel approach leveraging generative models for instance augmentation. Text3DAug does not depend on labeled data and is the first of its kind to generate instances and annotations from text. This allows for a fully automated pipeline, eliminating the need for manual effort in practical applications. Additionally, Text3DAug is sensor agnostic and can be applied regardless of the LiDAR sensor used. Comprehensive experimental analysis on LiDAR segmentation, detection and novel class discovery demonstrates that Text3DAug is effective in supplementing existing methods or as a standalone method, performing on par or better than established methods, however while overcoming their specific drawbacks. The code is publicly available.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frat11">
             <b>
              FrAT11
             </b>
            </a>
           </td>
           <td class="r">
            Room 11
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frat11" title="Click to go to the Program at a Glance">
             <b>
              Legged Robots I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#134222" title="Click to go to the Author Index">
             Zimmermann, Karel
            </a>
           </td>
           <td class="r">
            Ceske Vysoke Uceni Technicke V Praze, FEL
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat11_01">
             10:00-10:15, Paper FrAT11.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2380'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MonoForce: Self-Supervised Learning of Physics-Informed Model for Predicting Robot-Terrain Interaction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#223692" title="Click to go to the Author Index">
             Agishev, Ruslan
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague, FEE
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#134222" title="Click to go to the Author Index">
             Zimmermann, Karel
            </a>
           </td>
           <td class="r">
            Ceske Vysoke Uceni Technicke V Praze, FEL
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#149723" title="Click to go to the Author Index">
             Kubelka, Vladimir
            </a>
           </td>
           <td class="r">
            Ã–rebro University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195222" title="Click to go to the Author Index">
             Pecka, Martin
            </a>
           </td>
           <td class="r">
            Ceske Vysoke Uceni Technicke V Praze, FEL
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107657" title="Click to go to the Author Index">
             Svoboda, Tomas
            </a>
           </td>
           <td class="r">
            Ceske Vysoke Uceni Technicke V Praze, FEL
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2380" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#learning_from_experience" title="Click to go to the Keyword Index">
               Learning from Experience
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             While autonomous navigation of mobile robots on rigid terrain is a well-explored problem, navigating on deformable terrain such as tall grass or bushes remains a challenge. To address it, we introduce an explainable, physics-aware and end-to-end differentiable model which predicts the outcome of robot-terrain interaction from camera images, both on rigid and non-rigid terrain. The proposed MonoForce model consists of a black-box module which predicts robot-terrain interaction forces from onboard cameras, followed by a white-box module, which transforms these forces and a control signals into predicted trajectories, using only the laws of classical mechanics. The differentiable white-box module allows backpropagating the predicted trajectory errors into the black-box module, serving as a self-supervised loss that measures consistency between the predicted forces and ground-truth trajectories of the robot. Experimental evaluation on a public dataset and our data has shown that while the prediction capabilities are comparable to state-of-the-art algorithms on rigid terrain, MonoForce shows superior accuracy on non-rigid terrain such as tall grass or bushes. To facilitate the reproducibility of our results, we release both the code and datasets.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat11_02">
             10:15-10:30, Paper FrAT11.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('498'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LEEPS: Learning End-To-End Legged Perceptive Parkour Skills on Challenging Terrains
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352488" title="Click to go to the Author Index">
             Qian, Tangyu
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#317052" title="Click to go to the Author Index">
             Zhang, Hao
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#304443" title="Click to go to the Author Index">
             Zhou, Zhangli
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#304444" title="Click to go to the Author Index">
             Wang, Hao
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#250972" title="Click to go to the Author Index">
             Mingyu, Cai
            </a>
           </td>
           <td class="r">
            University of California Riverside
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#206291" title="Click to go to the Author Index">
             Kan, Zhen
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab498" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Empowering legged robots with agile maneuvers is a great challenge. While existing works have proposed diverse control-based and learning-based methods, it remains an open problem to endow robots with animal-like perception and athleticism. Towards this goal, we develop an End-to-End Legged Perceptive Parkour Skill Learning (LEEPS) framework to train quadruped robots to master parkour skills in complex environments. In particular, LEEPS incorporates a vision-based perception module equipped with multi-layered scans, supplying robots with comprehensive, precise, and adaptable information about their surroundings. Leveraging such visual data, a position-based task formulation liberates the robot from velocity constraints and directs it toward the target using innovative reward mechanisms. The resulting controller empowers an affordable quadruped robot to successfully traverse previously challenging and unprecedented obstacles. We evaluate LEEPS on various challenging tasks, which demonstrate its effectiveness, robustness, and generalizability. Supplementary and videos are available at: https://sites.google.com/view/leeps
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat11_03">
             10:30-10:45, Paper FrAT11.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('921'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DexDribbler: Learning Dexterous Soccer Manipulation Via Dynamic Supervision
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#306360" title="Click to go to the Author Index">
             Hu, Yutong
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394656" title="Click to go to the Author Index">
             Wen, Kehan
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#220438" title="Click to go to the Author Index">
             Yu, Fisher
            </a>
           </td>
           <td class="r">
            ETH ZÃ¼rich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab921" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Learning dexterous locomotion policy for legged robots is becoming increasingly popular due to its ability to handle diverse terrains and resemble intelligent behaviors. However, joint manipulation of moving objects and locomotion with legs, such as playing soccer, receive scant attention in the learning community, although it is natural for humans and smart animals. A key challenge to solve this multitask problem is to infer the objectives of locomotion from the states and targets of the manipulated objects. The implicit relation between the object states and robot locomotion can be hard to capture directly from the training experience. We propose adding a feedback control block to compute the necessary body-level movement accurately and using the outputs as dynamic joint-level locomotion supervision explicitly. We further utilize an improved ball dynamic model, an extended context-aided estimator, and a comprehensive ball observer to facilitate transferring policy learned in simulation to the real world. We observe that our learning scheme can not only make the policy network converge faster but also enable soccer robots to perform sophisticated maneuvers like sharp cuts and turns on flat surfaces, a capability that was lacking in previous methods. Video and code are available at github.com/SysCV/soccer-player/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat11_04">
             10:45-11:00, Paper FrAT11.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1271'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Modeling and Gait Analysis of Passive Rimless Wheel with Compliant Feet
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#194561" title="Click to go to the Author Index">
             Zheng, Yanqiu
            </a>
           </td>
           <td class="r">
            Ritsumeikan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#299399" title="Click to go to the Author Index">
             Yan, Cong
            </a>
           </td>
           <td class="r">
            Ritsumeikan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#309557" title="Click to go to the Author Index">
             He, Yuetong
            </a>
           </td>
           <td class="r">
            Japan Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103082" title="Click to go to the Author Index">
             Asano, Fumihiko
            </a>
           </td>
           <td class="r">
            Japan Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#145698" title="Click to go to the Author Index">
             Tokuda, Isao
            </a>
           </td>
           <td class="r">
            Ritsumeikan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1271" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#passive_walking" title="Click to go to the Keyword Index">
               Passive Walking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#modeling_and_simulating_humans" title="Click to go to the Keyword Index">
               Modeling and Simulating Humans
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The movement of the legs involves the interaction between the feet and the ground. Consequently, most animals possess a wide variety of foot morphologies and multifunctional capabilities. The selection and switching of these foot functions are passive and environment-dependent, ensuring environmental compliance. Despite this, current research on compliant feet lacks mathematical models that simultaneously encompass locomotion and foot compliance. Therefore, conducting in-depth studies on locomotion properties under current conditions is challenging. In this study, we present novel passive compliant feet applicable to the passive walking of a rimless wheel. We first introduce a dynamic model, achieve passive walking through numerical simulations, and subsequently analyze the gait patterns for compliance and multi-period gait. This study bridges a gap in understanding the interaction between motion and compliance in foot design, providing insights into the dynamics of compliant motion.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frat12">
             <b>
              FrAT12
             </b>
            </a>
           </td>
           <td class="r">
            Room 12
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frat12" title="Click to go to the Program at a Glance">
             <b>
              Semantic Scene Understanding II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat12_01">
             10:00-10:15, Paper FrAT12.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('186'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Volumetric Semantically Consistent 3D Panoptic Mapping
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#349399" title="Click to go to the Author Index">
             Miao, Yang
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#333608" title="Click to go to the Author Index">
             Armeni, Iro
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#128027" title="Click to go to the Author Index">
             Pollefeys, Marc
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#266276" title="Click to go to the Author Index">
             Barath, Daniel
            </a>
           </td>
           <td class="r">
            MTA SZTAKI; Visual Recognition Group in CTU Prague
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab186" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce an online 2D-to-3D semantic instance mapping algorithm aimed at generating comprehensive, accurate, and efficient semantic 3D maps suitable for autonomous agents in unstructured environments. The proposed approach is based on a Voxel-TSDF representation used in recent algorithms. It introduces novel ways of integrating semantic prediction confidence during mapping, producing semantic and instance-consistent 3D regions. Further improvements are achieved by graph optimization-based semantic labeling and instance refinement. The proposed method achieves accuracy superior to the state of the art on public large-scale datasets, improving on a number of widely used metrics. We also highlight a downfall in the evaluation of recent studies: using the ground truth trajectory as input instead of a SLAM-estimated one substantially affects the accuracy, creating a large gap between the reported results and the actual performance on real-world data. The code is available: https://github.com/y9miao/ConsistentPanopticSLAM.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat12_02">
             10:15-10:30, Paper FrAT12.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1709'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Answerability Fields: Answerable Location Estimation Via Diffusion Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394594" title="Click to go to the Author Index">
             Azuma, Daichi
            </a>
           </td>
           <td class="r">
            Sony Semiconductor Solutions
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394595" title="Click to go to the Author Index">
             Miyanishi, Taiki
            </a>
           </td>
           <td class="r">
            Advanced Telecommunications Research Institute International
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394186" title="Click to go to the Author Index">
             Kurita, Shuhei
            </a>
           </td>
           <td class="r">
            RIKEN
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390947" title="Click to go to the Author Index">
             Sakamoto, Koya
            </a>
           </td>
           <td class="r">
            Kyoto University, ATR
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#164056" title="Click to go to the Author Index">
             Kawanabe, Motoaki
            </a>
           </td>
           <td class="r">
            Advanced Telecommunications Research Institutte International
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1709" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose Answerability Fields (AnsFields), a novel approach for predicting the answerability of questions at different locations within indoor environments. AnsFields is represented as a map, where each gridâ€™s score reflects how well a question can be answered using the panoramic image at that location. Using a 3D question-answering dataset, we construct comprehensive AnsFields covering diverse scenes from ScanNet. Additionally, we employ a diffusion model to infer AnsFields from a sceneâ€™s top-down view image and the question. We then conduct 3D question-answering using these predicted AnsFields and achieve a 24% improvement in accuracy over the standard 3D-QA method. Our results demonstrate the importance of object locations for answering questions in the environment, highlighting the potential of AnsFields for applications in robotics, augmented reality, and human-robot interaction.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat12_03">
             10:30-10:45, Paper FrAT12.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1825'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Modal NeRF Self-Supervision for LiDAR Semantic Segmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394403" title="Click to go to the Author Index">
             Timoneda, Xavier
            </a>
           </td>
           <td class="r">
            CARIAD SE
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#242147" title="Click to go to the Author Index">
             Herb, Markus
            </a>
           </td>
           <td class="r">
            Technische UniversitÃ¤t MÃ¼nchen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#309525" title="Click to go to the Author Index">
             Duerr, Fabian
            </a>
           </td>
           <td class="r">
            Audi AG
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101824" title="Click to go to the Author Index">
             Goehring, Daniel
            </a>
           </td>
           <td class="r">
            Freie UniversitÃ¤t Berlin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#220438" title="Click to go to the Author Index">
             Yu, Fisher
            </a>
           </td>
           <td class="r">
            ETH ZÃ¼rich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1825" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             LiDAR Semantic Segmentation is a fundamental task in autonomous driving perception consisting of associating each LiDAR point to a semantic label. Fully-supervised models have widely tackled this task, but they require labels for each scan, which either limits their domain or requires impractical amounts of expensive annotations.
             <p>
              Camera images, which are generally recorded alongside LiDAR pointclouds, can be processed by the widely available 2D foundation models, which are generic and dataset-agnostic. However, distilling knowledge from 2D data to improve LiDAR perception raises domain adaptation challenges. For example, the classical perspective projection suffers from the parallax effect produced by the position shift between both sensors at their respective capture times.
              <p>
               We propose a Semi-Supervised Learning setup to leverage unlabeled LiDAR pointclouds alongside distilled knowledge from the camera images. To self-supervise our model on the unlabeled scans, we add an auxiliary NeRF head and cast rays from the camera viewpoint over the unlabeled voxel features. The NeRF head predicts densities and semantic logits at each sampled ray location which are used for rendering pixel semantics. Concurrently, we query the Segment-Anything (SAM) foundation model with the camera image to generate a set of unlabeled generic masks. We fuse the masks with the rendered pixel semantics from LiDAR to produce pseudo-labels that supervise the pixel predictions. During inference, we drop the NeRF head and run our model with only LiDAR.
               <p>
                We show the effectiveness of our approach in three public LiDAR Semantic Segmentation benchmarks: nuScenes, SemanticKITTI and ScribbleKITTI.
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat12_04">
             10:45-11:00, Paper FrAT12.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1831'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              PanopticRecon: Leverage Open-Vocabulary Instance Segmentation for Zero-Shot Panoptic Reconstruction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361265" title="Click to go to the Author Index">
             Yu, Xuan
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361267" title="Click to go to the Author Index">
             Liu, Yili
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397290" title="Click to go to the Author Index">
             Han, Chenrui
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352739" title="Click to go to the Author Index">
             Mao, Sitong
            </a>
           </td>
           <td class="r">
            ShenZhen Huawei Cloud Computing Technologies Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195314" title="Click to go to the Author Index">
             Zhou, Shunbo
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113216" title="Click to go to the Author Index">
             Xiong, Rong
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#178893" title="Click to go to the Author Index">
             Liao, Yiyi
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#156231" title="Click to go to the Author Index">
             Wang, Yue
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1831" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Panoptic reconstruction is a challenging task in 3D scene understanding. However, most existing methods heavily rely on pre-trained semantic segmentation models and known 3D object bounding boxes for 3D panoptic segmentation, which is not available for in-the-wild scenes. In this paper, we propose a novel zero-shot panoptic reconstruction method from RGB-D images of scenes. For zero-shot segmentation, we leverage open-vocabulary instance segmentation, but it has to face partial labeling and instance association challenges. We tackle both challenges by propagating partial labels with the aid of dense generalized features and building a 3D instance graph for associating 2D instance IDs. Specifically, we exploit partial labels to learn a classifier for generalized semantic features to provide complete labels for scenes with dense distilled features. Moreover, we formulate instance association as a 3D instance graph segmentation problem, allowing us to fully utilize the scene geometry prior and all 2D instance masks to infer global unique pseudo 3D instance ID. Our method outperforms state-of-the-art methods on the indoor dataset ScanNet V2 and the outdoor dataset KITTI-360, demonstrating the effectiveness of our graph segmentation method and reconstruction network.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frat13">
             <b>
              FrAT13
             </b>
            </a>
           </td>
           <td class="r">
            Room 13
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frat13" title="Click to go to the Program at a Glance">
             <b>
              Computer Vision for Automation III
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat13_01">
             10:00-10:15, Paper FrAT13.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('971'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              NRDF - Neural Region Descriptor Fields As Implicit ROI Representation for Robotic 3D Surface Processing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375817" title="Click to go to the Author Index">
             Pratheepkumar, Anish
            </a>
           </td>
           <td class="r">
            Profactor Gmbh
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#270664" title="Click to go to the Author Index">
             Ikeda, Markus
            </a>
           </td>
           <td class="r">
            PROFACTOR GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256169" title="Click to go to the Author Index">
             Hofmann, Michael
            </a>
           </td>
           <td class="r">
            Profactor Gmbh
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394934" title="Click to go to the Author Index">
             Widmoser, Fabian
            </a>
           </td>
           <td class="r">
            Profactor Gmbh
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103894" title="Click to go to the Author Index">
             Pichler, Andreas
            </a>
           </td>
           <td class="r">
            Profactor Gmbh
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102411" title="Click to go to the Author Index">
             Vincze, Markus
            </a>
           </td>
           <td class="r">
            Vienna University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab971" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             To automate 3D surface processing across diverse category-level objects it is imperative to represent process-related region of interest (P-ROI), which is not obtained with conventional keypoint or semantic part correspondences. To resolve this issue, we propose Neural Region Descriptor Fields (NRDF) for achieving unsupervised dense 3D surface region correspondence such that arbitrary ROI is retrieved for a new instance of a known category of object. We utilize the NRDF representation as a medium to facilitate one-shot P-ROI level process knowledge transfer. Recent developments in implicit 3D object representations have focused on keypoint or part correspondences, which have resulted in applications like robotic grasping and manipulation. However, explicit one-shot P-ROI correspondence, and its application for 3D surface process knowledge transfer, is treated for the first time in this work, to the best of our knowledge. The evaluation results show that the proposed approach outperforms the dense correspondence baselines in implicit shape representation and the capacity to retrieve matching arbitrary ROIs. In addition, we validate the practicality of our proposed system in a real-world robotic surface processing application. Our code is available at https://github.com/Profactor/Neural-Region-Descriptor-Fields.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat13_02">
             10:15-10:30, Paper FrAT13.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1249'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Sparse Points to Dense Clouds: Enhancing 3D Detection with Limited LiDAR Data
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#323741" title="Click to go to the Author Index">
             Kumar, Aakash
            </a>
           </td>
           <td class="r">
            University of Central Florida
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352227" title="Click to go to the Author Index">
             Chen, Chen
            </a>
           </td>
           <td class="r">
            University of Central Florida
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#323854" title="Click to go to the Author Index">
             Mian, Ajmal
            </a>
           </td>
           <td class="r">
            University of Western Australia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#140745" title="Click to go to the Author Index">
             Lobo, Niels
            </a>
           </td>
           <td class="r">
            University of Central Florida
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256614" title="Click to go to the Author Index">
             Shah, Mubarak
            </a>
           </td>
           <td class="r">
            University of Central Florida
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1249" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             3D detection is a critical task that enables machines to identify and locate objects in three-dimensional space. It has a broad range of applications in several fields, including autonomous driving, robotics and augmented reality. Monocular 3D detection is attractive as it requires only a single camera, however, it lacks the accuracy and robustness required for real world applications. High resolution LiDAR on the other hand, can be expensive and lead to interference problems in heavy traffic given their active transmissions. We propose a balanced approach that combines the advantages of monocular and point cloud-based 3D detection. Our method requires only a small number of 3D points, that can be obtained from a low-cost, low-resolution sensor. Specifically, we use only 512 points, which is just 1% of a full LiDAR frame in the KITTI dataset. Our method reconstructs a complete 3D point cloud from this limited 3D information combined with a single image. The reconstructed 3D point cloud and corresponding image can be used by any multi-modal off-the-shelf detector for 3D object detection. By using the proposed network architecture with an off-the-shelf multi-modal 3D detector, the accuracy of 3D detection improves by 20% compared to the state-of-the-art monocular detection methods and 6% to 9% compare to the baseline multi-modal methods on KITTI and JackRabbot datasets.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat13_03">
             10:30-10:45, Paper FrAT13.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2014'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Conditional Generative Denoiser for Nighttime UAV Tracking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336334" title="Click to go to the Author Index">
             Wang, Yucheng
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160488" title="Click to go to the Author Index">
             Fu, Changhong
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#326955" title="Click to go to the Author Index">
             Lu, Kunhan
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339398" title="Click to go to the Author Index">
             Yao, Liangliang
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324459" title="Click to go to the Author Index">
             Zuo, Haobo
            </a>
           </td>
           <td class="r">
            University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2014" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             State-of-the-art (SOTA) visual object tracking methods have significantly enhanced the autonomy of unmanned aerial vehicles (UAVs). However, in low-light conditions, the presence of irregular real noise from the environments severely degrades the performance of these SOTA methods. Moreover, existing SOTA denoising techniques often fail to meet the real-time processing requirements when deployed as plug-and-play denoisers for UAV tracking. To address this challenge, this work proposes a novel conditional generative denoiser (CGDenoiser), which breaks free from the limitations of traditional deterministic paradigms and generates the noise conditioning on the input, subsequently removing it. To better align the input dimensions and accelerate inference, a novel nested residual Transformer conditionalizer is developed. Furthermore, an innovative multi-kernel conditional refiner is designed to pertinently refine the denoised output. Extensive experiments show that CGDenoiser promotes the tracking precision of the SOTA tracker by 18.18% on DarkTrack2021 whereas working 5.8 times faster than the second well-performed denoiser. Real-world tests with complex challenges also prove the effectiveness and practicality of CGDenoiser. Code, video demo and supplementary proof for CGDenoier are now available at: https://github.com/vision4robotics/CGDenoiser.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frat13_04">
             10:45-11:00, Paper FrAT13.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2551'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SPDAGG-TransNet: Integrating Symmetric Positive Definite Networks with Transformers for UAV-Human Action Recognition
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378886" title="Click to go to the Author Index">
             Akremi, Mohamed Sanim
            </a>
           </td>
           <td class="r">
            Phd Student
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#236715" title="Click to go to the Author Index">
             Neji, Najett
            </a>
           </td>
           <td class="r">
            Universite Paris Saclay
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#220812" title="Click to go to the Author Index">
             Tabia, Hedi
            </a>
           </td>
           <td class="r">
            ETIS-ENSEA
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2551" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The advent of unmanned aerial vehicles (UAVs) has initiated a revolutionary era in human action recognition, profoundly influencing various domains. This transition underscores the critical necessity for comprehensive benchmarks crucial for formulating and evaluating UAV-centric models tailored to human behavior analysis.
             <p>
              This paper presents an novel approach called SPDAGG-TransNet network for UAV-human action recognition, leveraging the resilience of skeletal-based features amidst these obstacles. Our approach revolves around a deep neural network adept at capturing the intricate spatial and temporal dimensions of human actions, leading to the development of Semi-Positive Definite (SPD) matrix representations. These representations are then transformed using a transformer encoder before being classified using a Multilayer Perceptron (MLP). To assess the effectiveness of our approach, we conduct thorough evaluations using publicly available datasets such as the UAV-Human Action Recognition and UAV-Gesture datasets. Our findings underscore the state-of-the-art performance achieved by our method, highlighting its potential to significantly advance UAV-based human action recognition.
             </p>
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frbt1">
             <b>
              FrBT1
             </b>
            </a>
           </td>
           <td class="r">
            Room 1
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frbt1" title="Click to go to the Program at a Glance">
             <b>
              Vision-Based Navigation II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt1_01">
             11:00-11:15, Paper FrBT1.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('784'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DD-VNB: A Depth-Based Dual-Loop Framework for Real-Time Visually Navigated Bronchoscopy
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335224" title="Click to go to the Author Index">
             Tian, Qingyao
            </a>
           </td>
           <td class="r">
            University of Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#381811" title="Click to go to the Author Index">
             Liao, Huai
            </a>
           </td>
           <td class="r">
            Department of Pulmonary and Critical Care Medicine, the First Af
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#381812" title="Click to go to the Author Index">
             Huang, Xinyan
            </a>
           </td>
           <td class="r">
            Department of Pulmonary and Critical Care Medicine, the First Af
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#317513" title="Click to go to the Author Index">
             Chen, Jian
            </a>
           </td>
           <td class="r">
            Hong Kong Institute of Science and Innovation, Chinese Academy O
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336380" title="Click to go to the Author Index">
             Zhang, Zihui
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376266" title="Click to go to the Author Index">
             Yang, Bingyu
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciencesï¼› Sch
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#124246" title="Click to go to the Author Index">
             Ourselin, Sebastien
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336379" title="Click to go to the Author Index">
             Liu, Hongbin
            </a>
           </td>
           <td class="r">
            Institute of Automationï¼ŒChinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab784" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Real-time 6 DOF localization of bronchoscopes is crucial for enhancing intervention quality. However, current vision-based technologies struggle to balance between generalization to unseen data and computational speed. In this study, we propose a Depth-based Dual-Loop framework for real-time Visually Navigated Bronchoscopy (DD-VNB) that can generalize across patient cases without the need of re-training. The DD-VNB framework integrates two key modules: depth estimation and dual-loop localization. To address the domain gap among patients, we propose a knowledge-embedded depth estimation network that maps endoscope frames to depth, ensuring generalization by eliminating patient-specific textures. The network embeds view synthesis knowledge into a cycle adversarial architecture for scale-constrained monocular depth estimation. For real-time performance, our localization module embeds a fast ego-motion estimation network into the loop of depth registration. The ego-motion inference network estimates the pose change of the bronchoscope in high frequency while depth registration against the pre-operative 3D model provides absolute pose periodically. Specifically, the relative pose changes are fed into the registration process as the initial guess to boost its accuracy and speed. Experiments on phantom and in-vivo data from patients demonstrate the effectiveness of our framework: 1) monocular depth estimation outperforms SOTA, 2) localization achieves an accuracy of Absolute Tracking Error (ATE) of 4.7 Â± 3.17 mm in phantom and 6.49 Â± 3.88 mm in patient data, 3) with a frame-rate approaching video capture speed, 4) without the necessity of case-wise network retraining. The framework's superior speed and accuracy demonstrate its promising clinical potential for real-time bronchoscopic navigation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt1_02">
             11:15-11:30, Paper FrBT1.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('874'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RNR-Nav: A Real-World Visual Navigation System Using Renderable Neural Radiance Maps
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392190" title="Click to go to the Author Index">
             Kim, Minsoo
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#255120" title="Click to go to the Author Index">
             Kwon, Obin
            </a>
           </td>
           <td class="r">
            Seoul Natl University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#225162" title="Click to go to the Author Index">
             Jun, Howoong
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#119971" title="Click to go to the Author Index">
             Oh, Songhwai
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab874" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose a novel visual localization and navigation framework for real-world environments directly integrating observed visual information into the bird-eye-view map. While the renderable neural radiance map (RNR-Map) shows considerable promise in simulated settings, its deployment in real-world scenarios poses undiscovered challenges. RNR-Map utilizes projections of multiple vectors into a single latent code, resulting in information loss under suboptimal conditions. To address such issues, our enhanced RNR-Map for real-world robots, RNR-Map++, incorporates strategies to mitigate information loss, such as a weighted map and positional encoding. For robust real-time localization, we integrate a particle filter into the correlation-based localization framework using RNRMap++ without a rendering procedure. Consequently, we establish a real-world robot system for visual navigation utilizing RNR-Map++, which we call â€œRNR-Nav.â€ Experimental results demonstrate that the proposed methods significantly enhance rendering quality and localization robustness compared to previous approaches. In real-world navigation tasks, RNR-Nav achieves a success rate of 84.4%, marking a 68.8% enhancement over the methods of the original RNR-Map paper.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt1_03">
             11:30-11:45, Paper FrBT1.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('967'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Mind the Error! Detection and Localization of Instruction Errors in Vision-And-Language Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380976" title="Click to go to the Author Index">
             Taioli, Francesco
            </a>
           </td>
           <td class="r">
            University of Verona
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123015" title="Click to go to the Author Index">
             Rosa, Stefano
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#225224" title="Click to go to the Author Index">
             Castellini, Alberto
            </a>
           </td>
           <td class="r">
            Verona University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#111056" title="Click to go to the Author Index">
             Natale, Lorenzo
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#133775" title="Click to go to the Author Index">
             Del Bue, Alessio
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106097" title="Click to go to the Author Index">
             Farinelli, Alessandro
            </a>
           </td>
           <td class="r">
            University of Verona
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#166506" title="Click to go to the Author Index">
             Cristani, Marco
            </a>
           </td>
           <td class="r">
            University of Verona
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#192532" title="Click to go to the Author Index">
             Wang, Yiming
            </a>
           </td>
           <td class="r">
            Fondazione Bruno Kessler
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab967" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Vision-and-Language Navigation in Continuous Environments (VLN-CE) is one of the most intuitive yet challenging embodied AI tasks. Agents are tasked to navigate towards a target goal by executing a set of low-level actions, following a series of natural language instructions. All VLN-CE methods in the literature assume that language instructions are exact. However, in practice, instructions given by humans can contain errors when describing a spatial environment due to inaccurate memory or confusion. Current VLN-CE benchmarks do not address this scenario, making the state-of-the-art methods in VLN-CE fragile in the presence of erroneous instructions from human users. For the first time, we propose a novel benchmark dataset that introduces various types of instruction errors considering potential human causes. This benchmark provides valuable insight into the robustness of VLN systems in continuous environments. We observe a noticeable performance drop (up to âˆ’25%) in Success Rate when evaluating the state-of-the-art VLN-CE methods on our benchmark. Moreover, we formally define the task of Instruction Error Detection and Localization, and establish an evaluation protocol on top of our benchmark dataset. We also propose an effective method, based on a cross-modal transformer architecture, that achieves the best performance in error detection and localization, compared to baselines. Surprisingly, our proposed method has revealed errors in the validation set of the two commonly used datasets for VLN-CE, i.e., R2R-CE and RxR-CE, demonstrating the utility of our technique in other tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt1_04">
             11:45-12:00, Paper FrBT1.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('994'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Distilling Knowledge for Short-To-Long Term Trajectory Prediction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376773" title="Click to go to the Author Index">
             Das, Sourav
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376762" title="Click to go to the Author Index">
             Camporese, Guglielmo
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395036" title="Click to go to the Author Index">
             Cheng, Shaokang
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#198211" title="Click to go to the Author Index">
             Ballan, Lamberto
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab994" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Long-term trajectory forecasting is an important and challenging problem in the fields of computer vision, machine learning, and robotics. One fundamental difficulty stands in the evolution of the trajectory that becomes more and more uncertain and unpredictable as the time horizon grows, subsequently increasing the complexity of the problem. To overcome this issue, in this paper, we propose Di-Long, a new method that employs the distillation of a short-term trajectory model forecaster that guides a student network for long-term trajectory prediction during the training process. Given a total sequence length that comprehends the allowed observation for the student network and the complementary target sequence, we let the student and the teacher solve two different related tasks defined over the same full trajectory: the student observes a short sequence and predicts a long trajectory, whereas the teacher observes a longer sequence and predicts the remaining short target trajectory. The teacher's task is less uncertain, and we use its accurate predictions to guide the student through our knowledge distillation framework, reducing long-term future uncertainty. Our experiments show that our proposed Di-Long method is effective for long-term forecasting and achieves state-of-the-art performance on the Intersection Drone Dataset (inD) and the Stanford Drone Dataset (SDD).
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frbt2">
             <b>
              FrBT2
             </b>
            </a>
           </td>
           <td class="r">
            Room 2
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frbt2" title="Click to go to the Program at a Glance">
             <b>
              Human-Aware Motion Planning
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt2_01">
             11:00-11:15, Paper FrBT2.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1170'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SparseGTN: Human Trajectory Forecasting with Sparsely Represented Scene and Incomplete Trajectories
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#287894" title="Click to go to the Author Index">
             Liu, Jianbang
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395826" title="Click to go to the Author Index">
             Li, Guangyang
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361489" title="Click to go to the Author Index">
             Mao, Xinyu
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276477" title="Click to go to the Author Index">
             Meng, Fei
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#315069" title="Click to go to the Author Index">
             Mei, Jie
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100160" title="Click to go to the Author Index">
             Meng, Max Q.-H.
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1170" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_and_humanoid_motion_analysis_and_synthesis" title="Click to go to the Keyword Index">
               Human and Humanoid Motion Analysis and Synthesis
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In recent years, great progress has been made in forecasting human motion in crowded scenes. However, current methods are far from practical applications due to the unbearable high computation costs, especially for encoding scene context. In addition, neglecting the partially detected trajectories makes the predicted outcome deviate from the real trajectory distribution. To handle the aforementioned concerns, we propose to represent the scene context and partially observed trajectories with sparse graphs. Customized for this special data structure, we design a hierarchical Graph Transformer Network model SparseGTN to predict multiple possible future trajectories of the target pedestrian by digesting the sparsely represented inputs. Our approach exhibits superiority over the state-of-the-art (SOTA) methods, utilizing a mere 3.42% of the number of floating point operations (FLOPs) and 0.53% of the number of model parameters. The code will be available online.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt2_02">
             11:15-11:30, Paper FrBT2.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('825'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GazeMotion: Gaze-Guided Human Motion Forecasting
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394219" title="Click to go to the Author Index">
             Hu, Zhiming
            </a>
           </td>
           <td class="r">
            University of Stuttgart
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#141343" title="Click to go to the Author Index">
             Schmitt, Syn
            </a>
           </td>
           <td class="r">
            University of Stuttgart, Germany
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#141339" title="Click to go to the Author Index">
             Haeufle, Daniel Florian Benedict
            </a>
           </td>
           <td class="r">
            Heidelberg University, Germany
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380410" title="Click to go to the Author Index">
             Bulling, Andreas
            </a>
           </td>
           <td class="r">
            University of Stuttgart
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab825" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present GazeMotion â€“ a novel method for human motion forecasting that combines information on past human poses with human eye gaze. Inspired by evidence from behavioural sciences showing that human eye and body movements are closely coordinated, GazeMotion first predicts future eye gaze from past gaze, then fuses predicted future gaze and past poses into a gaze-pose graph, and finally uses a residual graph convolutional network to forecast body motion. We extensively evaluate our method on the MoGaze, ADT, and GIMO benchmarks and demonstrate that it outperforms state-of-the-art methods by up to 7.4% improvement in mean per joint position error. Using head direction as a proxy to gaze, our method still achieves an average improvement of 5.5%. We finally report an online user study showing that our method also outperforms prior methods in terms of perceived realism. These results show the significant information content available in eye gaze for human motion forecasting as well as the effectiveness of our method in exploiting this information.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt2_03">
             11:30-11:45, Paper FrBT2.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1780'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hyp2Nav: Hyperbolic Planning and Curiosity for Crowd Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396619" title="Click to go to the Author Index">
             D'Amely di Melendugno, Guido Maria
            </a>
           </td>
           <td class="r">
            Sapienza University of Rome
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396604" title="Click to go to the Author Index">
             Flaborea, Alessandro
            </a>
           </td>
           <td class="r">
            Sapienza University of Rome
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#240468" title="Click to go to the Author Index">
             Mettes, Pascal
            </a>
           </td>
           <td class="r">
            University of Amsterdam
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286924" title="Click to go to the Author Index">
             Galasso, Fabio
            </a>
           </td>
           <td class="r">
            Sapienza University of Rome
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1780" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous robots are increasingly becoming a strong fixture in social environments. Effective crowd navigation requires not only safe yet fast planning, but should also enable interpretability and computational efficiency for working in real-time on embedded devices. In this work, we advocate for hyperbolic learning to enable crowd navigation and we introduce Hyp2Nav. Different from conventional reinforcement learning-based crowd navigation methods, Hyp2Nav leverages the intrinsic properties of hyperbolic geometry to better encode the hierarchical nature of decision-making processes in navigation tasks. We propose a hyperbolic policy model and a hyperbolic curiosity module that results in effective social navigation, best success rates, and returns across multiple simulation settings, using up to 6 times fewer parameters than competitor state-of-the-art models. With our approach, it becomes even possible to obtain policies that work in 2-dimensional embedding spaces, opening up new possibilities for low-resource crowd navigation and model interpretability. Insightfully, the internal hyperbolic representation of Hyp2Nav correlates with how much attention the robot pays to the surrounding crowds, e.g. due to multiple people occluding its pathway or to a few of them showing colliding plans, rather than to its own planned route. The code is available at https://github.com/GDam90/hyp2nav.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt2_04">
             11:45-12:00, Paper FrBT2.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2408'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Map-Aware Human Pose Prediction for Robot Follow-Ahead
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#292728" title="Click to go to the Author Index">
             Jiang, Qingyuan
            </a>
           </td>
           <td class="r">
            University of Minnesota
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397392" title="Click to go to the Author Index">
             Susam, Burak
            </a>
           </td>
           <td class="r">
            University of Minnesota
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#292730" title="Click to go to the Author Index">
             Chao, Jun-Jee
            </a>
           </td>
           <td class="r">
            University of Minnesota
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101719" title="Click to go to the Author Index">
             Isler, Volkan
            </a>
           </td>
           <td class="r">
            University of Minnesota
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2408" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#gesture__posture_and_facial_expressions" title="Click to go to the Keyword Index">
               Gesture, Posture and Facial Expressions
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_detection_and_tracking" title="Click to go to the Keyword Index">
               Human Detection and Tracking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the robot follow-ahead task, a mobile robot is tasked to maintain its relative position in front of a moving human actor while keeping the actor in sight. To accomplish this task, it is important that the robot understand the full 3D pose of the human (since the head orientation can be different than the torso) and predict future human poses so as to plan accordingly. This prediction task is especially tricky in a complex environment with junctions and multiple corridors. In this work, we address the problem of forecasting the full 3D trajectory of a human in such environments. Our main insight is to show that one can first predict the 2D trajectory and then estimate the full 3D trajectory by conditioning the estimator on the predicted 2D trajectory. With this approach, we achieve results comparable or better than the state-of-the-art methods three times faster. As part of our contribution, we present a new dataset where, in contrast to existing datasets, the human motion is in a much larger area than a single room. We also present a complete robot system that integrates our human pose forecasting network on the mobile robot to enable real-time robot follow-ahead and present results from real-world experiments in multiple buildings on campus. Our project page, including supplementary material and videos, can be found at: https://qingyuan-jiang.github.io/iros2024_poseForecasting/
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frbt3">
             <b>
              FrBT3
             </b>
            </a>
           </td>
           <td class="r">
            Room 3
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frbt3" title="Click to go to the Program at a Glance">
             <b>
              Micro/Nano Robots I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#285160" title="Click to go to the Author Index">
             Liu, Song
            </a>
           </td>
           <td class="r">
            ShanghaiTech University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt3_01">
             11:00-11:15, Paper FrBT3.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('28'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning a Tracking Controller for Rolling Î¼bots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#229715" title="Click to go to the Author Index">
             Beaver, Logan
            </a>
           </td>
           <td class="r">
            Old Dominion University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#332041" title="Click to go to the Author Index">
             Max, Sokolich
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#369035" title="Click to go to the Author Index">
             Alsalehi, Suhail
            </a>
           </td>
           <td class="r">
            Boston Unviersity
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#169605" title="Click to go to the Author Index">
             Weiss, Ron
            </a>
           </td>
           <td class="r">
            Massachusettes Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#221428" title="Click to go to the Author Index">
             Das, Sambeeta
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101680" title="Click to go to the Author Index">
             Belta, Calin
            </a>
           </td>
           <td class="r">
            Boston University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab28" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Micron-scale robots (Î¼bots) have recently shown great promise for emerging medical applications. Accurate control of Î¼bots, while critical to their successful deployment, is challenging. In this work, we consider the problem of tracking a reference trajectory using a Î¼bot in the presence of disturbances and uncertainty. The disturbances primarily come from Brownian motion and other environmental phenomena, while the uncertainty originates from errors in the model parameters. We model the Î¼bot as an uncertain unicycle that is controlled by a global magnetic field. To compensate for disturbances and uncertainties, we develop a nonlinear mismatch controller. We define the model mismatch error as the difference between our model's predicted velocity and the actual velocity of the Î¼bot. We employ a Gaussian Process to learn the model mismatch error as a function of the applied control input. Then we use a least-squares minimization to select a control action that minimizes the difference between the actual velocity of the Î¼bot and a reference velocity. We demonstrate the online performance of our joint learning and control algorithm in simulation, where our approach accurately learns the model mismatch and improves tracking performance. We also validate our approach in an experiment and show that certain error metrics are reduced by up to 40%.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt3_02">
             11:15-11:30, Paper FrBT3.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3666'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              The Design of a Layered Brain-Computer Interface System with Target Identification Module to Control Home Service Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#342631" title="Click to go to the Author Index">
             Wang, Wenzhi
            </a>
           </td>
           <td class="r">
            Nankai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361410" title="Click to go to the Author Index">
             Mao, Yuqing, Troy
            </a>
           </td>
           <td class="r">
            University of California, Davis
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#116345" title="Click to go to the Author Index">
             Duan, Feng
            </a>
           </td>
           <td class="r">
            Nankai University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3666" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#biomimetics" title="Click to go to the Keyword Index">
               Biomimetics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#brain_machine_interfaces" title="Click to go to the Keyword Index">
               Brain-Machine Interfaces
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Brain-computer interface (BCI) systems, a kind of communication channel between human mind and the environment, turn brain activities into control commands. However, disabled people cannot withstand continuously high-tense operation of robots to fulfill complicated tasks. In order to simplify the operating process and strengthen the practicality of services, this paper proposed a layered BCI system integrated with a two-level target identification system to control a home service robot. We recorded single-channel steady-state visual evoked potentials (SSVEP) to diminish the number of electrodes in use. This hierarchical architecture can enhance the accuracy and sustainability during operation. The target identification system was established to reduce the burden of users and accelerate the service procedures. Subjects recruited in the experiment succeed in operating the robot to provide basic services. The average accuracy of online experiment is 87.38%. These results prove the effectiveness of this hierarchical system in operating a multifunctional home service robot with single-channel SSVEP, which plays an important role in both medical care and daily life.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt3_03">
             11:30-11:45, Paper FrBT3.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3753'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Magnetic Helical Miniature Robot with Soft Magnetic-Controlled Gripper
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380097" title="Click to go to the Author Index">
             Zhu, Aoji
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380802" title="Click to go to the Author Index">
             Bai, Chenyao
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380801" title="Click to go to the Author Index">
             Lu, Xiwen
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380800" title="Click to go to the Author Index">
             Zhu, Yunlong
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380803" title="Click to go to the Author Index">
             Wang, Kezhi
            </a>
           </td>
           <td class="r">
            Brunel University London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#380839" title="Click to go to the Author Index">
             Zhu, Jiarui
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3753" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Magnetic helical miniature robots (MHMRs) exhibit efficient motion performance in low Reynolds number environments, having great promise for biomedical applications like targeted delivery. However, during targeted delivery, the backward propulsion of MHMRs leads to cargo being released, limiting their degrees of freedom and interference resistance. Furthermore, the basic magnetic field parameter, amplitude, has not been effectively utilized in previous MHMRs. In this letter, we propose a magnetic helical miniature robot with soft magnetic-controlled gripper (MHMR-G), using magnetic field amplitude to functionalize the MHMR for the first time. The velocity of MHMR-G is controlled by magnetic field frequency and the grasping of gripper is controlled by magnetic field amplitude. It is proposed that the lag angle and rotation frequency will adversely affect the grasping of gripper under a rotating magnetic field, but results show that increasing magnetic field amplitude can effectively mitigate these adverse effects. Finally, a manipulation test of cargo transport is performed, demonstrating that the gripper of MHMR-G can effectively confine cargo during MHMR-G propulsion.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt3_04">
             11:45-12:00, Paper FrBT3.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1147'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ActNeRF: Uncertainty-Aware Active Learning of NeRF-Based Object Models for Robot Manipulators Using Visual and Re-Orientation Actions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392267" title="Click to go to the Author Index">
             Dasgupta, Saptarshi
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology Delhi
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392283" title="Click to go to the Author Index">
             Gupta, Akshat
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology Delhi
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#327748" title="Click to go to the Author Index">
             Tuli, Shreshth
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology Delhi
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#132742" title="Click to go to the Author Index">
             Paul, Rohan
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology Delhi
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1147" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#perception_action_coupling" title="Click to go to the Keyword Index">
               Perception-Action Coupling
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#incremental_learning" title="Click to go to the Keyword Index">
               Incremental Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Manipulating unseen objects is challenging without a 3D representation, as objects generally have occluded surfaces. This requires physical interaction with objects to build their internal representations. This paper presents an approach that enables a robot to rapidly learn the complete 3D model of a given object for manipulation in unfamiliar orientations. We use an ensemble of partially constructed NeRF models to quantify model uncertainty to determine the next action (a visual or re-orientation action) by optimizing informativeness and feasibility. Further, our approach determines emph{when} and how to grasp and re-orient an object given its partial NeRF model and re-estimates the object pose to rectify misalignments introduced during the interaction. Experiments with a simulated Franka Emika Robot Manipulator operating in a tabletop environment with benchmark objects demonstrate an improvement of (i) 14% in visual reconstruction quality (PSNR), (ii) 20% in the geometric/depth reconstruction of the object surface (F-score) and (iii) 71% in the task success rate of manipulating objects a-priori unseen orientations/stable configurations in the scene; over current methods. The project page can be found at https://actnerf.github.io/
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frbt4">
             <b>
              FrBT4
             </b>
            </a>
           </td>
           <td class="r">
            Room 4
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frbt4" title="Click to go to the Program at a Glance">
             <b>
              Micro/Nano Robots II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#285160" title="Click to go to the Author Index">
             Liu, Song
            </a>
           </td>
           <td class="r">
            ShanghaiTech University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt4_01">
             11:00-11:15, Paper FrBT4.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1257'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning the Inverse Kinematics of Magnetic Continuum Robot for Teleoperated Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#308739" title="Click to go to the Author Index">
             Xiang, Pingyu
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375427" title="Click to go to the Author Index">
             Qiu, Ke
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#356571" title="Click to go to the Author Index">
             Sun, Danying
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#251865" title="Click to go to the Author Index">
             Zhang, Jingyu
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#305674" title="Click to go to the Author Index">
             Fang, Qin
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375449" title="Click to go to the Author Index">
             Mi, Xiangyu
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#412783" title="Click to go to the Author Index">
             Wang, Shudong
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375452" title="Click to go to the Author Index">
             Chen, Mengxiao
            </a>
           </td>
           <td class="r">
            Zhejiang Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#156231" title="Click to go to the Author Index">
             Wang, Yue
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113216" title="Click to go to the Author Index">
             Xiong, Rong
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#184494" title="Click to go to the Author Index">
             Lu, Haojian
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1257" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#automation_at_micro_nano_scales" title="Click to go to the Keyword Index">
               Automation at Micro-Nano Scales
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Magnetic continuum robots are subject to external magnetic fields and deformed remotely, simplifying the robot's transmission mechanism and providing it with significant potential for miniaturization and operational flexibility. However, modeling magnetic field distribution generated by permanent magnets is complex and requires time-consuming pre-calibrations. Moreover, it is highly susceptible to environments with ferromagnetic materials, posing significant challenges for the control of magnetic continuum robots. In response, we propose an approach that does not overly focus on the magnetic field distribution but instead directly learns the inverse kinematics of magnetic continuum robots end-to-end. Binding the robot's configuration to the pose of external magnets, precise control of continuum robots is facilitated. Additionally, we leverage teleoperation techniques to broaden the applicability of this method. By mounting magnets on a robotic arm and directly utilizing the target pose of the external magnet predicted by a multi-layer perceptron (MLP), we achieve the operation and navigation of magnetic continuum robots in complex environments. Experiments demonstrate that the mean control accuracy along the robot using our learning-based inverse kinematics is about half of the robot's diameter.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt4_02">
             11:15-11:30, Paper FrBT4.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('569'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Real-Time Particle Cluster Manipulation with Holographic Acoustic End-Effector under Microscope
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385274" title="Click to go to the Author Index">
             An, Siyuan
            </a>
           </td>
           <td class="r">
            Shanghaitech University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310248" title="Click to go to the Author Index">
             Zhong, Chengxi
            </a>
           </td>
           <td class="r">
            ShanghaiTech University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335221" title="Click to go to the Author Index">
             Wang, Mingyue
            </a>
           </td>
           <td class="r">
            Shanghaitech Univerisity
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#412783" title="Click to go to the Author Index">
             Wang, Shudong
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#184494" title="Click to go to the Author Index">
             Lu, Haojian
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335232" title="Click to go to the Author Index">
             Li, Jiaqi
            </a>
           </td>
           <td class="r">
            ShanghaiTech University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104222" title="Click to go to the Author Index">
             Li, Y.F.
            </a>
           </td>
           <td class="r">
            City University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285160" title="Click to go to the Author Index">
             Liu, Song
            </a>
           </td>
           <td class="r">
            ShanghaiTech University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab569" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Non-contact particle cluster manipulation holds significant promise in the realms of advanced manufacturing, chemistry, and pharmacy. However, achieving precise and dynamic control over the spatial kinematics of particle clusters remains a significant challenge, necessitating real-time and accurately programmable robotic end-effector. To this end, we develop an innovative non-contact, precise particle cluster manipulation system with ultrasonic phased array transducer (PAT) under microscope. This system combines a physics-based deep learning algorithm for real-time calculation of phase-only holograms (POHs), supporting PAT to dynamically form acoustic fields, namely holographic acoustic end-effector (HAE). Leveraging the dynamically and accurately generated HAEs by our system, kinematics control of particle clusters including aggregation, rotation, and translation is yielded. The extensive experiments well demonstrated the effectiveness of proposed system for particle cluster manipulation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt4_03">
             11:30-11:45, Paper FrBT4.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3237'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Absolute Pose Estimation for a Millimeter-Scale Vision System
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351057" title="Click to go to the Author Index">
             Ozturk, Derin
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398962" title="Click to go to the Author Index">
             Wang, Zilin
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#169741" title="Click to go to the Author Index">
             Helbling, E. Farrell
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3237" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#embedded_systems_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Embedded Systems for Robotic and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Vision is an important component of robotic perception systems due to the rich information provided by high resolution image sensors, but computer vision algorithms can be computationally expensive and ill-suited to resource-constrained robotic systems. Here, we present a mm-scale vision system capable of performing absolute pose estimation at 16.5 FPS. This novel vision system uses a commercial-off-the-shelf sensor and microcontroller unit, as well as planar light-based landmarks in the environment to simplify feature detection. We exploit the structure of the planar pose problem to reduce algorithmic complexity and improve latency and energy consumption through software-, processor-, and hardware-in-the-loop testing. The end-to-end system consumes 49 mA of current and computes absolute pose estimates within 15 mm over a number of reference trajectories.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt4_04">
             11:45-12:00, Paper FrBT4.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3465'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design and Control of a Three-Dimensional Electromagnetic Drive System for Micro-Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398644" title="Click to go to the Author Index">
             Zhang, Yunrui
            </a>
           </td>
           <td class="r">
            Jiangnan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#241733" title="Click to go to the Author Index">
             Liu, Yueyue
            </a>
           </td>
           <td class="r">
            Jiangnan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#315953" title="Click to go to the Author Index">
             Fan, Qigao
            </a>
           </td>
           <td class="r">
            Jiangnan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3465" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Three-dimensional electromagnetic field drive technology, as a cutting-edge remote wireless control method, is extensively utilized in the biomedical diagnosis and treatment of micro-robots. This paper presents the design of a three-dimensional electromagnetic drive system for micro-robots, leveraging a gradient magnetic field to achieve comprehensive automatic control in three axes. Firstly, we refine the iron core's end structure to produce an uniform gradient magnetic field throughout the three-dimensional space. Following that, the parameters at the end of the iron core are fine-tuned to meet the specifications for magnetic field gradient, magnetic flux density, and effective workspace. Then a three-dimensional electromagnetic drive system with strong magnetic field gradient is established, achieving a remarkable maximum gradient of 1.70 T/m at the center of the workspace. Compared with other systems, the gradient is significantly enhanced. Subsequently, we carry out a three-dimensional drive experiment for a micro-robot, confirming the system's driving efficacy. To enable precise path following for micro-robots within a three-dimensional space, we have formulated a control strategy rooted in micro-robot dynamics. The controller stability is guaranteed through the Lyapunov theory. Ultimately, a three-dimensional path following experiment is executed on the developed electromagnetic drive system. The experiment confirms the capability of our designed system which can achieve the three-dimensional closed-loop motion for the micro-robot.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frbt5">
             <b>
              FrBT5
             </b>
            </a>
           </td>
           <td class="r">
            Room 5
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frbt5" title="Click to go to the Program at a Glance">
             <b>
              Grasping Control
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#324871" title="Click to go to the Author Index">
             Heppert, Nick
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt5_01">
             11:00-11:15, Paper FrBT5.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1523'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              AO-Grasp: Articulated Object Grasp Generation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#332615" title="Click to go to the Author Index">
             Pares-Morlans, Carlota
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#250207" title="Click to go to the Author Index">
             Chen, Claire
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#329719" title="Click to go to the Author Index">
             Weng, Yijia
            </a>
           </td>
           <td class="r">
            Stanford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372210" title="Click to go to the Author Index">
             Yi, Michelle
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#323796" title="Click to go to the Author Index">
             Huang, Yuying
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324871" title="Click to go to the Author Index">
             Heppert, Nick
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372207" title="Click to go to the Author Index">
             Zhou, Linqi
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#118397" title="Click to go to the Author Index">
             Guibas, Leonidas
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#116883" title="Click to go to the Author Index">
             Bohg, Jeannette
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1523" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce AO-Grasp, a grasp proposal method that generates 6 DoF grasps that enable robots to interact with articulated objects, such as opening and closing cabinets and appliances. AO-Grasp consists of two main contributions: the AO-Grasp Model and the AO-Grasp Dataset. Given a segmented partial point cloud of a single articulated object, the AO-Grasp Model predicts the best grasp points on the object with an Actionable Grasp Point Predictor. Then, it finds corresponding grasp orientations for each of these points, resulting in stable and actionable grasp proposals. We train the AO-Grasp Model on our new AO-Grasp Dataset, which contains 78K actionable parallel-jaw grasps on synthetic articulated objects. In simulation, AO-Grasp achieves a 45.0% grasp success rate, whereas the highest performing baseline achieves a 35.0% success rate. Additionally, we evaluate AO-Grasp on 120 real-world scenes of objects with varied geometries, articulation axes, and joint states, where AO-Grasp produces successful grasps on 67.5% of scenes, while the baseline only produces successful grasps on 33.3% of scenes. To the best of our knowledge, AO-Grasp is the first method for generating 6 DoF grasps on articulated objects directly from partial point clouds without requiring part detection or hand-designed grasp heuristics. The AO-Grasp Dataset and a pre-trained AO-Grasp model are available at our project website: https://stanford-iprl-lab.github.io/ao-grasp/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt5_02">
             11:15-11:30, Paper FrBT5.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1507'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Evaluating a Movable Palm in Caging Inspired Grasping Using a Reinforcement Learning-Based Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#292846" title="Click to go to the Author Index">
             Beddow, Luke Jonathan
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142097" title="Click to go to the Author Index">
             Wurdemann, Helge Arne
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#147896" title="Click to go to the Author Index">
             Kanoulas, Dimitrios
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1507" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we study the effectiveness of using a rigid movable palm for grasping varied objects, on a caging inspired gripper with three flexible fingers. This rigid palm extends to actively exert downwards force on objects, in contrast with existing methods, which combine movable palms with negative pressure to exert lifting forces on objects. We compare grasping with and without the palm, whilst also changing finger stiffness and fingertip angle, to analyse the effect on grasp success rate and stability over 24 design permutations. Reinforcement learning was used to train a unique grasping controller in every design case, aiming to achieve optimal grasping as the basis for comparison. Validation in both simulation and the real world was completed for every permutation. We demonstrated that the using palm improved success rates on average by 11% in simulation, 13% in the real world, and achieved a best real world success rate of 96% on 18 YCB benchmark food objects. Grasp stability against disturbances in three axes improved by 15% on average when using the palm. Our investigation determined fingertip angle had a large effect, whereas finger stiffness was less important.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt5_03">
             11:30-11:45, Paper FrBT5.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1816'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning a Shape-Conditioned Agent for Purely Tactile In-Hand Manipulation of Various Objects
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310399" title="Click to go to the Author Index">
             Pitz, Johannes
            </a>
           </td>
           <td class="r">
            German Aerospace Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#323464" title="Click to go to the Author Index">
             RÃ¶stel, Lennart
            </a>
           </td>
           <td class="r">
            German Aerospace Center (DLR)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#312100" title="Click to go to the Author Index">
             Sievers, Leon
            </a>
           </td>
           <td class="r">
            German Aerospace Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105286" title="Click to go to the Author Index">
             Burschka, Darius
            </a>
           </td>
           <td class="r">
            Technische Universitaet Muenchen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105517" title="Click to go to the Author Index">
             BÃ¤uml, Berthold
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1816" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#in_hand_manipulation" title="Click to go to the Keyword Index">
               In-Hand Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Reorienting diverse objects with a multi-fingered hand is a challenging task. Current methods in robotic in-hand manipulation are either object-specific or require permanent supervision of the object state from visual sensors. This is far from human capabilities and from what is needed in real-world applications. In this work, we address this gap by training shape-conditioned agents to reorient diverse objects in hand, relying purely on tactile feedback (via torque and position measurements of the fingers' joints). To achieve this, we propose a learning framework that exploits shape information in a reinforcement learning policy and a learned state estimator. We find that representing 3D shapes by vectors from a fixed set of basis points to the shape's surface, transformed by its predicted 3D pose, is especially helpful for learning dexterous in-hand manipulation. In simulation and real-world experiments, we show the reorientation of many objects with high success rates, on par with state-of-the-art results obtained with specialized single-object agents. Moreover, we show generalization to novel objects, achieving success rates of ~90% even for non-convex shapes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt5_04">
             11:45-12:00, Paper FrBT5.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2084'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Fine Manipulation Using a Tactile Skin: Learning in Simulation and Sim-To-Real Transfer
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397754" title="Click to go to the Author Index">
             Kasolowsky, Ulf
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105517" title="Click to go to the Author Index">
             BÃ¤uml , Berthold
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2084" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#in_hand_manipulation" title="Click to go to the Keyword Index">
               In-Hand Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We want to enable fine manipulation with a multi-fingered robotic hand by using modern deep reinforcement learning methods. Key for fine manipulation is a spatially resolved tactile sensor. Here, we present a novel model of a tactile skin that can be used together with rigid-body (hence fast) physics simulators. The model considers the softness of the real fingertips such that a contact can spread across multiple taxels of the sensor depending on the contact geometry. We calibrate the model parameters to allow for an accurate simulation of the real-world sensor. For this, we present a self-contained calibration method without external tools or sensors. To demonstrate the validity of our approach, we learn two challenging fine manipulation tasks: Rolling a marble and a bolt between two fingers. We show in simulation experiments that tactile feedback is crucial for precise manipulation and reaching sub-taxel resolution of &lt;1mm (despite a taxel spacing of 4mm). Moreover, we demonstrate that all policies successfully transfer from the simulation to the real robotic hand. Website: https://aidx-lab.org/skin/iros24
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frbt6">
             <b>
              FrBT6
             </b>
            </a>
           </td>
           <td class="r">
            Room 6
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frbt6" title="Click to go to the Program at a Glance">
             <b>
              Aerial Systems: Motion Control and Planning
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#113384" title="Click to go to the Author Index">
             Saska, Martin
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#220123" title="Click to go to the Author Index">
             Agarwal, Saurav
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt6_01">
             11:00-11:15, Paper FrBT6.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2833'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Identifying Optimal Launch Sites of High-Altitude Latex-Balloons Using Bayesian Optimisation for the Task of Station-Keeping
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#328337" title="Click to go to the Author Index">
             Saunders, Jack
            </a>
           </td>
           <td class="r">
            University of Bath
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#135321" title="Click to go to the Author Index">
             Saeedi, Sajad
            </a>
           </td>
           <td class="r">
            Toronto Metropolitan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395091" title="Click to go to the Author Index">
             Hartshorne, Adam
            </a>
           </td>
           <td class="r">
            University of Bath
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#202419" title="Click to go to the Author Index">
             Xu, Binbin
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353904" title="Click to go to the Author Index">
             ÅžimÅŸek, Ã–zgÃ¼r
            </a>
           </td>
           <td class="r">
            University of Bath
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354240" title="Click to go to the Author Index">
             Hunter, Alan Joseph
            </a>
           </td>
           <td class="r">
            University of Bath
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#195093" title="Click to go to the Author Index">
             Li, Wenbin
            </a>
           </td>
           <td class="r">
            University of Bath
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2833" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Station-keeping tasks for high-altitude balloons show promise in areas such as ecological surveys, atmospheric analysis, and communication relays. However, identifying the optimal time and position to launch a latex high-altitude balloon is still a challenging and multifaceted problem. For example, tasks such as forest fire tracking place geometric constraints on the launch location of the balloon. Furthermore, identifying the most optimal location also heavily depends on atmospheric conditions. We first illustrate how reinforcement learning-based controllers, frequently used for station-keeping tasks, can exploit the environment. This exploitation can degrade performance on unseen weather patterns and affect station-keeping performance when identifying an optimal launch configuration. Valuing all states equally in the region, the agent exploits the region's geometry by flying near the edge, leading to risky behaviours. We propose a modification which compensates for this exploitation and finds this leads to, on average, higher steps within the target region on unseen data. Then, we illustrate how Bayesian Optimisation (BO) can identify the optimal launch location to perform station-keeping tasks, maximising the return from a given rollout. We show BO can find this launch location in fewer steps compared to other optimisation methods. Results indicate that, surprisingly, the most optimal location to launch from is not commonly within the target region. Please find further information about our project at https://sites.google.com/view/bo-lauch-balloon/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt6_02">
             11:15-11:30, Paper FrBT6.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('683'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              TOPPQuad: Dynamically-Feasible Time-Optimal Path Parametrization for Quadrotors
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#342136" title="Click to go to the Author Index">
             Mao, Katherine
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#239282" title="Click to go to the Author Index">
             Spasojevic, Igor
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106150" title="Click to go to the Author Index">
             Hsieh, M. Ani
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104342" title="Click to go to the Author Index">
             Kumar, Vijay
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab683" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Planning time-optimal trajectories for quadrotors in cluttered environments is a challenging, non-convex problem. This paper addresses minimizing the traversal time of a given collision free geometric path without violating actuation bounds of the vehicle. Previous approaches have either relied on convex relaxations that do not guarantee dynamic feasibility, or have generated overly conservative time parametrizations. We propose TOPPQuad, a time-optimal path parameterization algorithm for quadrotors which explicitly incorporates quadrotor rigid body dynamics and constraints such as bounds on inputs (including motor thrusts) and state of the vehicle (including the pose, linear and angular velocity and acceleration). We demonstrate the ability of the planner to generate faster trajectories that respect hardware constraints of the robot compared to several planners with relaxed notions of dynamic feasibility in simulation and on hardware. We also demonstrate how TOPPQuad can be used to plan trajectories for quadrotors that utilize bidirectional motors. Overall, the proposed approach paves a way towards maximizing the efficacy of autonomous micro aerial vehicles while ensuring their safety.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt6_03">
             11:30-11:45, Paper FrBT6.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1462'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Model Predictive Path Integral Control for Agile Unmanned Aerial Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395919" title="Click to go to the Author Index">
             MinaÅ™Ã­k, Michal
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#181627" title="Click to go to the Author Index">
             Penicka, Robert
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#136324" title="Click to go to the Author Index">
             Vonasek, Vojtech
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113384" title="Click to go to the Author Index">
             Saska, Martin
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1462" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a control architecture for real-time and onboard control of Unmanned Aerial Vehicles (UAVs) in environments with obstacles using the Model Predictive Path Integral (MPPI) methodology. MPPI allows the use of the full nonlinear model of UAV dynamics and a more general cost function at the cost of a high computational demand. To run the controller in real-time, the sampling-based optimization is performed in parallel on a graphics processing unit onboard the UAV. We propose an approach to the simulation of the nonlinear system which respects low-level constraints, while also able to dynamically handle obstacle avoidance, and prove that our methods are able to run in real-time without the need for external computers. The MPPI controller is compared to MPC and SE(3) controllers on the reference tracking task, showing a comparable performance. We demonstrate the viability of the proposed method in multiple simulation and real-world experiments, tracking a reference at up to 44 km/h and acceleration close to 20 m/s^2, while still being able to avoid obstacles. To the best of our knowledge, this is the first method to demonstrate an MPPI-based approach in real flight.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt6_04">
             11:45-12:00, Paper FrBT6.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('218'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CoDe: A Cooperative and Decentralized Collision Avoidance Algorithm for Small-Scale UAV Swarms Considering Energy Efficiency
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319420" title="Click to go to the Author Index">
             Huang, Shuangyao
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong-Liverpool University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#227762" title="Click to go to the Author Index">
             Zhang, Haibo
            </a>
           </td>
           <td class="r">
            University of Otago
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#325166" title="Click to go to the Author Index">
             Huang, Zhiyi
            </a>
           </td>
           <td class="r">
            University of Otago
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab218" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a cooperative and decentralized collision avoidance algorithm (CoDe) for small-scale UAV swarms consisting of up to three UAVs. CoDe improves energy efficiency of UAVs by achieving effective cooperation among UAVs. Moreover, CoDe is specifically tailored for UAV's operations by addressing the challenges faced by existing schemes, such as ineffectiveness in selecting actions from continuous action spaces and high computational complexity. CoDe is based on Multi-Agent Reinforcement Learning (MARL), and finds cooperative policies by incorporating a novel credit assignment scheme. The novel credit assignment scheme estimates the contribution of an individual by subtracting a baseline from the joint action value for the swarm. The credit assignment scheme in CoDe outperforms other benchmarks as the baseline takes into account not only the importance of a UAV's action but also the interrelation between UAVs. Furthermore, extensive experiments are conducted against existing MARL-based and conventional heuristic-based algorithms to demonstrate the advantages of the proposed algorithm.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frbt7">
             <b>
              FrBT7
             </b>
            </a>
           </td>
           <td class="r">
            Room 7
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frbt7" title="Click to go to the Program at a Glance">
             <b>
              Computer Vision for Medical Robotics
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#160079" title="Click to go to the Author Index">
             Nasseri, M. Ali
            </a>
           </td>
           <td class="r">
            Technische Universitaet Muenchen
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt7_01">
             11:00-11:15, Paper FrBT7.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('744'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DeepBHMR: Learning Bidirectional Hybrid Mixture Models for Generalized Rigid Point Set Registration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#206118" title="Click to go to the Author Index">
             Min, Zhe
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#305117" title="Click to go to the Author Index">
             Zhang, Zhengyan
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#245651" title="Click to go to the Author Index">
             Zhang, Ang
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#225131" title="Click to go to the Author Index">
             Song, Rui
            </a>
           </td>
           <td class="r">
            Shandong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#163802" title="Click to go to the Author Index">
             Li, Yibin
            </a>
           </td>
           <td class="r">
            Shandong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100160" title="Click to go to the Author Index">
             Meng, Max Q.-H.
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab744" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#probability_and_statistical_methods" title="Click to go to the Keyword Index">
               Probability and Statistical Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a novel normal-assisted learning-based rigid registration method, Deep Bi-directional Hybrid Mixture Registration (DeepBHMR), where normal vectors are used in both correspondence and transformation stages, and also the optimization objective is formulated in a Bi-directional way. The designated neural network consists of three components, (1) the correspondence network that estimates the correspondence probability between points within one generalized point set and components of Hybrid Mixture Models (HMMs) representing the other generalized point set; (2) the posterior module that computes the HMMs parameters; (3) the transformation module that computes the rotation matrix and the translation vector is given the estimated generalized-point to hybrid-distribution correspondences and HMMs parameters. Our DeepBHMR has been validated on the medical data set and outperforms the state-of-the-art registration methods. In the circumstance of femur bones, the mean rotation error is around 1Â° (i.e., 1.01Â°) and the mean translation error is less than 1 mm (i.e., 0.36mm), respectively. Even under the large transformation (i.e., global registration), the mean rotation and translation error values being 3.47Â° and 2.08 mm are still satisfactory. The results demonstrate the DeepBHMR's favorable generalizability on the different shapes (e.g., from femur to hip), and that DeepBHMR can successfully handle the large transformation and partial registration respectively.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt7_02">
             11:15-11:30, Paper FrBT7.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('854'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A CT-Guided Control Framework of a Robotic Flexible Endoscope for the Diagnosis of the Maxillary Sinusitis
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391422" title="Click to go to the Author Index">
             Zhu, Puchen
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385089" title="Click to go to the Author Index">
             Zhang, Huayu
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#234095" title="Click to go to the Author Index">
             Ma, Xin
            </a>
           </td>
           <td class="r">
            Chinese Univerisity of HongKong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394401" title="Click to go to the Author Index">
             Zheng, Xiaoyin
            </a>
           </td>
           <td class="r">
            XMotors.ai
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#318144" title="Click to go to the Author Index">
             Wang, Xuchen
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#115274" title="Click to go to the Author Index">
             Au, K. W. Samuel
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab854" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#flexible_robotics" title="Click to go to the Keyword Index">
               Flexible Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#surgical_robotics__planning" title="Click to go to the Keyword Index">
               Surgical Robotics: Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Flexible endoscopes are commonly adopted in narrow and confined anatomical cavities due to their higher reachability and dexterity. However, prolonged and unintuitive manipulation of these endoscopes leads to an increased workload on surgeons and risks of collision. To address these challenges, this paper proposes a CT-guided control framework for the diagnosis of maxillary sinusitis by using a robotic flexible endoscope. In the CT-guided control framework, a feasible path to the target position in the maxillary sinus cavity for the robotic flexible endoscope is designed. Besides, an optimal control scheme is proposed to autonomously control the robotic flexible endoscope to follow the feasible path. This greatly improves the efficiency and reduces the workload for surgeons. Several experiments were conducted based on a widely utilized sinus phantom, and the results showed that the robotic flexible endoscope can accurately and autonomously follow the feasible path and reach the target position in the maxillary sinus cavity. The results also verified the feasibility of the CT-guided control framework, which contributes an effective approach to early diagnosis of sinusitis in the future.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt7_03">
             11:30-11:45, Paper FrBT7.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1017'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Estimating the Joint Angles of a Magnetic Surgical Tool Using Monocular 3D Keypoint Detection and Particle Filtering
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340723" title="Click to go to the Author Index">
             Fredin, Erik
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#117587" title="Click to go to the Author Index">
             Diller, Eric D.
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1017" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Magnetic surgical tools benefit greatly from real-time pose estimation, as this is essential for controlling them safely and effectively. Current pose estimation methods for surgical tools either focus on rigid tools, or are developed specifically for the da Vinci surgical system. In this work, we use computer vision from a monocular endoscopic camera to estimate the pose of an articulated magnetic surgical tool. In particular, we present a deep 3D keypoint estimation framework and a particle filter to achieve this. The former method can be used for any articulated surgical tool, while the latter method is specific to magnetic tools. We show that the deep 3D keypoint estimation framework estimates the surgical tool's joint angles with an average error of 4.0 degrees and a speed of 29 Hz. In addition, we demonstrate the robustness of the magnetic particle filter and the deep pose estimation method for real-time tool pose estimation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt7_04">
             11:45-12:00, Paper FrBT7.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1164'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Intraocular Reflection Modeling and Avoidance Planning in Image-Guided Ophthalmic Surgeries
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310783" title="Click to go to the Author Index">
             Yang, Junjie
            </a>
           </td>
           <td class="r">
            TUM
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#368476" title="Click to go to the Author Index">
             Zhao, Zhihao
            </a>
           </td>
           <td class="r">
            Technische UniversitÃ¤t MÃ¼nchen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395720" title="Click to go to the Author Index">
             Zhao, Yinzheng
            </a>
           </td>
           <td class="r">
            Klinikum Rechts Der Isar
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160087" title="Click to go to the Author Index">
             Zapp, Daniel
            </a>
           </td>
           <td class="r">
            Klinikum Rechts Der Isar Der TU MÃ¼nchen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160084" title="Click to go to the Author Index">
             Maier, Mathias
            </a>
           </td>
           <td class="r">
            Klinikum Rechts Der Isar Der TU MÃ¼nchen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#193739" title="Click to go to the Author Index">
             Huang, Kai
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107647" title="Click to go to the Author Index">
             Navab, Nassir
            </a>
           </td>
           <td class="r">
            TU Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160079" title="Click to go to the Author Index">
             Nasseri, M. Ali
            </a>
           </td>
           <td class="r">
            Technische Universitaet Muenchen
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1164" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#surgical_robotics__planning" title="Click to go to the Keyword Index">
               Surgical Robotics: Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Intuitive enhancement of surgical precision in robotic retinal surgery highly depends on the stable acquisition of intraocular imaging data. Such acquisition requires segmenting intraocular components, especially instrument-tip positions, to achieve state estimation and subsequent navigation and motion control. However, intraocular light reflections and glares significantly impact instrument segmentation, state estimation, and subsequent visual servoing in retinal surgery. At the same time, light reflections are among the sources of information for intraoperative navigation. In this work, we propose a method for modeling and optimizing light reflections using microscopy as the standard surgical imaging modality. Beyond optimization, our approach seamlessly integrates the optimized reflection with path planning, strategically circumventing reflection areas and ensuring uninterrupted visibility of instrument tips throughout the surgical procedure. Experiments demonstrate the efficacy and potential of the presented methodology to avoid glare affections during eye surgeries.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frbt8">
             <b>
              FrBT8
             </b>
            </a>
           </td>
           <td class="r">
            Room 8
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frbt8" title="Click to go to the Program at a Glance">
             <b>
              Autonomous Vehicle Navigation II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#146916" title="Click to go to the Author Index">
             Yang, Ming
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#204568" title="Click to go to the Author Index">
             Qin, Tong
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt8_01">
             11:00-11:15, Paper FrBT8.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('776'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              METAVerse: Meta-Learning Traversability Cost Map for Off-Road Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335667" title="Click to go to the Author Index">
             Seo, Junwon
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#295276" title="Click to go to the Author Index">
             Kim, Taekyung
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#308172" title="Click to go to the Author Index">
             Ahn, Seongyong
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#133576" title="Click to go to the Author Index">
             Kwak, Kiho
            </a>
           </td>
           <td class="r">
            Agency for Defense Development
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab776" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous navigation in off-road conditions requires an accurate estimation of terrain traversability. However, traversability estimation in unstructured environments is subject to high uncertainty due to the variability of numerous factors that influence vehicle-terrain interaction. Consequently, it is challenging to obtain a generalizable model that can accurately predict traversability in a variety of environments. This paper presents METAVerse, a meta-learning framework for learning a global model that accurately and reliably predicts terrain traversability across diverse environments. We train the traversability prediction network to generate a dense and continuous-valued cost map from a sparse LiDAR point cloud, leveraging vehicle-terrain interaction feedback in a self-supervised manner. Meta-learning is utilized to train a global model with driving data collected from multiple environments, effectively minimizing estimation uncertainty. During deployment, online adaptation is performed to rapidly adapt the network to the local environment by exploiting recent interaction experiences. To conduct a comprehensive evaluation, we collect driving data from various terrains and demonstrate that our method can obtain a global model that minimizes uncertainty. Moreover, by integrating our model with a model predictive controller, we demonstrate that the reduced uncertainty results in safe and stable navigation in unstructured and unknown terrains.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt8_02">
             11:15-11:30, Paper FrBT8.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1861'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MapLocNet: Coarse-To-Fine Feature Registration for Visual Re-Localization in Navigation Maps
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379762" title="Click to go to the Author Index">
             Wu, Hang
            </a>
           </td>
           <td class="r">
            Huawei Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397413" title="Click to go to the Author Index">
             Zhang, Zhenghao
            </a>
           </td>
           <td class="r">
            Huawei Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379767" title="Click to go to the Author Index">
             Lin, Siyuan
            </a>
           </td>
           <td class="r">
            Huawei Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339446" title="Click to go to the Author Index">
             Mu, Xiangru
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370115" title="Click to go to the Author Index">
             Zhao, Qiang
            </a>
           </td>
           <td class="r">
            Huawei
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#146916" title="Click to go to the Author Index">
             Yang, Ming
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#204568" title="Click to go to the Author Index">
             Qin, Tong
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1861" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robust localization is the cornerstone of autonomous driving, especially in challenging urban environments where GPS signals suffer from multipath errors. Traditional localization approaches rely on high-definition (HD) maps, which consist of precisely annotated landmarks. However, building HD map is expensive and challenging to scale up. Given these limitations, leveraging navigation maps has emerged as a promising low-cost alternative for localization. Current approaches based on navigation maps can achieve highly accurate localization, but their complex matching strategies lead to unacceptable inference latency that fails to meet the real-time demands. To address these limitations, we introduce MapLocNet, a novel transformer-based neural re-localization method. Inspired by image registration, our approach performs a coarse-to-fine neural feature registration between navigation map features and visual bird's-eye view features. MapLocNet substantially outperforms the current state-of-the-art methods on both nuScenes and Argoverse datasets, demonstrating significant improvements in localization accuracy and inference speed across both single-view and surround-view input settings. We highlight that our research presents an HD-map-free localization method for autonomous driving, offering a cost-effective, reliable, and scalable solution for challenging urban environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt8_03">
             11:30-11:45, Paper FrBT8.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1867'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ParkingE2E: Camera-Based End-To-End Parking Network, from Images to Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#356983" title="Click to go to the Author Index">
             Li, Changze
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397437" title="Click to go to the Author Index">
             Ji, Ziheng
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413330" title="Click to go to the Author Index">
             Chen, Zhe
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#204568" title="Click to go to the Author Index">
             Qin, Tong
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#146916" title="Click to go to the Author Index">
             Yang, Ming
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1867" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous parking is a crucial task in the intelligent driving field. Traditional parking algorithms are usually implemented using rule-based schemes. However, these methods are less effective in complex parking scenarios due to the intricate design of the algorithms. In contrast, neural-network-based methods tend to be more intuitive and versatile than the rule-based methods. By collecting a large number of expert parking trajectory data and emulating human strategy via learning-based methods, the parking task can be effectively addressed. In this paper, we employ imitation learning to perform end-to-end planning from RGB images to path planning by imitating human driving trajectories. The proposed end-to-end approach utilizes a target query encoder to fuse images and target features, and a transformer-based decoder to autoregressive predict future waypoints. We conducted extensive experiments in real-world scenarios, and the results demonstrate that the proposed method achieved an average parking success rate of 87.8% across four different real-world garages. Real-vehicle experiments further validate the feasibility and effectiveness of the method proposed in this paper.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt8_04">
             11:45-12:00, Paper FrBT8.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1941'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              M3-GMN: A Multi-Environment, Multi-LiDAR, Multi-Task Dataset for Grid Map Based Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351141" title="Click to go to the Author Index">
             Xie, Guanglei
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#295719" title="Click to go to the Author Index">
             Fu, Hao
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#295900" title="Click to go to the Author Index">
             Xue, Hanzhang
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#295902" title="Click to go to the Author Index">
             Liu, Bokai
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#131923" title="Click to go to the Author Index">
             Xu, Xin
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#355418" title="Click to go to the Author Index">
             Li, Xiaohui
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142827" title="Click to go to the Author Index">
             Sun, Zhenping
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1941" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we propose a multi-environment, multi-LiDAR, multi-task dataset to promote the grid map-based navigation capability for autonomous vehicles. The dataset comprises structured and unstructured environmental data captured by different types of LiDAR and contains various challenging scenarios, including moving objects, negative obstacles, steep slopes, cliffs, overhangs, etc. Further, we have devised an innovative method for the generation of ground truth, facilitating the creation of dense, accurate, and stable grid map with a minimal requirement for human annotation efforts. A new baseline method and two existing approaches are evaluated on this dataset. Results indicate that existing approaches perform much worse than the proposed baseline. The dataset will be made publicly available at https://github.com/guanglei96/M3-GMN.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frbt9">
             <b>
              FrBT9
             </b>
            </a>
           </td>
           <td class="r">
            Room 9
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frbt9" title="Click to go to the Program at a Glance">
             <b>
              Path Planning for Multiple Robots
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#141359" title="Click to go to the Author Index">
             Indelman, Vadim
            </a>
           </td>
           <td class="r">
            Technion - Israel Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#133879" title="Click to go to the Author Index">
             Bezzo, Nicola
            </a>
           </td>
           <td class="r">
            University of Virginia
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt9_01">
             11:00-11:15, Paper FrBT9.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('405'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Robot Communication-Aware Cooperative Belief Space Planning with Inconsistent Beliefs: An Action-Consistent Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#220508" title="Click to go to the Author Index">
             Kundu, Tanmoy
            </a>
           </td>
           <td class="r">
            Technion - Israel Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391584" title="Click to go to the Author Index">
             Rafaeli, Moshe
            </a>
           </td>
           <td class="r">
            Technion - Israel Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#141359" title="Click to go to the Author Index">
             Indelman, Vadim
            </a>
           </td>
           <td class="r">
            Technion - Israel Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab405" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-robot belief space planning (MR-BSP) is essential for reliable and safe autonomy. While planning, each robot maintains a belief over the state of the environment and reasons how the belief would evolve in the future for different candidate actions. Yet, existing MR-BSP works have a common assumption that the beliefs of different robots are consistent at planning time. Such an assumption is often highly unrealistic, as it requires prohibitively extensive and frequent communication capabilities. In practice, each robot may have a different belief about the state of the environment. Crucially, when the beliefs of different robots are inconsistent, state-of-the-art MR-BSP approaches could result in a lack of coordination between the robots, and in general, could yield dangerous, unsafe and sub-optimal decisions. In this paper, we tackle this crucial gap. We develop a novel decentralized algorithm that is guaranteed to find a consistent joint action. For a given robot, our algorithm reasons for action preferences about 1) its local information, 2) what it perceives about the reasoning of the other robot, and 3) what it perceives about the reasoning of itself perceived by the other robot. This algorithm finds a consistent joint action whenever these steps yield the same best joint action obtained by reasoning about action preferences; otherwise, it self-triggers communication between the robots. Experimental results show efficacy of our algorithm in comparison with two baseline algorithms.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt9_02">
             11:15-11:30, Paper FrBT9.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('475'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robust Online Epistemic Replanning of Multi-Robot Missions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#321794" title="Click to go to the Author Index">
             Bramblett, Lauren
            </a>
           </td>
           <td class="r">
            University of Virginia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#244270" title="Click to go to the Author Index">
             Miloradovic, Branko
            </a>
           </td>
           <td class="r">
            MÃ¤lardalen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392369" title="Click to go to the Author Index">
             Sherman, Patrick
            </a>
           </td>
           <td class="r">
            University of Virginia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#164408" title="Click to go to the Author Index">
             Papadopoulos, Alessandro Vittorio
            </a>
           </td>
           <td class="r">
            MÃ¤lardalen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#133879" title="Click to go to the Author Index">
             Bezzo, Nicola
            </a>
           </td>
           <td class="r">
            University of Virginia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab475" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             As Multi-Robot Systems (MRS) become more affordable and computing capabilities grow, they provide significant advantages for complex applications such as environmental monitoring, underwater inspections, or space exploration. However, accounting for potential communication loss or the unavailability of communication infrastructures in these application domains remains an open problem. Much of the applicable MRS research assumes that the system can sustain communication through proximity regulations and formation control or by devising a framework for separating and adhering to a predetermined plan for extended periods of disconnection. The latter technique enables an MRS to be more efficient, but breakdowns and environmental uncertainties can have a domino effect throughout the system, particularly when the mission goal is intricate or time-sensitive. To deal with this problem, our proposed framework has two main phases: i) a centralized planner to allocate mission tasks by rewarding intermittent rendezvous between robots to mitigate the effects of the unforeseen events during mission execution, and ii) a decentralized replanning scheme leveraging epistemic planning to formalize belief propagation and a Monte Carlo tree search for policy optimization given distributed rational belief updates. The proposed framework outperforms a baseline heuristic and is validated using simulations and experiments with aerial vehicles.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt9_03">
             11:30-11:45, Paper FrBT9.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('768'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Heterogeneous System of Systems Framework for Proactive Path Planning of a UAV-Assisted UGV in Uncertain Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392369" title="Click to go to the Author Index">
             Sherman, Patrick
            </a>
           </td>
           <td class="r">
            University of Virginia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#133879" title="Click to go to the Author Index">
             Bezzo, Nicola
            </a>
           </td>
           <td class="r">
            University of Virginia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab768" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A common challenge for mobile robots is traversing uncertain environments containing obstacles, rough terrain, or hazards. Without full knowledge of the environment, an unmanned ground vehicle (UGV) navigating towards a goal could easily drive down a path that is blocked (requiring the robot to retrace sections of its path) or run into a hazard causing a catastrophic failure. To address this issue we propose a
             <i>
              system of systems
             </i>
             (SoS) abstraction to group a distributed set of robots into a single system. Specifically, we propose augmenting the sensing capabilities of a UGV using an unmanned aerial vehicle (UAV). With different dynamic and sensing capabilities, the UAV scouts ahead and proactively updates the plan for the UGV using information discovered about the environment. To predict reachable states of the UGV, the UAV employs a sampling-based method in which a set of virtual particles representing simulated instances of the UGV are used to approximate the distribution of possible trajectories. The UAV assesses if the current UGV path plan is inefficient or unsafe, and if so, provides an alternative path to the UGV. For robustness, a model predictive path integral (MPPI) optimization method is used to modify the waypoints when delivered to the UGV. The strategy is validated in simulation and experimentally.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt9_04">
             11:45-12:00, Paper FrBT9.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3202'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              IR2: Implicit Rendezvous for Robotic Exploration Teams under Sparse Intermittent Connectivity
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398950" title="Click to go to the Author Index">
             Tan, Derek Ming Siang
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398994" title="Click to go to the Author Index">
             Ma, Yixiao
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398991" title="Click to go to the Author Index">
             Liang, Jingsong
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399001" title="Click to go to the Author Index">
             Chng, Yi Cheng
            </a>
           </td>
           <td class="r">
            Singapore Technologies Engineering Land Systems
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#305152" title="Click to go to the Author Index">
             Cao, Yuhong
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#180884" title="Click to go to the Author Index">
             Sartoretti, Guillaume Adrien
            </a>
           </td>
           <td class="r">
            National University of Singapore (NUS)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3202" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Information sharing is critical in time-sensitive and realistic multi-robot exploration, especially for smaller robotic teams in large-scale environments where connectivity may be sparse and intermittent. Existing methods often overlook such communication constraints by assuming unrealistic global connectivity. Other works account for communication constraints (by maintaining close proximity or line of sight during information exchange), but are often inefficient. For instance, preplanned rendezvous approaches typically involve unnecessary detours resulting from poorly timed rendezvous, while pursuit-based approaches often result in short-sighted decisions due to their greedy nature. We present IR2, a deep reinforcement learning approach to information sharing for multi-robot exploration. Leveraging attention-based neural networks trained via reinforcement and curriculum learning, IR2 allows robots to effectively reason about the longer-term trade-offs between disconnecting for solo exploration and reconnecting for information sharing. In addition, we propose a hierarchical graph formulation to maintain a sparse yet informative graph, enabling our approach to scale to large-scale environments. We present simulation results in three large-scale Gazebo environments, which show that our approach yields 6.6 - 34.1% shorter exploration paths and significantly improved mapped area consistency among robots when compared to state-of-the-art baselines. Our simulation training and testing code is available at https://github.com/marmotlab/IR2.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frbt10">
             <b>
              FrBT10
             </b>
            </a>
           </td>
           <td class="r">
            Room 10
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frbt10" title="Click to go to the Program at a Glance">
             <b>
              Computer Vision for Transportation II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#160427" title="Click to go to the Author Index">
             Valada, Abhinav
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt10_01">
             11:00-11:15, Paper FrBT10.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('697'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              PCT: Perspective Cue Training Framework for Multi-Camera BEV Segmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#248671" title="Click to go to the Author Index">
             Ishikawa, Haruya
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393052" title="Click to go to the Author Index">
             Iida, Takumi
            </a>
           </td>
           <td class="r">
            SenseTime Japan
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#149558" title="Click to go to the Author Index">
             Konishi, Yoshinori
            </a>
           </td>
           <td class="r">
            SenseTime Japan Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#168088" title="Click to go to the Author Index">
             Aoki, Yoshimitsu
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab697" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Generating annotations for bird's-eye-view (BEV) segmentation presents significant challenges due to the scenes' complexity and the high manual annotation cost. In this work, we address these challenges by leveraging the abundance of unlabeled data available. We propose the Perspective Cue Training (PCT) framework, a novel training framework that utilizes pseudo-labels generated from unlabeled perspective images using publicly available semantic segmentation models trained on large street-view datasets. PCT applies a perspective view task head to the image encoder shared with the BEV segmentation head, effectively utilizing the unlabeled data to be trained with the generated pseudo-labels. Since image encoders are present in nearly all camera-based BEV segmentation architectures, PCT is flexible and applicable to various existing BEV architectures. In this paper, we applied PCT for semi-supervised learning (SSL) and unsupervised domain adaptation (UDA). Additionally, we introduce strong input perturbation through Camera Dropout (CamDrop) and feature perturbation via BEV Feature Dropout (BFD), which are crucial for enhancing SSL capabilities using our teacher-student framework. Our comprehensive approach is simple and flexible but yields significant improvements over various baselines for SSL and UDA, achieving competitive performances even against the current state-of-the-art.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt10_02">
             11:15-11:30, Paper FrBT10.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1485'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Point-Based Approach to Efficient LiDAR Multi-Task Perception
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335435" title="Click to go to the Author Index">
             Lang, Christopher
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354309" title="Click to go to the Author Index">
             Braun, Alexander
            </a>
           </td>
           <td class="r">
            Robert Bosch GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123137" title="Click to go to the Author Index">
             Schillingmann, Lars
            </a>
           </td>
           <td class="r">
            Robert Bosch GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160427" title="Click to go to the Author Index">
             Valada, Abhinav
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1485" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-task networks can potentially improve performance and computational efficiency compared to single-task networks, facilitating online deployment. However, current multi-task architectures in point cloud perception combine multiple task-specific point cloud representations, each requiring a separate feature encoder and making the network structures bulky and slow. We propose PAttFormer, an efficient multi-task architecture for joint semantic segmentation and object detection in point clouds that only relies on a point-based representation. The network builds on transformer-based feature encoders using neighborhood attention and grid-pooling and a query-based detection decoder using a novel 3D deformable-attention detection head design. Unlike other LiDAR-based multi-task architectures, our proposed PAttFormer does not require separate feature encoders for multiple task-specific point cloud representations, resulting in a network that is 3x smaller and 1.4x faster while achieving competitive performance on the nuScenes and KITTI benchmarks for autonomous driving perception. Our extensive evaluations show substantial gains from multi-task learning, improving LiDAR semantic segmentation by +1.7% in mIou and 3D object detection by +1.7% in mAP on the nuScenes benchmark compared to the single-task models.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt10_03">
             11:30-11:45, Paper FrBT10.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2028'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Depth Completion Using Galerkin Attention
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397728" title="Click to go to the Author Index">
             Xu, Yinuo
            </a>
           </td>
           <td class="r">
            Beijing University of Posts and Telecommunications
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393131" title="Click to go to the Author Index">
             Zhang, Xuesong
            </a>
           </td>
           <td class="r">
            Beijing University of Posts and Telecommunications
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2028" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Current depth completion methods usually employ a pair of calibrated RGB and depth sensors to reconstruct a dense depth map. Although RGB (dense) and depth (sparse) measurements are collected from the same underlying scene, they reflect different physical characteristics and thus it remains rather intricate how the devised RGB guidance scheme can effectively leads to a faithful depth recovery. Different from existing 3D geometry representations, such as point cloud, voxels or meshes, we propose to define 3D scenes as vector-valued functions, mapping from the image plane to RGBD vectors. This scene function representation brings two benefits: 1) allowing for the adaptation of the Galerkin method to explore the nodal basis of the scene function space, and 2) transforming the irregularly scattered (X,Y,Z) points in the Euclidean space into the depth function defined over the regular grid in the image plane. We further leverage these two benefits within a deep neural network, characterized by an efficient Galerkin attention-based RGBD function embedding to effectively explore the interaction of color and depth information, and by the utilization of equivariant convolution operation on the RGBD feature map as efficient basic blocks. Experiments show that the proposed method achieves significant performance improvement over state-of-the-arts. Code at https://github.com/ZXS-Labs/DCGA.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt10_04">
             11:45-12:00, Paper FrBT10.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1413'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              BEV^2PR: BEV-Enhanced Visual Place Recognition with Structural Cues
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390793" title="Click to go to the Author Index">
             Ge, Fudong
            </a>
           </td>
           <td class="r">
            Institute of Automationï¼ŒChinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395534" title="Click to go to the Author Index">
             Zhang, Yiwei
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#141238" title="Click to go to the Author Index">
             Shen, Shuhan
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#213931" title="Click to go to the Author Index">
             Hu, Weiming
            </a>
           </td>
           <td class="r">
            University of Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#156231" title="Click to go to the Author Index">
             Wang, Yue
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#305106" title="Click to go to the Author Index">
             Gao, Jin
            </a>
           </td>
           <td class="r">
            Institute of Automation Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1413" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we propose a new image-based visual place recognition (VPR) framework by exploiting the structural cues in birdâ€™s-eye view (BEV) from a single monocular camera. The motivation arises from two key observations about place recognition methods based on both appearance and structure: 1) For the methods relying on LiDAR sensors, the integration of LiDAR in robotic systems has led to increased expenses, while the alignment of data between different sensors is also a major challenge. 2) Other image-/camera-based methods, involving integrating RGB images and their derived variants (e.g., pseudo depth images, pseudo 3D point clouds), exhibit several limitations, such as the failure to effectively exploit the explicit spatial relationships between different objects. To tackle the above issues, we design a new BEV-enhanced VPR framework, namely BEV^2PR, generating a composite descriptor with both visual cues and spatial awareness based on a single camera. The key points lie in: 1) We use BEV features as an explicit source of structural knowledge in constructing global features. 2) The lower layers of the pre-trained backbone from BEV generation are shared for visual and structural streams in VPR, facilitating the learning of fine-grained local features in the visual stream. 3) The complementary visual and structural features can jointly enhance VPR performance. Our BEV^2PR framework enables consistent performance improvements over several popular aggregation modules for RGB global features. The experiments on our collected VPR-NuScenes dataset demonstrate an absolute gain of 2.47% on Recall@1 for the strong Conv-AP baseline to achieve the best performance in our setting, and notably, a 18.06% gain on the hard set. The code and dataset will be available at https://github.com/FudongGe/BEV2PR.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frbt11">
             <b>
              FrBT11
             </b>
            </a>
           </td>
           <td class="r">
            Room 11
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frbt11" title="Click to go to the Program at a Glance">
             <b>
              Legged Robots II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#134222" title="Click to go to the Author Index">
             Zimmermann, Karel
            </a>
           </td>
           <td class="r">
            Ceske Vysoke Uceni Technicke V Praze, FEL
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt11_01">
             11:00-11:15, Paper FrBT11.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1956'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Accurate Power Consumption Estimation Method Makes Walking Robots Energy Efficient and Quiet
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238450" title="Click to go to the Author Index">
             Valsecchi, Giorgio
            </a>
           </td>
           <td class="r">
            Robotic System Lab, ETH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#342514" title="Click to go to the Author Index">
             Vicari, Andrea
            </a>
           </td>
           <td class="r">
            Scuola Superiore Sant'Anna
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#287944" title="Click to go to the Author Index">
             Tischhauser, Fabian
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142717" title="Click to go to the Author Index">
             Garabini, Manolo
            </a>
           </td>
           <td class="r">
            UniversitÃ  Di Pisa
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114045" title="Click to go to the Author Index">
             Hutter, Marco
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1956" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Power consumption is a frequently overlooked aspect in robotics, especially in the context of legged robots. Nevertheless, improving the efficiency of walking robots is crucial to overcome the current limitations in runtime. This work proposes a novel method for precisely estimating actuator power consumption based on LSTM neural networks. The performance of this approach is benchmarked against currently employed models and validated on real hardware using certified instruments. The proposed method is integrated into the Isaac Gym framework and utilized to train a power-efficient policy. Instead of optimizing for handcrafted cost functions, such as the often used torque-square minimization, our approach for the first time trains RL policies that minimize the effective energy consumption. Hardware results demonstrate a reduction of approximately 25% in the robot's total power consumption, with a notable 50% decrease observed for the knee actuator. Additionally, the newly developed policy generates significantly smoother and quieter motions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt11_02">
             11:15-11:30, Paper FrBT11.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2404'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Co-RaL: Complementary Radar-Leg Odometry with 4-DoF Optimization and Rolling Contact
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#311328" title="Click to go to the Author Index">
             Jung, Sangwoo
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#342598" title="Click to go to the Author Index">
             Yang, Wooseong
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#126962" title="Click to go to the Author Index">
             Kim, Ayoung
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2404" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robust and accurate localization in challenging environments is becoming crucial for SLAM. In this paper, we propose a unique sensor configuration for precise and robust odometry by integrating chip radar and a legged robot. Specifically, we introduce a tightly coupled radar-leg odometry algorithm for complementary drift correction. Adopting the 4-DoF optimization and decoupled RANSAC to mmWave chip radar significantly enhances radar odometry beyond the existing method, especially z-directional even when using a single radar. For the leg odometry, we employ rolling contact modeling-aided forward kinematics, accommodating scenarios with the potential possibility of contact drift and radar failure. We evaluate our method by comparing it with other chip radar odometry algorithms using real-world datasets with diverse environments while the datasets will be released for the robotics community. https://github.com/SangwooJung98/Co-RaL-Dataset
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt11_03">
             11:30-11:45, Paper FrBT11.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('337'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Experience-Learning Inspired Two-Step Reward Method for Efficient Legged Locomotion Learning towards Natural and Robust Gaits
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#318356" title="Click to go to the Author Index">
             Li, Yinghui
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310639" title="Click to go to the Author Index">
             Wu, Jinze
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392072" title="Click to go to the Author Index">
             Liu, Xin
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#125870" title="Click to go to the Author Index">
             Guo, Weizhong
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351724" title="Click to go to the Author Index">
             Xue, Yufei
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab337" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#bioinspired_robot_learning" title="Click to go to the Keyword Index">
               Bioinspired Robot Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Legged robots excel in navigating complex terrains, yet learning natural and robust motions in such environments remains challenging. Inspired by animalsâ€™ experience-based stepwise learning process, we propose a two-stage framework for legged robots to progressively learn naturally robust movements using a two-step reward method. Initially robots learn the fundamental gaits on flat terrains with gait-rewards and generating valuable motion data. Subsequently, leveraging learned motion experience, they adopt adversarial imitation learning to tackle challenging terrains with refined movements.Our method addresses the challenge of acquiring effective imitation data and facilitates the learning process under various gait parameters with ease. The effectiveness of this approach has been validated on both quadruped and hexapod robots, demonstrating naturally robust gaits in real-world applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt11_04">
             11:45-12:00, Paper FrBT11.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2770'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CaT: Constraints As Terminations for Legged Locomotion Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#327929" title="Click to go to the Author Index">
             Chane-Sane, Elliot
            </a>
           </td>
           <td class="r">
            LAAS, CNRS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256935" title="Click to go to the Author Index">
             Leziart, Pierre-Alexandre
            </a>
           </td>
           <td class="r">
            Laboratory for Analysis and Architecture of Systems (LAAS-CNRS),
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#199258" title="Click to go to the Author Index">
             Flayols, Thomas
            </a>
           </td>
           <td class="r">
            LAAS, CNRS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103148" title="Click to go to the Author Index">
             Stasse, Olivier
            </a>
           </td>
           <td class="r">
            LAAS, CNRS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107187" title="Click to go to the Author Index">
             Soueres, Philippe
            </a>
           </td>
           <td class="r">
            LAAS-CNRS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103132" title="Click to go to the Author Index">
             Mansard, Nicolas
            </a>
           </td>
           <td class="r">
            CNRS
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2770" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Deep Reinforcement Learning (RL) has demonstrated impressive results in solving complex robotic tasks such as quadruped locomotion. Yet, current solvers fail to produce efficient policies respecting hard constraints. In this work, we advocate for integrating constraints into robot learning and present Constraints as Terminations (CaT), a novel constrained RL algorithm. Departing from classical constrained RL formulations, we reformulate constraints through stochastic terminations during policy learning: any violation of a constraint triggers a probability of terminating potential future rewards the RL agent could attain. We propose an algorithmic approach to this formulation, by minimally modifying widely used off-the-shelf RL algorithms in robot learning (such as Proximal Policy Optimization). Our approach leads to excellent constraint adherence without introducing undue complexity and computational overhead, thus mitigating barriers to broader adoption. Through empirical evaluation on the real quadruped robot Solo crossing challenging obstacles, we demonstrate that CaT provides a compelling solution for incorporating constraints into RL frameworks. Videos and code are available at https://constraints-as-terminations.github.io.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frbt12">
             <b>
              FrBT12
             </b>
            </a>
           </td>
           <td class="r">
            Room 12
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frbt12" title="Click to go to the Program at a Glance">
             <b>
              Semantic Scene Understanding III
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#189409" title="Click to go to the Author Index">
             Beltrame, Giovanni
            </a>
           </td>
           <td class="r">
            Ecole Polytechnique De Montreal
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt12_01">
             11:00-11:15, Paper FrBT12.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2617'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              QueSTMaps: Queryable Semantic Topological Maps for 3D Scene Understanding
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#358171" title="Click to go to the Author Index">
             Mehan, Yash
            </a>
           </td>
           <td class="r">
            International Institute of Information Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397888" title="Click to go to the Author Index">
             Gupta, Kumaraditya
            </a>
           </td>
           <td class="r">
            IIIT Hyderabad
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397892" title="Click to go to the Author Index">
             Jayanti, Rohit
            </a>
           </td>
           <td class="r">
            Robotics Research Center, IIIT Hyderabad
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397993" title="Click to go to the Author Index">
             Govil, Anirudh
            </a>
           </td>
           <td class="r">
            Robotics Research Center, International Institute of Information
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196783" title="Click to go to the Author Index">
             Garg, Sourav
            </a>
           </td>
           <td class="r">
            University of Adelaide
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102906" title="Click to go to the Author Index">
             Krishna, Madhava
            </a>
           </td>
           <td class="r">
            IIIT Hyderabad
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2617" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic tasks such as planning and navigation require a hierarchical semantic understanding of a scene, which could include multiple floors and rooms. Current methods primarily focus on object segmentation for 3D scene understanding. However, such methods struggle to segment out topological regions like ``kitchen'' in the scene. In this work, we introduce a two-step pipeline to solve this problem. First, we extract a topological map, i.e., floorplan of the indoor scene using a novel multi-channel occupancy representation. Then, we generate CLIP-aligned features and semantic labels for every room instance based on the objects it contains using a self-attention transformer. Our language-topology alignment supports natural language querying, e.g., a ``place to cook'' locates the ``kitchen''. We outperform the current state-of-the-art on room segmentation by ~20% and room classification by~12%. Our detailed qualitative analysis and ablation studies provide insights into the problem of joint structural and semantic 3D scene understanding. Project Page: https://quest-maps.github.io
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt12_02">
             11:15-11:30, Paper FrBT12.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2736'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Commonsense Scene Graph-Based Target Localization for Object Search
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#346402" title="Click to go to the Author Index">
             Ge, Wenqi
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#257410" title="Click to go to the Author Index">
             Tang, Chao
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100155" title="Click to go to the Author Index">
             Zhang, Hong
            </a>
           </td>
           <td class="r">
            SUSTech
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2736" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Object search is a fundamental skill for household robots, yet the core problem lies in the robot's ability to locate the target object accurately. The dynamic nature of household environments, characterized by the arbitrary placement of daily objects by users, makes it challenging to perform target localization. To efficiently locate the target object, the robot needs to be equipped with knowledge at both the object and room level. However, existing approaches rely solely on one type of knowledge, leading to unsatisfactory object localization performance and,consequently, inefficient object search processes. To address this problem, we propose a commonsense scene graph-based target localization, CSG-TL, to enhance target object search in the household environment. Given the pre-built map with stationery items, the robot models the room-level knowledge by a scene graph and incorporates object-level commonsense knowledge generated by a large language model (LLM). To demonstrate the superiority of CSG-TL on object localization, extensive experiments are performed on the real-world ScanNet dataset and the AI2Thor simulator. Moreover, we have extended CSG-TL to an object search framework, CSG-OS, validated in both simulated and real-world environments. Code and videos are available at https://sites.google.com/view/csg-os.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt12_03">
             11:30-11:45, Paper FrBT12.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2952'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Language-Embedded Gaussian Splats (LEGS): Incrementally Building Room-Scale Representations with a Mobile Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#373306" title="Click to go to the Author Index">
             Yu, Justin
            </a>
           </td>
           <td class="r">
            University of California Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#373780" title="Click to go to the Author Index">
             Hari, Kush
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#328822" title="Click to go to the Author Index">
             Srinivas, Kishore
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398515" title="Click to go to the Author Index">
             El-Refai, Karim
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376766" title="Click to go to the Author Index">
             Rashid, Adam
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#312047" title="Click to go to the Author Index">
             Kim, Chung Min
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#234135" title="Click to go to the Author Index">
             Kerr, Justin
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#182088" title="Click to go to the Author Index">
             Cheng, Richard
            </a>
           </td>
           <td class="r">
            California Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237975" title="Click to go to the Author Index">
             Irshad, Muhammad Zubair
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238319" title="Click to go to the Author Index">
             Balakrishna, Ashwin
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107892" title="Click to go to the Author Index">
             Kollar, Thomas
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107102" title="Click to go to the Author Index">
             Goldberg, Ken
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2952" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#inventory_management" title="Click to go to the Keyword Index">
               Inventory Management
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Building semantic 3D maps is valuable for searching for objects of interest in offices, warehouses, stores, and homes. We present a mapping system that incrementally builds a Language-Embedded Gaussian Splat (LEGS): a detailed 3D scene representation that encodes both appearance and semantics in a unified representation. LEGS is trained online as a robot traverses its environment to enable localization of open-vocabulary object queries. We evaluate LEGS on 4 room-scale scenes where we query for objects in the scene to assess how LEGS can capture semantic meaning. We compare LEGS to LERF [1] and find that while both systems have comparable object query success rates, LEGS trains over 3.5x faster than LERF. Results suggest that a multi-camera setup and incremental bundle adjustment can boost visual reconstruction quality in constrained robot trajectories, and suggest LEGS can localize open-vocabulary and long-tail object queries with up to 66% accuracy. See project website at: berkeleyautomation.github.io/LEGS
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt12_04">
             11:45-12:00, Paper FrBT12.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3186'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SSCBench: A Large-Scale 3D Semantic Scene Completion Benchmark for Autonomous Driving
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#245328" title="Click to go to the Author Index">
             Li, Yiming
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#313837" title="Click to go to the Author Index">
             Li, Sihang
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#333297" title="Click to go to the Author Index">
             Liu, Xinhao
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#381035" title="Click to go to the Author Index">
             Gong, Moonjun
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398652" title="Click to go to the Author Index">
             Li, Kenan
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398223" title="Click to go to the Author Index">
             Nuo, Chen
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398874" title="Click to go to the Author Index">
             Wang, Zijun
            </a>
           </td>
           <td class="r">
            AI4CE
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397845" title="Click to go to the Author Index">
             Li, Zhiheng
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397871" title="Click to go to the Author Index">
             Jiang, Tao
            </a>
           </td>
           <td class="r">
            Tsinghua
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#220438" title="Click to go to the Author Index">
             Yu, Fisher
            </a>
           </td>
           <td class="r">
            ETH ZÃ¼rich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#315576" title="Click to go to the Author Index">
             Wang, Yue
            </a>
           </td>
           <td class="r">
            USC
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#207381" title="Click to go to the Author Index">
             Zhao, Hang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237832" title="Click to go to the Author Index">
             Yu, Zhiding
            </a>
           </td>
           <td class="r">
            NVIDIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160443" title="Click to go to the Author Index">
             Feng, Chen
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3186" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Monocular scene understanding is a foundational component of autonomous systems. Within the spectrum of monocular perception topics, one crucial and useful task for holistic 3D scene understanding is semantic scene completion (SSC), which jointly completes semantic information and geometric details from RGB input. However, progress in SSC, particularly in large-scale street views, is hindered by the scarcity of high-quality datasets. To address this issue, we introduce SSCBench, a comprehensive benchmark that integrates scenes from widely used automotive datasets (e.g., KITTI-360, nuScenes, and Waymo). SSCBench follows an established setup and format in the community, facilitating the easy exploration of SSC methods in various street views. We benchmark models using monocular, trinocular, and point cloud input to assess the performance gap resulting from sensor coverage and modality. Moreover, we have unified semantic labels across diverse datasets to simplify cross-domain generalization testing. We commit to including more datasets and SSC models to drive further advancements in this field. Our data and code are available at https://github.com/ai4ce/SSCBench.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frbt13">
             <b>
              FrBT13
             </b>
            </a>
           </td>
           <td class="r">
            Room 13
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frbt13" title="Click to go to the Program at a Glance">
             <b>
              Computer Vision for Automation IV
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#193502" title="Click to go to the Author Index">
             Popovic, Marija
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt13_01">
             11:00-11:15, Paper FrBT13.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2688'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Exploiting Priors from 3D Diffusion Models for RGB-Based One-Shot View Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#295112" title="Click to go to the Author Index">
             Pan, Sicong
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#301555" title="Click to go to the Author Index">
             Jin, Liren
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398518" title="Click to go to the Author Index">
             Huang, Xuying
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101642" title="Click to go to the Author Index">
             Stachniss, Cyrill
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#193502" title="Click to go to the Author Index">
             Popovic, Marija
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113220" title="Click to go to the Author Index">
             Bennewitz, Maren
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2688" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Object reconstruction is relevant for many autonomous robotic tasks that require interaction with the environment. A key challenge in such scenarios is planning view configurations to collect informative measurements for reconstructing an initially unknown object. One-shot view planning enables efficient data collection by predicting view configurations and planning the globally shortest path connecting all views at once. However, prior knowledge about the object is required to conduct one-shot view planning. In this work, we propose a novel one-shot view planning approach that utilizes the powerful 3D generation capabilities of diffusion models as priors. By incorporating such geometric priors into our pipeline, we achieve effective one-shot view planning starting with only a single RGB image of the object to be reconstructed. Our planning experiments in simulation and real-world setups indicate that our approach balances well between object reconstruction quality and movement cost.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt13_02">
             11:15-11:30, Paper FrBT13.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2699'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Shape-Prior Free Space-Time Neural Radiance Field for 4D Semantic Reconstruction of Dynamic Scene from Sparse-View RGB Videos
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#355739" title="Click to go to the Author Index">
             Biswas, Sandika
            </a>
           </td>
           <td class="r">
            IIT Bombay
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#356300" title="Click to go to the Author Index">
             Banerjee, Biplab
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology, Bombay
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#212097" title="Click to go to the Author Index">
             Rezatofighi, Hamid
            </a>
           </td>
           <td class="r">
            Monash University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2699" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Many applications in Augmented/Virtual Reality or robotics require precise geometry modeling of individual elements in a dynamic scene under a sparse-view camera setup, without any prior information about their semantic labels or shapes. In our research, we introduce a 3D shape prior-free Neural Radiance Field-based technique for detailed geometry reconstruction under human-object interactions, offering an explicit surface reconstruction with semantic labels for reconstructed geometry. Our approach harnesses the capabilities of an Invertible Neural Network to learn a deformation function that effectively connects local (current-frame input) and canonical spaces for each of the components under motion. The deformation process is guided by temporal constraints from multi-frame, facilitating the precise reconstruction of the complex interactions between humans and objects. Our experimental evaluations highlight the effectiveness of our framework, demonstrating its ability to accurately represent both the comprehensive object-compositional scene and individual components over state-of-the-art methods, under complex interactions between the scene entities. This research is deemed to mark a significant stride in semantic 3D geometry modeling within dynamic interactive environments, relying solely on sparse multi-view RGB data.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt13_03">
             11:30-11:45, Paper FrBT13.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2942'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hybrid Stereo Dense Depth Estimation for Robotics Tasks in Industrial Automation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397893" title="Click to go to the Author Index">
             Singh, Suhani
            </a>
           </td>
           <td class="r">
            Roboception GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100254" title="Click to go to the Author Index">
             Suppa, Michael
            </a>
           </td>
           <td class="r">
            Roboception GmbH and University of Bremen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104168" title="Click to go to the Author Index">
             Suarez, Raul
            </a>
           </td>
           <td class="r">
            Universitat Politecnica De Catalunya (UPC)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104063" title="Click to go to the Author Index">
             Rosell, Jan
            </a>
           </td>
           <td class="r">
            Universitat PolitÃ¨cnica De Catalunya (UPC)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2942" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce a simple yet effective approach for dense depth reconstruction that operates directly on raw disparity data, eliminating the need for additional disparity refinement stages. By leveraging disparity maps generated from conventional stereo methods, we train a U-Net-based model to directly map disparity to depth, bypassing complex feature engineering. Our method capitalizes on the robustness of traditional stereo matching techniques to varying scenes, focusing exclusively on dense depth reconstruction. This approach not only simplifies the training process but also significantly reduces the requirement for large-scale training datasets. Extensive evaluations demonstrate that our method surpasses classical stereo matching frameworks and state-of-the-art classical post-refinement techniques, achieving superior accuracy. Additionally, our approach offers competitive inference times, comparable to classical as well as end-to-end deep learning methods, making it highly suitable for real-time robotic applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frbt13_04">
             11:45-12:00, Paper FrBT13.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3485'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Recovering Missed Detections in an Elevator Button Segmentation Task
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#355306" title="Click to go to the Author Index">
             Verzic, Nicholas
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#355309" title="Click to go to the Author Index">
             Chadaga, Abhinav
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#186300" title="Click to go to the Author Index">
             Hart, Justin
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3485" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             One obstacle that mobile service robots face is operating elevators. Reading elevator control panel buttons involves both an instance segmentation of buttons and labels and associating buttons with their respective metal labels in the elevator. Segmentation algorithms, however, can miss detections. This paper presents a segmentation model specifically designed to solve the problem of missed detections. This can be used to recover detections that the initial model misses. This work presents: 1) a new elevator button dataset containing both 108 images sampled from the internet and 292 images imaged from 24 buildings from the University of Texas at Austin campus and the surrounding neighborhood, along with their segmentation boundaries and associated labels; 2) a vision pipeline based on Mask-RCNN for solving the initial image segmentation and labeling task; and 3) a novel method for identifying missed detections, using a Mask-RCNN network trained on expected button locations. Results show that the missed detections model, specifically developed to recover buttons and labels that were missed by the initial pass, is accurate on up to 99.33% of its predicted missed features on a synthetic missed-detection dataset and 97.14% of its predictions for features missed on a non-synthetic dataset. In the case of the average accuracy of successful button and label detections of a specifically-trained "weak" initial detector at a standard IoU threshold of 0.5, the missed detection model improves the detector's success rate from 78.57% on the button recognition task with the initial segmentation model only to an average accuracy of 87.08% with the missed detections model enabled. The overall accuracy of the best-performing pipeline implementing the missed detections model is 91.73% and 98.27% on our Internet subset and Campus subset of our dataset, respectively.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="fri6n">
             <b>
              FrI6N
             </b>
            </a>
           </td>
           <td class="r">
            Poster Area
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#fri6n" title="Click to go to the Program at a Glance">
             <b>
              Interactive Session 6
             </b>
            </a>
           </td>
           <td class="r">
            Interactive Poster session
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frf10o">
             <b>
              FrF10O
             </b>
            </a>
           </td>
           <td class="r">
            Auditorium
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frf10o" title="Click to go to the Program at a Glance">
             <b>
              Forum 10 - Marine Robotics in the Ocean Decade Initiative for Sustainable
              <br/>
              Development
             </b>
            </a>
           </td>
           <td class="r">
            Forum
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#284827" title="Click to go to the Author Index">
             De Masi, Giulia
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frf10o_01">
             09:00-12:00, Paper FrF10O.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Marine Robotics in the Ocean Decade Initiative for Sustainable Development
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#284827" title="Click to go to the Author Index">
             De Masi, Giulia
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#150250" title="Click to go to the Author Index">
             Renda, Federico
            </a>
           </td>
           <td class="r">
            Khalifa University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103339" title="Click to go to the Author Index">
             Ferri, Gabriele
            </a>
           </td>
           <td class="r">
            NATO Centre for Maritime Research and Experimentation
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frf11o">
             <b>
              FrF11O
             </b>
            </a>
           </td>
           <td class="r">
            Room 17/18
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frf11o" title="Click to go to the Program at a Glance">
             <b>
              Forum 11 - the Future of Work: AI-Enhanced Robotics and Human Interaction
              <br/>
              Research in M3S
             </b>
            </a>
           </td>
           <td class="r">
            Forum
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#128607" title="Click to go to the Author Index">
             Prakash, Alok
            </a>
           </td>
           <td class="r">
            Singapore-MIT Alliance for Research and Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frf11o_">
             , Paper FrF11O.
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             The Future of Work: AI-Enhanced Robotics and Human Interaction Research in M3S
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#128607" title="Click to go to the Author Index">
             Prakash, Alok
            </a>
           </td>
           <td class="r">
            Singapore-MIT Alliance for Research and Technology
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frp4l">
             <b>
              FrP4L
             </b>
            </a>
           </td>
           <td class="r">
            Auditorium
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frp4l" title="Click to go to the Program at a Glance">
             <b>
              Plenary 4: From Coordination to Collaboration in Multi-Robot Systems:
              <br/>
              Lessons from Ecology, by Magnus Egerstedt
             </b>
            </a>
           </td>
           <td class="r">
            Plenary session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#106618" title="Click to go to the Author Index">
             Tzes, Anthony
            </a>
           </td>
           <td class="r">
            New York University Abu Dhabi
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frp4l_01">
             12:00-13:00, Paper FrP4L.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             From Coordination to Collaboration in Multi-Robot Systems: Lessons from Ecology
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#181401" title="Click to go to the Author Index">
             Egerstedt, Magnus
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frlu_br">
             <b>
              FrLU_BR
             </b>
            </a>
           </td>
           <td class="r">
            Poster Area
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frlu_br" title="Click to go to the Program at a Glance">
             <b>
              Lunch (Fri)
             </b>
            </a>
           </td>
           <td class="r">
            Session
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frk4n">
             <b>
              FrK4N
             </b>
            </a>
           </td>
           <td class="r">
            Auditorium
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frk4n" title="Click to go to the Program at a Glance">
             <b>
              Keynote Session 4 - Robotic Competitions
             </b>
            </a>
           </td>
           <td class="r">
            Keynote session
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frk4n_01">
             14:00-15:30, Paper FrK4N.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Robot Competitions in Europe: European Robotics League and EuROBIN Coopetitions
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#307731" title="Click to go to the Author Index">
             Lima, Pedro U.
            </a>
           </td>
           <td class="r">
            Instituto Superior Tecnico
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frk4n_02">
             14:00-15:30, Paper FrK4N.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             -
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#158377" title="Click to go to the Author Index">
             Visser, Ubbo
            </a>
           </td>
           <td class="r">
            University of Miami
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frk4n_03">
             14:00-15:30, Paper FrK4N.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             -
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106700" title="Click to go to the Author Index">
             Chung, Timothy H.
            </a>
           </td>
           <td class="r">
            DARPA
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frk4n_04">
             14:00-15:30, Paper FrK4N.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Grand Challenges As a Mechanism to Hasten Translation from Lab to Market
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#370007" title="Click to go to the Author Index">
             McCarthy, Thomas Gerard
            </a>
           </td>
           <td class="r">
            ASPIRE UAE
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frpi7t1">
             <b>
              FrPI7T1
             </b>
            </a>
           </td>
           <td class="r">
            Room 1
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frpi7t1" title="Click to go to the Program at a Glance">
             <b>
              Aerial and Marine Robots and Multi-Robot Systems
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#147435" title="Click to go to the Author Index">
             Ferrante, Eliseo
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Amsterdam
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#273643" title="Click to go to the Author Index">
             Lee, Kyuman
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t1_01">
             15:30-16:30, Paper FrPI7T1.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3817'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multirotor UAV with Tilting Frame and Bidirectional Thrusters
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#217468" title="Click to go to the Author Index">
             Paul, Hannibal
            </a>
           </td>
           <td class="r">
            Ritsumeikan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#306654" title="Click to go to the Author Index">
             Rosales Martinez, Ricardo
            </a>
           </td>
           <td class="r">
            Ritsumeikan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#161409" title="Click to go to the Author Index">
             Shimonomura, Kazuhiro
            </a>
           </td>
           <td class="r">
            Ritsumeikan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3817" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Aerial manipulation systems coupled with UAVs have emerged as indispensable tools for navigating challenging environments, particularly in the inspection of aging infrastructure such as bridges and tunnels. Traditional inspection UAVs, however, are limited by the reach angle of their manipulators, confined to the aircraft's attachment point. In this paper, we present a novel system design that enables a manipulator to reach in all directions around the UAV. Our innovative approach features a tiltable airframe design for the manipulator body, complemented by auxiliary actuators to maintain rotor axis alignment with the frame. This design ensures that rotor thrust remains upright, enabling the UAV to carry maximum payload capacity even when tilted. Additionally, our system integrates multiple distance sensors to estimate the surface wall angle of a structure before initiating contact, thereby enhancing safety and precision. Furthermore, the tiltable airframe incorporates thrusters on either sides to facilitate bidirectional force control and provide the necessary force for surface data sensing. Through experimental demonstration, we validate the efficiency and effectiveness of our proposed system.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t1_02">
             15:30-16:30, Paper FrPI7T1.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3846'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Remote Situational Awareness for Coastal Vessels Using AIS Data-Based Navigation Pattern DB
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414182" title="Click to go to the Author Index">
             Kim, Chaewon
            </a>
           </td>
           <td class="r">
            Keimyung University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#223911" title="Click to go to the Author Index">
             Hong, Seonghun
            </a>
           </td>
           <td class="r">
            Keimyung University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#171826" title="Click to go to the Author Index">
             Park, Jeonghong
            </a>
           </td>
           <td class="r">
            KRISO
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104653" title="Click to go to the Author Index">
             Choi, Jinwoo
            </a>
           </td>
           <td class="r">
            KRISO, Korea Research Institute of Ships &amp; Ocean Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361888" title="Click to go to the Author Index">
             Hyejin, Kim
            </a>
           </td>
           <td class="r">
            KRISO
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3846" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#probability_and_statistical_methods" title="Click to go to the Keyword Index">
               Probability and Statistical Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             With continuous advances in the fields of mobile robotics and ocean engineering, studies on the safe maritime navigation in complex coastal areas where manned and unmanned vessels can operate simultaneously have gained increasing research attention. Automatic identification system (AIS) data obtained from vessel traffic service (VTS) centers can be used for maritime traffic analysis and management since they include motion and dimensional information of each vessel navigated in the control area of the VTS centers. In particular, navigation patterns reflected in historically accumulated AIS data can be used to evaluate the normalities of ship behaviors. This study addresses a remote situational awareness method with historical and global perspectives using long-term AIS data. A systematic procedure to build a navigation database(DB) is proposed by learning the navigation patterns of coastal vessels from historical AIS data. Experimental results based on an actual AIS dataset obtained from a VTS center are presented to demonstrate the practical feasibility of the proposed method in evaluating the nomalities of the vessels' behaviors in a coastal area.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t1_03">
             15:30-16:30, Paper FrPI7T1.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Search of Missing Persons and Objects Using an Autonomous Aerial Robot
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414288" title="Click to go to the Author Index">
             Lee, Joohyuk
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414289" title="Click to go to the Author Index">
             Lee, HoJun
            </a>
           </td>
           <td class="r">
            Kyungpook national university
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414132" title="Click to go to the Author Index">
             Song, JeongHoon
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#193164" title="Click to go to the Author Index">
             Joe, Hyun-Min
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#273643" title="Click to go to the Author Index">
             Lee, Kyuman
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t1_04">
             15:30-16:30, Paper FrPI7T1.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Motion Planning of an Aerial Striking Robot for Counter-Unmanned Aircraft Systems
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414289" title="Click to go to the Author Index">
             Lee, HoJun
            </a>
           </td>
           <td class="r">
            Kyungpook national university
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414288" title="Click to go to the Author Index">
             Lee, Joohyuk
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414132" title="Click to go to the Author Index">
             Song, JeongHoon
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#193164" title="Click to go to the Author Index">
             Joe, Hyun-Min
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#273643" title="Click to go to the Author Index">
             Lee, Kyuman
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t1_05">
             15:30-16:30, Paper FrPI7T1.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3876'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Collective Source Localization in 3D with a Flocking Nano UAV Swarm
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340425" title="Click to go to the Author Index">
             KaragÃ¼zel, Tugay Alperen
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Amsterdam
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#147435" title="Click to go to the Author Index">
             Ferrante, Eliseo
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Amsterdam
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3876" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study introduces a nature-inspired, swarm robotics approach for UAV swarms with very limited sensing capabilities, aimed at autonomous source localization in complex 3D environments. The control strategy is implemented onboard the Crazyflie 2.1 nano UAVs, allowing each agent to independently adjust its behavior based on locally perceived scalar values, such as light intensity. The method is designed to be highly generic and can be applied to other robotic systems, offering flexibility across various applications.
             <p>
              Simulation experiments were conducted using a dynamic simulator that accurately replicates the real UAV's properties, demonstrating that the swarm consistently moved toward the source. The center of mass (CoM) of the swarm exhibited a clear trend of increasing scalar values over time, with minor oscillations diminishing as the swarm approached the source. The CoM trajectories revealed highly coordinated movement, with agents following relatively straight paths toward the source, indicating effective collective behavior.
              <p>
               To validate these findings, the control logic was implemented in real-world experiments using the Crazyflie 2.1 UAVs. Despite real-world disturbances, such as positioning inaccuracies, controller delays, and communication latency, the UAVs mirrored the simulation results. The swarmâ€™s CoM scalar values showed a consistent upward trend, and the trajectories remained focused and straight toward the source. This consistency across different environments underscores the reliability and robustness of the proposed system.
               <p>
                Overall, this research highlights the potential of nature-inspired, swarm robotics strategies for UAV swarms, particularly in applications requiring autonomous, scalable, and efficient source localization under constrained sensing conditions. The fully onboard implementation, combined with the methodâ€™s generic applicability, ensures its relevance across different robotic systems and real-world scenarios. In the future, this system could be particularly beneficial for search and rescue operations in dangerous environments, disaster response scenarios such as wildfires, and various monitoring missions, making it a promising solution for dynamic and uncertain environments.
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t1_06">
             15:30-16:30, Paper FrPI7T1.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Emergency Landing Site Search for Advanced Air Mobility Using Geographic Information Systems and Real-Time Visual Information
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414132" title="Click to go to the Author Index">
             Song, JeongHoon
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414288" title="Click to go to the Author Index">
             Lee, Joohyuk
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414289" title="Click to go to the Author Index">
             Lee, HoJun
            </a>
           </td>
           <td class="r">
            Kyungpook national university
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#193164" title="Click to go to the Author Index">
             Joe, Hyun-Min
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#273643" title="Click to go to the Author Index">
             Lee, Kyuman
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t1_07">
             15:30-16:30, Paper FrPI7T1.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3878'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              PairTilt: Design and Control of an Active Tilt-Rotor Quadcopter for Improved Efficiency and Agility
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#275702" title="Click to go to the Author Index">
             Tang, Haoyun (Jerry)
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#146039" title="Click to go to the Author Index">
             Mueller, Mark Wilfried
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3878" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present PairTilt, a novel quadcopter design featuring two pairs of tiltable rotors, offering a balance between the mechanical simplicity of conventional quadcopters and the enhanced functionality of more complex tilt-rotor configurations. The PairTilt design enhances agility and efficiency by dynamically adjusting rotor angles, improving maneuverability and reducing drag. We use a dynamic model of the vehicle to design a cascaded controller that enables stable flight. We validate the performance of the vehicle through simulations and experiments, demonstrating the vehicle's agility, compact hovering capability, sensor pointing capability, and improved energy efficiency at higher speeds compared to a conventional quadcopter. These results highlight PairTilt's potential for various applications in aerial robotics, particularly those requiring maneuverability in confined spaces and efficient high-speed flight.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t1_08">
             15:30-16:30, Paper FrPI7T1.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3882'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              /pi-MPPI: A Projection-Based Model Predictive Path Integral Scheme for Smooth Optimal Control of Fixed-Wing Aerial Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414309" title="Click to go to the Author Index">
             Andrejev, Edvin Martin
            </a>
           </td>
           <td class="r">
            University of Tartu
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#226239" title="Click to go to the Author Index">
             Manoharan, Amith
            </a>
           </td>
           <td class="r">
            University of Tartu
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414310" title="Click to go to the Author Index">
             Unt, Karl-Eerik
            </a>
           </td>
           <td class="r">
            Estonian Aviation Academy
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123110" title="Click to go to the Author Index">
             Singh, Arun Kumar
            </a>
           </td>
           <td class="r">
            University of Tartu
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3882" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we present /pi-MPPI, a novel variant of the classical MPPI that can ensure arbitrary degree of smoothness in the computed optimal controls. Our core idea is to embed a projection optimizer within the MPPI pipeline that takes in samples from a baseline Gaussian distribution and modifies them in a minimal fashion to account for constraints on higher-level derivatives of the control inputs. Our projection optimizer is a Quadratic Programming (QP) problem and we develop a custom solver with an efficient GPU parallelizable structure. Moreover, we learn warm-start strategies to further accelerate convergence of the solver.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t1_09">
             15:30-16:30, Paper FrPI7T1.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Towards Efficient Underwater Robotic Swarms: Accurate Localization and Heading Estimation in Resource-Constrained Environments
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#382873" title="Click to go to the Author Index">
             Eltobgui, Rim
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#342751" title="Click to go to the Author Index">
             Zayer, Fakhreddine
            </a>
           </td>
           <td class="r">
            khalifa University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#221547" title="Click to go to the Author Index">
             Iacoponi, Saverio
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#284827" title="Click to go to the Author Index">
             De Masi, Giulia
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#150250" title="Click to go to the Author Index">
             Renda, Federico
            </a>
           </td>
           <td class="r">
            Khalifa University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101631" title="Click to go to the Author Index">
             Dias, Jorge
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t1_10">
             15:30-16:30, Paper FrPI7T1.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Affective Behaviors in Close-Proximity Interactions with Inflatable Flapping-Wing Robots
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335380" title="Click to go to the Author Index">
             Xu, Mingyang
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414277" title="Click to go to the Author Index">
             Ju, Yulan
            </a>
           </td>
           <td class="r">
            Keio University Graduate School of Media Design
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414272" title="Click to go to the Author Index">
             Meng, Xiaru
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414267" title="Click to go to the Author Index">
             Gao, Qingyuan
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414270" title="Click to go to the Author Index">
             Zhang, Qing
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414268" title="Click to go to the Author Index">
             Hoppe, Matthias
            </a>
           </td>
           <td class="r">
            Keio University Graduate School of Media Design
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#124714" title="Click to go to the Author Index">
             Minamizawa, Kouta
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#359029" title="Click to go to the Author Index">
             Barbareschi, Giulia
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#198912" title="Click to go to the Author Index">
             Kunze, Kai
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t1_11">
             15:30-16:30, Paper FrPI7T1.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Lie Theory-Based Sensor Fusion for Heading Estimation in Unmanned Surface Vehicles
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#253183" title="Click to go to the Author Index">
             Ko, Nak Yong
            </a>
           </td>
           <td class="r">
            Chosun University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#409261" title="Click to go to the Author Index">
             Jeong, Da Bin
            </a>
           </td>
           <td class="r">
            Chosun university
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#130223" title="Click to go to the Author Index">
             Choi, Hyun-Taek
            </a>
           </td>
           <td class="r">
            Korea Research Institute of Ships and Oceans Engineering
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t1_12">
             15:30-16:30, Paper FrPI7T1.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3911'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Mission Planning for Efficient Undersea Surveys Via Multi-Fleet Marine Vehicle Operations
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414176" title="Click to go to the Author Index">
             Kim, Donghyun
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#162950" title="Click to go to the Author Index">
             Kim, Jinwhan
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3911" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Efficient operation of long-term missions by autonomous systems involving multiple surface and underwater vehicles relies on concurrent actions and collaboration. This study addresses the temporal mission planning problem, focusing on minimizing the makespan. Given the NP-hard nature of this problem, we propose a hierarchical planning approach. At the higher level, missions are divided using hierarchical clustering, and tasks are allocated by solving the multiple Traveling Salesman Problem (mTSP). At the lower level, the reduced problems are defined and solved using PDDL to generate temporal action sequences. This approach enables efficient handling of large-scale planning problems. Additionally, mission planning performance is further improved by redefining the edge cost in the mTSP, which helps to reduce makespan bias between fleets, leading to more balanced task allocation and improved overall mission efficiency. The proposed methodologies are validated through qualitative results, such as Gantt charts illustrating the temporal plans and animations showing the agents' trajectories, as well as through quantitative results obtained from Monte Carlo simulations.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t1_13">
             15:30-16:30, Paper FrPI7T1.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3881'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Signal Temporal Logic Compliant Co-Design of Planning and Control for Single and Multi-Agent Systems
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377840" title="Click to go to the Author Index">
             Juvvi, Manas Sashank
            </a>
           </td>
           <td class="r">
            Indian Institute of Science, Bengaluru
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396373" title="Click to go to the Author Index">
             Kurne, Tushar
            </a>
           </td>
           <td class="r">
            Indian Institute of Science
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397656" title="Click to go to the Author Index">
             J, Vaishnavi
            </a>
           </td>
           <td class="r">
            Indian Institute of Science
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#148828" title="Click to go to the Author Index">
             Kolathaya, Shishir
            </a>
           </td>
           <td class="r">
            Indian Institute of Science
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#287363" title="Click to go to the Author Index">
             Jagtap, Pushpak
            </a>
           </td>
           <td class="r">
            Indian Institute of Science
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3881" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#formal_methods_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Formal Methods in Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work proposes a novel approach for motion planning in autonomous ground robots, focusing on handling signal temporal logic (STL) tasks. The approach is structured into two phases: (i) learning spatio-temporal motion primitives to encapsulate the inherent robot-specific constraints and ii) constructing STL-compliant motion plans using the learned spatio-temporal motion primitives. Initially, we employ reinforcement learning to construct a library of motion primitives. Then, Gaussian process regression is used to map motion primitives to spatio-temporal characteristics. Subsequently, we present a sampling-based STL-compliant motion planning strategy tailored to meet the STL specification. Additionally, we have incorporated a conflict-based search (CBS) algorithm to ensure STL satisfaction in multi-agent systems. We demonstrate the effectiveness and adaptability of our framework through experiments conducted on â€˜Differential-drive robotâ€™ and â€˜Quadrupedâ€™ for multiple STL specifications and environments for both single-agent and multi-agent systems. Videos of the demonstrations can be accessed here - https://drive.google.com/file/d/12ogHgbrrAV8aVuXXaYxWwkGjvt 8ZSb0b/view?usp=sharing. The proposed framework is entirely model-free and capable of generating feasible STL-compliant motion plans across diverse environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t1_14">
             15:30-16:30, Paper FrPI7T1.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Prescribed-Time Distributed MRAC for Multi-Agent Systems with Closed-Loop Reference Model
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#400881" title="Click to go to the Author Index">
             Zheng, Leyi
            </a>
           </td>
           <td class="r">
            Shenzhen Institute of Advanced Technology Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#151249" title="Click to go to the Author Index">
             Zhou, Yimin
            </a>
           </td>
           <td class="r">
            Chinese Academy of Sciences
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t1_15">
             15:30-16:30, Paper FrPI7T1.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3909'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RL-Based Variable Horizon Model Predictive Control of Multi-Robot Systems in Dynamic Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#313153" title="Click to go to the Author Index">
             Gupta, Shreyash
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology, Jodhpur
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#313423" title="Click to go to the Author Index">
             Tripathy, Niladri Sekhar
            </a>
           </td>
           <td class="r">
            IIT Jodhpur
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113621" title="Click to go to the Author Index">
             Shah, Suril Vijaykumar
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology Jodhpur
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3909" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-robot systems (MRS) are autonomous or semi-autonomous robots used in tasks like search and rescue, exploration, and logistics, offering greater efficiency, flexibility, and reliability than single robots. Model Predictive Control (MPC) is well-suited for MRS due to its ability to manage complex tasks, nonlinear dynamics, and constraints. The prediction horizon is a key factor affecting MPC's performance in dynamic environments. A longer horizon improves accuracy but requires more computation, potentially slowing response and causing instability. Conversely, a shorter horizon offers a faster response but may lead to less accurate predictions and suboptimal control. This challenge has led to the development of variable horizon MPC (VHMPC) for MRS. Traditional methods for selecting the prediction horizon are often task-specific, heuristic-based, or rely on assumptions that may not apply broadly. Therefore, learning-based approaches, like Reinforcement Learning (RL), offer advantages in estimating the horizon at each time step and are focused in this work.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frpi7t2">
             <b>
              FrPI7T2
             </b>
            </a>
           </td>
           <td class="r">
            Room 2
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frpi7t2" title="Click to go to the Program at a Glance">
             <b>
              Human-Robot Interaction and Collaboration
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#209027" title="Click to go to the Author Index">
             Tortora, Stefano
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#213444" title="Click to go to the Author Index">
             Canal, Gerard
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t2_01">
             15:30-16:30, Paper FrPI7T2.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3825'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              How to Improvehuman-Robot Interaction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413855" title="Click to go to the Author Index">
             Bertuccelli, Margherita
            </a>
           </td>
           <td class="r">
            UniversitÃ  Degli Studi Di Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#209027" title="Click to go to the Author Index">
             Tortora, Stefano
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396653" title="Click to go to the Author Index">
             Trombin, Edoardo
            </a>
           </td>
           <td class="r">
            University of Padua
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413858" title="Click to go to the Author Index">
             Pasinato, Mariasole
            </a>
           </td>
           <td class="r">
            UniversitÃ  Degli Studi Di Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413860" title="Click to go to the Author Index">
             Tasinazzo, William
            </a>
           </td>
           <td class="r">
            UniversitÃ  Degli Studi Di Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413862" title="Click to go to the Author Index">
             Sparacino, Giovanni
            </a>
           </td>
           <td class="r">
            UniversitÃ  Degli Studi Di Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105144" title="Click to go to the Author Index">
             Menegatti, Emanuele
            </a>
           </td>
           <td class="r">
            The University of Padua
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#404352" title="Click to go to the Author Index">
             Del Felice, Alessandra
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3825" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#embodied_cognitive_science" title="Click to go to the Keyword Index">
               Embodied Cognitive Science
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#design_and_human_factors" title="Click to go to the Keyword Index">
               Design and Human Factors
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Exoskeletons and wearable robotic devices are increasingly adopted in rehabilitation settings. Despite the recognized advantages of robotic-guided rehabilitation, its efficacy compared to traditional therapy is still controversial. One reason for this, is the lack of integration between end-users and the rehabilitative robotic devices. The phenomenon of integration between the human body and external tools has been referred to as â€œtool-embodimentâ€. Exoskeletons embodiment has been, so far, largely neglected, and assessed mainly by means of self-reported questionnaires. A neurophysiological marker able to catch the degree of integration between humans and exoskeletons is missing, though highly desirable to assess exoskeletons design and enhance their capability to assist human movements. This protocol aims to identify a new neurophysiological marker to quantify human-exoskeleton integration by exploiting the phenomenon of sensory attenuation. We hypothesize that an action generated while donning a hard lower limb exoskeleton would fail to provoke the sensory attenuation generally evoked by self-generated actions. Ten able-bodied volunteers, naif to the use of exoskeletons took part in the experiment. Each participant was presented with two experimental blocks (i.e., A and B): In block A participants were asked to don a lower limb exoskeleton (ALICE) and perform the experimental task; In block B, the same task was performed without donning the exoskeleton. In each block, the task consisted of 20 trials in which participants had either to electrically stimulate themselves by stepping on a button attached to an electrical stimulator (Digitimer DS7A) or stay still while stimulated by the experimenter. The somatosensory evoked potentials (SSEPs) associated to the median nerve stimulation were recorded with a 32-channel EEG cup (ANT neuro eegoâ„¢). Sensory attenuation was observed in the N60 component of the SSEP in the no-exoskeleton conditions when comparing self-stimulation and external stimulation in central-parietal areas (CP4 channel, Wilcoxon, p-value = 0.02). On the contrary, the amplitudes of N60 between self and external stimulations did not result significantly different while donning the exoskeleton (CP4 channel, Wilcoxon, p=0.22). The results of this study support the hypothesis that when participants wear the exoskeleton, there is no sensory attenuation in the self-stimulation condition relative to the external stimulation. This result might be interpreted as a reduction in the end-users' capacity to predict the outcomes of their motor programs when using the exoskeleton due to a lack of integration with it. These data provide a first quantitative index to assess human-exoskeleton integration.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t2_02">
             15:30-16:30, Paper FrPI7T2.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3829'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Trajectory Generation Method Based on DDP Considering Manipulaiblity Measure
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#186630" title="Click to go to the Author Index">
             Lee, Jaesoon
            </a>
           </td>
           <td class="r">
            Kookmin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109773" title="Click to go to the Author Index">
             Cho, Baek-Kyu
            </a>
           </td>
           <td class="r">
            Kookmin University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3829" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This poster introduces a trajectory generation technique for 6-DOF collaborative robots, utilizing the Differential Dynamic Programming (DDP) algorithm combined with the Manipulability Measure to effectively avoid singularities. Conventional trajectory generation approaches often overlook the robot's dynamic characteristics, resulting in suboptimal trajectories and an increased risk of encountering singularities. Our method addresses this issue by incorporating the Manipulability Measure within the DDP framework, ensuring that the robot's dynamics are accounted for while avoiding singularities efficiently. The developed algorithm was implemented on the 6-DOF collaborative robot model RB1-500e and subsequently tested on the actual robot. The experimental outcomes reveal that our approach offers significant enhancements in trajectory optimization and singularity avoidance when compared to conventional methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t2_03">
             15:30-16:30, Paper FrPI7T2.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3834'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Revisiting Flow-Based Interaction Recognition: Social Robots' Understanding of Behavioral Cues in Elderly Care
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#348926" title="Click to go to the Author Index">
             Jeon, HoBeom
            </a>
           </td>
           <td class="r">
            Korea University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#300669" title="Click to go to the Author Index">
             Kim, Hyungmin
            </a>
           </td>
           <td class="r">
            Korea University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#110378" title="Click to go to the Author Index">
             Kim, DoHyung
            </a>
           </td>
           <td class="r">
            Electronics and Telecommunications Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#130395" title="Click to go to the Author Index">
             Kim, Jaehong
            </a>
           </td>
           <td class="r">
            ETRI
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3834" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robot_companions" title="Click to go to the Keyword Index">
               Robot Companions
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intention_recognition" title="Click to go to the Keyword Index">
               Intention Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study investigates the recognition of nonverbal human-robot interactions from the perspective of doll-type social robots. We introduce the Act2Robot dataset, focusing on elderly participants to explore interactions relevant to elderly care. The dataset encompasses 2000 samples of ten interaction behaviors, capturing both expressive actions and unintended movements to provide insights into internal states. A comparative analysis of transfer learning techniques using RGB and Flow modalities highlights the effectiveness of flow-based models in managing ego-motion in close-proximity environments. Our findings suggest that pre-training on Kinetics-400 enhances model performance, demonstrating the potential of the Act2Robot dataset to improve social robot interactions upon its official release.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t2_04">
             15:30-16:30, Paper FrPI7T2.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3835'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              REBALANCE - REinforcing BALANCE with a Neurally-Driven Wearable Assistive Device
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#209027" title="Click to go to the Author Index">
             Tortora, Stefano
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413855" title="Click to go to the Author Index">
             Bertuccelli, Margherita
            </a>
           </td>
           <td class="r">
            UniversitÃ  Degli Studi Di Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#337688" title="Click to go to the Author Index">
             Monari, Eugenio
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#139023" title="Click to go to the Author Index">
             Muscolo, Giovanni Gerardo
            </a>
           </td>
           <td class="r">
            University of Verona
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#124752" title="Click to go to the Author Index">
             Conconi, Michele
            </a>
           </td>
           <td class="r">
            University of Bologna, Faculty of Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#186633" title="Click to go to the Author Index">
             Sancisi, Nicola
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105144" title="Click to go to the Author Index">
             Menegatti, Emanuele
            </a>
           </td>
           <td class="r">
            The University of Padua
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#324584" title="Click to go to the Author Index">
             Chiari, Lorenzo
            </a>
           </td>
           <td class="r">
            Alma Mater Studiorum, UniversitÃ  Di Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#404352" title="Click to go to the Author Index">
             Del Felice, Alessandra
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3835" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#prosthetics_and_exoskeletons" title="Click to go to the Keyword Index">
               Prosthetics and Exoskeletons
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#body_balancing" title="Click to go to the Keyword Index">
               Body Balancing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Falls are a significant cause of injury and disability in the elderly. Considering that western societies are rapidly aging, this imposes a considerable burden on social and healthcare systems. The project aims to reduce falls and related healthcare and social costs in the elderly. To tackle this pressing problem, the project develops a low-cost, neurally-driven, wearable assistive device (WAD) to prevent loss of balance (LoB), a prodromal sign of an incipient fall, in ecological environments. In this project, the WAD will be deployed as a rehabilitative tool in conjunction with an active balance board, to reinforce balance control based on individual cerebral, muscular, and kinematic responses. The project is organized in three phases. Phase I will identify the neurophysiological and kinematic features of LoB in the elderly. To do so, a controlled balance board with one degree of freedom is implemented to perturb balance in both the antero-posterior and medio-lateral directions. The aim is to collect a rich multimodal database of neurophysiological and biomechanical data to deepen our understanding on balance control in the elderly, which will provide the building block for following phases. Phase II will release WAD software and hardware components. Building on the experimental paradigm developed in Phase I, the contribution of the hip joint to maintain balance will be quantitatively characterized and its stabilizing role in the presence of an incipient LoB will be tested. This knowledge will be used to design and build an active hip WAD to reinforce neuro-biomechanical balance strategies. A machine learning model will fuse neural data and kinematic information to predict LoB and use it as a trigger to activate the WAD, starting from the data collected in Phase I. Knowledge and technologies built in this phase will provide the basis for the translation of the controlled platform and WAD prototype into a closed-loop rehabilitation tool (Phase III). Phase III will test the WAD prototype and platform developed in Phase I-II to reduce LoB in a pilot trial in a cohort of elderly fallers. The expected results will translate in advancement of scientific and technical knowledge (Phases I-II) and economic impact in terms of reduction of LoB and market access of the end products (Phases III).
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t2_05">
             15:30-16:30, Paper FrPI7T2.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3838'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Collaborative Robot-Based Surface Defect Inspection System for Machined Products Using Image Detection and 3D Reconstruction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414073" title="Click to go to the Author Index">
             Kim, Taeseok
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372632" title="Click to go to the Author Index">
             Choe, Seongsig
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414096" title="Click to go to the Author Index">
             Park, Hwijin
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414088" title="Click to go to the Author Index">
             Kwon, Hyeokjun
            </a>
           </td>
           <td class="r">
            Kyungpook
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414130" title="Click to go to the Author Index">
             Hu, Shengqiao
            </a>
           </td>
           <td class="r">
            Kyoungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#170957" title="Click to go to the Author Index">
             Yi, Hak
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3838" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study developed a surface defect inspection system using a collaborative robot and a RealSense D455 camera. The system is designed to efficiently inspect surface defects of CNC-machined parts by leveraging artificial intelligence (AI) and generated 3D images. The camera, mounted on the end effector of the robot, captures images and point clouds of the workpiece from various angles to acquire surface and shape information. Subsequently, the acquired 2D images are analyzed by defect detection AI to identify defects such as scratches and dents, with the detected defects visualized through point cloud data. During the 3D image generation stage, a 3D image containing the detected defects is created, allowing for a clear assessment of the part's defects. This system demonstrates the potential to enhance quality control in manufacturing processes by detecting and visualizing surface defects in CNC-machined parts. Future research will focus on improving the accuracy of the AI algorithms and enhancing the resolution of the 3D models.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t2_06">
             15:30-16:30, Paper FrPI7T2.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3844'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Physical Rehabilitation Robot Coaching Patients: A Long-Term Dataset for Body Movement Analysis
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#155041" title="Click to go to the Author Index">
             Nguyen, Sao Mai
            </a>
           </td>
           <td class="r">
            U2IS Ensta Paris
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3844" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#gesture__posture_and_facial_expressions" title="Click to go to the Keyword Index">
               Gesture, Posture and Facial Expressions
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             While automatic monitoring and coaching of exercises are showing encouraging results in non-medical applications, they still have limitations such as errors and limited use contexts. To allow the development and assessment of physical rehabilitation by an intelligent tutoring system, we identify in this article four challenges to address and propose a medical dataset of clinical patients carrying out low back-pain rehabilitation exercises. The dataset includes 3D Kinect skeleton positions and orientations, RGB videos, 2D skeleton data, and medical annotations to assess the correctness, and error classification and localisation of body part and timespan. Along this dataset, we perform a complete research path, from data collection to processing, and finally a small benchmark. We evaluated on the dataset two baseline movement recognition algorithms, pertaining to two different approaches: the probabilistic approach with a Gaussian Mixture Model (GMM), and the deep learning approach with a Long-Short Term Memory (LSTM). This dataset is valuable because it includes rehabilitation relevant motions in a clinical setting with patients in their rehabilitation program, using a cost-effective, portable, and convenient sensor, and because it shows the potential for improvement on these challenges.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t2_07">
             15:30-16:30, Paper FrPI7T2.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Exploring Feedback Dynamics for Human Teachers in Robot Programming Using Biometric and Performance Insights
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#348948" title="Click to go to the Author Index">
             Mehak, Shakra
            </a>
           </td>
           <td class="r">
            Pilz Ireland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393731" title="Click to go to the Author Index">
             Kelleher, John D.
            </a>
           </td>
           <td class="r">
            Trinity Colege Dublin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414209" title="Click to go to the Author Index">
             Guilfoyle, Michael
            </a>
           </td>
           <td class="r">
            Pilz Ireland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354355" title="Click to go to the Author Index">
             Leva, Maria Chiara
            </a>
           </td>
           <td class="r">
            Technological University Dublin
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t2_08">
             15:30-16:30, Paper FrPI7T2.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3860'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Exploring the Impact of Robot Intentions and Beliefs on Motor Learning Via Human Physical Tutoring Based on the Free Energy Principle
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310351" title="Click to go to the Author Index">
             Fukushima, Rui
            </a>
           </td>
           <td class="r">
            Okinawa Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#173198" title="Click to go to the Author Index">
             Tani, Jun
            </a>
           </td>
           <td class="r">
            Okinawa Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3860" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#developmental_robotics" title="Click to go to the Keyword Index">
               Developmental Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensorimotor_learning" title="Click to go to the Keyword Index">
               Sensorimotor Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Motor skill development involves incremental processes of interaction with the world, often explored through trial-and-error approaches that demonstrate how agents gradually acquire skills. However, human motor skills are also significantly influenced by social interactions or guided experiences. This study introduces a novel approach to developing motor skills in robots through human tutoring using an artificial neural network utilizing a Predictive Coding-inspired Variational Recurrent Neural Network (PV-RNN) based on the Free Energy Principle (FEP). The FEP provides a theoretical framework for understanding how biological systems update their internal state and adapt to their environment by minimizing free energy through prediction, perception, and action.
             <p>
              In this approach, we modulate a meta-level parameter within the FEP framework that adjusts the strength of intention or prior belief. This parameter is crucial in determining how the robot responds to human guidance, potentially leading to either conflict or adaptation during tutoring. An infant-like humanoid robot performs object manipulation tasks, such as lifting objects, across multiple phases of tutoring, training, and evaluation. During tutoring sessions, the robot generates behaviors while a human tutor provides corrective guidance by physically manipulating the robot's hands. The conflict between the robotâ€™s and the tutorâ€™s intentions is quantified by measuring the torque at the robotâ€™s joints.
              <p>
               Our experiments explore different settings of prior belief strength, which remains constant throughout the developmental stage. The results show that robots with weaker prior beliefs tend to perform poorly in tasks but are more easily guided, requiring less force due to their higher adaptability to the tutor's guidance. Conversely, robots with stronger prior beliefs exhibit better task performance but generate greater conflict, as indicated by increased exerted force. This heightened conflict introduces noise into the tutored sequences, complicating subsequent training and potentially leading to poor learning outcomes due to interference.
               <p>
                These findings highlight the importance of balancing between intention strength and adaptability for effective motor learning through human tutoring. This research offers valuable insights for designing more adaptable and intuitive robotic partners, enhancing their usability in various applications.
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t2_09">
             15:30-16:30, Paper FrPI7T2.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3867'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Decoding Userâ€™s Walking Intentions to Provide Active Assistance in Smart Walkers
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366340" title="Click to go to the Author Index">
             Polato, Anna
            </a>
           </td>
           <td class="r">
            University of Padua
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397816" title="Click to go to the Author Index">
             Zanchi, Luca
            </a>
           </td>
           <td class="r">
            University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#209027" title="Click to go to the Author Index">
             Tortora, Stefano
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105144" title="Click to go to the Author Index">
             Menegatti, Emanuele
            </a>
           </td>
           <td class="r">
            The University of Padua
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#187558" title="Click to go to the Author Index">
             Tonin, Luca
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3867" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#intention_recognition" title="Click to go to the Keyword Index">
               Intention Recognition
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Fall is one of the most common causes of injuries among older adults and may seriously damage their physical and psychological health. Walkers are commonly proposed as assistive devices to help maintain stability, mobility, and independence. In the last years, smart walkers have been introduced for actively assisting the locomotion by exploiting artificial intelligence. This study has the purpose of developing a method for decoding user's intentions in real-time, i.e., the intention to walk, stop, turn left and turn right and it aims at integrating such system in an active walker. An artificial skin was devised for capturing the differences of pressure coming from handles grip and to predict the intention of the user to turn. Points and areas of pressure are collected and fed into a CNN2D. An RGB-D Camera is used to infer the intention of the user to walk and stop by capturing a depth-image of userâ€™s legs and extracting legs profile as polar points. Clustering is then applied to find two centroids which are fed into a CNN2D. The system outputs six possible user's intentions and one "unknown" state when the camera detects points not belonging to the legs, it achieved an accuracy of 86.45%	and an Unknown-class percentage lower than 6%. In conclusion, this research provides a userâ€™s intention inferring system for walkers, able to support the userâ€™s ambulatory. Future works will focus on confirm offline performance online, assign the walker behavior from predicted state, define optimal route from userâ€™s predicted intention and environmental data.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t2_10">
             15:30-16:30, Paper FrPI7T2.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3879'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              VR-Based Teleoperation and Data Collection for Dual Hand-Arm Robots with Fine Manipulation Capabilities
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#131736" title="Click to go to the Author Index">
             Kim, Donghyung
            </a>
           </td>
           <td class="r">
            Electronics and Telecommunications Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#163715" title="Click to go to the Author Index">
             Kim, Taewoo
            </a>
           </td>
           <td class="r">
            Electronics and Telecommunications Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#127992" title="Click to go to the Author Index">
             Kim, Wansoo
            </a>
           </td>
           <td class="r">
            Hanyang University ERICA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#135799" title="Click to go to the Author Index">
             Hwang, Soonwoong
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#347330" title="Click to go to the Author Index">
             Kim, Joonhyun
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#388500" title="Click to go to the Author Index">
             Lee, Jungsoo
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#130395" title="Click to go to the Author Index">
             Kim, Jaehong
            </a>
           </td>
           <td class="r">
            ETRI
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3879" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a novel approach to the teleoperation and data collection for dual hand-arm robots with fine manipulation capabilities. The study addresses the current challenges in the field of robotic manipulation, particularly focusing on the scarcity of suitable datasets and the complexity of teleoperating dual hand-arm robots.
             <p>
              We developed an open-source dual hand-arm robot simulation, accessible via NVIDIA's Isaac Sim, to facilitate research in this area. The primary objective was to create an intuitive and visually guided VR-based teleoperation system, enabling operators to control the robotâ€™s movements and interactions with objects using only the visual feedback provided by the VR environment.
              <p>
               A key innovation in this system is the implementation of a motion re-targeting technique. This involves the use of a Closed-loop Inverse Kinematics (CLIK) algorithm from the Pinocchio library, which maps the operatorâ€™s hand movements captured by Meta Quest 3 to the robot's 7-DOF (Degrees of Freedom) robotic arms. The human handâ€™s pose data is tracked and processed in real-time, allowing for accurate manipulation by the robot.
               <p>
                We also developed a data collection framework, which records human-demonstrated data during five different manipulation tasks. These tasks include actions such as lifting a pot with both hands and wiping a table, with over 100 of human-demonstrated data collected for each task. The data is recorded at 20Hz and includes multiple elements such as RGBD camera streams, head and wrist camera angles, joint positions, and fingertip contact forces.
                <p>
                 The paper highlights the benefits of using this VR-based teleoperation system for collecting high-quality datasets that are critical for advancing fine manipulation tasks in humanoid robots. Additionally, the visual feedback system, including fingertip force indicators, enhances the operatorâ€™s ability to control the robot with precision.
                 <p>
                  Overall, this research contributes significantly to the field of humanoid robotics by providing an accessible tool for teleoperation and data collection, which can be used to improve the robot manipulation skill learning in fine manipulation tasks. The open-source nature of this research also invites further collaboration and development in the broader research community.
                 </p>
                </p>
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t2_11">
             15:30-16:30, Paper FrPI7T2.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3885'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Engineering Design, Humans vs. Machines
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#208311" title="Click to go to the Author Index">
             Isakhani, Hamid
            </a>
           </td>
           <td class="r">
            University of Birmingham
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#111859" title="Click to go to the Author Index">
             Nefti-Meziani, Samia
            </a>
           </td>
           <td class="r">
            University of Salford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106380" title="Click to go to the Author Index">
             Davis, Steven
            </a>
           </td>
           <td class="r">
            University of Birmingham
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3885" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#product_design__development_and_prototyping" title="Click to go to the Keyword Index">
               Product Design, Development and Prototyping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#design_and_human_factors" title="Click to go to the Keyword Index">
               Design and Human Factors
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_performance_augmentation" title="Click to go to the Keyword Index">
               Human Performance Augmentation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             As a problem-solving activity, engineering design that is an integral part of robotics hardware development is usually iterative involving multiple proposed solutions that are tested against a predefined set of constraints to determine the most satisfactory proposal. Human designers usually rely on their knowledge, experience, and intuition, which is a drawback when dealing with certain unknown problems especially for the first time. This is easily overcome by a machine that can generate and test several thousand alternative solutions to a design problem defined by a human iteratively with its criteria and constraints in the form of a parametric computational model. Considering the computer as a collaborative partner in the design process, we may call this technology as Computer-Associated Design (CAsD) shaping the next generation of Computer-Aided Design (CAD) technology that emerged during the third industrial revolution.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t2_12">
             15:30-16:30, Paper FrPI7T2.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3886'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Designing Workplace Robots: A Social Impact Assessment Tool for Automation and Augmentation in Construction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394050" title="Click to go to the Author Index">
             Wu, Sihui
            </a>
           </td>
           <td class="r">
            Swiss Federal Institutes of Technology in Zurich (ETH Zurich)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396584" title="Click to go to the Author Index">
             Helmersen, Kim Norgaard
            </a>
           </td>
           <td class="r">
            Swiss Federal Institute of Technology in Zurich (ETH Zurich)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396587" title="Click to go to the Author Index">
             Chen, Li
            </a>
           </td>
           <td class="r">
            Swiss Federal Institute of Technology in Zurich (ETH Zurich)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396583" title="Click to go to the Author Index">
             Grote, Gudela
            </a>
           </td>
           <td class="r">
            Swiss Federal Institute of Technology in Zurich (ETH Zurich)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3886" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#design_and_human_factors" title="Click to go to the Keyword Index">
               Design and Human Factors
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_centered_automation" title="Click to go to the Keyword Index">
               Human-Centered Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robotics_and_automation_in_construction" title="Click to go to the Keyword Index">
               Robotics and Automation in Construction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The architecture, engineering, and construction (AEC) sector, the world's largest industrial sector, confronts significant challenges such as climate change and labor shortages. Robotization and automation offer substantial opportunities to boost productivity, reduce environmental impacts, and address workforce issues. However, the design and implementation of these technologies often overlooks human and social aspects, focusing predominantly on economic and technical factors. This study aims to develop a social impact assessment tool tailored to robot design and use, emphasizing the work and organizational implications of construction robots. Rooted in socio-technical systems theory, the study explores and operationalizes indicators for the social impact of automation and augmentation in AEC. The outcome of the study is a tool defined as a boardgame called â€œBUILDWORKâ€. Such educational games or serious games facilitate a motivating learning experience by challenging and engaging the players in a safe and interactive manner. Adopting a participatory approach, the study engages stakeholdersâ€”including technology designers, implementers, managers, and end-usersâ€”through interviews and workshops to co-create and validate the prototype of the game. Preliminary findings from the pre-development workshops have identified a gap between technology development and implementation in AEC in terms of the factors being considered. During the pilot testing of the prototype, most of the participants have shown their initial approaches and further learnings through the game playing. The outcome of the study equips practitioners with a robust framework for evaluating the social impacts of robot design and implementation at the workplace. By integrating technical capabilities and human factors, the research contributes to improving effective design and use of construction robots as well as to promote job quality and the overall well-being of the workforce. As future work, the paper-based boardgame will be advanced by a web-based user interface that will be accessible online. Future research will continue to validate the operationalizability of the indicators and their relations in real-world cases.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t2_13">
             15:30-16:30, Paper FrPI7T2.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Beyond Linear Connections: Explore New Embodiment Potentials between People with Disabilities and Their Robotic Avatars
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#359029" title="Click to go to the Author Index">
             Barbareschi, Giulia
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#318870" title="Click to go to the Author Index">
             Yukawa, Hikari
            </a>
           </td>
           <td class="r">
            Nagoya Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414342" title="Click to go to the Author Index">
             Hatada, Yuji
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414325" title="Click to go to the Author Index">
             Kawaguchi, Midori
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414344" title="Click to go to the Author Index">
             Hiroaki, Kato
            </a>
           </td>
           <td class="r">
            Ory Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#321732" title="Click to go to the Author Index">
             Nishimura, Takumi
            </a>
           </td>
           <td class="r">
            Nagoya Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414347" title="Click to go to the Author Index">
             Takeuchi, Kazuaki
            </a>
           </td>
           <td class="r">
            Ory Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#321852" title="Click to go to the Author Index">
             Tanada, Ryohei
            </a>
           </td>
           <td class="r">
            Nagoya Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414349" title="Click to go to the Author Index">
             Shiiba, Yoshifumi
            </a>
           </td>
           <td class="r">
            Ory Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#214036" title="Click to go to the Author Index">
             Ema, Arisa
            </a>
           </td>
           <td class="r">
            the University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414351" title="Click to go to the Author Index">
             Kasahara, Shunichi
            </a>
           </td>
           <td class="r">
            Sony Computer Science Laboratories, Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414353" title="Click to go to the Author Index">
             Spoden, Celia
            </a>
           </td>
           <td class="r">
            German Institute for Japanese Studies
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414354" title="Click to go to the Author Index">
             Karino, Manaka
            </a>
           </td>
           <td class="r">
            Chuo University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#159030" title="Click to go to the Author Index">
             Saraiji, MHD Yamen
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#371563" title="Click to go to the Author Index">
             Dogus Ates, Eren
            </a>
           </td>
           <td class="r">
            avatarin Inc.
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414358" title="Click to go to the Author Index">
             Charith, Fernando
            </a>
           </td>
           <td class="r">
            Avatarin Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109395" title="Click to go to the Author Index">
             Osawa, Hirotaka
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414335" title="Click to go to the Author Index">
             Yoshifuji, Ory
            </a>
           </td>
           <td class="r">
            Ory Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#198912" title="Click to go to the Author Index">
             Kunze, Kai
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109360" title="Click to go to the Author Index">
             Tanaka, Yoshihiro
            </a>
           </td>
           <td class="r">
            Nagoya Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#294676" title="Click to go to the Author Index">
             Narumi, Takuji
            </a>
           </td>
           <td class="r">
            Graduate School of Information Science and Technology, The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#124714" title="Click to go to the Author Index">
             Minamizawa, Kouta
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t2_14">
             15:30-16:30, Paper FrPI7T2.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Enhancing Embodied &amp; Proprioception Experience for ALS Patients by Haptic Feedback in Using Integrated Robotic Augmentation Limbs
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#124714" title="Click to go to the Author Index">
             Minamizawa, Kouta
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#359029" title="Click to go to the Author Index">
             Barbareschi, Giulia
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414298" title="Click to go to the Author Index">
             Hu, Zheng
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414317" title="Click to go to the Author Index">
             Zhou, Songchen
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#275537" title="Click to go to the Author Index">
             Horie, Arata
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414321" title="Click to go to the Author Index">
             Ando, Ryoichi
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414335" title="Click to go to the Author Index">
             Yoshifuji, Ory
            </a>
           </td>
           <td class="r">
            Ory Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414338" title="Click to go to the Author Index">
             Muto, Masatane
            </a>
           </td>
           <td class="r">
            WITH ALS General Incorporated Foundation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414337" title="Click to go to the Author Index">
             Zhu, Yufan
            </a>
           </td>
           <td class="r">
            Keio University, Graduate School of Media Design,
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t2_15">
             15:30-16:30, Paper FrPI7T2.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Design and Evaluation of a Human-Comparable Modeless and Featureless General Visual-Servoing Robot Controller Based on Closed-Loop GPT-4O
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391372" title="Click to go to the Author Index">
             Yang, Jialun
            </a>
           </td>
           <td class="r">
            Clemson University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#300017" title="Click to go to the Author Index">
             Yan, Yuchen
            </a>
           </td>
           <td class="r">
            Clemson University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#128943" title="Click to go to the Author Index">
             Jia, Yunyi
            </a>
           </td>
           <td class="r">
            Clemson University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t2_16">
             15:30-16:30, Paper FrPI7T2.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3912'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Deep Active Inference for Engagement Recognition in Robot-Assisted Autism Therapy
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414315" title="Click to go to the Author Index">
             Shaldambayeva, Shyrailym
            </a>
           </td>
           <td class="r">
            Nazarbayev University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#400226" title="Click to go to the Author Index">
             Kassymbekov, Saparkhan
            </a>
           </td>
           <td class="r">
            Nazarbayev University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#174294" title="Click to go to the Author Index">
             Sandygulova, Anara
            </a>
           </td>
           <td class="r">
            Nazarbayev University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#173492" title="Click to go to the Author Index">
             Shintemirov, Almas
            </a>
           </td>
           <td class="r">
            Nazarbayev University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3912" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robot-Assisted Autism Therapy (RAAT) is becoming increasingly popular due to its ability to enhance therapeutic outcomes for children with autism spectrum disorders (ASD). RAAT offers consistent, personalized, and engaging interventions, complementing traditional therapies and supporting social and cognitive development. However, the rising use of RAAT also brings challenges for therapists, who must make real-time, personalized decisions during sessions. This demands a deep understanding of individual needs and effective strategies, placing significant cognitive pressure on therapists.
             <p>
              To address these challenges, our research aims to develop an AI-driven RAAT system that supports therapists by assisting with decision-making during sessions. By analyzing real-time data and leveraging prior knowledge, the AI system can suggest appropriate interventions and adapt strategies to each childâ€™s specific needs. In this study we apply Deep Active Inference (dAIF) model to enable the robot to learn and improve its interventions over time, enhancing the effectiveness of RAAT. The proposed approach aims to ultimately offer a more personalized and dynamic therapeutic experience for children with ASD.
             </p>
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frpi7t3">
             <b>
              FrPI7T3
             </b>
            </a>
           </td>
           <td class="r">
            Room 3
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frpi7t3" title="Click to go to the Program at a Glance">
             <b>
              Mobile Robotics
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#118310" title="Click to go to the Author Index">
             Kyung, Ki-Uk
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science &amp; Technology (KAIST)
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t3_01">
             15:30-16:30, Paper FrPI7T3.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3800'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Training Self-Localization Models for Unseen Unfamiliar Places Via Teacher-To-Student Data-Free Knowledge Transfer
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396158" title="Click to go to the Author Index">
             Tsukahara, Kenta
            </a>
           </td>
           <td class="r">
            University of Fukui
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109542" title="Click to go to the Author Index">
             Tanaka, Kanji
            </a>
           </td>
           <td class="r">
            University of Fukui
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372078" title="Click to go to the Author Index">
             Iwata, Daiki
            </a>
           </td>
           <td class="r">
            University of Fukui
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3800" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#continual_learning" title="Click to go to the Keyword Index">
               Continual Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A typical assumption in state-of-the-art self-localization models is that an annotated training dataset is available in the target places. However, this is not always the case when a robot operates in a general open-world environment. This study introduces a novel training scheme for open-world distributed robot systems. In our scheme, a robot (â€œstudentâ€) can seek guidance from other robots it encounters in unfamiliar places (â€œteachersâ€). Specifically, a pseudo-training dataset is reconstructed from the teacher model and is subsequently used for continual learning of the student model. Unlike typical knowledge transfer schemes, our method makes only minimal assumptions about the teacher model, allowing it to handle various types of open-set teachers, including uncooperative, untrainable (e.g., image retrieval engines), and black box teachers (i.e., data privacy). Instead of relying on the availability of private data from teachers as in existing methods, we leverage a universally applicable assumption in self-localization tasks: â€œThe teacher model is a self-localization systemâ€ and reuse the teacherâ€™s self-localization system as the sole accessible communication channel. We particularly focus on designing an excellent student/questioner whose interactions with teachers can generate effective question-and-answer sequences, which can be used as pseudo-training datasets for the student self-localization model. When applied to a generic recursive knowledge distillation scenario, our approach demonstrated stable and consistent performance improvement.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t3_02">
             15:30-16:30, Paper FrPI7T3.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3826'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Comparison of Path Following Performance in Autonomous Vehicles Using Model Predictive Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#409208" title="Click to go to the Author Index">
             Choi, KangHyeon
            </a>
           </td>
           <td class="r">
            University of Seoul
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414027" title="Click to go to the Author Index">
             Lee, Taegyeom
            </a>
           </td>
           <td class="r">
            University of Seoul
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413845" title="Click to go to the Author Index">
             Jo, Sung Bin
            </a>
           </td>
           <td class="r">
            University of Seoul
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413837" title="Click to go to the Author Index">
             Moon, DongWook
            </a>
           </td>
           <td class="r">
            University of Seoul
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413850" title="Click to go to the Author Index">
             Choi, KyuHwan
            </a>
           </td>
           <td class="r">
            Univeristy of Seoul
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#401768" title="Click to go to the Author Index">
             Choi, JungHyun
            </a>
           </td>
           <td class="r">
            University of Seoul
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100369" title="Click to go to the Author Index">
             Hwang, Myun Joong
            </a>
           </td>
           <td class="r">
            University of Seoul
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3826" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In autonomous vehicles, minimizing the lateral error from the path is important for safety driving. Algorithms such as Pure Pursuit and Stanley method are widely used in path following. However, they do not consider vehicle dynamics, which results in reduced path-following accuracy. Model Predictive Control(MPC) can consider dynamic model. Comparison of MPC, Pure Pursuit, and Stanley method are evaluated to verify impact of dynamic motion.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t3_03">
             15:30-16:30, Paper FrPI7T3.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Enhancing OCR-Based Indoor Place Recognition with Visitor Map Image by Mitigating Noise from Distracting Words
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385768" title="Click to go to the Author Index">
             Lee, Chaehyeuk
            </a>
           </td>
           <td class="r">
            KC
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391769" title="Click to go to the Author Index">
             Jinmyoung, Lee
            </a>
           </td>
           <td class="r">
            KC-ML2
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#152168" title="Click to go to the Author Index">
             Zaheer, Sheir Afgen
            </a>
           </td>
           <td class="r">
            KC Machine Learning Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392102" title="Click to go to the Author Index">
             Lee, Seula
            </a>
           </td>
           <td class="r">
            ML2
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391781" title="Click to go to the Author Index">
             Park, Chan Y.
            </a>
           </td>
           <td class="r">
            KC
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t3_04">
             15:30-16:30, Paper FrPI7T3.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3836'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Incorporating Road Topography and Bank Angle Estimation in Model Predictive Control for Enhancing Path Tracking Accuracy and Stability of Autonomous Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414103" title="Click to go to the Author Index">
             Choi, Jeongmin
            </a>
           </td>
           <td class="r">
            DGIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398769" title="Click to go to the Author Index">
             Choi, Joonyoung
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340162" title="Click to go to the Author Index">
             Lim, Sungjin
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology (DGIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#320517" title="Click to go to the Author Index">
             Sadiq, Bilal
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#279782" title="Click to go to the Author Index">
             Lim, Yongseob
            </a>
           </td>
           <td class="r">
            DGIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3836" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#process_control" title="Click to go to the Keyword Index">
               Process Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study enhances Model Predictive Control (MPC) by integrating road topography to improve vehicle stability. Using Nonlinear MPC, it accounts for vehicle dynamics like road curvature and bank angle, estimating bank angle with an Extended Kalman Filter. Stability is further ensured with sideslip and ZMP constraints. Results confirm that this integration significantly improves path tracking accuracy and stability.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t3_05">
             15:30-16:30, Paper FrPI7T3.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3840'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Spatially Unconstrained Vehicle-In-The-Loop Testing Method for Autonomous Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413308" title="Click to go to the Author Index">
             Shim, Youngbo
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413313" title="Click to go to the Author Index">
             Bae, Jiyeon
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413442" title="Click to go to the Author Index">
             Jung, Howon
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute (KETI)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413314" title="Click to go to the Author Index">
             Hyun, Sang Hwa
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414149" title="Click to go to the Author Index">
             Giho, Sung
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3840" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             With the advancement of autonomous vehicle levels, the complexity of the autonomous driving system has increased, and verification methods have also become more sophisticated. Traditionally, simulation-based testing methods such as SIL (Software-In-the-Loop) and HIL (Hardware-In-the-Loop), which involve not only simulation but also hardware setups for steering, accelerator, and brake pedals, have been used to verify the functions and software of autonomous vehicles. However, there is a limitation when validating advanced driver assistance systems (ADAS) or autonomous driving functions in a virtual environment, as they do not fully reflect the dynamic characteristics of real vehicles. To address this, a testing method utilizing the VIL (Vehicle-In-the-Loop) system, which allows simulations in a virtual environment while reflecting the dynamic characteristics of actual vehicles, has emerged. VILS receives environmental information from the simulator, measures or estimates the position and posture of the real vehicle, and transmits it back to the simulator. This approach allows the simulation to incorporate the dynamics of the actual vehicle while receiving virtual environmental information from the simulator. Through this, scenarios with high collision risks can be safely tested, enabling function verification in a manner closest to real-world vehicle and environment testing, even in complex situations. Existing VILS methods for verifying autonomous driving functions mostly involve VILS setups where the virtual environment simulates a proving ground (PG) and the real vehicle is also on the PG. However, as testing in complex road environments is necessary, VILS can also be configured to simulate the environment and place the vehicle on real roads. In such cases, although the real road can be simulated in the virtual environment using a digital twin, one of the advantages of VILSâ€”ensuring the safety of the vehicle during testingâ€”cannot be guaranteed if the vehicle is on a real road, as collisions with other vehicles cannot be prevented. To address this issue, this paper proposes a method that digitally twins real roads in the virtual environment while positioning the vehicle on a PG instead of on a real road, thereby removing spatial constraints and considering both real and virtual environmental objects. The proposed method not only has all the advantages of VILS but also offers the benefit of being able to test various scenarios in complex environments like urban areas as autonomous driving levels increase. It allows testing to be conducted safely in a PG by eliminating the risk of collisions, while also enabling the virtualization of multiple test sites, rather than being limited to a single test site.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t3_06">
             15:30-16:30, Paper FrPI7T3.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3841'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Magnetic-Tracked Mobile Robot for Navigating Corrugated Container Ceiling
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#295103" title="Click to go to the Author Index">
             Yi, Yesung
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#400487" title="Click to go to the Author Index">
             Kim, Jun Young
            </a>
           </td>
           <td class="r">
            Ujin Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#140412" title="Click to go to the Author Index">
             Kim, Younggeun
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#118310" title="Click to go to the Author Index">
             Kyung, Ki-Uk
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science &amp; Technology (KAIST)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3841" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#climbing_robots" title="Click to go to the Keyword Index">
               Climbing Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             To improve the efficiency of customs inspections, which typically involve time-consuming and labor-intensive manual work, robots have been developed to inspect containerized cargo. In this article, we present a magnetic-tracked mobile robot designed for navigating the corrugated container ceiling.To prevent overturning while maintaining sufficient adhesion and contact area of tracks, we developed auxiliary wheels based on static force analysis and finite element method (FEM) simulations. These auxiliary wheels allow the robot to move with two degrees of freedom (DOFs), including translation and rotation. Performance evaluation experiments demonstrate that the proposed robot can travel linearly exceeding 0.1 m/s while carrying a load of 30 kg, and rotate beyond 23Â° exceeding 8.5 Â°/s and move diagonally while carrying a load of 15 kg on the corrugated container ceiling.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t3_07">
             15:30-16:30, Paper FrPI7T3.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3842'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Failure Event-Driven Scenario Reconstruction for Autonomous Vehicles: Enhancing Realism through Data Correction in Virtual Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413314" title="Click to go to the Author Index">
             Hyun, Sang Hwa
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413313" title="Click to go to the Author Index">
             Bae, Jiyeon
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413442" title="Click to go to the Author Index">
             Jung, Howon
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute (KETI)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414166" title="Click to go to the Author Index">
             Lee, Seonyoung
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413308" title="Click to go to the Author Index">
             Shim, Youngbo
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3842" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             At present, it has become common to test autonomous driving system in the simulator due to its efficiency, low cost and high safety. To test in simulator, users need to define scenarios that simulate driving situations. What is importance here is that the defined scenarios should closely resemble the real driving situations. Recently, to generate more realistic scenarios, actual logged data based scenario generation and testing methods have also been introduced. However, most of real driving situations are normal, and situations that lead to system failures are only a small portion of these. Therefore, it is necessary to select significant situations from the logged data to generate meaningful scenarios from actual driving data. Additionally, if errors occur in the perception system, such as tracking lost, issues can arise in the generated scenarios, like obstacle blinking or vehicle model changing. In this study, we introduce failure event logging system and motion based obstacle matching and trajectory interpolation method to solve above issues. First, failure event logging system logs only the situations where the failure events occur during autonomous driving. It constantly stores the raw data in buffer and once autonomous status is changed by driver override or a system failure, the system merges next few seconds data with the past data into one log file. Next, to correct short-term tracking loss, we predict recently disappeared obstacleâ€™s position and heading based on constant turn rate and velocity (CTRV) motion and match it with newly appeared obstacle. After matching, we interpolate the disappeared part of obstacleâ€™s trajectory by applying spline interpolation. For this, we extract control points from the obstacleâ€™s predicted trajectory. With the above two methods, we then extract trajectories of ego vehicle and surrounding obstacles and apply transformation to convert the trajectories into the coordinate system of the HD Map defined in the ASAM OpenDRIVE format. Then, we finally generate meaningful and real-data based scenarios in ASAM OpenSCENARIO format and test them in our own simulator. Through this process, we can concentrate on the driving situation where our autonomous system is weak and improve our system. Our work can only generate one scenario from one log file. So, in the future, we will reveal the feature that causes the failure event and generate different version of the scenario by adjusting feature parameters. Also we will analyze the potential of generative AI to create multiple test scenarios from one logged data and scenario. If possible, it is expected that a large number of scenarios can be obtained from a single logged data.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t3_08">
             15:30-16:30, Paper FrPI7T3.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3843'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Spatially Coherent Costmap: A Weakly Supervised Pipeline for Outdoor Traversability
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389724" title="Click to go to the Author Index">
             Thomas, Guillaume
            </a>
           </td>
           <td class="r">
            ENSTA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389556" title="Click to go to the Author Index">
             Bouchabou, Damien
            </a>
           </td>
           <td class="r">
            ENSTA IP Paris
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396833" title="Click to go to the Author Index">
             Ravaud, Tom
            </a>
           </td>
           <td class="r">
            ENSTA Paris
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103035" title="Click to go to the Author Index">
             Filliat, David
            </a>
           </td>
           <td class="r">
            ENSTA ParisTech
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350983" title="Click to go to the Author Index">
             Chapoutot, Alexandre
            </a>
           </td>
           <td class="r">
            ENSTA Paris
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3843" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#big_data_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Big Data in Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Terrain perception is crucial for autonomous navigation, especially in off-road environments where terrain variability can pose challenges. Beyond simple obstacle avoidance, autonomous navigation can benefit from finer terrain traversability analysis. We introduce a novel method for creating terrain traversability maps, bringing benefits in terms of navigation safety and efficiency. The challenge of defining and manually annotating terrain traversability advocates for the use of limited annotations. Our method introduces a new weakly supervised approach with Siamese Networks to estimate trajectory cost from IMU and a generic Segmentation model to extend this annotation to full images. This methodology overcomes data sparsity and the limitations of existing formulas that struggle with simple terrain discrimination (like gravel vs road) while keeping very low annotation effort.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t3_09">
             15:30-16:30, Paper FrPI7T3.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3849'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Line Segment-Based SLAM Using Downward Perspective Images in Indoor Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414180" title="Click to go to the Author Index">
             Kim, Dongwoo
            </a>
           </td>
           <td class="r">
            Keimyung University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#223911" title="Click to go to the Author Index">
             Hong, Seonghun
            </a>
           </td>
           <td class="r">
            Keimyung University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3849" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurate localization and mapping are crucial capabilities for the efficient and safe operation of autonomous mobile robots in indoor environments where GPS signals are unavailable. Because dead reckoning using proprioceptive sensors is vulnerable to accumulated drift errors, geometric feature information found in the operational environments is typically utilized to correct the drift errors and precisely estimate the pose of mobile robots. In this study, a monocular camera obliquely tilted in a downward direction is considered as an environmental perception sensor to simultaneously perform obstacle avoidance and ground surface inspection. In particular, this study proposes a monocular vision-based SLAM algorithm that utilizes the pose information extracted from line segment features in the downward perspective images. The effectiveness of the proposed method is demonstrated through experimental results in an indoor environment using a mobile robot platform.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t3_10">
             15:30-16:30, Paper FrPI7T3.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3863'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Slip Detection and Relocalization Using LiDAR Data and Particle Filter in Autonomous Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414246" title="Click to go to the Author Index">
             Oh, Jun Seok
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414250" title="Click to go to the Author Index">
             Lee, Jong Hyuk
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414249" title="Click to go to the Author Index">
             Kim, Seong Kyeoung
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142861" title="Click to go to the Author Index">
             Kim, Min Young
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3863" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#domestic_robotics" title="Click to go to the Keyword Index">
               Domestic Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study presents a method to address the slip problem that occurs during indoor autonomous driving. The solution involves detecting slips using map feature points and LiDAR data, and then re-estimating the robot's position by increasing the covariance of the Particle Filter. Experiments were conducted in various environments, such as during turns, on thresholds, with unsecured rugs, and under external impacts. The results confirmed that slips can be effectively detected and the localization problem successfully resolved. It is hoped that this research will contribute to overcoming slip issues in autonomous robot research.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t3_11">
             15:30-16:30, Paper FrPI7T3.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3864'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GRU-Based Trajectory Tracking Controller Design for Autonomous Vehicles: A Data-Driven Approach to Stability and Performance
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336306" title="Click to go to the Author Index">
             Jin, Yongsik
            </a>
           </td>
           <td class="r">
            Electronics and Telecommunications Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398769" title="Click to go to the Author Index">
             Choi, Joonyoung
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#279782" title="Click to go to the Author Index">
             Lim, Yongseob
            </a>
           </td>
           <td class="r">
            DGIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3864" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study introduces a novel trajectory tracking controller design method for autonomous vehicles using a Gated Recurrent Unit (GRU) neural network. The method addresses challenges in vehicle dynamics modeling by replacing traditional physics based models with a GRU-based data-driven approach. The controller is designed through a two-step process, involving GRU training with data from a vehicle equipped with a PID controller and then using the trained GRU model to ensure system stability. Stability is guaranteed by formulating the stabilization criterion in terms of Linear Matrix Inequalities (LMIs). The effectiveness of this controller is demonstrated using the CarSim simulation tool, showing promising results for real-world application.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t3_12">
             15:30-16:30, Paper FrPI7T3.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3869'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Prototype Mobile Robot with a Passive Self-Balancing Mechanism
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#401082" title="Click to go to the Author Index">
             Ahmad, Huthaifa
            </a>
           </td>
           <td class="r">
            RIKEN Information R&amp;D and Strategy Headquarters, RIKEN, Kyoto, J
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#117967" title="Click to go to the Author Index">
             Nakamura, Yutaka
            </a>
           </td>
           <td class="r">
            RIKEN
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3869" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#domestic_robotics" title="Click to go to the Keyword Index">
               Domestic Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a robotic design that addresses the limitations of existing home robots to achieve harmonious coexistence with humans. By leveraging passive dynamics, our design incorporates a blend of features tailored for smooth integration into human-centric environments. The robot is self-balancing, compact, and lightweight, with an appropriate size, multi-modal communication, obstacle-surmounting, and a compliant body that ensures safe and natural physical interactions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t3_13">
             15:30-16:30, Paper FrPI7T3.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             NMPC-Based Smooth Path Planning with Snap Minimization for Wheeled Mobile Robot(WMR)
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#250340" title="Click to go to the Author Index">
             Kim, Sunhong
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106608" title="Click to go to the Author Index">
             Choi, Youngjin
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114046" title="Click to go to the Author Index">
             Won, Daehee
            </a>
           </td>
           <td class="r">
            Korea Institute of Industrial Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t3_14">
             15:30-16:30, Paper FrPI7T3.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3883'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Integrating Specialized and Generic Agent Motion Prediction with Dynamic Occupancy Grid Maps
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219840" title="Click to go to the Author Index">
             Asghar, Rabbia
            </a>
           </td>
           <td class="r">
            INRIA / Univ. Grenoble Alpes
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384038" title="Click to go to the Author Index">
             Liu, Wenqian
            </a>
           </td>
           <td class="r">
            Southeast University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#187177" title="Click to go to the Author Index">
             Rummelhard, Lukas
            </a>
           </td>
           <td class="r">
            INRIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107673" title="Click to go to the Author Index">
             Spalanzani, Anne
            </a>
           </td>
           <td class="r">
            INRIA / Univ. Grenoble Alpes
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101907" title="Click to go to the Author Index">
             Laugier, Christian
            </a>
           </td>
           <td class="r">
            INRIA
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3883" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#behavior_based_systems" title="Click to go to the Keyword Index">
               Behavior-Based Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurate prediction of driving scene is a challenging task due to uncertainty in sensor data, the complex behaviors of agents and possibility of multiple feasible futures. Existing prediction methods using Occupancy Grid Maps (OGMs) primarily focus on agent-agnostic scene prediction while agent-specific predictions provide specialized behavior insights with the available semantic information. In this work, we introduce a multi-task framework that leverages dynamic OGMs and semantic information to combine these two approaches. Our method not only focuses on predicting the behaviors of vehicle agents but also identifies other dynamic entities within the scene and anticipates their possible evolutions.	We employ deep-learning-based spatio-temporal and probabilistic approaches to predict the scene evolution as agent semantic grids, OGMs and future flow of the scene. Evaluation on the real-world NuScenes dataset demonstrates that the complementary grids significantly enhances prediction capabilities, enabling reliable predictions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t3_15">
             15:30-16:30, Paper FrPI7T3.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             TUM CONTROL: OpenÂ Source Controller-Vehicle in Loop SimulationÂ FrameworkÂ forÂ ultra-RapidÂ prototyping in Python
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398581" title="Click to go to the Author Index">
             Zarrouki, Baha
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#268360" title="Click to go to the Author Index">
             Betz, Johannes
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t3_16">
             15:30-16:30, Paper FrPI7T3.16
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3905'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DRIVE: Datasets for Research in Intelligent Vehicles and Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219093" title="Click to go to the Author Index">
             Berrio Perez, Julie Stephany
            </a>
           </td>
           <td class="r">
            ACFR - the University of Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#159718" title="Click to go to the Author Index">
             Shan, Mao
            </a>
           </td>
           <td class="r">
            The University of Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103694" title="Click to go to the Author Index">
             Worrall, Stewart
            </a>
           </td>
           <td class="r">
            University of Sydney
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3905" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Large, high-quality datasets are becoming more necessary as robotic perception systems become more dependent on machine learning (ML) approaches. In response, a collection of datasets has been created by the Australian Centre for Robotics (ACFR) to aid in the study of Connected and Autonomous Vehicles. These include: the V2X Dataset for advancing Vehicle-to-Everything (V2X) collaborative perception, the Australian NSW Dataset for 3D object detection, the Sydney semantic image semantic segmentation dataset, the Rural Areas AV Dataset for research on perception in challenging rural environments, the Cassowary Dataset for detecting underrepresented animal species from road side perspective, the road damage dataset for detecting road damage under different weather conditions. These tools are intended to facilitate the creation of machine learning models that can function in a variety of settings and improve the development of autonomous systems that are more dependable and safe.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frpi7t4">
             <b>
              FrPI7T4
             </b>
            </a>
           </td>
           <td class="r">
            Room 4
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frpi7t4" title="Click to go to the Program at a Glance">
             <b>
              Robot Learning and Vision
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#126893" title="Click to go to the Author Index">
             Tasaki, Tsuyoshi
            </a>
           </td>
           <td class="r">
            Meijo University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t4_01">
             15:30-16:30, Paper FrPI7T4.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3892'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Motion-Aware Data Generation: Incorporating Dynamic Object Kinematics in LiDAR Datasets
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413442" title="Click to go to the Author Index">
             Jung, Howon
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute (KETI)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413313" title="Click to go to the Author Index">
             Bae, Jiyeon
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413314" title="Click to go to the Author Index">
             Hyun, Sang Hwa
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#270601" title="Click to go to the Author Index">
             Son, Haengseon
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413308" title="Click to go to the Author Index">
             Shim, Youngbo
            </a>
           </td>
           <td class="r">
            Korea Electronics Technology Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3892" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the field of 3D object detection using LiDAR data, transfer learning has emerged as a crucial technique, enabling deep learning (DL) networks to leverage knowledge from rich source datasets. However, a persistent challenge arises when the LiDAR data used during deployment differs significantly from the source data utilized during the initial training phase. This discrepancy often necessitates a substantial amount of annotated target domain data to fine-tune the models, which is both expensive and time-consuming. To mitigate this issue, various self-training frameworks for unsupervised domain adaptation have been proposed. These frameworks allow models to generate pseudo-labels for objects in the target domain and use these labels to iteratively improve their own performance without the need for extensive human annotation.
             <p>
              One of the most notable self-training frameworks is MS3D++, which has experimentally proven that object detectors trained using its methodology can achieve state-of-the-art performance levels. The frameworkâ€™s effectiveness is largely due to its utilization of fused predictions from multi-frame pre-trained detectors combined with accumulated multi-frame LiDAR data. This approach enhances domain generalization and captures high-resolution details of objects. However, MS3D++ primarily accounts for ego-motion while largely ignoring the motion of dynamic objects within the scene. This oversight can lead to a degradation in the performance of object detectors, as the accumulation of multi-frame LiDAR data without considering dynamic object motion can introduce inaccuracies.
              <p>
               The objective of this study is to address this limitation by proposing a novel data synthesis methodology that explicitly incorporates the kinematic properties of dynamic objects. By considering in the motion of these objects, the proposed method significantly enhances the realism and quality of the generated datasets. This improvement is expected to have a profound impact on the training of object detectors, leading to models that are not only more accurate but also more robust across varying domain conditions. We believe that the enhanced realism of the datasets generated through this method will reduce the need for large-scale annotated data, while offering a more efficient pathway to achieve high-performance of 3D object detectors.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t4_02">
             15:30-16:30, Paper FrPI7T4.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3796'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Metric Scale Obstacle Distance Estimation Using 3D Map and Monocular Camera Based on the Semantic Segmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392676" title="Click to go to the Author Index">
             Higashi, Daijiro
            </a>
           </td>
           <td class="r">
            University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392739" title="Click to go to the Author Index">
             Kurake, Kotaro
            </a>
           </td>
           <td class="r">
            University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#126893" title="Click to go to the Author Index">
             Tasaki, Tsuyoshi
            </a>
           </td>
           <td class="r">
            Meijo University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3796" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Obstacle avoidance is important for autonomous driving. Metric scale obstacle detection by using a monocular camera for obstacle avoidance has been studied. In this study, metric scale obstacle detection means detecting obstacles and measuring the distance to them with a metric scale. We have already developed PMOD-Net which realizes metric scale obstacle detection by using a monocular camera and 3D map for autonomous driving. However, PMOD-Net's distance error of nonfixed obstacles which do not exist in 3D map is large. Accordingly, this study deals with the problem of improving distance estimation of nonfixed obstacles for obstacle avoidance. To solve the problem, we focused that PMOD-Net simultaneously performed object detection and distance estimation. We have developed a new loss function called â€œDifSegâ€. DifSeg is calculated from the distance estimation results on the nonfixed obstacle region which is defined based on the object detection results. Therefore, DifSeg makes PMOD-Net focus nonfixed obstacles during training. We evaluated the effect of DifSeg by using CARLA simulator, KITTI, and an original indoor dataset. The evaluation results showed that the distance estimation accuracy was improved on all datasets. Specially in the case of KITTI, the distance estimation error of our method was 2.419m, which was 1.259m less than the latest monocular depth estimation method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t4_03">
             15:30-16:30, Paper FrPI7T4.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3865'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Incremental Learning in Human-Robot Interaction Using Predictive Coding-Inspired Variational RNNs
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#308510" title="Click to go to the Author Index">
             Sawada, Hiroki
            </a>
           </td>
           <td class="r">
            Okinawa Institute of Science and Technology Graduate University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#173198" title="Click to go to the Author Index">
             Tani, Jun
            </a>
           </td>
           <td class="r">
            Okinawa Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3865" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#neurorobotics" title="Click to go to the Keyword Index">
               Neurorobotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Advancing Human-Robot Interaction (HRI) requires robots to learn and adapt from human guidance in ways that mimic human cognitive processes. This study introduces a novel approach using a Predictive Coding-inspired Variational Recurrent Neural Network (PV-RNN) based on the Free Energy Principle (FEP), a theory suggesting that the brain reduces uncertainty by predicting sensory inputs and continuously updating its internal models. Central to the FEP, predictive coding explains how the brain minimizes differences between prediction and observation. The PV-RNN leverages these principles, making it suitable for learning and adapting sequences over time, which is crucial for HRI. In this research, the PV-RNN was trained on four distinct cyclic movement patterns, forming the robotâ€™s foundational movement skills. During HRI, a human guided the robot to repeat these learned movements while introducing a new, fifth movement. This interaction enabled incremental learning, allowing the PV-RNN to expand its range of movements. We applied k-means clustering to the trajectories generated without human interference after each training phase to evaluate the number of distinct movement patterns learned. As more patterns were learned, a "blurring" effect emergedâ€”movements became less distinct and more variable. Initially, the movement patterns were clear and consistent, tightly grouped in terms of their characteristics. However, as the PV-RNN continued to learn and incorporate additional patterns, these movements began to spread out and overlap, suggesting that as more movements are learned, they may start to mix, potentially leading to the emergence of novel, creative patterns. The experimental process included several steps: (1) Initial training with four movement patterns; (2) Validation through autonomous generation and clustering analysis; (3) HRI sessions where the human introduced a novel movement; (4) Repetition of step (3) to reinforce learning; (5) Incremental training of the PV-RNN with the new trajectories from these interactions; and (6) Repetition of the validation and training process until memory saturation was observed. The results demonstrate that the PV-RNN, guided by the Free Energy Principle, can integrate up to ten different movement patterns through repeated human interaction without showing immediate signs of memory saturation or interference. PCA analysis suggests that learning additional patterns could eventually lead to mixing, possibly fostering the emergence of new movement patterns. The potential for memory saturation leading to creative pattern formation parallels human cognition, where blending learned experiences can generate new ideas or actions. This research marks a significant step toward developing robots capable of more human-like interactions, with promising applications in assistive robotics and creative collaborations.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t4_04">
             15:30-16:30, Paper FrPI7T4.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Reinforcement Learning for Shepherding Control in Multi-Robot Systems
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413272" title="Click to go to the Author Index">
             Napolitano, Italo
            </a>
           </td>
           <td class="r">
            Scuola Superiore Meridionale
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413416" title="Click to go to the Author Index">
             Lama, Andrea
            </a>
           </td>
           <td class="r">
            Scuola Superiore Meridionale
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413281" title="Click to go to the Author Index">
             De Lellis, Francesco
            </a>
           </td>
           <td class="r">
            University of Napoli Federico II
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#239678" title="Click to go to the Author Index">
             Di Bernardo, Mario
            </a>
           </td>
           <td class="r">
            University of Naples Federico II
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t4_05">
             15:30-16:30, Paper FrPI7T4.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3821'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Reliable Reinforcement Learning Framework for Multi-Agent Cooperation under Complex Mission Environment
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#224021" title="Click to go to the Author Index">
             Yoon, Sukmin
            </a>
           </td>
           <td class="r">
            Agency for Defense Development
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393757" title="Click to go to the Author Index">
             Park, Junho
            </a>
           </td>
           <td class="r">
            Agency for Defense Development
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105705" title="Click to go to the Author Index">
             Kim, Yong-Duk
            </a>
           </td>
           <td class="r">
            Agency for Defense Development
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3821" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This research proposes a framework for reinforcement learning and execution of multi agent systems. This research was conducted to address the reliability issues in real world grounding, the difficulty of learning itself, and the limitations of simulation limited to 2D grid environments, which have hindered the use of existing multi-agent reinforcement learning methods. By fusing commonly used rule-based and residual reinforcement learning methods with multi-head attention critic techniques, a reliable and scalable learning/execution framework has been proposed. For effective fusion between the two results, the trained deep neural network was proposed to obtain the weights for the sum of the two results. The proposed method has demonstrated its usefulness and performance through a convoy mission in a 3D continuous environment. Comparisons with rule based and pure reinforcement learning methods showed that the proposed method could better maintain the convoy target and ensure its reliability well.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t4_06">
             15:30-16:30, Paper FrPI7T4.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3827'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Reinforcement Learning Based Control for Robotic Flexible Element Disassembly
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396835" title="Click to go to the Author Index">
             Tapia Sal Paz, Benjamin
            </a>
           </td>
           <td class="r">
            IKERLAN
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#306044" title="Click to go to the Author Index">
             Sorrosal, Gorka
            </a>
           </td>
           <td class="r">
            IKERLAN
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#184055" title="Click to go to the Author Index">
             Mancisidor, Aitziber
            </a>
           </td>
           <td class="r">
            University of the Basque Country (UPV/EHU)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3827" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#intelligent_and_flexible_manufacturing" title="Click to go to the Keyword Index">
               Intelligent and Flexible Manufacturing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_control" title="Click to go to the Keyword Index">
               Force Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work investigates the application of Reinforcement Learning (RL) algorithms to enhance the adaptability and performance of robotic disassembly processes involving flexible elements. The RL-based control strategy is designed to execute Cartesian displacement actions on the robot's end effector, enabling precise manipulation. By developing an adaptive reward function, the system achieves generalization and robustness by effectively responding to changes in the elasticity of different components. This approach allows the robot to demonstrate a comprehensive understanding of disassembly tasks, adapting to different flexible elements and achieving successful extraction through low-force trajectories.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t4_07">
             15:30-16:30, Paper FrPI7T4.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3837'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Machine Vision AI-Based Parcel Detection for Automated Robotic Depalletization through Adaptive Boundary Detection Using 3D Vision
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389913" title="Click to go to the Author Index">
             Seongje, Kim
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389922" title="Click to go to the Author Index">
             KwangHee, Lee
            </a>
           </td>
           <td class="r">
            KITECH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#228417" title="Click to go to the Author Index">
             Yoon, Jonghun
            </a>
           </td>
           <td class="r">
            Hanyang University ERICA
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3837" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_manufacturing" title="Click to go to the Keyword Index">
               Computer Vision for Manufacturing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#logistics" title="Click to go to the Keyword Index">
               Logistics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurate detection of parcels as they are unloaded from trucks onto conveyor belts is always a challenging task due to the variety and complexity of how parcels are stacked. Existing methods have difficulty in classifying various shapes and surface patterns of unsorted parcels quickly and accurately. In this paper, we propose a parcel picking surface detection method based on deep learning and image processing for efficient unloading of various shapes of unsorted parcels. Our goal is to develop an image processing algorithm that recognizes boxes by highlighting their boundaries, regardless of the shape, pattern, or arrangement of the parcels. The key to this algorithm is to utilize RGB-D and AI techniques to detect box boundaries regardless of obstacles such as invoices, tape, or parcel surface patterns. When the gap between parcels is wide, image processing with depth maps can be used to detect parcels, but when the gap between parcels is narrow and boundary detection is difficult, we propose to use deep learning-based boundary detection with a deep learning-based YOLACT (You Only Look At Coefficients) model. This algorithm uses image segmentation techniques to efficiently predict boundary lines, which can accurately detect irregularly sized parcels with complex surface patterns. In addition, even for rotated parcels, the edges can be extracted through complex mathematical operations using the depth value at a given location, which can detect a wider surface of the rotated parcel. Finally, we verify the accuracy and real-time performance of the proposed method through various case studies, achieving mAP (50) of 93.8% and 90.8% for randomly sized and rotated parcels with different colors and patterns, respectively.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t4_08">
             15:30-16:30, Paper FrPI7T4.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3847'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Camera Projection Based Auto-Labeling Method for Transfer Learning of Depth CNNs
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413647" title="Click to go to the Author Index">
             Song, Chanho
            </a>
           </td>
           <td class="r">
            KMEDIhub
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3847" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#transfer_learning" title="Click to go to the Keyword Index">
               Transfer Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this study, we propose an transfer learning method based on auto-labeling for 3D object detection using depth images, targeting applications in Autonomous Mobile Robots (AMRs). The approach consists of two key components: auto-labeling applying pre-trained RGB CNNs alongside intrinsic and extrinsic parameters, and RGB-to-depth transfer learning using the auto-labeled data. For the auto-labeling process, pre-trained RGB CNNs (YOLOv7) trained on the COCO dataset is employed. With calibrated RGB and depth sensors, bounding boxes are generated in the RGB images using the pre-trained CNNs. The RGB pixel coordinates are mapped to depth pixel coordinates via inverse perspective projection, rigid transformation, and perspective projection, which automatically generates depth labels. Transfer learning is then performed on the auto-labeled depth dataset to train depth-based CNNs for direct object detection from depth images. Validation on depth images from the Freiburg RGB-D People dataset resulted in a precision of 0.743, recall of 0.856, and mAP@0.5 of 0.807. We expect that the proposed auto-labeling method can be applied to deep learning training in robotic vision.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t4_09">
             15:30-16:30, Paper FrPI7T4.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3859'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Movement Analysis for Activities of Daily Living Using Infrared Cameras: â€¨an Evaluation of Deep Learning Human Pose Estimation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#155041" title="Click to go to the Author Index">
             Nguyen, Sao Mai
            </a>
           </td>
           <td class="r">
            U2IS Ensta Paris
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414215" title="Click to go to the Author Index">
             Gan, Qi
            </a>
           </td>
           <td class="r">
            TÃ©lÃ©com Paris
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3859" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#gesture__posture_and_facial_expressions" title="Click to go to the Keyword Index">
               Gesture, Posture and Facial Expressions
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             For human activity analysis, while RGB videos accurately capture human activity, they raise privacy concerns. Conversely, InfraRed videos, while preserving privacy, are more ambiguous. This paper introduces a dataset comprising both IR and RGB videos of activities of daily living. We assess the feasibility of extracting human pose information from IR videos using state-of-the-art deep learning models by comparing results with those from RGB videos. Our experiments show that IR and RGB videos yield similar 3D pose sequences, with an average joint discrepancy of 122mm evaluated by PA-MPJPE.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t4_10">
             15:30-16:30, Paper FrPI7T4.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3868'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Deep Reinforcement Learning on Two-Wheeled Bipedal Robot: FlaminGO with Zero-Shot Sim2Real Transfer
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#409133" title="Click to go to the Author Index">
             Cho, Jaehyung
            </a>
           </td>
           <td class="r">
            POSTECH
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334373" title="Click to go to the Author Index">
             Kwon, Wookyong
            </a>
           </td>
           <td class="r">
            ETRI
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#139894" title="Click to go to the Author Index">
             Han, Soohee
            </a>
           </td>
           <td class="r">
            Pohang University of Science and Technology ( POSTECH )
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3868" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#transfer_learning" title="Click to go to the Keyword Index">
               Transfer Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a deep reinforcement learning (DRL) framework for controlling the two-wheeled bipedal robot, FlaminGO, using a sim-to-sim-to-real zero-shot transfer approach. Our method involves training in Isaac Lab and finetuning in MuJoCo, which enhances the robustness and adaptability of control policies before real-world deployment. This pipeline effectively bridges the reality gap, allowing FlaminGO to navigate and maintain stability across varied terrains without additional real-world training, demonstrating a significant improvement in zero-shot transfer for robotic control.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t4_11">
             15:30-16:30, Paper FrPI7T4.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3889'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Agile Maneuvers and Tactical Decisions: Multi-Agent Reinforcement Learning in Two-On-Two Air Combat
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384643" title="Click to go to the Author Index">
             Jung, Hoseong
            </a>
           </td>
           <td class="r">
            Agency for Defense Development
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3889" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we consider autonomous air combat for two-on-two engagements. Due to the need for precise and agile maneuvers, agents must not only learn complex and diverse individual tactical maneuvers but also consider cooperative movements that take into account the actions of their teammates. To tackle this challenge, we explore the multi-agent reinforcement learning framework for air combat. We first implement two-on-two air combat environments based on high-fidelity flight simulation environment. The intrinsic reward network is then proposed to maximize the influence of each agent on the other agents for generating cooperative tactical maneuvers. We also propose formation-based curriculum to enhance the efficiency and effectiveness of training. Extensive experimental results demonstrate the effectiveness of the proposed framework.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t4_12">
             15:30-16:30, Paper FrPI7T4.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Safe Deep Reinforcement Learning (RL) Agent Adapts the Cost Function Weights of a Weights-Varying MPC (WMPC)
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398581" title="Click to go to the Author Index">
             Zarrouki, Baha
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#268360" title="Click to go to the Author Index">
             Betz, Johannes
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t4_13">
             15:30-16:30, Paper FrPI7T4.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Deep Reinforcement Learning Driven Adaptive Stochastic and Robust NMPCs
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398581" title="Click to go to the Author Index">
             Zarrouki, Baha
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#268360" title="Click to go to the Author Index">
             Betz, Johannes
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t4_14">
             15:30-16:30, Paper FrPI7T4.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3910'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhancement of Reinforcement Learning Algorithm through Design of Deep Learning Networks for Jumping Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366655" title="Click to go to the Author Index">
             Kim, Hyeonjin
            </a>
           </td>
           <td class="r">
            Seoul National University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#111445" title="Click to go to the Author Index">
             Kim, Jinhyun
            </a>
           </td>
           <td class="r">
            Seoul National University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3910" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper aims to improve reinforcement learning performance by designing a deep learning network for robust control. The proposed network integrates a CNN for long-term input/output with an attention mechanism for short-term input/output. Its effectiveness was validated by comparing its performance with existing reinforcement learning methods in studies focused on robotic jumping motion.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t4_15">
             15:30-16:30, Paper FrPI7T4.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             A Two-Layered Approach to Situational Awareness System: Flexible Structure and Modular Algorithms
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#130223" title="Click to go to the Author Index">
             Choi, Hyun-Taek
            </a>
           </td>
           <td class="r">
            Korea Research Institute of Ships and Oceans Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#171826" title="Click to go to the Author Index">
             Park, Jeonghong
            </a>
           </td>
           <td class="r">
            KRISO
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104653" title="Click to go to the Author Index">
             Choi, Jinwoo
            </a>
           </td>
           <td class="r">
            KRISO, Korea Research Institute of Ships &amp; Ocean Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319846" title="Click to go to the Author Index">
             Kang, Minju
            </a>
           </td>
           <td class="r">
            KOREA RESEARCH INSTITUTE OF SHIPS &amp; OCEAN ENGINEERING
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361596" title="Click to go to the Author Index">
             Ha, Namhoon
            </a>
           </td>
           <td class="r">
            Korea Research Institute of Ships and Oceans Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#361718" title="Click to go to the Author Index">
             Choo, Ki-Beom
            </a>
           </td>
           <td class="r">
            KOREA RESEARCH INSTITUTE OF SHIPS &amp; OCEAN ENGINEERING(KRISO)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#162950" title="Click to go to the Author Index">
             Kim, Jinwhan
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#253183" title="Click to go to the Author Index">
             Ko, Nak Yong
            </a>
           </td>
           <td class="r">
            Chosun University
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frpi7t5">
             <b>
              FrPI7T5
             </b>
            </a>
           </td>
           <td class="r">
            Room 5
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frpi7t5" title="Click to go to the Program at a Glance">
             <b>
              Robot Manipulation
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#103731" title="Click to go to the Author Index">
             Mueller, Andreas
            </a>
           </td>
           <td class="r">
            Johannes Kepler University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t5_01">
             15:30-16:30, Paper FrPI7T5.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3854'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Human-Guidied Task Using VIEF Motion Planner for a Mobile Manipulator
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#401768" title="Click to go to the Author Index">
             Choi, JungHyun
            </a>
           </td>
           <td class="r">
            University of Seoul
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#401739" title="Click to go to the Author Index">
             Sagong, Uihun
            </a>
           </td>
           <td class="r">
            University of Seoul
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#409208" title="Click to go to the Author Index">
             Choi, KangHyeon
            </a>
           </td>
           <td class="r">
            University of Seoul
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414027" title="Click to go to the Author Index">
             Lee, Taegyeom
            </a>
           </td>
           <td class="r">
            University of Seoul
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100369" title="Click to go to the Author Index">
             Hwang, Myun Joong
            </a>
           </td>
           <td class="r">
            University of Seoul
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3854" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#nonholonomic_mechanisms_and_systems" title="Click to go to the Keyword Index">
               Nonholonomic Mechanisms and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Mobile manipulators operating with humans require safety motion planning. However, the high degree of freedom of mobile manipulators makes safety motion planning challenge. Thus, a virtual impedance model is employed to consider safety and characteristics of the system. To account for the nonholonomic constraints, we convert the virtual impedance into a virtual impedance energy field(VIEF). The experiments validate that the mobile manipulator can conform with human intentions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t5_02">
             15:30-16:30, Paper FrPI7T5.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3866'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Gaze-Based Augmented Reality Interface for Fast Telemanipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#305467" title="Click to go to the Author Index">
             Lahoud, Marcel
            </a>
           </td>
           <td class="r">
            Italian Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#355853" title="Click to go to the Author Index">
             MoradiMaryamnegari, Hoomaan
            </a>
           </td>
           <td class="r">
            Free University of Bozen-Bolzano (Unibz)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#302442" title="Click to go to the Author Index">
             Marchello, Gabriele
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#160198" title="Click to go to the Author Index">
             D'Imperio, Mariapaola
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103731" title="Click to go to the Author Index">
             Mueller, Andreas
            </a>
           </td>
           <td class="r">
            Johannes Kepler University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#128184" title="Click to go to the Author Index">
             Cannella, Ferdinando
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3866" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#virtual_reality_and_interfaces" title="Click to go to the Keyword Index">
               Virtual Reality and Interfaces
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The use of gaze-based approaches for human-robot interaction is crucial for designing interfaces that understand user intentions and simplify the human effort required for telemanipulation. Previous frameworks often required multiple devices and voice commands. However, recent advancements in augmented reality interfaces and head-mounted devices embedded with many sensors have reduced the need for additional hardware. This paper introduces an intuitive gaze-based augmented reality interface for fast human-robot collaboration with minimal hardware requirements. We integrate a set of telemanipulation elements that have not previously been combined in a single interface and compare them with a traditional kinesthetic interaction approach focused on fast interactions. Experiments are conducted using a real UR5e robot controlled at 500Hz and a HoloLens 2 Headmounted Device. Experimental results from expert and non-expert users to study the effect of proficiency on task completion time and success rate are compared. Moreover, at the end of our work we study the burden operators felt during the telemanipulations and garther insights for future works.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t5_03">
             15:30-16:30, Paper FrPI7T5.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3811'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Object Detection by Selecting Anomaly Detection for Product Arrangement
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393365" title="Click to go to the Author Index">
             Kondo, Ryota
            </a>
           </td>
           <td class="r">
            Meijo University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#126893" title="Click to go to the Author Index">
             Tasaki, Tsuyoshi
            </a>
           </td>
           <td class="r">
            Meijo University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3811" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Currently, labor shortage is a significant issue in retail stores, and there is a demand for automating product arrangement using robots. As shown in Fig. 1, there are infinite states of product to be arranged, such as upside down, misplacement and so on. Therefore, we regard products to be arranged as anomalies and detect them using anomaly detection Neural Network (NN). However, since the states of products to be arranged can exist in countless, even a high accurate anomaly detection NN like PatchCore[1] cannot detect all products to be arranged. On the other hand, there are anomaly detection NNs that can detect anomalies that PatchCore cannot detect, despite having lower accuracy than PatchCore. Therefore, this study addresses the challenge of selectively using different anomaly detection NNs and aims to detect products to be arranged.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t5_04">
             15:30-16:30, Paper FrPI7T5.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3820'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Automated Microrobotic Manipulation Using Reconfigurable Magnetic Microswarms
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#280048" title="Click to go to the Author Index">
             Jiang, Jialin
            </a>
           </td>
           <td class="r">
            The Chinese University of HONG KONG
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#212278" title="Click to go to the Author Index">
             Yang, Lidong
            </a>
           </td>
           <td class="r">
            The Hong Kong Polytechnic University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#314840" title="Click to go to the Author Index">
             Hao, Bo
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#150750" title="Click to go to the Author Index">
             Xu, Tiantian
            </a>
           </td>
           <td class="r">
            Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#304535" title="Click to go to the Author Index">
             Wu, Xinyu
            </a>
           </td>
           <td class="r">
            SIAT
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103797" title="Click to go to the Author Index">
             Zhang, Li
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3820" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#automation_at_micro_nano_scales" title="Click to go to the Keyword Index">
               Automation at Micro-Nano Scales
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Micromanipulation has been widely applied in both industry and biomedicine. However, conventional macroscale robotics systems may lack flexibility in narrow and tortuous environments. To tackle this challenge, researchers have explored utilizing untethered microrobots to fulfill remote-controlled micromanipulation. In this work, we demonstrate that reconfigurable microswarms could be potential candidates for this task. By exploiting the various fluid fields of the multi-modal swarms, concise capture and release behaviors could be obtained. To improve the efficiency and accuracy of the manipulation, a finite state machine and several auxiliary algorithms are designed to achieve autonomy and extend the application scenarios. This work provides a new tool for micromanipulation task, and extends the application potential for swarm microrobotics.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t5_05">
             15:30-16:30, Paper FrPI7T5.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3823'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Adaptable Robotic Grasping and Actuation through Discrete Variable Stiffness Mechanisms
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#140522" title="Click to go to the Author Index">
             Gan, Dongming
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3823" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#compliant_joints_and_mechanisms" title="Click to go to the Keyword Index">
               Compliant Joints and Mechanisms
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Compliant mechanisms and structures have high flexibility and adaptability to various application scenarios with uncertainties and condition changes. Stiffness change is essential to enable adaptability in applications in airplane wing morphing for efficient flight, variable-stiffness actuation for safe human-robot interaction, adaptable robotic grasping, robotic exoskeletons, walking robots, and robotics surgery. How to systematically design variable stiffness functions to match those application needs is a challenging research problem. This poster presents the concept of discrete variable stiffness design concept with its applications to compliant grippers for flexible grasping, soft actuators/exoskeletons for rehabilitation, compliant actuators and links for safe human-robot interaction through latest research results.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t5_06">
             15:30-16:30, Paper FrPI7T5.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3828'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Study on High Payload Gripper with Woven Structure According to Strip Material Properties
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319757" title="Click to go to the Author Index">
             Kang, Gyeongji
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413233" title="Click to go to the Author Index">
             Choe, Junpil
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#156028" title="Click to go to the Author Index">
             Lee, Dae-Young
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#224033" title="Click to go to the Author Index">
             Song, Kahye
            </a>
           </td>
           <td class="r">
            Korea Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3828" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the domain of robotics, extensive research has been dedicated to the exploration and refinement of various gripper designs to facilitate efficient object manipulation. Recent advancements in this field have prioritized the development of grippers capable of seamlessly integrating stiffness and flexibility characteristics. This study was undertaken with the objective of augmenting both payload capacity and flexibility in grippers through the utilization of woven structures. By examining performance variations associated with the incorporation of PET and TPU-bonded fabric materials, particular emphasis is placed on elucidating the pivotal role of material selection in optimizing weaving gripper efficacy. The various material properties could lead to grippers with properties such as flexibility and stiffness, which showed the potential for applications in diverse fields such as agriculture, space, and industry. It is anticipated that through the exploration of weaving grippers employing materials with diverse properties, this research will contribute to the expansion of applicability across various domains, thereby advancing the state-of-the-art in robotic manipulation systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t5_07">
             15:30-16:30, Paper FrPI7T5.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3853'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              In-Situ Pose Estimation of an Industrial Manipulator with a 2D Laser Profiler
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392333" title="Click to go to the Author Index">
             Chen, Tao
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392334" title="Click to go to the Author Index">
             Liu, Jia-Xin
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392322" title="Click to go to the Author Index">
             Tsai, Yao-Yang
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123193" title="Click to go to the Author Index">
             Lin, Pei-Chun
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3853" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#calibration_and_identification" title="Click to go to the Keyword Index">
               Calibration and Identification
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#engineering_for_robotic_systems" title="Click to go to the Keyword Index">
               Engineering for Robotic Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This research presents a two-step method for in-situ estimation of the tool center point (TCP) pose, involving the sequential solving of orientation and position, using a single scan of a four-plane gauge with a 2D Laser Profiler (LPF). The method is based on a mathematical model of the geometrical constraints provided by the four-plane gauge and the profile data obtained from real-time scanning using the LPF. To design a suitable gauge, sensitivity analysis of the impact of dimensional errors on pose calculation was conducted via simulation, and the performance of an optimal gauge geometry was validated through experiments. Additionally, the method allows the LPF to apply widely used hand-eye calibration algorithms typically employed by CCD cameras. This capability was further demonstrated by comparing the calibration results with measurements from an optical motion capture system, VICON, highlighting the methodâ€™s potential applicability in the field robot vision calibration.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t5_08">
             15:30-16:30, Paper FrPI7T5.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3858'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RIM Hand: Design of a Robotic Hand Based on Human Anatomy
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392088" title="Click to go to the Author Index">
             Lee, Joon
            </a>
           </td>
           <td class="r">
            Sogang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414214" title="Click to go to the Author Index">
             Han, Jeongyoon
            </a>
           </td>
           <td class="r">
            Sogang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#179932" title="Click to go to the Author Index">
             Jeong, Seokhwan
            </a>
           </td>
           <td class="r">
            Mechanical Eng., Sogang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3858" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#prosthetics_and_exoskeletons" title="Click to go to the Keyword Index">
               Prosthetics and Exoskeletons
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#biomimetics" title="Click to go to the Keyword Index">
               Biomimetics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study presents the development of the RIM Hand, a robotic hand designed to closely mimic the anatomical structures and functionalities of both the fingers and palm of the human hand. By accurately modeling the carpometacarpal (CMC) joint, this design facilitates naturalistic motion patterns that closely replicate those of the human hand. The RIM Hand incorporates detailed skeletal and muscular simulations to achieve a comprehensive range of motion (ROM), utilizing a tendon-driven mechanism with a rolling joint. Moreover, the overall dimensions of the RIM Hand (180 mm in height, 75 mm in width, and 18 mm in depth) were determined based on anthropometric data from average Korean adults, thus ensuring a close approximation to the operational range of the human hand. This anatomy-based design process aims not only to capture the intricate movements of human fingers but also the versatile movements of the palm, thereby advancing the implementation of essential human hand movements. The study envisions the creation of a robotic hand capable of biomimicking the sophistication and dexterity of the human hand.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t5_09">
             15:30-16:30, Paper FrPI7T5.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             DISG: Driving-Integrated Spherical Gear Enables Singularity-Free Full-Range Joint Motion
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#267777" title="Click to go to the Author Index">
             Liang, Guanqi
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#292813" title="Click to go to the Author Index">
             Zong, Lijun
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113090" title="Click to go to the Author Index">
             Lam, Tin Lun
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong, Shenzhen
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t5_10">
             15:30-16:30, Paper FrPI7T5.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Stacked Four-Bar Gripper Mechanism for Grasping Launcher Adapter Ring
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#235867" title="Click to go to the Author Index">
             Hong, Geun Young
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106608" title="Click to go to the Author Index">
             Choi, Youngjin
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114046" title="Click to go to the Author Index">
             Won, Daehee
            </a>
           </td>
           <td class="r">
            Korea Institute of Industrial Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t5_11">
             15:30-16:30, Paper FrPI7T5.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3888'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              UMAPS: An Application for Robotized Horizontal Directional Drilling
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397828" title="Click to go to the Author Index">
             Colazo, AgustÃ­n
            </a>
           </td>
           <td class="r">
            University Carlos III of Madrid
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#270397" title="Click to go to the Author Index">
             Salvador, Elisabeth Menendez
            </a>
           </td>
           <td class="r">
            Universidad Carlos III De Madrid
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#124032" title="Click to go to the Author Index">
             MartÃ­nez, Santiago
            </a>
           </td>
           <td class="r">
            Universidad Carlos III De Madrid
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105670" title="Click to go to the Author Index">
             Balaguer, Carlos
            </a>
           </td>
           <td class="r">
            Universidad Carlos III De Madrid
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3888" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robotics_and_automation_in_construction" title="Click to go to the Keyword Index">
               Robotics and Automation in Construction
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#software_architecture_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Software Architecture for Robotic and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#view_planning_for_slam" title="Click to go to the Keyword Index">
               View Planning for SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Nowadays, Geographic Information Systems (GIS) are widely adopted to assist the navigation of ground and aerial robots for many applications like agriculture and inspection, but these systems usually do not contribute to the up-keeping of these databases. This paper introduces the approach to integrating 3D GIS into the novel application uMAPS (underground mapping application) for planning and monitoring of underground horizontal directional drilling (HDD) works. The application is benefited by the sensing capabilities of the HDD ROBOSUB robot. It leverages the robot's mapping capabilities to update map information in shared data spaces.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t5_12">
             15:30-16:30, Paper FrPI7T5.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Exploring the Potential of Robotic Arms for Enhancing Interactions of People with ALS
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414322" title="Click to go to the Author Index">
             Zhou, Songchen
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414321" title="Click to go to the Author Index">
             Ando, Ryoichi
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414325" title="Click to go to the Author Index">
             Kawaguchi, Midori
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414326" title="Click to go to the Author Index">
             Armstrong, Mark
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#359029" title="Click to go to the Author Index">
             Barbareschi, Giulia
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414331" title="Click to go to the Author Index">
             Fu, Zening
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414298" title="Click to go to the Author Index">
             Hu, Zheng
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414334" title="Click to go to the Author Index">
             Ajioka, Toshihiro
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414335" title="Click to go to the Author Index">
             Yoshifuji, Ory
            </a>
           </td>
           <td class="r">
            Ory Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414336" title="Click to go to the Author Index">
             Ogino, Mikito
            </a>
           </td>
           <td class="r">
            University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414338" title="Click to go to the Author Index">
             Muto, Masatane
            </a>
           </td>
           <td class="r">
            WITH ALS General Incorporated Foundation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#124714" title="Click to go to the Author Index">
             Minamizawa, Kouta
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t5_13">
             15:30-16:30, Paper FrPI7T5.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Grasping Performance Comparison of Bell-Shaped Soft Suction Cup on Design Parameters
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#409056" title="Click to go to the Author Index">
             Choi, Jeongil
            </a>
           </td>
           <td class="r">
            Chonnam National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414365" title="Click to go to the Author Index">
             Park, Jiyeon
            </a>
           </td>
           <td class="r">
            Hanyang University ERICA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#345222" title="Click to go to the Author Index">
             Jang, Bumjin
            </a>
           </td>
           <td class="r">
            Hanyang University ERICA Campus
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#150612" title="Click to go to the Author Index">
             Hong, Ayoung
            </a>
           </td>
           <td class="r">
            Chonnam National University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t5_14">
             15:30-16:30, Paper FrPI7T5.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3913'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Development of a Two-Degree-Of-Freedom Wrist for the Wearable Haptic Interface
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383603" title="Click to go to the Author Index">
             Kim, Hongmin
            </a>
           </td>
           <td class="r">
            Yonsei University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#233343" title="Click to go to the Author Index">
             Yun, SeongSeop
            </a>
           </td>
           <td class="r">
            Yonsei Univercity
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#343315" title="Click to go to the Author Index">
             Park, Jong Hoon
            </a>
           </td>
           <td class="r">
            Yonsei University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109730" title="Click to go to the Author Index">
             Shin, Dongjun
            </a>
           </td>
           <td class="r">
            Yonsei University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3913" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#haptics_and_haptic_interfaces" title="Click to go to the Keyword Index">
               Haptics and Haptic Interfaces
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces the development of a compact two-degree-of-freedom (2-DOF) wrist exoskeleton designed for wearable haptic interfaces, aimed at providing enhanced orientation feedback to users. Given the complexity of the human wrist, which involves rotational axes intersecting in three directions, traditional human-machine interfaces (HMIs) often become bulky and heavy. To address this issue, our research focuses on developing a small, lightweight 2-DOF wrist exoskeleton that delivers effective haptic feedback while minimizing size and weight, thus overcoming the limitations of existing large and heavy HMIs.
             <p>
              Key design considerations include the selection of motors and gear ratios, motor placement, and structural design. For effective haptic feedback, we chose a gear ratio of 14:1, along with Maxon's EC-i brushless motors (45 W and 75 W) to ensure adequate torque and manipulability. Motor placement was optimized by aligning the rotation axis of the interface with that of the human wrist and positioning the supination and pronation motors near the elbow to minimize the end-effector's weight. The range of motion (ROM) for each motor was mechanically limited to align with the human wrist's movement. A ring-shaped structure was incorporated to stabilize the forearm and enhance interface manipulability by preventing separation from the user's body.
              <p>
               The preliminary results, obtained by actually producing the device, indicate that we have developed a 2.8 kg two-degree-of-freedom wrist interface that can provide haptic feedback in the x, y, and z directions, as well as rotational directions. It has also been confirmed that operations can be performed smoothly and quickly and that it can be used in combination with other interfaces with additional degrees of freedom, such as in a simulation environment.
               <p>
                Through this, we aim to validate the effect of orientation feedback through task performance comparison. Additionally, we plan to evaluate manipulability in robots with joint configurations different from those of humans.
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t5_15">
             15:30-16:30, Paper FrPI7T5.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3809'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Data-Driven Spatiotemporal Tubes for Temporal Reach-Avoid-Stay Specifications
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339642" title="Click to go to the Author Index">
             Das, Ratnangshu
            </a>
           </td>
           <td class="r">
            Indian Institute of Science, Bangalore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#411499" title="Click to go to the Author Index">
             Basu, Ahan
            </a>
           </td>
           <td class="r">
            Indian Institute of Science
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#287363" title="Click to go to the Author Index">
             Jagtap, Pushpak
            </a>
           </td>
           <td class="r">
            Indian Institute of Science
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3809" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The paper considers the controller synthesis problem for general MIMO systems with unknown dynamics, aiming to fulfill the temporal reach-avoid-stay task, where the unsafe regions are time-dependent, and the target must be reached within a specified time frame. The primary aim of the paper is to construct the spatiotemporal tube using a data-driven approach and thereby devise a closed-form approximation-free control strategy to ensure that system trajectory reaches the target set while avoiding time-dependent unsafe sets. The proposed scheme utilizes a novel method involving spatiotemporal tubes to provide controllers that guarantee both system safety and reachability. In our data-driven framework, we translate the requirements of spatiotemporal tubes into a Robust Convex Program (RCP). To address the infeasibility of RCP caused by infinite constraints, we utilize the sampling-based Scenario Convex Program (SCP). Subsequently, we solve the SCP to generate the tube and closed-form controller for an unknown system, ensuring the temporal reach-avoid-stay specification. Finally, the effectiveness of the proposed approach is demonstrated through three case studies: an omnidirectional robot, a SCARA manipulator, and a magnetic levitation system.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frpi7t6">
             <b>
              FrPI7T6
             </b>
            </a>
           </td>
           <td class="r">
            Room 6
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frpi7t6" title="Click to go to the Program at a Glance">
             <b>
              Robot Sensing, Control and Algorithms
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#117967" title="Click to go to the Author Index">
             Nakamura, Yutaka
            </a>
           </td>
           <td class="r">
            RIKEN
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t6_01">
             15:30-16:30, Paper FrPI7T6.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3824'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Modelling Herding Behaviours: From Simulations to Human-Machine Teaming
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413236" title="Click to go to the Author Index">
             bin Kamruddin, Ayman
            </a>
           </td>
           <td class="r">
            Scuola Superiore Meridionale
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413600" title="Click to go to the Author Index">
             Lam, Christopher
            </a>
           </td>
           <td class="r">
            Macquarie University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#210739" title="Click to go to the Author Index">
             Patil, Gaurav
            </a>
           </td>
           <td class="r">
            Macquarie University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#381688" title="Click to go to the Author Index">
             Musolesi, Mirco
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#239678" title="Click to go to the Author Index">
             Di Bernardo, Mario
            </a>
           </td>
           <td class="r">
            University of Naples Federico II
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#211273" title="Click to go to the Author Index">
             Richardson, Michael
            </a>
           </td>
           <td class="r">
            Univeristy of Cincinnati
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3824" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#modeling_and_simulating_humans" title="Click to go to the Keyword Index">
               Modeling and Simulating Humans
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Herding tasks provide an excellent testbed on which to study models of human behaviour, as well as for developing intelligent artificial collaborative agents for human-machine teaming. This study examined the navigational strategies, movement trajectories and decision policies of human herders in various herding tasks, ranging from single-herder single-target to multi-agent multi-target scenarios. The first aim of the project was to understand and model how human herders manage to select and corral target agents into a designated containment zone, employing both simple and complex task contexts. The second aim was to design intelligent artificial agents that could complete the task collaboratively with human team-mates.
             <p>
              For single-herder single-target tasks, the study found that human herders followed a consistent sequence of approach and corral phases, regardless of initial positions. The behaviour of human herders was effectively captured using a low-dimensional, environmentally coupled dynamical perceptual-motor primitive (DPMP) model. Extending these findings to single-herder multi-target tasks, the herder demonstrated the ability to prioritize and sequentially corral multiple targets, with the DPMP framework successfully modelling these behaviours, once combined with an appropriate target selection decision policy. This latter target selection policy was derived from human data and validated on additional experiments.
              <p>
               In multi-human-herder multi-target scenarios, findings revealed that the above DPMP herding model could be effectively generalized to such scenarios, highlighting the scalability of the model. Moreover, artificial herders controlled by the DPMP model were able to dynamically adjust their strategies based on the positions and movements of multiple targets and other herders, showcasing the robustness of the model in handling increased task complexity.
               <p>
                Finally, our research findings also demonstrated that a system combining a simple DPMP navigation model with Deep Reinforcement Learning decision (target selection) policies for target selection could also generate artificial agents able to complete the task successfully alongside human participants in a realistic, human-like fashion.
                <p>
                 Collectively, these findings demonstrated the generalizability of DPMP models for the development of interactive artificial agents, with applications in collaborative human-machine teaming for interactive autonomous robots engaged in search and rescue missions and crowd control behaviours.
                </p>
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t6_02">
             15:30-16:30, Paper FrPI7T6.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3845'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhanced VCC with Adaptive Neighborhood Selection for Improved Covariance Calculation in GICP
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#349341" title="Click to go to the Author Index">
             Moon, Youngtae
            </a>
           </td>
           <td class="r">
            Pohang University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#359816" title="Click to go to the Author Index">
             Kwon, Wookyong
            </a>
           </td>
           <td class="r">
            Polaris3D
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#139894" title="Click to go to the Author Index">
             Han, Soohee
            </a>
           </td>
           <td class="r">
            Pohang University of Science and Technology ( POSTECH )
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3845" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents an enhancement to the Generalized Iterative Closest Point (GICP) algorithm by introducing a refined Voxelized Covariance Calculation (VCC) method with an adaptive neighborhood selection strategy. The proposed method addresses the limitations of traditional KDTree searches and fixed voxel size parameters by incorporating a more robust neighborhood selection to ensure adequate point sampling for covariance calculation. By dividing each voxel into 27 sub-voxels and categorizing points based on their spatial location (vertex, edge, face, center), the algorithm improves the stability and accuracy of point cloud registration. Experimental results on the KITTI dataset demonstrate significant performance improvements, making the proposed method highly suitable for real-time applications in SLAM.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t6_03">
             15:30-16:30, Paper FrPI7T6.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3861'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Study on a Generative Model of Motion and Observation for Situation-Dependent Motion Generation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393014" title="Click to go to the Author Index">
             Xu, Chenfei
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#147255" title="Click to go to the Author Index">
             Okadome, Yuya
            </a>
           </td>
           <td class="r">
            Tokyo University of Science
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101596" title="Click to go to the Author Index">
             Ishiguro, Hiroshi
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#117967" title="Click to go to the Author Index">
             Nakamura, Yutaka
            </a>
           </td>
           <td class="r">
            RIKEN
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3861" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In an unstructured environment, it is not easy to exhaustively enumerate situations a priori and design control laws. Many studies focus on transferring skills from humans to address these difficulties. In this paper, we constructed a generative model for a series of observations and actions collected during teleoperated robot control and a fundamental system that utilizes this model for autonomous mobile robot control in human coexisting environments. This model allows the mobile robot to roam automatically in an unstructured environment, actively responsive to all dynamic changes without manually assigned tasks. We also studied the framework that it interacts with human beings by imitating the recorded human behaviors. Our experiments show that the robot can perform the movements generated by the system in an indoor environment while avoiding collisions and exploring the area. It also shows that the robot imitates human behaviors and exhibits the ability to avoid dynamic obstacles robustly.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t6_04">
             15:30-16:30, Paper FrPI7T6.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3810'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Local-To-Global Feature Fusion for Robust Point Cloud Registration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350689" title="Click to go to the Author Index">
             Slimani, Karim
            </a>
           </td>
           <td class="r">
            Sorbonne UniversitÃ©, CNRS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#156400" title="Click to go to the Author Index">
             Achard, Catherine
            </a>
           </td>
           <td class="r">
            ISIR-Sorbonne UniversitÃ©
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#117023" title="Click to go to the Author Index">
             Tamadazte, Brahim
            </a>
           </td>
           <td class="r">
            CNRS
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3810" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a hybrid descriptor for 3D point matching and point cloud registration. It combines local geometric properties with learning-based feature propagation to describe the neighborhood structure of each point. The architecture first extracts prior geometric information by computing each pointâ€™s planarity, anisotropy, and omnivariance using Principal Component Analysis (PCA). This information is augmented by a descriptor based on normal vectors estimated by a triangle-based shape construction. The main contributions are summarised in the following: - Estimating a single normal vector for each point by weighting the normals of triangles formed with their nearest neighbors. - Using local PCA to compute a Local Reference Frame (LRF) and local geometric features such as anisotropy, omnivariance, and planarity are used to create a robust feature vector by combining them with 3D spatial coordinates. - Ensuring rotation invariant descriptors by projecting the normals into the LRFs. - Propagating descriptor information from local to global using KNN-based graphs and a textit{self-attention} mechanism.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t6_05">
             15:30-16:30, Paper FrPI7T6.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3815'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Preliminary Analysis of Synthetic-To-Real Domain Shifts in the Daily Action Recognition with KENT Benchmark for Service Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#300669" title="Click to go to the Author Index">
             Kim, Hyungmin
            </a>
           </td>
           <td class="r">
            Korea University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#348926" title="Click to go to the Author Index">
             Jeon, HoBeom
            </a>
           </td>
           <td class="r">
            Korea University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#110378" title="Click to go to the Author Index">
             Kim, DoHyung
            </a>
           </td>
           <td class="r">
            Electronics and Telecommunications Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#130395" title="Click to go to the Author Index">
             Kim, Jaehong
            </a>
           </td>
           <td class="r">
            ETRI
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3815" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#datasets_for_human_motion" title="Click to go to the Keyword Index">
               Datasets for Human Motion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this research, we investigate the effects of synthetic-to-real (S2R) domain shifts on action recognition models by proposing the KENT benchmark. The KENT benchmark includes three types of S2R domain shifts. The first, DS_{min}, has minimal S2R domain shifts by utilizing carefully designed KIST-SynADL and ETRI-Activity3D datasets, focusing on S2R domain shifts rather than other types of domain shifts. The second S2R domain shift is the S2R scene-debiased domain shift. We hypothesize that daily action recognition datasets can be biased towards scene information because scene-relevant action classes, such as washing hands and cooking, are dominant. The NTU RGB+D dataset is selected as DS_{1} for modeling the scene-debiased domain shift, as it is filmed in a single laboratory room. The third type is the hard case-comprehensive S2R domain shift. The Toyota Smarthome dataset is selected as DS_{2} in KENT. In DS_{2}, variations in viewpoint, occlusion, and transitions from short-term to relatively long-term videos occur. As a pilot analysis, we trained several widely known action recognition models with a subset of the KIST dataset (referred to as mini-KIST). From these results, several insights were gained. The X3D model outperforms the VideoSwinTransformer with only 10% of the parameters, achieving a 0.31% average performance improvement on comprehensive domain shifts. This reveals
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t6_06">
             15:30-16:30, Paper FrPI7T6.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3819'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Multi-Dimensional Spatial Informationization and Control Implementation Approach for 3D Mobility Management Platform
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392164" title="Click to go to the Author Index">
             Seongwon, Jo
            </a>
           </td>
           <td class="r">
            CLROBUR
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#270733" title="Click to go to the Author Index">
             Choi, Taein
            </a>
           </td>
           <td class="r">
            Clrobur Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391643" title="Click to go to the Author Index">
             Bae, Joon Ho
            </a>
           </td>
           <td class="r">
            Clrobur
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392131" title="Click to go to the Author Index">
             Pak, InKyu
            </a>
           </td>
           <td class="r">
            Clrobur
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3819" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#environment_monitoring_and_management" title="Click to go to the Keyword Index">
               Environment Monitoring and Management
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recently, the application areas of 3D Mobility have been continuously expanding, and it is being utilized in various industrial sectors. As the scope widens, traditional 2D-based ATM control systems fail to account for environmental variables associated with low-altitude mobility and can lead to human errors due to user-centric dependencies. To overcome these limitations, this proposal suggests an effective approach to urban air and traffic management based on point cloud-generated multidimensional spatial data. To digitize multidimensional spatial data, the concept of spatial vector points, defining elements such as location, terrain, and time, is introduced. Utilizing this well-defined spatial information, the proposal aims to validate and simulate various flight paths of unmannedvehicles, preventing accidents proactively and ensuring the realization of safe urban air traffic management.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t6_07">
             15:30-16:30, Paper FrPI7T6.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3822'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Necessity Feature Correspondence for Large-Scale Global Place Recognition and Relocalization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350111" title="Click to go to the Author Index">
             Kang, Kyeongsu
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350110" title="Click to go to the Author Index">
             Lee, Sibaek
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University (SKKU)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#209868" title="Click to go to the Author Index">
             Yu, Hyeonwoo
            </a>
           </td>
           <td class="r">
            SungKyunKwan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3822" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             To find the accurate global 6-DoF transform by feature matching approach, various end-to-end architectures have been proposed. However, existing methods have typically not considered the geometrical false correspondence of features, resulting in unnecessary features being involved in global place recognition and relocalization. In this paper, we introduce a robust correspondence estimation method by removing unnecessary features and highlighting necessary features simultaneously. To emphasize necessary features while disregarding unnecessary ones, we leverage the geometric correlation between two scenes represented in 3D LiDAR point clouds. We thus introduce the correspondence auxiliary loss that finds key correlations based on the point align algorithm, achieving end-to-end training of the proposed networks with robust correspondence estimation. Considering the ground with numerous plane patches can disrupt correspondence estimation by acting as an outlier, we propose a preprocessing step aimed at mitigating the influence of dominant plane patches from the perspective of addressing negative correspondences. Evaluation results on the dynamic urban driving dataset show that our proposed method can improve the performances of both global place recognition and relocalization tasks, highlighting the significance of estimating robust feature correspondence in these processes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t6_08">
             15:30-16:30, Paper FrPI7T6.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3870'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Observability-Aware Active Calibration of Multi-Sensor Extrinsics
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334426" title="Click to go to the Author Index">
             Wang, Jiang
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414274" title="Click to go to the Author Index">
             Kang, Yaozhong
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334429" title="Click to go to the Author Index">
             Fu, Linya
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237433" title="Click to go to the Author Index">
             Kong, He
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3870" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#calibration_and_identification" title="Click to go to the Keyword Index">
               Calibration and Identification
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robot_audition" title="Click to go to the Keyword Index">
               Robot Audition
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurate estimation of sensor extrinsic parameters is fundamental for advanced planning, control, and environmental perception in robotics. For calibrating multiple sensors (Lidarï¼Œmicrophone array, and wheel encoder) on a robot, we propose a framework that actively plans the robot trajectory in real time to improve the calibration accuracy. By optimizing the minimum eigenvalue of the Fisher information matrix, the framework generates a trajectory with strong observability using B spline curves and updates the sensor extrinsic parameters through Extended Kalman Filtering. Real-world experimental results demonstrate that the observability-aware active calibration method provides richer excitation to the sensor model and yields more accurate parameter estimates.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t6_09">
             15:30-16:30, Paper FrPI7T6.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3880'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Adaptive Impedance Control of Free-Floating Space Robot Capturing a Non-Cooperative Target
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414306" title="Click to go to the Author Index">
             Dal, Prasad
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology Jodhpur
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113621" title="Click to go to the Author Index">
             Shah, Suril Vijaykumar
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology Jodhpur
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3880" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#compliance_and_impedance_control" title="Click to go to the Keyword Index">
               Compliance and Impedance Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Space robots will play a crucial role in on-orbit operations like refuelling, servicing, and capture of debris. This paper focuses on capturing a non-cooperative target using a multi-link arm of a space robot and its impedance control. The most critical phase of the capturing operation by the robotic arm is the impact phase because improper contact may cause damage to the end effector, or the end effector and the target may move away from each other by the impact force. Moreover, the unknown parameter of the target complicates the system dynamics and enhances difficulty in achieving contact between the end effector and the target. Additionally, a target in space does not have any specific mountings to capture and necessitates accurate impedance characteristics to promise a soft impact. Such a non-cooperative target demands parameter estimation to achieve impedance control. We introduce an adaptive impedance control, in which impedance parameters are estimated to keep safe contact between the end effector and the target and reduce contact force. In a presented adaptive impedance control strategy, the end effector is assumed to be stiff, and a contact model is included to establish contact and reduce contact force. The impedance characteristics of the contact model need to be estimated as they depend upon the force applied by the target with unknown parameters. An estimation of the model parameters is obtained using the regressor form based on the relative motion states of the end effector and the target. The recursive least square method is used as an estimation method, and system states are obtained to keep contact with the target and reduce damage to the end effector.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t6_10">
             15:30-16:30, Paper FrPI7T6.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3891'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Evaluation of Autoencoder-Based Data Compression Techniques for Enhancing Communication Bandwidth Efficiency of Time Series Data
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#272973" title="Click to go to the Author Index">
             Joo, Subin
            </a>
           </td>
           <td class="r">
            Korea Institute of Machinery and Metals
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3891" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#big_data_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Big Data in Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this study, three types of autoencoders were developed to compress time series data by 50%, using Gated Recurrent Units (GRU), Temporal Convolutional Networks (TCN), and Full Convolutional Layers (CAE). The study focuses on the efficient transmission of robot joint monitoring data, including motor current, voltage, vibration, and temperature, to the main processing unit. The models were evaluated using metrics like Dynamic Time Warping (DTW), Correlation Coefficient, and Mean Absolute Error (MAE). The TCN-GRU and CAE-based algorithms demonstrated excellent reconstruction performance, preserving most of the original data characteristics while compressing by 50%. The GRU-based algorithm, while effective in restoring general patterns, showed weaknesses in handling sharp data changes and extraordinary data. All input data were normalized for consistent evaluation. This research suggests further exploration into hybrid compression methods, feature enhancement in reconstructed data, and new algorithms considering data dependencies and int-to-int compression.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t6_11">
             15:30-16:30, Paper FrPI7T6.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3907'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Stochastic Model Predictive Control of Space Robot in Pre-Capture Phase Using Sparse Gaussian Process
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#313162" title="Click to go to the Author Index">
             Chaudhary, Saurabh
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology, Jodhpur
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#313423" title="Click to go to the Author Index">
             Tripathy, Niladri Sekhar
            </a>
           </td>
           <td class="r">
            IIT Jodhpur
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113621" title="Click to go to the Author Index">
             Shah, Suril Vijaykumar
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology Jodhpur
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3907" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The growing interest in space exploration has increased the demand for in-orbit operations, ranging from satellite maintenance to debris removal. Satellites equipped with robotic arms have emerged as a promising solution for these tasks. During the target capture operation, the robotic arm faces uncertainties such as changes in dynamical parameters, joint friction, and external disturbances. This work focuses on the Model Predictive Control (MPC) of a free-floating space robot (FFSR) in the presence of uncertainties, using previous operational data estimated with the Sparse Gaussian Process (SGP), which offers low computational costs. Additionally, the FFSR base experiences attitude and position disturbances due to arm motion, which can be minimized using a reactionless constraint. We propose a Sparse Gaussian Process-based Stochastic Model Predictive Control (SGP-SMPC) with reactionless constraint to control the space robot subjected to uncertainties in the pre-capture phase. Numerical simulations are performed on a planar FFSR to validate the effectiveness of the SGP-SMPC approach.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t6_12">
             15:30-16:30, Paper FrPI7T6.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             A Multi-Axis Hybrid Levitation-Based Precision Positioning Stage
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101239" title="Click to go to the Author Index">
             Moheimani, S. O. Reza
            </a>
           </td>
           <td class="r">
            The University of Texas at Dallas
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#347154" title="Click to go to the Author Index">
             Kumar Singh, Vikrant
            </a>
           </td>
           <td class="r">
            The University of Texas at Dallas
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#347155" title="Click to go to the Author Index">
             Mahmoodi Nasrabadi, Hazhir
            </a>
           </td>
           <td class="r">
            The University of Texas at Dallas
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t6_13">
             15:30-16:30, Paper FrPI7T6.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3857'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Unknown Input Observer for Takagi-Sugeno Fuzzy Bilinear System with Input Disturbance
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#233469" title="Click to go to the Author Index">
             Yoneyama, Jun
            </a>
           </td>
           <td class="r">
            Aoyama Gakuin University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3857" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#neural_and_fuzzy_control" title="Click to go to the Keyword Index">
               Neural and Fuzzy Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             An estimation of the state variables for systems with disturbances is an important problem. In a practical situation, not all the state variables are measurable, and disturbance noises come into the system. Especially, it is difficult to estimate the state variables of complicated nonlinear systems with input disturbances. In this paper, observer design methods for a discrete-time Takagi-Sugeno fuzzy bilinear system with unknown inputs and input disturbances are proposed. Our observer filters out unknown input and estimates the state and input disturbance of the system. Since Takagi-Sugeno fuzzy bilinear system represents a quite large class of nonlinear systems, an unknown input observer that estimates the state and input disturbance of Takagi-Sugeno fuzzy bilinear system with unknown inputs and disturbances is essential in many engineering fields. Observer design has started with a parallel distributed observer(PDO), which is constructed with local linear observers and the appropriate grade of the membership functions. However, design conditions for PDO are very conservative. To overcome such disadvantage, non-PDO with multiple Lyapunov matrices technique is proposed to design our observer in this paper. Such a design method is based on a multiple Lyapunov function with a sum of the membership functions. This method drastically reduces the conservatism. To demonstrate the validity of our proposed observer design approach, an illustrative numerical example is provided. Lastly, we end with concluding remarks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t6_14">
             15:30-16:30, Paper FrPI7T6.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             2-DOF Tensegrity Sensor Mechanism with Dual Functionality As Universal Joint and Angle Sensor
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#243012" title="Click to go to the Author Index">
             Choi, Yuna
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#330774" title="Click to go to the Author Index">
             Lee, Daehun
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106608" title="Click to go to the Author Index">
             Choi, Youngjin
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t6_15">
             15:30-16:30, Paper FrPI7T6.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             CyberRunner: An Inexpensive Research and Education Robotics Platform
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219464" title="Click to go to the Author Index">
             Bi, Thomas
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#118138" title="Click to go to the Author Index">
             D'Andrea, Raffaello
            </a>
           </td>
           <td class="r">
            ETHZ
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frpi7t7">
             <b>
              FrPI7T7
             </b>
            </a>
           </td>
           <td class="r">
            Room 7
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frpi7t7" title="Click to go to the Program at a Glance">
             <b>
              Soft Robotics and Bioinspired Robotics
             </b>
            </a>
           </td>
           <td class="r">
            Teaser Session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#171243" title="Click to go to the Author Index">
             Shigemune, Hiroki
            </a>
           </td>
           <td class="r">
            Shibaura Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#193164" title="Click to go to the Author Index">
             Joe, Hyun-Min
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t7_01">
             15:30-16:30, Paper FrPI7T7.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3816'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design and Implementation of Planetary Gear-Based Pipe Cleaning Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#386917" title="Click to go to the Author Index">
             Jeong, Byeongchan
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102438" title="Click to go to the Author Index">
             Choi, Hyouk Ryeol
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3816" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Industrial pipes can become clogged with powdery waste, which can completely stop the production equipment connected to the pipes. Cleaning pipes is a very important task as this reduces productivity. Manual cleaning is difficult because pipes are complexly installed in spaces that are not easy to access. Additionally, because hazardous substances may exist inside the pipes, the work environment is not good as you may be exposed to dangerous situations. In this work, we solved the problem of powdery waste accumulating in pipes in front of the robot, making suction impossible. The brushes of the pipe cleaning robot rotate individually, and at the same time, the brush as a whole rotates around the sun gear. We designed a mechanism to adjust the angle of the brush, allowing for more effective cleaning than before. This mechanism breaks down large debris into smaller pieces, making them easier to remove. Additionally, by changing the brush angle, you can easily remove foreign substances stuck to the inner wall of the pipe. The goal of this research is to develop an autonomous pipe cleaning robot that can inspect and clean pipes, saving labor and ensuring maintenance in industrial sites.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t7_02">
             15:30-16:30, Paper FrPI7T7.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3852'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Formation Control of Multi-Agent System with Local Interaction and Artificial Potential Field
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414199" title="Click to go to the Author Index">
             Zhao, Luoyin
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#143631" title="Click to go to the Author Index">
             Yan, Zheping
            </a>
           </td>
           <td class="r">
            Harbin Engineering University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414207" title="Click to go to the Author Index">
             Wang, Yuqing
            </a>
           </td>
           <td class="r">
            Harbin University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#150817" title="Click to go to the Author Index">
             Yeow, Chen-Hua
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3852" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A novel local interaction control method (LICM) is proposed in this paper to realize the formation control of multi-agent system (MAS). A local leader follower (LLF) structure is provided by coupling the advantages of information consensus and leader follower frame, the agents can obtain the state information of the leader by interacting with their neighbours, which will reduce the communication overhead of the system and the dependence on a single node of the topology. In addition, the artificial potential field (APF) method is introduced to achieve obstacle avoidance and collision avoidance between agents. Inspired by the stress response of animals, a stress response mechanism-artificial potential field (SRM-APF) is proposed, which will be triggered when the local minimum problem of APF occurs. Ultimately, the simulation experiments of three formation shapes, including triangular formation, square formation and hexagonal formation, validate the effectiveness of the proposed method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t7_03">
             15:30-16:30, Paper FrPI7T7.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3830'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design of a 4-DoF Robot Leg with Dual Differential Gear Mechanisms for Amphibious Locomotion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#197940" title="Click to go to the Author Index">
             Ji, Won-Suk
            </a>
           </td>
           <td class="r">
            Kookmin University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396899" title="Click to go to the Author Index">
             Jang, JeongHwan
            </a>
           </td>
           <td class="r">
            Kookmin University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109773" title="Click to go to the Author Index">
             Cho, Baek-Kyu
            </a>
           </td>
           <td class="r">
            Kookmin University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3830" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes the design of a robot leg capable of both walking and swimming, with four degrees of freedom (4-DoF), leveraging a differential gear mechanism. The designed leg demonstrates the ability to perform trotting on land as well as swimming motions in the water. To reduce the torque required by the actuators, the four joints of the leg are designed in pairs using a differential gear mechanism. A quadrupedal walking robot is constructed using the designed leg, and experiments are conducted for both trotting and swimming motions. Analysis of the torque and angular velocity on the four joints during trotting and swimming motions reveals that the leg design with the applied differential gear mechanism enables more efficient torque utilization compared to the conventional single actuator - single joint approach used in underwater walking robots.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t7_04">
             15:30-16:30, Paper FrPI7T7.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3839'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Combination of CPG-RBFN-RL in Crawling-Quadruped Walking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414130" title="Click to go to the Author Index">
             Hu, Shengqiao
            </a>
           </td>
           <td class="r">
            Kyoungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372632" title="Click to go to the Author Index">
             Choe, Seongsig
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#170957" title="Click to go to the Author Index">
             Yi, Hak
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3839" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#passive_walking" title="Click to go to the Keyword Index">
               Passive Walking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Central Pattern Generators (CPGs) are instrumental in legged robot control due to their capability to produce rhythmic motions, ideal for consistent terrains. Leveraging the synergy between CPGs and reinforcement learning, we used the incremental DDPG-PI^BB algorithm to train the RBFN neuron weights, allowing us to mold the CPG to match any target trajectory. We deployed three unique control algorithms (direct, indirect, and semi-indirect) tailored for various terrains, training the robot's leg and joint trajectories. Integrating incremental DDPG and PI^BB, we honed trajectories across four motion directions in diverse simulated terrains. In our initial simulations, we mapped out foundational terrains and harnessed reinforcement learning to derive optimal joint trajectories, ensuring adaptability. Post-training, we engaged in a comprehensive analysis of our results, leading to the creation of a bespoke memory pool cataloging robot joint trajectories for specific terrains. This repository aims to bolster the robot's navigation in intricate real-world terrains. In these scenarios, we meticulously recorded data on terrain conditions and both external and internal proprioceptive feedback. To further refine our approach, we employed transfer learning, utilizing an estimator to fine-tune the CPG-RBFN joint trajectory weights, amplifying the robot's versatility across environments. Finally, the robot can walk steadily in the known training environment and can explore the unknown environment.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t7_05">
             15:30-16:30, Paper FrPI7T7.5
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Aircraft Skin Defect Inspection Using a Double Frame Climbing Robot and Deep Learning Algorithm
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#242497" title="Click to go to the Author Index">
             Wang, Congqing
            </a>
           </td>
           <td class="r">
            University of Aeronautics and Astronautics
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t7_06">
             15:30-16:30, Paper FrPI7T7.6
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3906'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Torque Reduction of 1-DOF Transformable Wheel with Spring Mechanism
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414191" title="Click to go to the Author Index">
             Lee, Jaebaek
            </a>
           </td>
           <td class="r">
            Pusan National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414311" title="Click to go to the Author Index">
             Park, Jaeseong
            </a>
           </td>
           <td class="r">
            Pusan National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#170859" title="Click to go to the Author Index">
             Kim, Youngsoo
            </a>
           </td>
           <td class="r">
            Pusan National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3906" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#methods_and_tools_for_robot_system_design" title="Click to go to the Keyword Index">
               Methods and Tools for Robot System Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             As the mobile service robot market rapidly expands, ensuring stable navigation across various environments has become crucial. In response to this challenge, significant research has focused on developing transformable wheel mechanisms that enhance robot mobility in structured environments. Notably, the STEP â…¡ platform, featuring
             <p>
              a 1-DOF RPRP-based transformable wheel, has demonstrated outstanding performance in overcoming obstacles while minimizing number of actuators. However, the platform encounters high maximum required torque due to torque fluctuations when overcoming obstacles. To address this issue, this study proposes a new spring mechanism designed to reduce the large torque variations that occur during the obstacle-overcombing process of the 1-DOF transformable wheel. The proposed spring mechanism effectively distributes the torque load during obstacle climbing, thereby reducing the maximum torque required by the motor, which enhances energy efficiency and improves the overall operational stability of the robot. To validate the effectiveness of the spring mechanism, a quasi-static analysis was conducted to evaluate the forces and moments acting on each joint and motor. MATLAB simulations were then performed to determine the optimal spring constant for the system's weight, resulting in an approximate 15% reduction in maximum torque. Following these simulations, the spring's physical properties were selected, and a detailed design was completed. Experimental
              <p>
               validation subsequently demonstrated a reduction of approximately 31% in maximum torque when overcoming a 300x100 mm step obstacle.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t7_07">
             15:30-16:30, Paper FrPI7T7.7
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3915'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design of a Soft Material Foot for Humanoid Robot to Reduce Ground Reaction Force
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#382126" title="Click to go to the Author Index">
             Lee, Jin-Deok
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#366412" title="Click to go to the Author Index">
             Kwon, Hyeokjun
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#273643" title="Click to go to the Author Index">
             Lee, Kyuman
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#193164" title="Click to go to the Author Index">
             Joe, Hyun-Min
            </a>
           </td>
           <td class="r">
            Kyungpook National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3915" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_robot_systems" title="Click to go to the Keyword Index">
               Humanoid Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_control" title="Click to go to the Keyword Index">
               Force Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this study, we designed a humanoid robot foot using soft materials that consider stiffness and damping properties. The proposed foot material is easy to implement, lightweight, and cost-effective. We designed the humanoid robot foot using two soft materials: SR18 (low stiffness, high damping) and SR55 (high stiffness, low damping). Three-dimensional walking experiments were conducted using a humanoid robot equipped with the designed foot. To verify the effectiveness of the designed humanoid robot foot, we examined the performance of the admittance controller and Zero-Moment-Point(ZMP) tracking performance. Through the experiments, the robot foot with SR18 reduced the maximum ground reaction force by 10% and showed a lower rate of change in ground-reaction- force(GRF) compared to the robot foot with SR55. In terms of admittance control performance, the robot foot with SR18 reduced the RMSE (Root Mean Square Error) of pitch torque by 13%, roll torque by 62.8%, and vertical ground reaction force by 31% compared to the robot foot with SR55. In terms of ZMP tracking performance, the robot foot with SR18 reduced the ZMP Y RMSE by 41.1% compared to the robot foot with SR55. The proposed humanoid robot foot can absorb GRF and dampen vibrations, thereby functioning as a mechanical filter. Additionally, it makes significant contributions to the design of humanoid robot feet that can achieve stable walking.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t7_08">
             15:30-16:30, Paper FrPI7T7.8
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3914'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Soft Wearable Robotic Suit with Gait Phase Estimation System Using Embedded Stretch Sensors and Incremental Phase Shift Estimation Method
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#414367" title="Click to go to the Author Index">
             Kim, Jeongmin
            </a>
           </td>
           <td class="r">
            Yonsei University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#233343" title="Click to go to the Author Index">
             Yun, SeongSeop
            </a>
           </td>
           <td class="r">
            Yonsei Univercity
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109730" title="Click to go to the Author Index">
             Shin, Dongjun
            </a>
           </td>
           <td class="r">
            Yonsei University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3914" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#wearable_robotics" title="Click to go to the Keyword Index">
               Wearable Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_modal_perception_for_hri" title="Click to go to the Keyword Index">
               Multi-Modal Perception for HRI
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we developed a soft wearable sensor system capable of estimating gait phase across a wide range of walking and running speeds, regardless of the wearer's body shape. Soft wearable robots are actively being researched for purposes such as rehabilitation due to their comfort and safety stemming from high flexibility. For soft wearable robots that assist basic human movements like walking to be used not only in rehabilitation but also in daily life, they must be able to adapt to a wide range of speeds, including both walking and running. Generally, wearable robots for gait assistance estimate the gait phase for control, necessitating a system that can estimate gait phase over a broad range of speeds. Moreover, the characteristics of soft wearables present a challenge, as the sensor's measurement environment can vary depending on the wearer's body shape. This study addresses these challenges from both hardware and algorithmic perspectives. From a hardware perspective, a stretch sensor, more suitable for soft wearable robots, was used instead of the commonly used encoders or IMUs, and artificial intelligence learning methods were employed to select sensor positions that effectively predict gait phase. On the algorithmic side, a preprocessing algorithm utilizing dynamic window size adjustment and normalization were applied to compensate for variations in sensor data due to walking speed and the wearer's body shape, and an Incremental Phase Shift Estimation Method was used to convert this data into gait phase. The gait phase estimated by the proposed system showed a consistent increase regardless of walking speed or the wearer's body shape, with a small error of approximately 3% on average as measured by RMSE. Additionally, while the system showed a similar level of error compared to systems using MLP or CNN for gait phase estimation, it had a shorter processing time, making it advantageous for real-time phase prediction.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t7_09">
             15:30-16:30, Paper FrPI7T7.9
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3814'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Biodegradable and Disposable Corrugated Self-Folding Origami Devices
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#344595" title="Click to go to the Author Index">
             Harada, Takuma
            </a>
           </td>
           <td class="r">
            Shibaura Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#344509" title="Click to go to the Author Index">
             Fukatsu, Yuki
            </a>
           </td>
           <td class="r">
            Shibaura Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376479" title="Click to go to the Author Index">
             Okamoto, Shuta
            </a>
           </td>
           <td class="r">
            Shibaura Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#171243" title="Click to go to the Author Index">
             Shigemune, Hiroki
            </a>
           </td>
           <td class="r">
            Shibaura Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3814" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes a biodegradable origami device that utilize self-folding technology for paper. We have developed a technique that enables paper to self-fold along printed lines by an inkjet printer. By alternating mountain and valley folds using self-folding technology, we had created a corrugated structure. The corrugated structure exhibits high rigidity in the out-of-plane direction and high extensibility in the in-plane direction. By folding the paper with an inkjet-printed electrode, we have developed two types of sustainable origami devices: a compression sensor and a stretchable sensor, both of which are introduced in this paper.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t7_10">
             15:30-16:30, Paper FrPI7T7.10
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3818'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Origami Amphibious Soft Robot with Omnidirectional Motion and Self-Sensing Obstacle Avoidance
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#321252" title="Click to go to the Author Index">
             Gong, Shoulu
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286126" title="Click to go to the Author Index">
             Zhang, Wen-Ming
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#321304" title="Click to go to the Author Index">
             Shao, Lei
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3818" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Self-sensing adaptability is the performance of high-level intelligence in biology and essential for soft robots to interact efficiently with their surroundings.Inspired by vertebrate animals supported by highly evolved backbones, this work presents an origami soft robot with a piezoelectric MFC sheet and special designed feet, the MFC sheet acts as the bionic spine and serves both supporting and sensing functions, endowing the origami soft robots with the ability of environmental self-sensing and adaption. We demonstrate that the soft robot can powerfully exercise different terrains and perform omnidirectional motion at different actuation frequencies from 1 Hz to 8 Hz. Supported by machine learning algorithms,the origami soft robot can accurately recognize the surrounding environments.We demonstrate an amphibious robot for robust multi-terrains transitions and autonomous obstacle avoidance.We envision that the proposed concept may serve as a building block for all-active soft robots with potential applications for future more intelligent machine-environment interactions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t7_11">
             15:30-16:30, Paper FrPI7T7.11
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3831'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Estimating Hysteresis through Tension Detection in Antagonistic Tendon-Sheath Mechanisms
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#412150" title="Click to go to the Author Index">
             Im, Hankyung
            </a>
           </td>
           <td class="r">
            Pusan National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#349815" title="Click to go to the Author Index">
             Kim, Minhyo
            </a>
           </td>
           <td class="r">
            Pusan National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#359748" title="Click to go to the Author Index">
             Zhang, Youqiang
            </a>
           </td>
           <td class="r">
            Pusan National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#426851" title="Click to go to the Author Index">
             Kim, Taehoon
            </a>
           </td>
           <td class="r">
            Pusan National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#426852" title="Click to go to the Author Index">
             Mun, Jongchan
            </a>
           </td>
           <td class="r">
            Pusan National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#426853" title="Click to go to the Author Index">
             Park, Kyuna
            </a>
           </td>
           <td class="r">
            Pusan National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#145436" title="Click to go to the Author Index">
             Jin, Sangrok
            </a>
           </td>
           <td class="r">
            Pusan National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3831" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The tendon-sheath mechanism (TSM), a principal method for transferring motion from remote actuators to the end-effector in flexible surgical robots, facilitates the development of compact systems but also presents significant challenges for precision control due to unavoidable hysteresis effects. Furthermore, the size constraints in flexible robots result in a lack of sensory feedback. Despite these limitations, high precision is required for surgical robots. To compensate for hysteresis, accurate hysteresis modeling is necessary using limited information. This study proposes a hysteresis modeling approach based on tension information obtained from a load cell located in the input module of the Antagonistic Tendon-Sheath Mechanism (ATSM). To investigate the relationships between tension and hysteresis, experimental conditions such as curve angle, end-effector resistance, and input velocity were varied, and the resulting behaviors were analyzed. Through experiments, a strong correlation between tension and hysteresis was presented, demonstrating that this relationship remains consistent despite variations in curve angle, input velocity, and end-effector friction. Based on these experimental results, the tension-hysteresis model effectively predicted hysteresis with minimal error using only input and tension information.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t7_12">
             15:30-16:30, Paper FrPI7T7.12
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Programmable Soft Electromagnetic Sliding Actuator for Compliant Planar and Curved Surface Motion
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383338" title="Click to go to the Author Index">
             Choi, YeongJin
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351461" title="Click to go to the Author Index">
             Shin, Gyowook
            </a>
           </td>
           <td class="r">
            Samsung Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#223821" title="Click to go to the Author Index">
             Yoon, Sohee John
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106679" title="Click to go to the Author Index">
             Park, Yong-Lae
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t7_13">
             15:30-16:30, Paper FrPI7T7.13
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3856'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Investigation of Arm Stiffness Effects on Cavitation Impact in a Mantis Shrimp-Inspired Striking Mechanism
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#243005" title="Click to go to the Author Index">
             Ito, Fumio
            </a>
           </td>
           <td class="r">
            Chuo University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#183014" title="Click to go to the Author Index">
             Kurumaya, Shunichi
            </a>
           </td>
           <td class="r">
            Chuo University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#413811" title="Click to go to the Author Index">
             Katsushi, Kagaya
            </a>
           </td>
           <td class="r">
            Kitami Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102634" title="Click to go to the Author Index">
             Nakamura, Taro
            </a>
           </td>
           <td class="r">
            Chuo University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3856" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#biomimetics" title="Click to go to the Keyword Index">
               Biomimetics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents experimental results on the effects of arm stiffness differences on the cavitation force generated by a high-speed striking mechanism based on the mantis shrimp's striking motion. The study aims to enhance the impact force of the developed mechanism by understanding and applying the cavitation generation mechanism of the mantis shrimp. The shrimp utilizes arm rebound in water to create cavitation, delivering two consecutive impacts on hard objects. Therefore, it is hypothesized that arm stiffness influences cavitation generation. Experiments comparing the impact forces of arms with varying stiffness in the developed mechanism show that, compared to stiff arms, soft arms resulted in a 63.7% reduction in cavitation impact force. These results indicate that arm stiffness greatly affects cavitation generation, suggesting that the mantis shrimp's striking arm employs optimal stiffness.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t7_14">
             15:30-16:30, Paper FrPI7T7.14
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3887'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Towards a Robust Starfish Robot for AI Research
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397920" title="Click to go to the Author Index">
             Alhakami, Mohannad
            </a>
           </td>
           <td class="r">
            King Abdullah University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397914" title="Click to go to the Author Index">
             Ashley, Dylan Robert
            </a>
           </td>
           <td class="r">
            King Abdullah University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#206144" title="Click to go to the Author Index">
             Dunham, Joel
            </a>
           </td>
           <td class="r">
            OptoXense, Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#424396" title="Click to go to the Author Index">
             Dai, Yanning
            </a>
           </td>
           <td class="r">
            King Abdullah University of Science and Technology (KAUST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397928" title="Click to go to the Author Index">
             Faccio, Francesco
            </a>
           </td>
           <td class="r">
            King Abdullah University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#333888" title="Click to go to the Author Index">
             Feron, Eric
            </a>
           </td>
           <td class="r">
            King Abdullah University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#111933" title="Click to go to the Author Index">
             Schmidhuber, Jurgen
            </a>
           </td>
           <td class="r">
            Technische UniversitÃ¤t MÃ¼nchen
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3887" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Artificial intelligence has made great strides in many areas lately, yet it has struggled to achieve a similar level of success in general-purpose robotics. We believe that one of the reasons for this is the disconnect between the traditional robotic design needed by classic control algorithms and the properties needed by a robot to run open-ended, creativity-based AI systems. To that end, we---taking selective inspiration from nature---have undertaken a journey of developing a robot from the ground up to handle free-form training of cutting-edge AI algorithms. Specifically, in this work, we showcase the different iterations of our design, all of which were built with the aim of (1) being highly resilient to the stresses needed to train modern neural network-based algorithms, enabling long periods of training without supervision; (2) having extreme levels of redundancy to deal with any sensor or actuator loss that could occur when the robot damages itself; (3) having a rich action space that enables many ways of reaching the same objective, reducing the likelihood of an algorithm falling into a strong local minima during training; and (4) having a rich observation space with strong exploitable regularities (e.g., by having many cameras that can serve the role of many different sensors simultaneously). Each iteration of our design builds up these properties, increasing its suitability to work with advanced AI algorithms, with our final design being unique in having a total of 48 cameras and 48 actuators. Along with the description of each iteration of our robot, we discuss the weaknesses of that version and how we overcame them in the next iteration. Altogether, we believe that our journey serves as a first step to building a robot tailor-made for achieving artificial general intelligence. By showcasing the design process, we hope to inspire similar works that may further advance this goal as well as help others avoid similar pitfalls to the ones we encounter along the way.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frpi7t7_15">
             15:30-16:30, Paper FrPI7T7.15
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3806'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Walking = Traversable? : Traversability Prediction Via Multiple Human Object Tracking under Occlusion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#367929" title="Click to go to the Author Index">
             Tay Yu Liang, Jonathan
            </a>
           </td>
           <td class="r">
            University of Fukui
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#109542" title="Click to go to the Author Index">
             Tanaka, Kanji
            </a>
           </td>
           <td class="r">
            University of Fukui
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3806" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_robot_systems" title="Click to go to the Keyword Index">
               Humanoid Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a new method for traversability prediction in indoor environments using a third-person-view monocular camera mounted on a robot. Traditional approaches rely on first-person-view sensors, which are limited by occlusions and require significant computational resources. The proposed method uses the "Floor Plan from Human Trails (PfH)" technique, predicting traversable areas based on human movement patterns. By integrating PfH with Simultaneous Localization and Mapping (SLAM) and Multi-Object Tracking (MOT), the method aims to improve navigation performance in complex indoor spaces.
             <p>
              The core component of this approach is the Human-Object Occlusion Ordering (HO3) system. It observes human movement through a monocular camera and applies SLAM and MOT to track both stationary objects and people. This system determines the traversability of occluded pathways by identifying which stationary objects a person has passed between. It provides real-time predictions and adapts to asynchronous events like loop closures in SLAM, maintaining stability even in challenging visual conditions.
              <p>
               A 2D grid traversability map is used, initialized with all cells marked as "unknown." As the system processes data, these cells are updated to reflect traversability status. The grid is divided into 10 cm Ã— 10 cm cells, balancing detail and efficiency. The traversability score for each cell is determined using three methods: (1) Structure-from-Motion (SfM) for tracking static objects and detecting obstacles, (2) PfH for tracking dynamic humans and defining paths, and (3) HO3-SLAM for analyzing interactions between static and dynamic elements.
               <p>
                Experiments involved datasets with various human and object configurations to simulate crowded indoor environments. Data were captured using a monocular camera on a robot at 30 frames per second, with objects arranged in I-shaped, L-shaped, and T-shaped paths within a 3m Ã— 6m area. The method was compared with traditional approaches like SfM and PfH variants, showing that SLAM, MOT, and HO3 integration achieved stable traversability predictions even with severe occlusions and complex scenarios.
                <p>
                 The study demonstrates the limitations of first-person-view sensors in handling occlusions and complex perspectives. The third-person-view monocular camera system reduces hardware requirements and expands the range of environments where robots can operate effectively. This method advances traversability prediction by focusing on human motion patterns and SLAM techniques.
                 <p>
                  The findings have implications beyond robotics, potentially benefiting augmented reality and urban planning by enhancing human-environment interactions and spatial awareness. The study underscores the importance of further exploration and application of the proposed method.
                 </p>
                </p>
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frct1">
             <b>
              FrCT1
             </b>
            </a>
           </td>
           <td class="r">
            Room 1
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frct1" title="Click to go to the Program at a Glance">
             <b>
              Vision-Based Navigation III
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct1_01">
             16:30-16:45, Paper FrCT1.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('997'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              AutoNeRF: Training Implicit Scene Representations with Autonomous Agents
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#312774" title="Click to go to the Author Index">
             Marza, Pierre
            </a>
           </td>
           <td class="r">
            INSA Lyon
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#175605" title="Click to go to the Author Index">
             Matignon, Laetitia
            </a>
           </td>
           <td class="r">
            UniversitÃ© Lyon Claude Bernard
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#118822" title="Click to go to the Author Index">
             Simonin, Olivier
            </a>
           </td>
           <td class="r">
            INSA De Lyon
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238503" title="Click to go to the Author Index">
             Batra, Dhruv
            </a>
           </td>
           <td class="r">
            Georgia Tech / Facebook AI Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#176078" title="Click to go to the Author Index">
             Wolf, Christian
            </a>
           </td>
           <td class="r">
            Naver Labs Europe
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#248292" title="Click to go to the Author Index">
             Chaplot, Devendra Singh
            </a>
           </td>
           <td class="r">
            CMU
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab997" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Implicit representations such as Neural Radiance Fields (NeRF) allow to map color, density and semantics in a 3D scene through a continuous neural function. However, these models typically require manual and careful human data collection for training. This paper addresses the problem of active exploration for autonomous NeRF construction. We study how an agent can learn to efficiently explore an unknown 3D environment so that the data collected during autonomous exploration enables the learning of a high-quality neural implicit map representation. The quality of the learned representation is evaluated on four robotics-related downstream tasks: classical viewpoint rendering, map reconstruction, planning, and pose refinement. We compare the impact of different exploration strategies including frontier-based and learning-based approaches (end-to-end and modular) with different reward functions tailored to this problem. Empirical results show that NeRFs can be trained on actively collected data using just a single episode of experience in an unseen environment and that AutoNeRF, a modular exploration policy trained with reinforcement learning, enables obtaining a higher-quality NeRF for the considered downstream robotic tasks. Finally, we show that with AutoNeRF an agent can be deployed to a previously unknown scene and then automatically improve its navigation performance by adapting to the scene through a cycle of exploration, reconstruction, and policy finetuning.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct1_02">
             16:45-17:00, Paper FrCT1.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1127'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              In-Flight Initialization of Global Visual-Inertial Estimators Using Geospatial Data
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#316523" title="Click to go to the Author Index">
             Li, Chunyu
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#344890" title="Click to go to the Author Index">
             He, Mengfan
            </a>
           </td>
           <td class="r">
            TsinghuaUniversity
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#363329" title="Click to go to the Author Index">
             Lyu, Xu
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#161918" title="Click to go to the Author Index">
             Meng, Ziyang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1127" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_inertial_slam" title="Click to go to the Keyword Index">
               Visual-Inertial SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we propose a solution that leverages geospatial data to initialize the monocular visual-inertial navigation system. For Visual-Inertial Navigation Systems (VINS) operating on UAVs, the ability to perform initialization and relocalization in mid-air is essential. However, degenerate motion can cause VINS to lose scale, making traditional initialization algorithms less reliable. To address this issue, we fuse geographic information in the initialization process, and utilize a learning-based feature matching algorithm to associate the information with inertial states. The proposed approach demonstrates adaptability to the degenerate motions of UAVs and significantly surpasses the estimation accuracy of conventional VINS initialization algorithms. Compared to methods that assist initialization by using a laser-range-finder (LRF), the proposed method solely relies on low-cost satellite imagery and elevation information. We evaluate the proposed approach on a largescale UAV dataset, and compare with existing methods. The results demonstrate the superior effectiveness of the proposed method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct1_03">
             17:00-17:15, Paper FrCT1.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1181'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CMR-Agent: Learning a Cross-Modal Agent for Iterative Image-To-Point Cloud Registration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#297111" title="Click to go to the Author Index">
             Yao, Gongxin
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395401" title="Click to go to the Author Index">
             Xuan, Yixin
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395380" title="Click to go to the Author Index">
             Li, Xinyang
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393990" title="Click to go to the Author Index">
             Pan, Yu
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1181" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Image-to-point cloud registration aims to determine the relative camera pose of an RGB image with respect to a point cloud. It plays an important role in camera localization within pre-built LiDAR maps. Despite the modality gaps, most learning-based methods establish direct 2D-3D point correspondences in feature space without any feedback mechanism for iterative optimization, resulting in poor accuracy and interpretability. In this paper, we propose to reformulate the registration procedure as an iterative Markov decision process, allowing for incremental adjustments to the camera pose based on each intermediate state. To achieve this, we employ reinforcement learning to develop a cross-modal registration agent (CMR-Agent), and use imitation learning to initialize its registration policy for stability and quick-start of the training. According to the cross-modal observations, we propose a 2D-3D hybrid state representation that fully exploits the fine-grained features of RGB images while reducing the useless neutral states caused by the spatial truncation of camera frustum. Additionally, the overall framework is well-designed to efficiently reuse one-shot cross-modal embeddings, avoiding repetitive and time-consuming feature extraction. Extensive experiments on the KITTI-Odometry and NuScenes datasets demonstrate that CMR-Agent achieves competitive accuracy and efficiency in registration. Once the one-shot embeddings are completed, each iteration only takes a few milliseconds.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct1_04">
             17:15-17:30, Paper FrCT1.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2111'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Imagine2Servo: Intelligent Visual Servoing with Diffusion-Driven Goal Generation for Robotic Tasks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#312331" title="Click to go to the Author Index">
             Pathre, Pranjali
            </a>
           </td>
           <td class="r">
            International Institute of Information Technology, Hyderabad
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#327732" title="Click to go to the Author Index">
             Gupta, Gunjan
            </a>
           </td>
           <td class="r">
            International Institute of Information Technology (IIIT), Hydera
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#290805" title="Click to go to the Author Index">
             Qureshi, Mohammad Nomaan
            </a>
           </td>
           <td class="r">
            International Institute of Information Technology (IIIT), Hydera
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398144" title="Click to go to the Author Index">
             Mandyam, Brunda
            </a>
           </td>
           <td class="r">
            International Institute of Information Technology, Hyderabad
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#169930" title="Click to go to the Author Index">
             Brahmbhatt, Samarth Manoj
            </a>
           </td>
           <td class="r">
            Intel Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102906" title="Click to go to the Author Index">
             Krishna, Madhava
            </a>
           </td>
           <td class="r">
            IIIT Hyderabad
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2111" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#visual_servoing" title="Click to go to the Keyword Index">
               Visual Servoing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visual servoing, the method of controlling robot motion through feedback from visual sensors, has seen significant advancements with the integration of optical flow-based methods. However, its application remains limited by inherent challenges such as the necessity for a target image at test time, the requirement of substantial overlap between initial and target images, and the reliance on feedback from a single camera. This paper introduces Imagine2Servo, an innovative approach leveraging diffusion-based image editing techniques to enhance visual servoing algorithms by generating intermediate goal images. This methodology allows for the extension of visual servoing applications beyond traditional constraints, enabling tasks like long-range navigation and manipulation without pre-defined goal images. We propose a pipeline that synthesizes subgoal images grounded in the task at hand, facilitating servoing in scenarios with minimal initial and target image overlap and integrating multi-camera feedback for comprehensive task execution. Our contributions demonstrate a novel application of image generation to robotic control, significantly broadening the capabilities of visual servoing systems. Real-world experiments validate the effectiveness and versatility of the Imagine2Servo framework in accomplishing a variety of tasks, marking a notable advancement in the field of visual servoing.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frct2">
             <b>
              FrCT2
             </b>
            </a>
           </td>
           <td class="r">
            Room 2
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frct2" title="Click to go to the Program at a Glance">
             <b>
              Telerobotics and Teleoperation I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#100579" title="Click to go to the Author Index">
             Kheddar, Abderrahmane
            </a>
           </td>
           <td class="r">
            CNRS-AIST
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct2_01">
             16:30-16:45, Paper FrCT2.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('797'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Reducing Performance Variability and Overcoming Limited Spatial Ability: Targeted Training for Remote Robot Teleoperation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#246227" title="Click to go to the Author Index">
             Lin, Tsung-Chi
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391049" title="Click to go to the Author Index">
             Chen, Juo-Tung
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#131676" title="Click to go to the Author Index">
             Huang, Chien-Ming
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab797" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we present a targeted training approach for remote teleoperation aimed at achieving consistent proficiency levels across users with varying capabilities. Our approach begins by assessing users' abilities to perform robot motion control, workspace adaptation, and gripper control. It then provides tailored training based on identified skill gaps to enhance the learning effectiveness and user experience. To demonstrate our approach, we conducted a user study, with one group undergoing conventional, free-form training and the other engaging in targeted training in accordance with their skill gaps; after the training phase, participants teleoperated a robotic arm in a simulated medication preparation task for performance evaluation. Our results show that the targeted training approach effectively reduces performance variability and mitigates the influence of spatial ability on both training and task completion time. We discuss the implications of our results for practical teleoperation training and future research.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct2_02">
             16:45-17:00, Paper FrCT2.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1183'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Interactive Multi-Stiffness Mixed Reality Interface: Controlling and Visualizing Robot and Environment Stiffness
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#332023" title="Click to go to the Author Index">
             DÃ­az Rosales, Alejandro
            </a>
           </td>
           <td class="r">
            CERN; Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374549" title="Click to go to the Author Index">
             Rodriguez-Nogueira, Jose
            </a>
           </td>
           <td class="r">
            CERN
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#192665" title="Click to go to the Author Index">
             Matheson, Eloise
            </a>
           </td>
           <td class="r">
            CERN
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#144135" title="Click to go to the Author Index">
             Abbink, David A.
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#156776" title="Click to go to the Author Index">
             Peternel, Luka
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1183" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#virtual_reality_and_interfaces" title="Click to go to the Keyword Index">
               Virtual Reality and Interfaces
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#compliance_and_impedance_control" title="Click to go to the Keyword Index">
               Compliance and Impedance Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Teleoperation is a crucial technology enabling human operators to control robots remotely to perform tasks in hazardous and difficult-to-access environments. Tasks in such environments often involve complex physical interactions with tools and objects of various softness. To this end, teleimpedance enables the operators to adjust the robot impedance in real-time to simplify such interactions. While the existing teleimpedance approaches provide several interfaces to command the robot impedance, there are no interfaces to visualize both the commanded impedance and that of the objects to be interacted with. This paper presents a novel interface to provide visual feedback on the impedance of remote robots and objects. To do so, we use virtual stiffness ellipsoids and different modes that display the individual impedance of the robot and objects as well as combined post-contact impedance. The key advantage of visual feedback on the impedance compared to force feedback is that the operator can see the interaction characteristics before the contact occurs. This enables the operator to act proactively before contact rather than just reactively after the contact. This paper also proposes a new more intuitive way to command the robot impedance using augmented reality, interacting with these ellipsoids and modifying them as needed. To demonstrate the key functionalities of the developed interface, we performed proof-of-concept experiments on teleoperated tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct2_03">
             17:00-17:15, Paper FrCT2.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1627'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GestRight: Understanding the Feasibility of Gesture-Driven Tele-Operation in Human-Robot Teams
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396954" title="Click to go to the Author Index">
             Rippy, Kevin
            </a>
           </td>
           <td class="r">
            University of Maryland, Baltimore County
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399493" title="Click to go to the Author Index">
             Gangopadhyay, Aryya
            </a>
           </td>
           <td class="r">
            University of Maryland Baltimore County
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396949" title="Click to go to the Author Index">
             Jayarajah, Kasthuri
            </a>
           </td>
           <td class="r">
            New Jersey Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1627" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#gesture__posture_and_facial_expressions" title="Click to go to the Keyword Index">
               Gesture, Posture and Facial Expressions
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we propose GestRight, a real-time system for gesture-based teleoperation of a mobile robot. For field use (e.g., smart factory settings, search and rescue missions, etc.), relying on tablet-based controls or joysticks are limiting which has led to the recent interest in hands-free operation of these assistive robots. In this work, we design three gesture-based schemes, namely, emph{fist}, emph{touch}, and emph{wheel}, represent three levels of precision--intuitiveness tradeoffs for low-level navigational control of mobile robots. name includes a head-mounted device that captures hand joint data for accurate gesture recognition which is then translated to motion commands at an edge server. Through a user study involving seventeen participants, we present quantitative insights in comparison to traditional modes of control. Specifically, we evaluate GestRight in terms of the ease of navigational control, task time, and amount of errors/corrective actions required, run extensive statistical analyses, and provide a series of design recommendations for gesture-driven teleoperation systems. Our results show that gesture based schemes perform as well as traditional modes of control in contrast to participants' self-reports on how successful they felt in controlling the robots.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct2_04">
             17:15-17:30, Paper FrCT2.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2667'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Digital Twin-Driven Immersive Teleoperation Framework for Robot-Assisted Microsurgery
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#364650" title="Click to go to the Author Index">
             Jiang, Peiyang
            </a>
           </td>
           <td class="r">
            University of Bristol
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191798" title="Click to go to the Author Index">
             Zhang, Dandan
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2667" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#virtual_reality_and_interfaces" title="Click to go to the Keyword Index">
               Virtual Reality and Interfaces
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a novel digital twin (DT)-driven framework for immersive teleoperation in the domain of robot-assisted microsurgery (RAMS). The proposed method leverages the power of DT with mixed reality (MR) technology to create an interactive, immersive teleoperation environment for surgeons to conduct RAMS with higher precision, improved safety, and higher efficiency. More specifically, the MR device can provide operators with the 3D visualization of a digital microsurgical robot mimicking the motions of the physical one as well as the 2D real-time microscopic images during microsurgical operation. We evaluated the proposed framework through user studies based on a Trajectory Following task and conducted comparisons between scenarios with and without using the proposed framework for RAMS. The NASA-TLX questionnaire, along with additional evaluation metrics such as total trajectory, time cost, mean velocity, and a predefined collision metric, were used to analyze the user studies. Results indicated that the proposed DT-driven immersive teleoperation framework could enhance the precision, safety, and efficiency of teleoperation, and provide a satisfactory user experience to operators during microsurgical operation.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frct3">
             <b>
              FrCT3
             </b>
            </a>
           </td>
           <td class="r">
            Room 3
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frct3" title="Click to go to the Program at a Glance">
             <b>
              Dexterous Manipulation
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#188794" title="Click to go to the Author Index">
             Romeres, Diego
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Research Laboratories
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#223070" title="Click to go to the Author Index">
             Ganguly, Amartya
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct3_01">
             16:30-16:45, Paper FrCT3.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1495'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Object Augmentation Algorithm: Computing Virtual Object Motion and Object Induced Interaction Wrench from Optical Markers
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#319823" title="Click to go to the Author Index">
             Herneth, Christopher
            </a>
           </td>
           <td class="r">
            Technical University Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338803" title="Click to go to the Author Index">
             Li, Junnan
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396502" title="Click to go to the Author Index">
             Fatoni, Muhammad Hilman
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#223070" title="Click to go to the Author Index">
             Ganguly, Amartya
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108317" title="Click to go to the Author Index">
             Haddadin, Sami
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1495" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#datasets_for_human_motion" title="Click to go to the Keyword Index">
               Datasets for Human Motion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_and_humanoid_motion_analysis_and_synthesis" title="Click to go to the Keyword Index">
               Human and Humanoid Motion Analysis and Synthesis
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study addresses the critical need for diverse and comprehensive data focused on human arm joint torques while performing activities of daily living (ADL). Previous studies have often overlooked the influence of objects on joint torques during ADL, resulting in limited datasets for analysis. To address this gap, we propose an Object Augmentation Algorithm (OAA) capable of augmenting existing marker-based databases with virtual object motions and object-induced joint torque estimations. The OAA consists of five phases: (1) computing hand coordinate systems from optical markers, (2) characterising object movements with virtual markers, (3) calculating object motions through inverse kinematics (IK), (4) determining the wrench necessary for prescribed object motion using inverse dynamics (ID), and (5) computing joint torques resulting from object manipulation. The algorithmâ€™s accuracy is validated through trajectory tracking and torque analysis on a 7+4 degree of freedom (DoF) robotic hand-arm system, manipulating three unique objects. The results show that the OAA can accurately and precisely estimate 6 DoF object motion and object-induced joint torques. Correlations between computed and measured quantities were &gt; 0.99 for object trajectories and &gt; 0.93 for joint torques. The OAA was further shown to be robust to variations in the number and placement of input markers, which are expected between databases. Differences between repeated experiments were minor but significant (p &lt; 0.05). The algorithm expands the scope of available data and facilitates more comprehensive analyses of human-object interaction dynamics.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct3_02">
             16:45-17:00, Paper FrCT3.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2714'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Generalizable Manipulation Policy with Adapter-Based Parameter Fine-Tuning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#246458" title="Click to go to the Author Index">
             Lu, Kai
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#290338" title="Click to go to the Author Index">
             Ly, Kim Tien
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#415089" title="Click to go to the Author Index">
             Hebberd, William
            </a>
           </td>
           <td class="r">
            The University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376394" title="Click to go to the Author Index">
             Zhou, Kaichen
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123323" title="Click to go to the Author Index">
             Havoutis, Ioannis
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#129241" title="Click to go to the Author Index">
             Markham, Andrew
            </a>
           </td>
           <td class="r">
            Oxford University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2714" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study investigates the use of adapters in reinforcement learning for robotic skill generalization across multiple robots and tasks. Traditional methods are typically reliant on robot-specific retraining and face challenges such as efficiency and adaptability, particularly when scaling to robots with varying kinematics. We propose an alternative approach where a disembodied (virtual) hand manipulator learns a task (i.e. an abstract skill) and then transfers it to various robots with different kinematic constraints without retraining the entire model (i.e. the concrete, physical implementation of the skill). Whilst adapters are commonly used in other domains with strong supervision available, we show how weaker feedback from robotic control can be used to optimize task execution by preserving the abstract skill dynamics whilst adapting to new robotic domains. We demonstrate the effectiveness of our method with experiments conducted in the SAPIEN ManiSkill environment, showing improvements in generalization and task success rates. All code, data, and additional videos are at this GitHub link: https://kl-research.github.io/genrob.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct3_03">
             17:00-17:15, Paper FrCT3.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('679'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              In-Hand Following of Deformable Linear Objects Using Dexterous Fingers with Tactile Sensing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#297309" title="Click to go to the Author Index">
             Yu, Mingrui
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#309175" title="Click to go to the Author Index">
             Liang, Boyuan
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#278815" title="Click to go to the Author Index">
             Zhang, Xiang
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#246683" title="Click to go to the Author Index">
             Zhu, Xinghao
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#254317" title="Click to go to the Author Index">
             Sun, Lingfeng
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#223791" title="Click to go to the Author Index">
             Wang, Changhao
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#244251" title="Click to go to the Author Index">
             Song, Shiji
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#132634" title="Click to go to the Author Index">
             Li, Xiang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100071" title="Click to go to the Author Index">
             Tomizuka, Masayoshi
            </a>
           </td>
           <td class="r">
            University of California
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab679" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#in_hand_manipulation" title="Click to go to the Keyword Index">
               In-Hand Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Most research on deformable linear object (DLO) manipulation assumes rigid grasping. However, beyond rigid grasping and re-grasping, in-hand following is also an essential skill that humans use to dexterously manipulate DLOs, which requires continuously changing the grasp point by in-hand sliding while holding the DLO to prevent it from falling. Achieving such a skill is very challenging for robots without using specially designed but not versatile end-effectors. Previous works have attempted using generic parallel gripper, but their robustness is unsatisfactory owing to the conflict between following and holding, which is hard to balance with a one degree-of-freedom gripper. In this work, inspired by how humans use fingers to follow DLOs, we explore the usage of a generic dexterous hand with tactile sensing to imitate the human skill and achieve robust in-hand DLO following. To enable the hardware system to function in the real world, we develop a framework which includes Cartesian-space arm-hand control, tactile-based in-hand 3-D DLO pose estimation, and task-specific motion design. Experimental results demonstrate the significant superiority of our method over using parallel grippers, as well as its great robustness, generalizability, and efficiency.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct3_04">
             17:15-17:30, Paper FrCT3.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2537'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Autonomous Robotic Assembly: From Part Singulation to Precise Assembly
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#246037" title="Click to go to the Author Index">
             Ota, Kei
            </a>
           </td>
           <td class="r">
            Tokyo Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#192415" title="Click to go to the Author Index">
             Jha, Devesh
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Research Laboratories
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#135389" title="Click to go to the Author Index">
             Jain, Siddarth
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Research Laboratories (MERL)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#236118" title="Click to go to the Author Index">
             Yerazunis, William
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Research Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#233444" title="Click to go to the Author Index">
             Corcodel, Radu
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Research Laboratories
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277268" title="Click to go to the Author Index">
             Shukla, Yash
            </a>
           </td>
           <td class="r">
            Tufts University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#211767" title="Click to go to the Author Index">
             Bronars, Antonia
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#188794" title="Click to go to the Author Index">
             Romeres, Diego
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Research Laboratories
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2537" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_and_flexible_manufacturing" title="Click to go to the Keyword Index">
               Intelligent and Flexible Manufacturing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#factory_automation" title="Click to go to the Keyword Index">
               Factory Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Imagine a robot that can assemble a functional product from the individual parts presented in any configuration to the robot. Designing such a robotic system is a complex problem which presents several open challenges. To bypass these challenges, the current generation of assembly systems is built with a lot of system integration effort to provide the structure and precision necessary for assembly. These systems are mostly responsible for part singulation, part kitting, and part detection, which is accomplished by intelligent system design. In this paper, we present autonomous assembly of a gear box with minimum requirements on structure. The assembly parts are randomly placed in a two-dimensional work environment for the robot. The proposed system makes use of several different manipulation skills such as sliding for grasping, in-hand manipulation, and insertion to assemble the gear box. All these tasks are run in a closed-loop fashion using vision, tactile, and Force-Torque (F/T) sensors. We perform extensive hardware experiments to show the robustness of the proposed methods as well as the overall system. See supplementary video at https://www.youtube.com/watch?v=cZ9M1DQ23OI
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frct4">
             <b>
              FrCT4
             </b>
            </a>
           </td>
           <td class="r">
            Room 4
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frct4" title="Click to go to the Program at a Glance">
             <b>
              Bio-Inspired Robots
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#105018" title="Click to go to the Author Index">
             Ijspeert, Auke
            </a>
           </td>
           <td class="r">
            EPFL
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#120785" title="Click to go to the Author Index">
             Manoonpong, Poramate
            </a>
           </td>
           <td class="r">
            Vidyasirimedhi Institute of Science and Technology (VISTEC)
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct4_01">
             16:30-16:45, Paper FrCT4.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('812'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Bayesian Deep Predictive Coding for Snake-Like Robotic Control in Unknown Terrains
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#337521" title="Click to go to the Author Index">
             Qu, William Ziming
            </a>
           </td>
           <td class="r">
            Canadian Academy
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#337516" title="Click to go to the Author Index">
             Qu, Jessica Ziyu
            </a>
           </td>
           <td class="r">
            Canadian Academy
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#337523" title="Click to go to the Author Index">
             Li, Li
            </a>
           </td>
           <td class="r">
            Beijing Shouyejiehuo Company
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394092" title="Click to go to the Author Index">
             Yang, Jie
            </a>
           </td>
           <td class="r">
            Beijing Shouyejiehuo Company
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276070" title="Click to go to the Author Index">
             Jia, Yuanyuan
            </a>
           </td>
           <td class="r">
            Kyoto University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab812" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#redundant_robots" title="Click to go to the Keyword Index">
               Redundant Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#probability_and_statistical_methods" title="Click to go to the Keyword Index">
               Probability and Statistical Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Effectively modeling the spatio-temporal interactions both internally and externally is a challenge in controlling multi-linked snake robots. This paper presents an effective method based on deep predictive coding: SnakeFormer, to address the aforementioned issue. The main contributions include: 1) Deriving a variational free energy function with two innovative regularization terms through Bayesian probabilistic analysis, offering a novel perspective to simulate the interactions between agent and the environment; 2) Introducing an interaction-attention model within a Transformer structure for predicting dynamics, and collaboratively addressing path planning and obstacle avoidance tasks. 3) By incorporating serpenoid embedding and optimizing self-attention computations, the gait stability and motion efficiency are improved. Preliminary experiments and comparative analysis with baseline models fully validate the effectiveness and generalizability of the method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct4_02">
             16:45-17:00, Paper FrCT4.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2703'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Importance of Translational Velocity for Bird-Scale Flapping Wing Vehicles Incapable of Hovering
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383272" title="Click to go to the Author Index">
             Zhou, Shijun
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398418" title="Click to go to the Author Index">
             Orr, Aidan
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#192428" title="Click to go to the Author Index">
             Hyun, Nak-seung Patrick
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2703" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#underactuated_robots" title="Click to go to the Keyword Index">
               Underactuated Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             There exist multiple types of flyers in the world that either achieve lift through leveraging aerodynamics by cleverly choosing the wing airfoils of an airplane, or by flapping their wings. As the flapping wing vehicles (FWVs) decrease in scale, lift is predominantly generated by flapping. However, bigger birds or bird-scale flapping wing vehicle (BFWV) may not be able to hover but leverage the forward velocity to augment the lift generation. In this paper, we analyze the aerodynamic lift augmentation through the translational velocity for a 12g, BFWV with tail (flapping around 14 Hz). We prove that the vehicle is unable to hover, but there exist a significant augmentation through the translational motion. A cycle-averaged aerodynamic model including the contribution from the translational velocity is proposed, and experimentally validated. Finally, the analysis of the sufficient conditions on the velocity direction and orientation are studied to maintain the zero angular moment forward flight.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct4_03">
             17:00-17:15, Paper FrCT4.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2768'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Online Optimization of Central Pattern Generators for Quadruped Locomotion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398571" title="Click to go to the Author Index">
             Zhang, Zewei
            </a>
           </td>
           <td class="r">
            EPFL
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#216565" title="Click to go to the Author Index">
             Bellegarda, Guillaume
            </a>
           </td>
           <td class="r">
            EPFL
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205571" title="Click to go to the Author Index">
             Shafiee, Milad
            </a>
           </td>
           <td class="r">
            EPFL
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105018" title="Click to go to the Author Index">
             Ijspeert, Auke
            </a>
           </td>
           <td class="r">
            EPFL
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2768" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Typical legged locomotion controllers are designed or trained offline. This is in contrast to many animals, which are able to locomote at birth, and rapidly improve their locomotion skills with few real-world interactions. Such motor control is possible through primitive patterns of neural control known to exist in vertebrates, known as Central Pattern Generators (CPGs). Models of the CPG have been widely used to generate locomotion skills in robotics, but can require extensive hand-tuning or offline optimization of inter-connected parameters with genetic algorithms. In this paper, we present a framework for the online optimization of the CPG parameters through Bayesian Optimization. We show that our framework can rapidly optimize and adapt to varying velocity commands and changes in the terrain, for example to varying coefficients of friction, terrain slope angles, and added mass loads placed on the robot. We study the effects of sensory feedback on the CPG, and find that both force feedback in the phase equations, as well as posture control (Virtual Model Control) are both beneficial for robot stability and energy efficiency. In hardware experiments on the Unitree Go1, we show rapid optimization (in under 3 minutes) and adaptation of energy-efficient gaits to varying target velocities in a variety of scenarios: varying coefficients of friction, added payloads up to 15 kg, and variable slopes up to 10 degrees.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct4_04">
             17:15-17:30, Paper FrCT4.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2944'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Heading Control for Obstacle Avoidance Using Dynamic Posture Manipulation During Tumbling Locomotion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#332346" title="Click to go to the Author Index">
             Salagame, Adarsh
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378279" title="Click to go to the Author Index">
             Gangaraju, Kruthika
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#184688" title="Click to go to the Author Index">
             Sihite, Eric
            </a>
           </td>
           <td class="r">
            California Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390910" title="Click to go to the Author Index">
             Schirner, Gunar
            </a>
           </td>
           <td class="r">
            Northeastern U., Dept. of Electrical and Computer Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#150160" title="Click to go to the Author Index">
             Ramezani, Alireza
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2944" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Passive tumbling structures are energy efficient, but often sacrifice control authority due to their under actuated nature. Unlike many passive tumbling robots, Northeastern University's COBRA is a snake robot with eleven articulated joints that transforms into a wheel-like structure with a high degree of posture control during tumbling, and using this posture manipulation, COBRA can control its forward velocity and heading angle while tumbling. This paper presents a mathematical framework that describes the dynamics of posture manipulation during tumbling and identifies two types of control actions that allow it to control its movement. This is validated in hardware testing to demonstrate obstacle avoidance during passive tumbling using only posture manipulation.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frct5">
             <b>
              FrCT5
             </b>
            </a>
           </td>
           <td class="r">
            Room 5
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frct5" title="Click to go to the Program at a Glance">
             <b>
              Force Sensing and Control
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#102549" title="Click to go to the Author Index">
             Hirai, Shinichi
            </a>
           </td>
           <td class="r">
            Ritsumeikan Univ
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct5_01">
             16:30-16:45, Paper FrCT5.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1586'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Deep Domain Adaptation Regression for Force Calibration of Optical Tactile Sensors
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396868" title="Click to go to the Author Index">
             Chen, Zhuo
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#334836" title="Click to go to the Author Index">
             Ou, Ni
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285049" title="Click to go to the Author Index">
             Jiang, Jiaqi
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#165900" title="Click to go to the Author Index">
             Luo, Shan
            </a>
           </td>
           <td class="r">
            King's College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1586" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Optical tactile sensors provide robots with rich force information for robot grasping in unstructured environments. The fast and accurate calibration of three-dimensional contact forces holds significance for new sensors and existing tactile sensors which may have incurred damage or aging. However, the conventional neural-network-based force calibration method necessitates a large volume of force-labeled tactile images to minimize force prediction errors, with the need for accurate Force/Torque measurement tools as well as a time-consuming data collection process. To address this challenge, we propose a novel deep domain-adaptation force calibration method, designed to transfer the force prediction ability from a calibrated optical tactile sensor to uncalibrated ones with various combinations of domain gaps, including marker presence, illumination condition, and elastomer modulus. Experimental results show the effectiveness of the proposed unsupervised force calibration method, with the lowest force prediction errors of 0.102N (3.4% in full force range) for normal force, and 0.095N (6.3%) and 0.062N (4.1%) for shear forces along the x-axis and y-axis, respectively. This study presents a promising, general force calibration methodology for optical tactile sensors.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct5_02">
             16:45-17:00, Paper FrCT5.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2687'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learned Slip-Detection-Severity Framework Using Tactile Deformation Field Feedback for Robotic Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385939" title="Click to go to the Author Index">
             Jawale, Neel Anand
            </a>
           </td>
           <td class="r">
            University of Washington
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385940" title="Click to go to the Author Index">
             Kaur, Navneet
            </a>
           </td>
           <td class="r">
            University of Washington
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396969" title="Click to go to the Author Index">
             Santoso, Elizabeth Amy
            </a>
           </td>
           <td class="r">
            University of Washington
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350255" title="Click to go to the Author Index">
             Hu, Xiaohai
            </a>
           </td>
           <td class="r">
            University of Washington
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#135676" title="Click to go to the Author Index">
             Chen, Xu
            </a>
           </td>
           <td class="r">
            University of Washington
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2687" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Safely handling objects and avoiding slippage are fundamental challenges in robotic manipulation, yet traditional techniques often oversimplify the issue by treating slippage as a binary occurrence. Our research presents a framework that both identifies slip incidents and measures their severity. We introduce a set of features based on detailed vector field analysis of tactile deformation data captured by the GelSight Mini sensor. Two distinct machine learning models use these features: one focuses on slip detection, and the other evaluates the slip's severity, which is the slipping velocity of the object against the sensor surface. Our slip detection model achieves an average accuracy of 92%, and the slip severity estimation model exhibits a mean absolute error (MAE) of 0.6 cm/s for unseen objects. To demonstrate the synergistic approach of this framework, we employ both models in a tactile feedback-guided vertical sliding task. Leveraging the high accuracy of slip detection, we utilize it as the foundational and corrective model and integrate the slip severity estimation into the feedback control loop to address slips without overcompensating. Videos and demonstrations are available at: https://sites.google.com/uw.edu/lsds.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct5_03">
             17:00-17:15, Paper FrCT5.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('609'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Development Force Control of a Series Elastic Actuator to Excavator for Mechanization of Manual Work
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#288611" title="Click to go to the Author Index">
             Hiramatsu, Toshifumi
            </a>
           </td>
           <td class="r">
            Yanmar Holdings Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391656" title="Click to go to the Author Index">
             Saiki, Miyuki
            </a>
           </td>
           <td class="r">
            Yanmar Holdings Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#254284" title="Click to go to the Author Index">
             Hara, Naohiro
            </a>
           </td>
           <td class="r">
            YANMAR Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391802" title="Click to go to the Author Index">
             Yamada, Masaki
            </a>
           </td>
           <td class="r">
            Yanmar Holdings Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391861" title="Click to go to the Author Index">
             Momii, Masaki
            </a>
           </td>
           <td class="r">
            Yanmar Holdings Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391631" title="Click to go to the Author Index">
             Uebayashi, Yuichi
            </a>
           </td>
           <td class="r">
            Yanmar Holdings Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105276" title="Click to go to the Author Index">
             Sugiura, Hisashi
            </a>
           </td>
           <td class="r">
            Yanmar Co., Ltd
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab609" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#force_control" title="Click to go to the Keyword Index">
               Force Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robotics_and_automation_in_construction" title="Click to go to the Keyword Index">
               Robotics and Automation in Construction
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Automation can address labor shortage and enhance worker safety in construction. However, workers continue to perform majority of the work at construction sites that can be automated. Construction machinery require force control for automation, which can absorb external shocks and provide appropriate forces along with environmental forces. This study proposes a force-controlled excavator that fulfills these requirements by replacing the hydraulic system with a series elastic actuator (SEA). Few studies have applied SEA to large high-output construction machinery. We designed the structure of the SEA to deliver high output power in a compact form that can be mounted on an excavator. A 2.5-T class excavator equipped with this SEA is designed, which achieved a force resolution of 15â€“35 N at the tip. The effectiveness of this excavator in automating a major portion of the manual work is demonstrated.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct5_04">
             17:15-17:30, Paper FrCT5.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('236'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Passive Underwater Robot Hand Utilizing Water Resistance
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#317967" title="Click to go to the Author Index">
             Nate, Issei
            </a>
           </td>
           <td class="r">
            Ritsumeikan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102549" title="Click to go to the Author Index">
             Hirai, Shinichi
            </a>
           </td>
           <td class="r">
            Ritsumeikan Univ
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab236" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Numerous robot grippers have been developed to reduce energy consumption by utilizing contact forces with fixed objects. In underwater environments, most objects are not fixed, particularly in the mid and surface layers, posing a challenge for obtaining contact forces. To address this issue, this study proposes a multi-finger gripper that utilizes water resistance for opening and closing actions underwater. As the gripper ascends in water, it closes its fingers, each equipped with a locking mechanism at the tip. This mechanism allows the fingers to maintain a closed shape when converged towards the center and locked. Unlocking occurs when the gripper descends underwater, as the direction of water resistance changes. This design enables locking and unlocking without actuators, offering a solution for grasping underwater objects. The gripper's underwater movement has speed limits. Below the lower limit, fingers may not achieve sufficient bending, while exceeding the upper limit can cause vibrations and affect the locking function. Therefore, maintaining an appropriate speed is crucial. Finally, gripping experiments were conducted to confirm the gripper's ability to grasp objects underwater.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frct6">
             <b>
              FrCT6
             </b>
            </a>
           </td>
           <td class="r">
            Room 6
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frct6" title="Click to go to the Program at a Glance">
             <b>
              Task and Motion Planning II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#217244" title="Click to go to the Author Index">
             Ornik, Melkior
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct6_01">
             16:30-16:45, Paper FrCT6.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('737'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ComTraQ-MPC: Meta-Trained DQN-MPC Integration for Trajectory Tracking with Limited Active Localization Updates
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379600" title="Click to go to the Author Index">
             Puthumanaillam, Gokul
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393733" title="Click to go to the Author Index">
             Vora, Manav Ketan
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#217244" title="Click to go to the Author Index">
             Ornik, Melkior
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab737" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Optimal decision-making for trajectory tracking in partially observable, stochastic environments where the number of active localization updates---the process by which the agent obtains its true state information from the sensors---are limited, presents a significant challenge. Traditional methods often struggle to balance resource conservation, accurate state estimation and precise tracking, resulting in suboptimal performance. This problem is particularly pronounced in environments with large action spaces, where the need for frequent, accurate state data is paramount, yet the capacity for active localization updates is restricted by external limitations. This paper introduces ComTraQ-MPC, a novel framework that combines Deep Q-Networks (DQN) and Model Predictive Control (MPC) to optimize trajectory tracking with constrained active localization updates. The meta-trained DQN ensures adaptive active localization scheduling, while the MPC leverages available state information to improve tracking. The central contribution of this work is their reciprocal interaction: DQN's update decisions inform MPC's control strategy, and MPC's outcomes refine DQN's learning, creating a cohesive, adaptive system. Empirical evaluations in simulated and real-world settings demonstrate that ComTraQ-MPC significantly enhances operational efficiency and accuracy, providing a generalizable and approximately optimal solution for trajectory tracking in complex partially observable environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct6_02">
             16:45-17:00, Paper FrCT6.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1512'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              On Learning Scene-Aware Generative State Abstractions for Task-Level Mobile Manipulation Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#223618" title="Click to go to the Author Index">
             FÃ¶rster, Julian
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#150492" title="Click to go to the Author Index">
             Chung, Jen Jen
            </a>
           </td>
           <td class="r">
            The University of Queensland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142888" title="Click to go to the Author Index">
             Ott, Lionel
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100088" title="Click to go to the Author Index">
             Siegwart, Roland
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1512" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_categories_and_concepts" title="Click to go to the Keyword Index">
               Learning Categories and Concepts
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Task and motion planning (TAMP) is a promising approach for efficient long-horizon manipulation planning, which is a prerequisite for being able to deploy manipulation systems in human-centered environments at scale. TAMP systems often rely on so-called predicates to abstractly describe the world. Today, predicates and their groundings are often hand-engineered. Furthermore, robot action parameterizations required to fulfill desired predicates are typically discovered by sampling naively or using oracles (again hand-engineered). We aim to automate predicate discovery and grounding with a system that learns to classify the state of predicates in a set of scenes while concurrently learning to generate scene configurations that fulfill the desired predicates. Our results show that high classification accuracies and generation success rates can be achieved with architectures based on multi-layer perceptrons (MLPs) and graph neural networks (GNNs) that are trained on bounding box as well as point cloud-based features in a Generative Adversarial Network (GAN)-inspired fashion, decisively outperforming both decision tree and uniform sampler baselines. The integration of our framework into a TAMP system demonstrates its positive impact on solving mobile manipulation tasks. A reference implementation of our method and data are available at https://github.com/ethz-asl/predicate_learning.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct6_03">
             17:00-17:15, Paper FrCT6.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2826'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LGMCTS: Language-Guided Monte-Carlo Tree Search for Executable Semantic Object Rearrangement
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219127" title="Click to go to the Author Index">
             Chang, Haonan
            </a>
           </td>
           <td class="r">
            Rutgers University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#251355" title="Click to go to the Author Index">
             Gao, Kai
            </a>
           </td>
           <td class="r">
            Rutgers University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377752" title="Click to go to the Author Index">
             Boyalakuntla, Kowndinya
            </a>
           </td>
           <td class="r">
            Rutgers University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377657" title="Click to go to the Author Index">
             Lee, Alex
            </a>
           </td>
           <td class="r">
            Rutgers University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#236991" title="Click to go to the Author Index">
             Huang, Baichuan
            </a>
           </td>
           <td class="r">
            Rutgers University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114720" title="Click to go to the Author Index">
             Yu, Jingjin
            </a>
           </td>
           <td class="r">
            Rutgers University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114191" title="Click to go to the Author Index">
             Boularias, Abdeslam
            </a>
           </td>
           <td class="r">
            Rutgers University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2826" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present LGMCTS, a framework that uniquely combines language guidance with geometrically informed sampling distributions to effectively rearrange objects according to geometric patterns dictated by natural language descriptions. LGMCTS uses Monte Carlo Tree Search (MCTS) to create feasible action plans that ensure executable semantic object rearrangement. We present a comprehensive comparison with leading approaches that use language to generate goal rearrangements independently of actionable planning, including Structformer, StructDiffusion, and Code as policies. We also present a new benchmark, the Executable Language Guided Rearrangement (ELGR) Bench, containing tasks involving intricate geometry. With the ELGR bench, we show limitations of task and motion planning (TAMP) solutions that are purely based on Large Language Models (LLM) such as Code as Policies and Progprompt on such tasks. Our findings advocate for using LLMs to generate intermediary representations rather than direct action planning in geometrically complex rearrangement scenarios, aligning with perspectives from recent literature. Our code and supplementary materials are accessible at https://github.com/changhaonan/LG-MCTS.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct6_04">
             17:15-17:30, Paper FrCT6.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1276'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Task Planning for Long-Horizon Cooking Tasks Based on Large Language Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338378" title="Click to go to the Author Index">
             Shin, Jungkyoo
            </a>
           </td>
           <td class="r">
            Chung Ang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338582" title="Click to go to the Author Index">
             Han, Jieun
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372246" title="Click to go to the Author Index">
             Kim, Seungjun
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#154127" title="Click to go to the Author Index">
             Oh, Yoonseon
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#163619" title="Click to go to the Author Index">
             Kim, Eunwoo
            </a>
           </td>
           <td class="r">
            Chung-Ang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1276" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#software_architecture_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Software Architecture for Robotic and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the field of robot manipulation, learnable task planners are gaining attention, especially for long-horizon tasks such as cooking. However, existing methods that predominantly rely on symbolic representations suffer from limitations in generalization capabilities, particularly in handling unseen objects. Given that objects may vary in real-world environments, this limitation may constrain their practical applicability. To address this issue, we propose a novel task-planning framework that leverages a pretrained large language model (LLM) for environmental interpretation. Our proposed framework extracts semantic features directly from textual data, enabling the planner to accommodate unfamiliar objects. We further incorporate a transformer-based encoder-decoder framework to understand environmental attributes derived from the language model and generate sequential predictions in line with objectoriented subgoals. To validate the effectiveness of our model, we utilize a dataset focused on cooking recipes. Going a step further, we propose a method that automatically generates objectoriented data from natural language description using recurrent LLM, enhancing the framework to manage previously unseen targets as well. Our framework shows an average success rate of 95% when validated with test sets that involve unseen objects. By providing the automatically generated dataset to the framework, we achieve a significant 27% increase in success rate on unknown target recipes. We also provide evidence of the real-world viability of our planner by successfully deploying it on a robot platform.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frct7">
             <b>
              FrCT7
             </b>
            </a>
           </td>
           <td class="r">
            Room 7
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frct7" title="Click to go to the Program at a Glance">
             <b>
              Prosthetics and Exoskeleton
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#209027" title="Click to go to the Author Index">
             Tortora, Stefano
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct7_01">
             16:30-16:45, Paper FrCT7.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1057'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Velocity Dependent Delayed Output Feedback Control (v-DOFC) for Gait Assistance with an Ergonomically Designed Bi-Directional Cable-Driven Hip Assist Device
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#320923" title="Click to go to the Author Index">
             Kim, Dong Hyun
            </a>
           </td>
           <td class="r">
            Samsung Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#321305" title="Click to go to the Author Index">
             Park, Junghoon
            </a>
           </td>
           <td class="r">
            Samsung Electronics Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351461" title="Click to go to the Author Index">
             Shin, Gyowook
            </a>
           </td>
           <td class="r">
            Samsung Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339397" title="Click to go to the Author Index">
             Yoon, Chiyul
            </a>
           </td>
           <td class="r">
            Samsung Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#147182" title="Click to go to the Author Index">
             Kim, Yongtae Giovanni
            </a>
           </td>
           <td class="r">
            Samsung Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#183739" title="Click to go to the Author Index">
             Kim, Sang-Hun
            </a>
           </td>
           <td class="r">
            Samsung Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#146457" title="Click to go to the Author Index">
             Hyung, SeungYong
            </a>
           </td>
           <td class="r">
            Samsung Electronics Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105736" title="Click to go to the Author Index">
             Kang, Sung-Chul
            </a>
           </td>
           <td class="r">
            Samsung Research, Samsung Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#146456" title="Click to go to the Author Index">
             Lee, Minhyung
            </a>
           </td>
           <td class="r">
            Samsung Advanced Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1057" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#prosthetics_and_exoskeletons" title="Click to go to the Keyword Index">
               Prosthetics and Exoskeletons
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_factors_and_human_in_the_loop" title="Click to go to the Keyword Index">
               Human Factors and Human-in-the-Loop
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#wearable_robotics" title="Click to go to the Keyword Index">
               Wearable Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Hip assistance with cable-driven devices has been proven to help decrease the metabolic cost of gait. However, most existing devices use heavy actuating modules or provide assistance in only one direction, limiting the effectiveness. Cable-driven devices are also difficult to accurately estimate the hip position using only motor encoders, therefore utilizing various auxiliary sensors. This paper introduces a 1.5 kg cable-driven soft wearable hip assist device that can provide assistance in both flexion and extension, using a velocity-dependent delayed output feedback controller (v-DOFC). The device is designed with the consideration of ergonomics and pressure distribution of wearable parts, to increase the anchoring performance and comfort. The controller uses time-delayed feedback proportional to the velocity output state, allowing control without requiring accurate position estimation. Additionally, directional weighting is used to provide different assistance forces for extension and flexion to match different optimal assistance values. Experimental results show that the device can reduce metabolic cost by 13.8 % compared to walking without the device. The soft wearable hip assist device can be applied to help the elderly with weaker muscles to walk longer distances.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct7_02">
             16:45-17:00, Paper FrCT7.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1705'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Closed-Loop Control for Lower Limb Exoskeleton Considering Overall Deformations: A Simple and Direct Application Method
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310628" title="Click to go to the Author Index">
             Li, Feng
            </a>
           </td>
           <td class="r">
            Shenzhen Institute of Advanced Technology Chinere Academy of Sci
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#369878" title="Click to go to the Author Index">
             Yang, Ming
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#369856" title="Click to go to the Author Index">
             Chen, Ziqiang
            </a>
           </td>
           <td class="r">
            Shenzhen Institute of Advanced Technology, Chinese Academy of Sc
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#373318" title="Click to go to the Author Index">
             Luan, Mengbo
            </a>
           </td>
           <td class="r">
            Shenzhen Institute of Advanced Technologyï¼ŒChinese Academy
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#362318" title="Click to go to the Author Index">
             Tian, Dingkui
            </a>
           </td>
           <td class="r">
            Shenzhen Advanced Technology Research Institute, Chinese Academy
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100984" title="Click to go to the Author Index">
             Wu, Xinyu
            </a>
           </td>
           <td class="r">
            CAS
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1705" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#prosthetics_and_exoskeletons" title="Click to go to the Keyword Index">
               Prosthetics and Exoskeletons
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, considering overall deformations of the exoskeleton, we couple deformations relationship network (DRN) with fractional order viscoelastic (FOV) controller, proposing a novel DRN-FOV closed-loop control method, endowing exoskeleton with stable dynamic walking ability. Simply by utilizing only the data from the 6-axis force/torque sensors, the DRN can directly capture the mapping relationship between the foot reaction force/torque of the exoskeleton and its overall deformations. We introduce the FOV to eliminate disturbances and stabilize during walking tasks. The closed-loop control method directly compensates for the overall deformations of the exoskeleton and enables the wearer to walk stably wearing the exoskeleton. To assess the effectiveness of the proposed control method, walking tasks were effectively carried out on subjects with varying body parameters using the developed exoskeleton. The experimental results show that the DRN-FOV closed-loop control method accurately estimates and compensates for deformations, resulting in an improved dynamic walking ability of the exoskeleton with wearers.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct7_03">
             17:00-17:15, Paper FrCT7.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2177'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Effect of Tactile and Deep Sensory Feedback Synchronized with the Manipulation of Myoelectric Hand on Body Recognition
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394907" title="Click to go to the Author Index">
             Hamaoka, Rintaro
            </a>
           </td>
           <td class="r">
            Yokohama National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#121763" title="Click to go to the Author Index">
             Kato, Ryu
            </a>
           </td>
           <td class="r">
            Yokohama National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2177" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#prosthetics_and_exoskeletons" title="Click to go to the Keyword Index">
               Prosthetics and Exoskeletons
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cyborgs" title="Click to go to the Keyword Index">
               Cyborgs
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A prosthetic hand is intended to be recognized as a part of new body, but the current myoelectric prosthetic hand is not recognized as a body due to clumsy movements and lack of sensory feedback (FB). To improve the body recognition of a prosthetic hand, existing research has discussed the body recognition of myoelectric prosthetic hands from the two concepts of the sense of ownership and the sense of agency, with the rubber hand illusion as a representative example. The sense of ownership (SO) is the feeling that a body part is part of one's own body, and the sense of agency (SA) is the feeling that one is in control of the body part's movement. However, these studies were conducted on prosthetic hands that were left stationary, and there are still many unknowns regarding the specific factors associated with the movements of myoelectric prosthetic hands. Therefore, in this study, we prototyped a myoelectric prosthetic hand with tactile and deep sensory FB and investigated the effects of each sensory FB on body recognition through psychophysical experiments. In this study, a 2-DOF myoelectric prosthetic hand that can open and close the hand and rotate the wrist was equipped with a tactile and deep sensory FB system. Tactile FB transmits the fingertip pressure of the prosthetic hand through vibration, and deep sensory FB transmits the wrist angle of the prosthetic hand by tightening the cuff wrapped around the arm. Using this prosthetic hand, we performed an object grasping task with the tactile FB and a reaching task with the deep sensory FB. We evaluated the degree of body recognition when performing tasks using a questionnaire and investigated the effect of each sensory FB on body recognition by comparing the presence and absence of sensory FB. The object grasping task was performed on 8 able-bodied subjects and 1 forearm amputee. Tactile FB was shown to improve SO and SA in able-bodied subjects. Furthermore, it was shown that with repeated trials, the SO improved even in the absence of tactile FB. On the other hand, in forearm amputees, tactile FB did not change the SO and improved the SA. This indicates that the tactile FB in this study improves body recognition in able-bodied subjects, but it may only improve the SA in forearm amputees. The reaching task was performed on 5 healthy subjects. As a result, deep sensory FB slightly improved the SO, but no effect on the SA was observed. One possible reason for this result may be that the subjects trusted their natural deep sensation more than the prosthetic hand's deep sensory FB system. In conclusion, tactile FB may improve body recognition of myoelectric prosthetic hands. Furthermore, deep sensory FB may have little effect on body recognition in this setup. To investigate the effect of deep sensory FB in detail, it is considered necessary to conduct tests on able-bodied subjects and forearm amputees in an experimental setup that takes into account natural deep sensations.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct7_04">
             17:15-17:30, Paper FrCT7.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2206'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Environment-Adaptive Gait Planning for Obstacle Avoidance in Lower-Limb Robotic Exoskeletons
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396653" title="Click to go to the Author Index">
             Trombin, Edoardo
            </a>
           </td>
           <td class="r">
            University of Padua
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#209027" title="Click to go to the Author Index">
             Tortora, Stefano
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105144" title="Click to go to the Author Index">
             Menegatti, Emanuele
            </a>
           </td>
           <td class="r">
            The University of Padua
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#187558" title="Click to go to the Author Index">
             Tonin, Luca
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2206" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#prosthetics_and_exoskeletons" title="Click to go to the Keyword Index">
               Prosthetics and Exoskeletons
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Powered lower limb exoskeletons (LLEs) have emerged as wearable robots designed to augment users' locomotion capabilities, offering mechanical support and additional power for both healthy and impaired subjects. However, current assistive exoskeletons are limited by predefined motion trajectories, hindering adaptability to unstructured environments encountered in daily life. To address this limitation, this paper proposes an environment-adaptive gait planning (EAGP) solution. The approach integrates scene understanding, pose estimation, and adaptive gait planning modules. A novel Collision-Free Foot Trajectory Generator (CFFTG) algorithm facilitates obstacle avoidance by computing collision-free foot trajectories, enhancing safety and adaptability. Through inverse kinematics, the planned trajectories are converted into angular joint trajectories for execution by low-level control. This comprehensive framework aims to enhance the adaptability and safety of LLEs, paving the way for broader real-world applications beyond clinical and research settings.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frct8">
             <b>
              FrCT8
             </b>
            </a>
           </td>
           <td class="r">
            Room 8
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frct8" title="Click to go to the Program at a Glance">
             <b>
              Intelligent Transportation Systems II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#103628" title="Click to go to the Author Index">
             Matteucci, Matteo
            </a>
           </td>
           <td class="r">
            Politecnico Di Milano
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct8_01">
             16:30-16:45, Paper FrCT8.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1417'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Agent Traffic Prediction Via Denoised Endpoint Distribution
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340645" title="Click to go to the Author Index">
             Liu, Yao
            </a>
           </td>
           <td class="r">
            Macquarie University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396078" title="Click to go to the Author Index">
             Wang, Ruoyu
            </a>
           </td>
           <td class="r">
            University of New South Wales
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395969" title="Click to go to the Author Index">
             Cao, Yuanjiang
            </a>
           </td>
           <td class="r">
            Macquarie University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396429" title="Click to go to the Author Index">
             Sheng, Quan Z.
            </a>
           </td>
           <td class="r">
            Macquarie University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#340665" title="Click to go to the Author Index">
             Yao, Lina
            </a>
           </td>
           <td class="r">
            Csiro &amp; Unsw
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1417" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intention_recognition" title="Click to go to the Keyword Index">
               Intention Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The exploration of high-speed movement by robots or road traffic agents is crucial for autonomous driving and navigation. Trajectory prediction at high speeds requires considering historical features and interactions with surrounding entities, a complexity not as pronounced in lower-speed environments. Prior methods have assessed the spatio-temporal dynamics of agents but often neglected intrinsic intent and uncertainty, thereby limiting their effectiveness. We present the Denoised Endpoint Distribution model for trajectory prediction, which distinctively models agents' spatio-temporal features alongside their intrinsic intentions and uncertainties. By employing Diffusion and Transformer models to focus on agent endpoints rather than entire trajectories, our approach significantly reduces model complexity and enhances performance through endpoint information. Our experiments on open datasets, coupled with comparison and ablation studies, demonstrate our model's efficacy and the importance of its components. This approach advances trajectory prediction in high-speed scenarios and lays groundwork for future developments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct8_02">
             16:45-17:00, Paper FrCT8.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1217'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Towards Enhanced Fairness and Sample Efficiency in Traffic Signal Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#389961" title="Click to go to the Author Index">
             Huang, Xingshuai
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384488" title="Click to go to the Author Index">
             Wu, Di
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104422" title="Click to go to the Author Index">
             Jenkin, Michael
            </a>
           </td>
           <td class="r">
            York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#225214" title="Click to go to the Author Index">
             Boulet, Benoit
            </a>
           </td>
           <td class="r">
            McGill University, Centre for Intelligent Machines
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1217" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Traffic signal control (TSC) has seen substantial advancements through the application of reinforcement learning (RL) algorithms, which have shown remarkable potential in enhancing traffic flow efficiency. These RL-based approaches often surpass traditional rule-based methods, particularly in dynamic traffic environments. However, current RL solutions for TSC predominantly rely on model-free methods, necessitating extensive environmental interactions during training. This requirement can be prohibitively expensive or unfeasible in real-world implementations. Furthermore, existing methods have frequently neglected the issue of fairness in multi-intersection control, resulting in unbalanced congestion across different intersections. To address these challenges, we present FM2Light, a fairness-aware model-based multi-agent RL framework for TSC. Our approach leverages an ensemble of global world models for generating synthetic samples to enhance sample efficiency, thereby mitigating the data-intensive nature of the training process. Additionally, FM2Light incorporates a refined reward structure to promote fairness and improve coordination across multiple intersections. Extensive evaluations conducted in diverse real-world scenarios demonstrate that FM2Light achieves performance comparable to or exceeding that of model-free RL (MFRL) methods, while significantly reducing sample requirements and ensuring more equitable control among multiple agents.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct8_03">
             17:00-17:15, Paper FrCT8.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1510'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Automatic 3D Road Surface Reconstruction Via Cross-Section Modeling and Interpolation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#315095" title="Click to go to the Author Index">
             Bellusci, Matteo
            </a>
           </td>
           <td class="r">
            Politecnico Di Milano
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103628" title="Click to go to the Author Index">
             Matteucci, Matteo
            </a>
           </td>
           <td class="r">
            Politecnico Di Milano
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1510" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurate 3D road surfaces are important for the development of detailed and realistic scenarios to validate autonomous driving algorithms. In these scenarios, simulations can be conducted, for instance, to evaluate the response of a safety system under dangerous conditions. In this paper, we propose an approach designed to automatically generate 3D road surfaces from data collected by a vehicle equipped with various sensors, including a LiDAR. These road surfaces are meant to be both accurate and realistic for driving simulations. The proposed approach, after deriving the clothoidal representation of the surface borders, pursues the idea of extracting and interpolating a set of smooth 3D cross-section profiles. The resulting surface provides a 3D representation in analytical form, allowing detailed rendering at the desired resolution. We experimentally evaluate the proposed approach in a real-world scenario to assess its performance in terms of accuracy, scalability, and computing time.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct8_04">
             17:15-17:30, Paper FrCT8.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2901'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              EnduRL: Enhancing Safety, Stability, and Efficiency of Mixed Traffic under Real-World Perturbations Via Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#348744" title="Click to go to the Author Index">
             Poudel, Bibek
            </a>
           </td>
           <td class="r">
            University of Tennessee Knoxville
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#233248" title="Click to go to the Author Index">
             Li, Weizi
            </a>
           </td>
           <td class="r">
            University of Tennessee, Knoxville
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#213522" title="Click to go to the Author Index">
             Heaslip, Kevin
            </a>
           </td>
           <td class="r">
            University of Tennessee Knoxville
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2901" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Human-driven vehicles amplify naturally occurring perturbations in traffic, leading to congestion -- a major contributor to increased fuel consumption, higher collision risks, and reduced capacity utilization. While previous research demonstrates that a fraction of Robot Vehicles (RVs) can mitigate these issues, most such studies rely on simulations with simplistic models of human car-following behavior. In contrast, this study analyzes real-world human driving trajectories, extracting a wide range of acceleration behaviors during car-following, then incorporates these behaviors in simulation where RVs from prior studies are employed to mitigate congestion. We focus on evaluation of safety, efficiency, and stability with comprehensive experiments conducted in two mixed traffic environments (Ring road and Bottleneck) at various densities, configurations and RV penetration rates. The results demonstrate that under the real-world perturbations, prior RVs have performance degradation on all 3 categories (sometimes even lower than 100% human traffic). To address this, we introduce a reinforcement learning based RV that utilizes a congestion stage classifier neural network to optimize either safetyplus stability or efficiency. Our RVs demonstrate significant improvements: safety by up to 66%, efficiency by up to 54%, and stability by up to 97%.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frct9">
             <b>
              FrCT9
             </b>
            </a>
           </td>
           <td class="r">
            Room 9
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frct9" title="Click to go to the Program at a Glance">
             <b>
              Planning, Scheduling and Coordination I
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#166583" title="Click to go to the Author Index">
             Bhounsule, Pranav
            </a>
           </td>
           <td class="r">
            University of Illinois at Chicago
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#191337" title="Click to go to the Author Index">
             Mettu, Ramgopal
            </a>
           </td>
           <td class="r">
            Tulane University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct9_01">
             16:30-16:45, Paper FrCT9.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2766'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Evaluating Dynamic Environment Difficulty for Obstacle Avoidance Benchmarking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#331836" title="Click to go to the Author Index">
             Shi, Moji
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#252947" title="Click to go to the Author Index">
             Chen, Gang
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#225975" title="Click to go to the Author Index">
             Serra-GÃ³mez, Ãlvaro
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#297457" title="Click to go to the Author Index">
             Wu, Siyuan
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142433" title="Click to go to the Author Index">
             Alonso-Mora, Javier
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2766" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#performance_evaluation_and_benchmarking" title="Click to go to the Keyword Index">
               Performance Evaluation and Benchmarking
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#software_tools_for_benchmarking_and_reproducibility" title="Click to go to the Keyword Index">
               Software Tools for Benchmarking and Reproducibility
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Dynamic obstacle avoidance is a popular research topic for autonomous systems, such as micro aerial vehicles and service robots. Accurately evaluating the performance of dynamic obstacle avoidance methods necessitates the establishment of a metric to quantify the environment's difficulty, a crucial aspect that remains unexplored. In this paper, we propose four metrics to measure the difficulty of dynamic environments. These metrics aim to comprehensively capture the influence of obstacles' number, size, velocity, and other factors on the difficulty. We compare the proposed metrics with existing static environment difficulty metrics and validate them through over 1.5 million trials in a customized simulator. This simulator excludes the effects of perception and control errors and supports different motion and gaze planners for obstacle avoidance. The results indicate that the survivability metric outperforms and establishes a monotonic relationship between the success rate, with a Spearman's Rank Correlation Coefficient (SRCC) of over 0.9. Specifically, for every planner, lower survivability leads to a higher success rate. This metric not only facilitates fair and comprehensive benchmarking but also provides insights for refining collision avoidance methods, thereby furthering the evolution of autonomous systems in dynamic environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct9_02">
             16:45-17:00, Paper FrCT9.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('696'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Attention-Aware Deep Reinforcement Learning Framework for UAV-UGV Collaborative Route Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354972" title="Click to go to the Author Index">
             Mondal, Mohammad Safwan
            </a>
           </td>
           <td class="r">
            University of Illinois Chicago
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#329588" title="Click to go to the Author Index">
             Ramasamy, Subramanian
            </a>
           </td>
           <td class="r">
            University of Illinois at Chicago
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#328786" title="Click to go to the Author Index">
             Humann, James
            </a>
           </td>
           <td class="r">
            DEVCOM Army Research Laboratory,
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#415366" title="Click to go to the Author Index">
             James, Dotterweich, Jim
            </a>
           </td>
           <td class="r">
            Army Research Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#328781" title="Click to go to the Author Index">
             Reddinger, Jean-Paul
            </a>
           </td>
           <td class="r">
            DEVCOM Army Research Laboratory,
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#328784" title="Click to go to the Author Index">
             Childers, Marshal
            </a>
           </td>
           <td class="r">
            DEVCOM Army Research Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#166583" title="Click to go to the Author Index">
             Bhounsule, Pranav
            </a>
           </td>
           <td class="r">
            University of Illinois at Chicago
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab696" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Unmanned aerial vehicles (UAVs) possess the capability to survey vast areas, yet their operational range is limited by their battery capacity. Deploying mobile recharging stations via unmanned ground vehicles (UGVs) can significantly enhance the endurance and effectiveness of UAVs. However, optimizing the routes for both UAVs and UGVs, referred to as the UAV-UGV cooperative routing problem, requires a sophisticated planning framework to determine the vehiclesâ€™ routes and their recharging points. To address this, in this paper, we utilize a deep reinforcement learning (DRL) based framework equipped with multi-head attention layers. The framework is designed to sequentially select actions to construct routes for the UAV and UGV and to establish their rendezvous points for recharging. We evaluate our framework across various problem instance sizes and distributions, comparing it against recent heuristic-based methods and an existing learning-based method as baselines. Our proposed algorithm surpasses these baselines in terms of solution quality and runtime efficiency in the test scenarios, thus proving its effectiveness. Additionally, we investigate the application of our DRL policy in online mission planning to accommodate dynamic changes within the mission scenario.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct9_03">
             17:00-17:15, Paper FrCT9.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('764'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Coordinated Multi-Arm 3D Printing Using Reeb Decomposition
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#267635" title="Click to go to the Author Index">
             Khatkar, Jayant
            </a>
           </td>
           <td class="r">
            University of Technology Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238113" title="Click to go to the Author Index">
             Sukkar, Fouad
            </a>
           </td>
           <td class="r">
            University of Technology Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#268876" title="Click to go to the Author Index">
             Clemon, Lee
            </a>
           </td>
           <td class="r">
            University of Technology Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#191337" title="Click to go to the Author Index">
             Mettu, Ramgopal
            </a>
           </td>
           <td class="r">
            Tulane University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab764" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#additive_manufacturing" title="Click to go to the Keyword Index">
               Additive Manufacturing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic additive manufacturing has the potential to replace traditional production techniques with more flexible, capable and efficient methods. However, this potential has not been realized to date due to the intrinsic physical limitations of extruders. Thus improved speed and efficiency lies in coordinated fabrication by multiple extruders. In this paper, we propose a framework for utilizing multiple extruders to collaboratively fabricate objects in a shared workspace. In contrast to related work, we make use of a Reeb decomposition method of the input model, which dramatically reduces the search space over feasible toolpaths but still results in highly effective allocation of model components to each extruder. We demonstrate superior performance of our approach in simulation as well as in hardware with a two-robot arm extruder system. When compared to a single extruder approach over a benchmark of 14 models, our method achieves a mean improvement of 72% in extruder utilization. When compared to two additional toolpath planning methods for multiple extruders, only our method is able to successfully complete a valid toolpath on all models. Prior methods fail on more than half of our benchmark due to reaching deadlocked states during toolpath planning. On the models for which all methods succeed, our approach achieves mean utilization improvements of 132% over zone-blocking and 12% over contour greedy. We demonstrate that our approach is also suitable for models with non-planar slicings both in simulation and in practice. Results for the non-planar setting yielded further improvements in extruder utilization. For more results and information see: https://sites.google.com/view/multi-arm-reeb.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct9_04">
             17:15-17:30, Paper FrCT9.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2856'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Transformer-Based Multi-Agent Reinforcement Learning for Generalization of Heterogeneous Multi-Robot Cooperation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#358509" title="Click to go to the Author Index">
             Cai, Yuxin
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#300172" title="Click to go to the Author Index">
             He, Xiangkun
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238454" title="Click to go to the Author Index">
             Guo, Hongliang
            </a>
           </td>
           <td class="r">
            Agency for Science Technology and Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196715" title="Click to go to the Author Index">
             Yau, Wei-Yun
            </a>
           </td>
           <td class="r">
            I2R
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#240752" title="Click to go to the Author Index">
             Lv, Chen
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2856" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent advances in multi-agent reinforcement learning (MARL) have significantly enhanced cooperation capabilities within multi-robot teams. However, the application to heterogeneous teams poses the critical challenge of combinatorial generalizationâ€”adapting learned policies to teams with new compositions of varying sizes and robots capabilities. This challenge is paramount for dynamic real-world scenarios where teams must swiftly adapt to changing environmental and task conditions. To address this, we introduce a novel transformer-based MARL method for heterogeneous multi-robot cooperation. Our approach leverages graph neural net-works and self-attention mechanisms to effectively capture the intricate dynamics among heterogeneous robots, facilitating policy adaptation to team size variations. Moreover, by treating robot team decisions as sequential inputs, a capability-oriented decoder is introduced to generate actions in an auto-regressive manner, enabling decentralized decision-making that tailored each robotâ€™s varying capabilities and heterogeneity type. Furthermore, we evaluate our method across two heterogeneous cooperation scenarios in both simulated and real-world environments, featuring variations in team number and robot capabilities. Comparative results reveal our methodâ€™s superior generalization performance compared to existing MARL methodologies, marking its potential for real-world multi-robot applications.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frct10">
             <b>
              FrCT10
             </b>
            </a>
           </td>
           <td class="r">
            Room 10
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frct10" title="Click to go to the Program at a Glance">
             <b>
              Object Detection, Segmentation and Categorization II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#101712" title="Click to go to the Author Index">
             Song, Dezhen
            </a>
           </td>
           <td class="r">
            Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI) and Texas A&amp;M University (TAMU)
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#196876" title="Click to go to the Author Index">
             Vu, Minh Nhat
            </a>
           </td>
           <td class="r">
            TU Wien, Austria
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct10_01">
             16:30-16:45, Paper FrCT10.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('209'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              IC-FPS: Instance-Centroid Faster Point Sampling Framework for 3D Point-Based Object Detection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390840" title="Click to go to the Author Index">
             Hu, Haotian
            </a>
           </td>
           <td class="r">
            Zhejiang Leapmotor Technology Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390841" title="Click to go to the Author Index">
             Wang, Fanyi
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#411061" title="Click to go to the Author Index">
             Wang, YaoNong
            </a>
           </td>
           <td class="r">
            Zhejiang Leapmotor Technology Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#411058" title="Click to go to the Author Index">
             Hu, Laifeng
            </a>
           </td>
           <td class="r">
            Zhejiang Leapmotor Technology Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390864" title="Click to go to the Author Index">
             Zhang, Zhiwang
            </a>
           </td>
           <td class="r">
            NingboTech University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab209" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             3D object detection is one of the most important tasks in autonomous driving and robotics. Our research focuses on tackling low efficiency issue of point-based methods, and we propose a novel Instance-Centroid Faster Point Sampling (IC-FPS) framework. We design a Neighboring Feature Diffusion Module (NFDM) to extract local features for the purpose of efficiently distinguishing the foreground from the background. Considering Farthest Point Sampling (FPS) strategy for downsampling is computationally intensive, we propose the Centroid-Instance Sampling Strategy (CISS).CISS samples center point in large-scale point cloud by rapidly sampling the centroid and instance points of the foreground block. The proposed IC-FPS framework can be inserted into every point-based model and effectively replace the first Set Abstraction (SA) layer. Extensive experiments on several public benchmarks demonstrate the superior performance of our proposed IC-FPS. On the Waymo dataset, IC-FPS significantly improves performance of the benchmark model and increases inference speed by 3.8 times. And real-time detection of point-based methods is realized for the first time, which is meaningful for industrial applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct10_02">
             16:45-17:00, Paper FrCT10.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('282'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Similarity Distance-Based Label Assignment for Tiny Object Detection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390163" title="Click to go to the Author Index">
             Shi, Shuohao
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#289699" title="Click to go to the Author Index">
             Fang, Qiang
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391523" title="Click to go to the Author Index">
             Zhao, Tong
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#131923" title="Click to go to the Author Index">
             Xu, Xin
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab282" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Tiny object detection is becoming one of the most challenging tasks in computer vision because of the limited object size and lack of information. The label assignment strategy is a key factor affecting the accuracy of object detection. Although there are some effective label assignment strategies for tiny objects, most of them focus on reducing the sensitivity to the bounding boxes to increase the number of positive samples and have some fixed hyperparameters need to set. However, more positive samples may not necessarily lead to better detection results, in fact, excessive positive samples may lead to more false positives. In this paper, we introduce a simple but effective strategy named the Similarity Distance (SimD) to evaluate the similarity between bounding boxes. This proposed strategy not only considers both location and shape similarity but also learns hyperparameters adaptively, ensuring that it can adapt to different datasets and various object sizes in a dataset. Our approach can be simply applied in common anchor-based detectors in place of the IoU for label assignment and Non Maximum Suppression (NMS). Extensive experiments on four mainstream tiny object detection datasets demonstrate superior performance of our method, especially, 1.8 AP points and 4.1 AP points of very tiny higher than the state-of-the-art competitors on AI-TOD. Code is available at: https://github.com/cszzshi/SimD.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct10_03">
             17:00-17:15, Paper FrCT10.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('285'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Lightweight Language-Driven Grasp Detection Using Conditional Consistency Model
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391536" title="Click to go to the Author Index">
             Nguyen, Nghia
            </a>
           </td>
           <td class="r">
            FPT Software Company Limited
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196876" title="Click to go to the Author Index">
             Vu, Minh Nhat
            </a>
           </td>
           <td class="r">
            TU Wien, Austria
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#234039" title="Click to go to the Author Index">
             Huang, Baoru
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350994" title="Click to go to the Author Index">
             Vuong, An Dinh
            </a>
           </td>
           <td class="r">
            MBZUAI
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351637" title="Click to go to the Author Index">
             Le, Ngan
            </a>
           </td>
           <td class="r">
            University of Arkansas
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#351899" title="Click to go to the Author Index">
             Vo, Thieu
            </a>
           </td>
           <td class="r">
            Ton Duc Thang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#171078" title="Click to go to the Author Index">
             Nguyen, Anh
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab285" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Language-driven grasp detection is a fundamental yet challenging task in robotics with various industrial applications. This work presents a new approach for language-driven grasp detection that leverages lightweight diffusion models to achieve fast inference time. By integrating diffusion processes with grasping prompts in natural language, our method can effectively encode visual and textual information, enabling more accurate and versatile grasp positioning that aligns well with the text query. To overcome the long inference time problem in diffusion models, we leverage the image and text features as the condition in the consistency model to reduce the number of denoising timesteps during inference. The intensive experimental results show that our method outperforms other recent grasp detection methods and lightweight diffusion models by a clear margin. We further validate our method in real-world robotic experiments to demonstrate its fast inference time capability.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct10_04">
             17:15-17:30, Paper FrCT10.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1516'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Road Boundary Estimation Using Sparse Automotive Radar Inputs
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219778" title="Click to go to the Author Index">
             Kingery, Aaron
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101712" title="Click to go to the Author Index">
             Song, Dezhen
            </a>
           </td>
           <td class="r">
            Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1516" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Low-cost millimeter wavelength automotive radar can work effectively under low visibility or low reflection conditions caused by lighting, weather, pollution, or object surface properties when a camera or a lidar may fail. It can serve as a fallback solution to improve safety in autonomous driving.	However, after filtering, radar signals tend to be sparse and noisy which pose new challenges in scene understanding. This paper presents a new approach to detecting road boundaries based on sparse radar signals. We model the roadway using a homogeneous model and derive its conditional predictive model under known radar motion. Using this predictive model and model radar points using a Dirichlet Process Mixture Model, we employ Mean Field Variational Inference (MFVI) to derive an unconditional road boundary model distribution. In order to generate initial candidate solutions for the MFVI, we develop a custom Random Sample and Consensus (RANSAC) variant to propose unseen model instances as candidate road boundaries. For each radar point cloud we alternate the MFVI and RANSAC proposal steps until convergence to generate the best estimate of all candidate models. We select the candidate model with the minimum lateral distance to the radar on each side as the estimates of the left and right boundaries. We have implemented the proposed algorithm and it has shown satisfactory results. More specifically, the mean lane boundary estimation error is not more than 11.0 cm.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frct11">
             <b>
              FrCT11
             </b>
            </a>
           </td>
           <td class="r">
            Room 11
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frct11" title="Click to go to the Program at a Glance">
             <b>
              Locomotion Control
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct11_01">
             16:30-16:45, Paper FrCT11.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3089'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Motion Planning for Automata-Based Objectives Using Efficient Gradient-Based Methods
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#241031" title="Click to go to the Author Index">
             Balakrishnan, Anand
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396641" title="Click to go to the Author Index">
             Atasever, Merve
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#241241" title="Click to go to the Author Index">
             Deshmukh, Jyotirmoy
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3089" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#formal_methods_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Formal Methods in Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In recent years, there has been increasing interest in using formal methods-based techniques to safely achieve temporal tasks, such as timed sequence of goals, or patrolling objectives. Such tasks are often expressed in real-time logics such as Signal Temporal Logic (STL), whereby, the logical specification is encoded into an optimization problem. Such approaches usually involve optimizing over the quantitative semantics, or robustness degree, of the logic over bounded horizons: the semantics can be encoded as mixed-integer linear constraints or into smooth approximations of the robustness degree. A major limitation of this approach is that it faces scalability challenges with respect to temporal complexity: for example, encoding long-term tasks requires storing the entire history of the system. In this paper, we present a quantitative generalization of such tasks in the form of symbolic automata objectives. Specifically, we show that symbolic automata can be expressed as matrix operators that lend themselves to automatic differentiation, allowing for the use of off-the-shelf gradient-based optimizers. We show how this helps solve the need to store arbitrarily long system trajectories, while efficiently leveraging the task structure encoded in the automaton.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct11_02">
             16:45-17:00, Paper FrCT11.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2530'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Real-Time Model Predictive Control with Zonotope-Based Neural Networks for Bipedal Social Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#226703" title="Click to go to the Author Index">
             Shamsah, Abdulaziz
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395495" title="Click to go to the Author Index">
             Agarwal, Krishanu
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#206254" title="Click to go to the Author Index">
             Kousik, Shreyas
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#158317" title="Click to go to the Author Index">
             Zhao, Ye
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2530" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study addresses the challenge of bipedal navigation in a dynamic human-crowded environment, a research area that remains largely underexplored in the field of legged navigation. We propose two cascaded zonotope-based neural networks: a Pedestrian Prediction Network (PPN) for pedestrians' future trajectory prediction and an Ego-agent Social Network (ESN) for ego-agent social path planning. Representing future paths as zonotopes allows for efficient reachability-based planning and collision checking. The ESN is then integrated with a Model Predictive Controller (ESN-MPC) for footstep planning for our bipedal robot Digit designed by Agility Robotics. ESN-MPC solves for a collision-free optimal trajectory by optimizing through the gradients of ESN. ESN-MPC optimal trajectory is sent to the low-level controller for full-order simulation of Digit. The overall proposed framework is validated with extensive simulations on randomly generated initial settings with varying human crowd densities.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct11_03">
             17:00-17:15, Paper FrCT11.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2555'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              FootstepNet: An Efficient Actor-Critic Method for Fast On-Line Bipedal Footstep Planning and Forecasting
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394243" title="Click to go to the Author Index">
             Gaspard, ClÃ©ment
            </a>
           </td>
           <td class="r">
            LaBRI - University of Bordeaux
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#163740" title="Click to go to the Author Index">
             Passault, GrÃ©goire
            </a>
           </td>
           <td class="r">
            LaBRI
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285942" title="Click to go to the Author Index">
             Daniel, MÃ©lodie
            </a>
           </td>
           <td class="r">
            LaBRI - UniversitÃ© De Bordeaux
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#137536" title="Click to go to the Author Index">
             Ly, Olivier
            </a>
           </td>
           <td class="r">
            LaBRI - Bordeaux University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2555" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Designing a humanoid locomotion controller is challenging and classically split up in sub-problems. Footstep planning is one of those, where the sequence of footsteps is defined. Even in simpler environments, finding a minimal sequence, or even a feasible sequence, yields a complex optimization problem.
             <p>
              In the literature, this problem is usually addressed by search-based algorithms (e.g. variants of A*). However, such approaches are either computationally expensive or rely on hand-crafted tuning of several parameters.
              <p>
               In this work, at first, we propose an efficient footstep planning method to navigate in local environments with obstacles, based on state-of-the art Deep Reinforcement Learning (DRL) techniques, with very low computational requirements for on-line inference. Our approach is heuristic-free and relies on a continuous set of actions to generate feasible footsteps. In contrast, other methods necessitate the selection of a relevant discrete set of actions.
               <p>
                Second, we propose a forecasting method, allowing to quickly estimate the number of footsteps required to reach different candidates of local targets. This approach relies on inherent computations made by the actor-critic DRL architecture.
                <p>
                 We demonstrate the validity of our approach with simulation results, and by a deployment on a kid-size humanoid robot during the RoboCup 2023 competition.
                </p>
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct11_04">
             17:15-17:30, Paper FrCT11.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2811'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              On the Benefits of GPU Sample-Based Stochastic Predictive Controllers for Legged Locomotion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277908" title="Click to go to the Author Index">
             Turrisi, Giulio
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#177063" title="Click to go to the Author Index">
             Modugno, Valerio
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286825" title="Click to go to the Author Index">
             Amatucci, Lorenzo
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#147896" title="Click to go to the Author Index">
             Kanoulas, Dimitrios
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108792" title="Click to go to the Author Index">
             Semini, Claudio
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2811" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Quadrupedal robots excel in mobility, navigating complex terrains with agility. However, their complex control systems present challenges that are still far from being fully addressed. In this paper, we introduce the use of Sample-Based Stochastic control strategies for quadrupedal robots, as an alternative to traditional optimal control laws. We show that Sample-Based Stochastic methods, supported by GPU acceleration, can be effectively applied to real quadruped robots. In particular, in this work, we focus on achieving gait frequency adaptation, a notable challenge in quadrupedal locomotion for gradient-based methods. To validate the effectiveness of Sample-Based Stochastic controllers we test two distinct approaches for quadrupedal robots and compare them against a conventional gradient-based Model Predictive Control system. Our findings, validated both in simulation and on a real 21Kg Aliengo quadruped, demonstrate that our method is on par with a traditional Model Predictive Control strategy when the robot is subject to zero or moderate disturbance, while it surpasses gradient-based methods in handling sustained external disturbances, thanks to the straightforward gait adaptation strategy that is possible to achieve within their formulation.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frct12">
             <b>
              FrCT12
             </b>
            </a>
           </td>
           <td class="r">
            Room 12
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frct12" title="Click to go to the Program at a Glance">
             <b>
              Semantic Scene Understanding IV
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#189409" title="Click to go to the Author Index">
             Beltrame, Giovanni
            </a>
           </td>
           <td class="r">
            Ecole Polytechnique De Montreal
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct12_01">
             16:30-16:45, Paper FrCT12.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('932'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GRID: Scene-Graph-Based Instruction-Driven Robotic Task Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372995" title="Click to go to the Author Index">
             Ni, Zhe
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375194" title="Click to go to the Author Index">
             Deng, Xiaoxin
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375208" title="Click to go to the Author Index">
             Tai, Cong
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375369" title="Click to go to the Author Index">
             Zhu, Xinyue
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#385142" title="Click to go to the Author Index">
             Xie, Qinghongbing
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391567" title="Click to go to the Author Index">
             Huang, Weihang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375277" title="Click to go to the Author Index">
             Wu, Xiang
            </a>
           </td>
           <td class="r">
            Shenzhen Pudu Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#214687" title="Click to go to the Author Index">
             Zeng, Long
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab932" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#service_robotics" title="Click to go to the Keyword Index">
               Service Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent works have shown that Large Language Models (LLMs) can facilitate the grounding of instructions for robotic task planning. Despite this progress, most existing works have primarily focused on utilizing raw images to aid LLMs in understanding environmental information. However, this approach not only limits the scope of observation but also typically necessitates extensive multimodal data collection and large-scale models. In this paper, we propose a novel approach called Graph-based Robotic Instruction Decomposer (GRID), which leverages scene graphs instead of images to perceive global scene information and iteratively plan subtasks for a given instruction. Our method encodes object attributes and relationships in graphs through an LLM and Graph Attention Networks, integrating instruction features to predict subtasks consisting of pre-defined robot actions and target objects in the scene graph. This strategy enables robots to acquire semantic knowledge widely observed in the environment from the scene graph. To train and evaluate GRID, we establish a dataset construction pipeline to generate synthetic datasets for graphbased robotic task planning. Experiments have shown that our method outperforms GPT-4 by over 25.4% in subtask accuracy and 43.6% in task accuracy. Moreover, our method achieves a real-time speed of 0.11s per inference. Experiments conducted on datasets of unseen scenes and scenes with varying numbers of objects demonstrate that the task accuracy of GRID declined by at most 3.8%, showcasing its robust cross-scene generalization ability. We validate our method in both physical simulation and the real world. More details can be found on the project page https://jackyzengl.github.io/GRID.github.io/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct12_02">
             16:45-17:00, Paper FrCT12.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3429'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ASI-Seg: Audio-Driven Surgical Instrument Segmentation with Surgeon Intention Understanding
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286502" title="Click to go to the Author Index">
             Chen, Zhen
            </a>
           </td>
           <td class="r">
            Centre for Artificial Intelligence and Robotics (CAIR), Hong Kon
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395677" title="Click to go to the Author Index">
             Zhang, Zongmin
            </a>
           </td>
           <td class="r">
            CAIR
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395728" title="Click to go to the Author Index">
             Guo, Wenwu
            </a>
           </td>
           <td class="r">
            CAIR
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394593" title="Click to go to the Author Index">
             Luo, Xingjian
            </a>
           </td>
           <td class="r">
            Centre for Artificial Intelligence and Robotics (CAIR) Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310803" title="Click to go to the Author Index">
             Bai, Long
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#381813" title="Click to go to the Author Index">
             Wu, Jinlin
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106795" title="Click to go to the Author Index">
             Ren, Hongliang
            </a>
           </td>
           <td class="r">
            Chinese Univ Hong Kong (CUHK) &amp; National Univ Singapore(NUS)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104575" title="Click to go to the Author Index">
             Liu, Hongbin
            </a>
           </td>
           <td class="r">
            Hong Kong Institute of Science &amp; Innovation, Chinese Academy Of
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3429" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Surgical instrument segmentation is crucial in surgical scene understanding, thereby facilitating surgical safety. Existing algorithms directly detected all instruments of pre-defined categories in the input image, lacking the capability to segment specific instruments according to the surgeon's intention. During different stages of surgery, surgeons exhibit varying preferences and focus toward different surgical instruments. Therefore, an instrument segmentation algorithm that adheres to the surgeon's intention can minimize distractions from irrelevant instruments and assist surgeons to a great extent. The recent Segment Anything Model (SAM) reveals the capability to segment objects following prompts, but the manual annotations for prompts are impractical during the surgery. To address these limitations in operating rooms, we propose an audio-driven surgical instrument segmentation framework, named ASI-Seg, to accurately segment the required surgical instruments by parsing the audio commands of surgeons. Specifically, we propose an intention-oriented multimodal fusion to interpret the segmentation intention from audio commands and retrieve relevant instrument details to facilitate segmentation. Moreover, to guide our ASI-Seg segment of the required surgical instruments, we devise a contrastive learning prompt encoder to effectively distinguish the required instruments from the irrelevant ones. Therefore, our ASI-Seg promotes the workflow in the operating rooms, thereby providing targeted support and reducing the cognitive load on surgeons. Extensive experiments are performed to validate the ASI-Seg framework, which reveals remarkable advantages over classical state-of-the-art and medical SAMs in both semantic segmentation and intention-oriented segmentation. The source code is available at https://github.com/Zonmgin-Zhang/ASI-Seg.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct12_03">
             17:00-17:15, Paper FrCT12.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3434'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              OV-MAP : Open-Vocabulary Zero-Shot 3D Instance Segmentation Map for Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352172" title="Click to go to the Author Index">
             Kim, Juno
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352260" title="Click to go to the Author Index">
             Park, Yesol
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339622" title="Click to go to the Author Index">
             Yoon, Hye Jung
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#133606" title="Click to go to the Author Index">
             Zhang, Byoung-Tak
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3434" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce OV-MAP, a novel approach to open-world 3D mapping for mobile robots by integrating open-features into 3D maps to enhance object recognition capabilities. A significant challenge arises when overlapping features from adjacent voxels reduce instance-level precision, as features spill over voxel boundaries, blending neighboring regions together. Our method overcomes this by employing a class-agnostic segmentation model to project 2D masks into 3D space, combined with a supplemented depth image created by merging raw and synthetic depth from point clouds. This approach, along with a 3D mask voting mechanism, enables accurate zero-shot 3D instance segmentation without relying on 3D supervised segmentation models. We assess the effectiveness of our method through comprehensive experiments on public datasets such as ScanNet200 and Replica, demonstrating superior zero-shot performance, robustness, and adaptability across diverse environments. Additionally, we conducted real-world experiments to demonstrate our method's adaptability and robustness when applied to diverse real-world environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct12_04">
             17:15-17:30, Paper FrCT12.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1675'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Active Semantic Mapping and Pose Graph Spectral Analysis for Robot Exploration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#348824" title="Click to go to the Author Index">
             Zhang, Rongge
            </a>
           </td>
           <td class="r">
            Polytechnique Montreal
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379270" title="Click to go to the Author Index">
             Bong, Haechan Mark
            </a>
           </td>
           <td class="r">
            Polytechnique Montreal
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#189409" title="Click to go to the Author Index">
             Beltrame, Giovanni
            </a>
           </td>
           <td class="r">
            Ecole Polytechnique De Montreal
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1675" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#view_planning_for_slam" title="Click to go to the Keyword Index">
               View Planning for SLAM
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Exploration in unknown and unstructured environments is a pivotal requirement for robotic applications. A robot's exploration behavior can be inherently affected by the performance of its Simultaneous Localization and Mapping (SLAM) subsystem, although SLAM and exploration are generally studied separately. In this paper, we formulate exploration as an active mapping problem and extend it with semantic information. We introduce a novel active metric-semantic SLAM approach, leveraging recent research advances in information theory and spectral graph theory: we combine semantic mutual information and the connectivity metrics of the underlying pose graph of the SLAM subsystem. We use the resulting utility function to evaluate different trajectories to select the most favorable strategy during exploration. Exploration and SLAM metrics are analyzed in experiments. Running our algorithm on the Habitat dataset, we show that, while maintaining efficiency close to the state-of-the-art exploration methods, our approach effectively increases the performance of metric-semantic SLAM with a 21% reduction in average map error and a 9% improvement in average semantic classification accuracy.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frct13">
             <b>
              FrCT13
             </b>
            </a>
           </td>
           <td class="r">
            Room 13
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frct13" title="Click to go to the Program at a Glance">
             <b>
              Robot Safety II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#154562" title="Click to go to the Author Index">
             Saveriano, Matteo
            </a>
           </td>
           <td class="r">
            University of Trento
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct13_01">
             16:30-16:45, Paper FrCT13.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('432'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Exploiting Hybrid Policy in Reinforcement Learning for Interpretable Temporal Logic Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#317052" title="Click to go to the Author Index">
             Zhang, Hao
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#304444" title="Click to go to the Author Index">
             Wang, Hao
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#376442" title="Click to go to the Author Index">
             Huang, Xiucai
            </a>
           </td>
           <td class="r">
            Chongqing University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#166682" title="Click to go to the Author Index">
             Chen, Wenrui
            </a>
           </td>
           <td class="r">
            Hunan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#206291" title="Click to go to the Author Index">
             Kan, Zhen
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab432" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#formal_methods_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Formal Methods in Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Reinforcement Learning (RL) based methods have been increasingly explored for robot learning. However, RL based methods often suffer from low sampling efficiency in the exploration phase, especially for long-horizon manipulation tasks, and generally neglect the semantic information from the task level, resulted in a delayed convergence or even tasks failure. To address these issues, we develop a Temporal-Logic-guided Hybrid policy framework (HyTL) which exploits three-level decision layers to facilitate robot learning. Specifically, the task specifications are encoded via linear temporal logic (LTL) to improve performance and offer interpretability. And a waypoints planning module is designed with the feedback from the LTL-encoded task level as a high-level policy to improve the exploration efficiency. The middle- level policy chooses which behavior primitives to implement and the low-level policy determines how to interact with the environment. We evaluate HyTL on four challenging manipulation tasks, which demonstrate its effectiveness and interpretability. Supplementary and simulation videos are available at: https://sites.google.com/view/hytl-0257/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct13_02">
             16:45-17:00, Paper FrCT13.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2635'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CoBL-Diffusion: Diffusion-Based Conditional Robot Planning in Dynamic Environments Using Control Barrier and Lyapunov Functions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398470" title="Click to go to the Author Index">
             Mizuta, Kazuki
            </a>
           </td>
           <td class="r">
            University of Washington
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#220110" title="Click to go to the Author Index">
             Leung, Karen
            </a>
           </td>
           <td class="r">
            University of Washington
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2635" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Equipping autonomous robots with the ability to navigate safely and efficiently around humans is a crucial step toward achieving trusted robot autonomy. However, generating robot plans while ensuring safety in dynamic multi-agent environments remains a key challenge. Building upon recent work on leveraging deep generative models for robot planning in static environments, this paper proposes algo, a novel diffusion-based safe robot planner for dynamic environments. CoBL-Diffusion uses Control Barrier and Lyapunov functions to guide the denoising process of a diffusion model, iteratively refining the robot control sequence to satisfy the safety and stability constraints. We demonstrate the effectiveness of CoBL-Diffusion using two settings: a synthetic single-agent environment and a real-world pedestrian dataset. Our results show that CoBL-Diffusion generates smooth trajectories that enable the robot to reach goal locations while maintaining a low collision rate with dynamic obstacles.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct13_03">
             17:00-17:15, Paper FrCT13.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3020'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ODD-diLLMma: Driving Automation System ODD Compliance Checking Using LLMs
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#226219" title="Click to go to the Author Index">
             Hildebrandt, Carl
            </a>
           </td>
           <td class="r">
            University of Virginia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291289" title="Click to go to the Author Index">
             Woodlief, Trey
            </a>
           </td>
           <td class="r">
            University of Virginia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#147791" title="Click to go to the Author Index">
             Elbaum, Sebastian
            </a>
           </td>
           <td class="r">
            University of Virginia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3020" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#big_data_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Big Data in Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Although Driving Automation Systems (DASs) are rapidly becoming more advanced and ubiquitous, they are still confined to specific Operational Design Domains (ODDs) over which the system must be trained and validated. Yet, each DAS has a bespoke and often informally defined ODD, which makes it intractable to manually judge whether a dataset satisfies a DASâ€™s ODD. This results in inadequate data leaking into the training and testing processes, weakening them, and causes large amounts of collected data to go unused given the inability to check their ODD compliance. This presents a dilemma: How do we cost-effectively determine if existing sensor data complies with a DASâ€™s ODD? To address this challenge, we start by reviewing the ODD specifications of 10 commercial DASs to understand current practices in ODD documentation. Next, we present ODD-diLLMma, an automated method that leverages Large Language Models (LLMs) to analyze existing datasets with respect to the natural language specifications of ODDs. Our evaluation of ODD-diLLMma examines its utility in analyzing inputs from 3 real-world datasets. Our empirical findings show that ODD-diLLMma significantly enhances the efficiency of detecting ODD compliance, showing improvements of up to 147% over a human baseline. Further, our analysis highlights the strengths and limitations of employing LLMs to support ODD-diLLMma, underscoring their potential to effectively address the challenges of ODD compliance detection.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frct13_04">
             17:15-17:30, Paper FrCT13.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3256'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MADE: Malicious Agent Detection for Robust Multi-Agent Collaborative Perception
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398953" title="Click to go to the Author Index">
             Zhao, Yangheng
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399022" title="Click to go to the Author Index">
             Xiang, Zhen
            </a>
           </td>
           <td class="r">
            University of Illinois, Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398970" title="Click to go to the Author Index">
             Yin, Sheng
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398958" title="Click to go to the Author Index">
             Pang, Xianghe
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#313278" title="Click to go to the Author Index">
             Wang, Yanfeng
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#320620" title="Click to go to the Author Index">
             Chen, Siheng
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3256" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recently, multi-agent collaborative (MAC) percep- tion has been proposed and outperformed the traditional single- agent perception in many applications, such as autonomous driving. However, MAC perception is more vulnerable to adversarial attacks than single-agent perception due to the information exchange. The attacker can easily degrade the performance of a victim agent by sending harmful information from a malicious agent nearby. In this paper, we propose Malicious Agent Detection (MADE), a reactive defense specific to MAC perception that can be deployed by an agent to accurately detect and then remove any potential malicious agent in its local collaboration network. In particular, MADE inspects each agent in the network independently using a semi-supervised anomaly detector based on a double-hypothesis test with the Benjamini-Hochberg procedure for false positive control. For the two hypothesis tests, we propose a match loss statistic and a collaborative reconstruction loss statistic, respectively, both based on the consistency between the agent to be inspected and the ego agent deployed with our detector. We comprehensively evaluate MADE on a benchmark 3D dataset, V2X-sim, and a real-road dataset, DAIR-V2X, comparing it to baseline defenses. Notably, with the protection of MADE, the drops in the average precision compared with the best-case â€˜Oracleâ€™ defender are merely 1.27% and 0.28%, respectively.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frdt1">
             <b>
              FrDT1
             </b>
            </a>
           </td>
           <td class="r">
            Room 1
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frdt1" title="Click to go to the Program at a Glance">
             <b>
              Vision-Based Navigation IV
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt1_01">
             17:30-17:45, Paper FrDT1.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1730'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhancing Exploratory Capability of Visual Navigation Using Uncertainty of Implicit Scene Representation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392365" title="Click to go to the Author Index">
             Wang, Yichen
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393991" title="Click to go to the Author Index">
             Liu, Qiming
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#147237" title="Click to go to the Author Index">
             Liu, Zhe
            </a>
           </td>
           <td class="r">
            University of Cambridge
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103003" title="Click to go to the Author Index">
             Wang, Hesheng
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1730" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the context of visual navigation in unknown scenes, both "exploration" and "exploitation" are equally crucial. Robots must first establish environmental cognition through exploration and then utilize the cognitive information to accomplish target searches. However, most existing methods for image-goal navigation prioritize target search over the generation of exploratory behavior. To address this, we propose the Navigation with Uncertainty-driven Exploration (NUE) pipeline, which uses an implicit and compact scene representation, NeRF, as a cognitive structure. We estimate the uncertainty of NeRF and augment the exploratory ability by the uncertainty to in turn facilitate the construction of implicit representation. Simultaneously, we extract memory information from NeRF to enhance the robot's reasoning ability for determining the location of the target. Ultimately, we seamlessly combine the two generated abilities to produce navigational actions. Our pipeline is end-to-end, with the environmental cognitive structure being constructed online. Extensive experimental results on image-goal navigation demonstrate the capability of our pipeline to enhance exploratory behaviors, while also enabling a natural transition from the exploration to exploitation phase. This enables our model to outperform existing memory-based cognitive navigation structures in terms of navigation performance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt1_02">
             17:45-18:00, Paper FrDT1.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2963'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ActiveRIR: Active Audio-Visual Exploration for Acoustic Environment Modeling
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398757" title="Click to go to the Author Index">
             Somayazulu, Arjun
            </a>
           </td>
           <td class="r">
            UT Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#287044" title="Click to go to the Author Index">
             Majumder, Sagnik
            </a>
           </td>
           <td class="r">
            UT Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237583" title="Click to go to the Author Index">
             Chen, Changan
            </a>
           </td>
           <td class="r">
            UT Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#285477" title="Click to go to the Author Index">
             Grauman, Kristen
            </a>
           </td>
           <td class="r">
            UT Austin and Facebook AI Research
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2963" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             An environment acoustic model represents how sound is transformed by the physical characteristics of an indoor environment, for any given source/receiver location. Traditional methods for constructing acoustic models involve expensive and time-consuming collection of large quantities of acoustic data at dense spatial locations in the space, or rely on privileged knowledge of scene geometry to intelligently select acoustic data sampling locations. We propose active acoustic sampling, a new task for efficiently building an environment acoustic model of an unmapped environment in which a mobile agent equipped with visual and acoustic sensors jointly constructs the environment acoustic model and the occupancy map on-the-fly. We introduce ActiveRIR, a reinforcement learning (RL) policy that leverages information from audio-visual sensor streams to guide agent navigation and determine optimal acoustic data sampling positions, yielding a high quality acoustic model of the environment from a minimal set of acoustic samples. We train our policy with a novel RL reward based on information gain in the environment acoustic model. Evaluating on diverse unseen indoor environments from a state-of-the-art acoustic simulation platform, ActiveRIR outperforms an array of methods-both traditional navigation agents based on spatial novelty and visual exploration as well as existing state-of-the-art methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt1_03">
             18:00-18:15, Paper FrDT1.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3063'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CoNVOI: Context-Aware Navigation Using Vision Language Models in Outdoor and Indoor Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#243363" title="Click to go to the Author Index">
             Sathyamoorthy, Adarsh Jagan
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#308861" title="Click to go to the Author Index">
             Kulathun Mudiyanselage, Kasun Weerakoon
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#367201" title="Click to go to the Author Index">
             Elnoor, Mohamed
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398884" title="Click to go to the Author Index">
             Zore, Anuj
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#202934" title="Click to go to the Author Index">
             Ichter, Brian
            </a>
           </td>
           <td class="r">
            Google Brain
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#235958" title="Click to go to the Author Index">
             Xia, Fei
            </a>
           </td>
           <td class="r">
            Google Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219934" title="Click to go to the Author Index">
             Tan, Jie
            </a>
           </td>
           <td class="r">
            Google
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#198071" title="Click to go to the Author Index">
             Yu, Wenhao
            </a>
           </td>
           <td class="r">
            Google
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106235" title="Click to go to the Author Index">
             Manocha, Dinesh
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3063" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present CoNVOI, a novel method for autonomous robot navigation in real-world indoor and outdoor environments using Vision Language Models (VLMs). We employ VLMs in two ways: first, we leverage their zero-shot image classification capability to identify the context or scenario (e.g., indoor corridor, outdoor terrain, crosswalk, etc) of the robot's surroundings, and formulate context-based navigation behaviors as simple text prompts (e.g. "stay on the pavement"). Second, we utilize their state-of-the-art semantic understanding and logical reasoning capabilities to compute a suitable trajectory given the identified context. To this end, we propose a novel multi-modal visual marking approach to annotate the obstacle-free regions in the RGB image used as input to the VLM with numbers, by correlating it with a local occupancy map of the environment. The marked numbers ground image locations in the real-world, direct the VLM's attention solely to navigable locations, and elucidate the spatial relationships between them and terrains depicted in the image to the VLM. Next, we query the VLM to select numbers on the marked image that satisfy the context-based behavior text prompt, and construct a reference path using the selected numbers. Finally, we propose a method to extrapolate the reference trajectory when the robot's environmental context has not changed to prevent unnecessary VLM queries. We use the reference trajectory to guide a motion planner, and demonstrate that it leads to human-like behaviors (e.g. not cutting through a group of people, using crosswalks, etc.) in various real-world indoor and outdoor scenarios. We perform several ablations and navigation comparisons and demonstrate that CoNVOI's trajectories are most similar to human teleoperated ground truth in terms of FrÃ©chet distance (9.7-58.2% closer), lowest path errors (up to 88.13% lower), and up to 86.09% lower % of unacceptable paths.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt1_04">
             18:15-18:30, Paper FrDT1.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3439'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Malicious Path Manipulations Via Exploitation of Representation Vulnerabilities of Vision-Language Navigation Systems
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#393509" title="Click to go to the Author Index">
             Islam, Chashi Mahiul
            </a>
           </td>
           <td class="r">
            Florida State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395965" title="Click to go to the Author Index">
             Salman, Shaeke
            </a>
           </td>
           <td class="r">
            Florida State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397026" title="Click to go to the Author Index">
             Shams, Montasir
            </a>
           </td>
           <td class="r">
            Florida State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#117760" title="Click to go to the Author Index">
             Liu, Xiuwen
            </a>
           </td>
           <td class="r">
            Florida State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395955" title="Click to go to the Author Index">
             Kumar, Piyush
            </a>
           </td>
           <td class="r">
            Florida State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3439" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Building on the unprecedented capabilities of large language models for command understanding and zero-shot recognition of multi-modal vision-language transformers, visual language navigation (VLN) has emerged as an effective way to address multiple fundamental challenges toward a natural language interface to robot navigation. However, such vision- language models are inherently vulnerable due to the lack of semantic meaning of the underlying embedding space. Using a recent developed gradient-based optimization procedure, we demonstrate that images can be modified imperceptibly to match the representation of totally different images and unrelated texts for a vision-language model. Building on this, we develop algorithms that can adversarially modify a minimal number of images so that the robot will follow a route of choice for commands that require a number of landmarks. We demonstrate that experimentally using a recently proposed VLN system; for a given navigation command, a robot can be made to follow drastically different routes. We also develop an efficient algorithm to detect such malicious modifications reliably based on the fact that the adversarially modified images have much higher sensitivity to added Gaussian noise than the original images.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frdt2">
             <b>
              FrDT2
             </b>
            </a>
           </td>
           <td class="r">
            Room 2
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frdt2" title="Click to go to the Program at a Glance">
             <b>
              Telerobotics and Teleoperation II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#100579" title="Click to go to the Author Index">
             Kheddar, Abderrahmane
            </a>
           </td>
           <td class="r">
            CNRS-AIST
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt2_01">
             17:30-17:45, Paper FrDT2.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2686'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Feelit: Combining Compliant Shape Displays with Vision-Based Tactile Sensors for Real-Time Teletaction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#373030" title="Click to go to the Author Index">
             Yu, Oscar
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#184771" title="Click to go to the Author Index">
             She, Yu
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2686" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#haptics_and_haptic_interfaces" title="Click to go to the Keyword Index">
               Haptics and Haptic Interfaces
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Teletaction, the transmission of tactile feedback or touch, is a crucial aspect in the field of teleoperation. High-quality teletaction feedback allows users to remotely manipulate objects and increase the quality of the human-machine interface between the operator and the robot, making complex manipulation tasks possible. Advances in the field of teletaction for teleoperation however, have yet to make full use of the high-resolution 3D data provided by modern vision-based tactile sensors. Existing solutions for teletaction lack in one or more areas of form or function, such as fidelity or hardware footprint. In this paper, we showcase our design for a low-cost teletaction device that can utilize real-time high-resolution tactile information from vision-based tactile sensors, through both physical 3D surface reconstruction and shear displacement. We present our device, the Feelit, which uses a combination of a pin-based shape display and compliant mechanisms to accomplish this task. The pin-based shape display utilizes an array of 24 servomotors with miniature Bowden cables, giving the device a resolution of 6x4 pins in a 15x10 mm display footprint. Each pin can actuate up to 3 mm in 200 ms, while providing ~80 N of force and 1.5 um of depth resolution. Shear displacement and rotation is achieved using a compliant mechanism design, allowing a minimum of 1 mm displacement laterally and 10 degrees of rotation. This real-time 3D tactile reconstruction is achieved with the use of a vision-based tactile sensor, the GelSight, along with an algorithm that samples the depth data and marker tracking to generate actuator commands. Through a series of experiments including shape recognition and relative weight identification, we show that our device has the potential to expand teletaction capabilities in the teleoperation space.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt2_02">
             17:45-18:00, Paper FrDT2.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2690'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Radiance Fields for Robotic Teleoperation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398435" title="Click to go to the Author Index">
             Wilder-Smith, Maximum
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#275404" title="Click to go to the Author Index">
             Patil, Vaishakh
            </a>
           </td>
           <td class="r">
            RSL ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#114045" title="Click to go to the Author Index">
             Hutter, Marco
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2690" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#virtual_reality_and_interfaces" title="Click to go to the Keyword Index">
               Virtual Reality and Interfaces
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Radiance field methods such as Neural Radiance Fields (NeRFs) or 3D Gaussian Splatting (3DGS), have revolutionized graphics and novel view synthesis. Their ability to synthesize new viewpoints with photo-realistic quality, as well as capture complex volumetric and specular scenes, makes them an ideal visualization for robotic teleoperation setups. Direct camera teleoperation provides high-fidelity operation at the cost of maneuverability, while reconstruction-based approaches offer controllable scenes with lower fidelity. With this in mind, we propose replacing the traditional reconstruction-visualization components of the robotic teleoperation pipeline with online radiance fields, offering highly maneuverable scenes with photorealistic quality. As such, there are three main contributions to state of the art: (1) online training of radiance fields using live data from multiple cameras, (2) support for a variety of radiance methods including NeRF and 3DGS, (3) visualization suite for these methods including a virtual reality scene. To enable seamless integration with existing setups, these components were tested with multiple robots in multiple configurations and were displayed using traditional tools as well as the VR headset. The results across methods and robots were compared quantitatively to a baseline of mesh reconstruction, and a user study was conducted to compare the different visualization methods. The code and additional samples are available at https://leggedrobotics.github.io/rffr.github.io/
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt2_03">
             18:00-18:15, Paper FrDT2.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2692'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Demonstrating Trustworthiness in Open-Loop Model Mediated Teleoperation for Collecting Lunar Regolith Simulant
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395961" title="Click to go to the Author Index">
             Louca, Joe
            </a>
           </td>
           <td class="r">
            University of Bristol
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396797" title="Click to go to the Author Index">
             Zemeny, Aliz
            </a>
           </td>
           <td class="r">
            European Space Agency
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#139741" title="Click to go to the Author Index">
             Tzemanaki, Antonia
            </a>
           </td>
           <td class="r">
            University of Bristol
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397854" title="Click to go to the Author Index">
             Charles, Romain
            </a>
           </td>
           <td class="r">
            European Space Agency
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2692" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#acceptability_and_trust" title="Click to go to the Keyword Index">
               Acceptability and Trust
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Teleoperated robotics will be an essential tool to support upcoming lunar exploration and in-situ resource utilisation activities. However, the communication delays between Earth and the Moon makes operating these robots extremely challenging. Model-Mediated Teleoperation (MMT) is a method of controlling these remote systems in perceived real-time, via a simulation, but is dependent on the accuracy of its model. In this work, a computationally efficient model of lunar regolith was implemented in an open-loop MMT system. The behaviour of the virtual model was compared with its physical equivalent during manipulation tasks. The model predicted the outcome of a regolith simulant scooping task with sufficient accuracy to be considered effective and trustworthy 100% and 92.5% of the time, respectively. Pouring actions were less accurate, but trustworthiness and effectiveness can still be ensured by restricting the orientation of the end effector whilst carrying simulant material. Simulated haptic interactions were representative of the real-world during simple, linear tasks (pressing and dragging), but not during more complex motions. This simulation could be adapted to account for reduced gravity, to form a delay-robust lunar MMT system, or to build operators' trust in the system by familiarising themselves in a low-risk virtual world.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt2_04">
             18:15-18:30, Paper FrDT2.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3431'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Towards Kbps-Level Vehicle Teleoperation Via Persistent-Transient Environment Modelling
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#253652" title="Click to go to the Author Index">
             Zhao, Chunyang
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397190" title="Click to go to the Author Index">
             Zhou, Zeyu
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397192" title="Click to go to the Author Index">
             Liu, Haoran
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#226688" title="Click to go to the Author Index">
             Kircali, Dogan
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205806" title="Click to go to the Author Index">
             Chi, Guoyi
            </a>
           </td>
           <td class="r">
            Intelligent Robotics Lab, S2.1-B4-01, EEE, NTU, 50 Nanyang Avenue
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#281401" title="Click to go to the Author Index">
             Shen, Hongming
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#240150" title="Click to go to the Author Index">
             Wang, Yuanzhe
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100565" title="Click to go to the Author Index">
             Wang, Danwei
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3431" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Traditional teleoperation technologies based on video streaming are facing several challenges in practical applications, including limited bandwidth, constrained spatial awareness, and sensitivity to illumination. Existing studies have not adequately addressed these issues. This paper presents a novel non-video based teleoperation framework for autonomous vehicles operating in bandwidth-limited environments. To reduce the amount of data being transmitted, a persistent-transient environment model is proposed for telepresence. Initially, a digital twin of the environment is preconstructed, containing only persistent environmental information. Subsequently, transient information captured by onboard sensors, such as vehicle state and dynamic objects, necessitate real-time transmission. Based on this model, a 3D virtual scene is rendered in front of the teleoperator, offering any desired virtual viewpoint to enhance spatial awareness. This telepresence model only requires real-time transmission of minimal data, i.e., vehicle state and detected objects, and remains unaffected by illumination conditions, enabling teleoperation even in applications with Kbps-level bandwidth constraints. Experimental results showcase the substantial potential of the proposed framework in bandwidth-limited settings.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frdt3">
             <b>
              FrDT3
             </b>
            </a>
           </td>
           <td class="r">
            Room 3
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frdt3" title="Click to go to the Program at a Glance">
             <b>
              Manipulation Planning
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#104011" title="Click to go to the Author Index">
             Choset, Howie
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#106618" title="Click to go to the Author Index">
             Tzes, Anthony
            </a>
           </td>
           <td class="r">
            New York University Abu Dhabi
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt3_01">
             17:30-17:45, Paper FrDT3.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1550'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Unified Control Framework for Real-Time Interception and Obstacle Avoidance of Fast-Moving Objects with Diffusion Variational Autoencoder
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276258" title="Click to go to the Author Index">
             Dastider, Apan
            </a>
           </td>
           <td class="r">
            University of Central Florida
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#373815" title="Click to go to the Author Index">
             Fang, Hao
            </a>
           </td>
           <td class="r">
            University of Central Florida
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#222632" title="Click to go to the Author Index">
             Mingjie, Lin
            </a>
           </td>
           <td class="r">
            University of Central Florida
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1550" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Real-time interception of fast-moving objects by robotic arms in dynamic environments poses a formidable challenge due to the need for rapid reaction times, often within milliseconds, amidst dynamic obstacles. This paper introduces a unified control framework to address the above challenge by simultaneously intercepting dynamic objects and avoiding moving obstacles. Central to our approach is using diffusion-based variational autoencoder for motion planning to perform both object interception and obstacle avoidance. We begin by encoding the high-dimensional temporal information from streaming events into a two-dimensional latent manifold, enabling the discrimination between safe and colliding trajectories, culminating in the construction of an offline densely connected trajectory graph. Subsequently, we employ an extended Kalman filter to achieve precise real-time tracking of the moving object. Leveraging a graph-traversing strategy on the established offline dense graph, we generate encoded robotic motor control commands. Finally, we decode these commands to enable real-time motion of robotic motors, ensuring effective obstacle avoidance and high interception accuracy of fast-moving objects. Experimental validation on both computer simulations and autonomous 7-DoF robotic arms demonstrates the efficacy of our proposed framework. Results indicate the capability of the robotic manipulator to navigate around multiple obstacles of varying sizes and shapes while successfully intercepting fast-moving objects thrown from different angles by hand. Complete video demonstrations of our experiments can be found in https://sites.google.com/view/multirobotskill/home.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt3_02">
             17:45-18:00, Paper FrDT3.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2694'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              One-Shot Transfer of Long-Horizon Extrinsic Manipulation through Contact Retargeting
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#233985" title="Click to go to the Author Index">
             Wu, Albert
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398531" title="Click to go to the Author Index">
             Wang, Ruocheng
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#315905" title="Click to go to the Author Index">
             Chen, Sirui
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122977" title="Click to go to the Author Index">
             Eppner, Clemens
            </a>
           </td>
           <td class="r">
            NVIDIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#132937" title="Click to go to the Author Index">
             Liu, Karen
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2694" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Extrinsic manipulation, the use of environment contacts to achieve manipulation objectives, enables strategies that are otherwise impossible with a parallel jaw gripper. However, orchestrating a long-horizon sequence of contact interactions between the robot, object, and environment is notoriously challenging due to the scene diversity, large action space, and difficult contact dynamics. We observe that most extrinsic manipulation are combinations of short-horizon primitives, each of which depend strongly on initializing from a desirable contact configuration to succeed. Therefore, we propose to generalize one extrinsic manipulation trajectory to diverse objects and environments by retargeting contact requirements. We prepare a single library of robust short-horizon, goal-conditioned primitive policies, and design a framework to compose state constraints stemming from contacts specifications of each primitive. Given a test scene and a single demo prescribing the primitive sequence, our method enforces the state constraints on the test scene and find intermediate goal states using inverse kinematics. The goals are then tracked by the primitive policies. Using a 7+1 DoF robotic arm-gripper system, we achieved an overall success rate of 80.5% on hardware over 4 long-horizon extrinsic manipulation tasks, each with up to 4 primitives. Our experiments cover 10 objects and 6 environment configurations. We further show empirically that our method admits a wide range of demonstrations, and that contact retargeting is indeed the key to successfully combining primitives for long-horizon extrinsic manipulation. Code and additional details are available at stanford-tml.github.io/extrinsic-manipulation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt3_03">
             18:00-18:15, Paper FrDT3.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2954'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Motion Planning for Object Manipulation by Edge-Rolling
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398303" title="Click to go to the Author Index">
             Boroji, Maede
            </a>
           </td>
           <td class="r">
            Stony Brook University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398384" title="Click to go to the Author Index">
             Danesh, Vahid
            </a>
           </td>
           <td class="r">
            Stony Brook University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101678" title="Click to go to the Author Index">
             Kao, Imin
            </a>
           </td>
           <td class="r">
            SUNY at Stony Brook
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#132319" title="Click to go to the Author Index">
             Fakhari, Amin
            </a>
           </td>
           <td class="r">
            Stony Brook University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2954" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A common way to manipulate heavy objects is to maintain at least one point of the object in contact with the environment during the manipulation. When the object has a cylindrical shape or, in general, a curved edge, not only sliding and pivoting motions but also rolling the object along the edge can effectively satisfy this condition. Edge-rolling offers several advantages in terms of efficiency and maneuverability. This paper aims to develop a novel approach for approximating the prehensile edge-rolling motion on any path by a sequence of constant screw displacements, leveraging the principles of screw theory. Based on this approach, we proposed an algorithmic method for task-space-based path generation of object manipulation between two given configurations using a sequence of rolling and pivoting motions. The method is based on an optimization algorithm that takes into account the joint limitations of the robot. To validate our approach, we conducted experiments to manipulate a cylinder along linear and curved paths using the Franka Emika Panda manipulator.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt3_04">
             18:15-18:30, Paper FrDT3.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2647'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              PINSAT: Parallelized Interleaving of Graph Search and Trajectory Optimization for Kinodynamic Motion Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#279375" title="Click to go to the Author Index">
             Natarajan, Ramkumar
            </a>
           </td>
           <td class="r">
            Robotics Institute, Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#203683" title="Click to go to the Author Index">
             Mukherjee, Shohin
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104011" title="Click to go to the Author Index">
             Choset, Howie
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106468" title="Click to go to the Author Index">
             Likhachev, Maxim
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2647" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#nonholonomic_motion_planning" title="Click to go to the Keyword Index">
               Nonholonomic Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Trajectory optimization is a widely used technique in robot motion planning for letting the dynamics of the system shape and synthesize complex behaviors. Several previous works have shown its benefits in high-dimensional continuous state spaces and under differential constraints. However, long time horizons and planning around obstacles in non-convex spaces pose challenges in guaranteeing convergence or finding optimal solutions. As a result, discrete graph search planners and sampling-based planers are preferred when facing obstacle-cluttered environments. A recently developed algorithm called INSAT effectively combines graph search in the low-dimensional subspace and trajectory optimization in the full-dimensional space for global kinodynamic planning over long horizons. Although INSAT successfully reasoned about and solved complex planning problems, the numerous expensive calls to an optimizer resulted in large planning times, thereby limiting its practical use. Inspired by the recent work on edge-based parallel graph search, we present PINSAT, which introduces systematic parallelization in INSAT to achieve lower planning times and higher success rates, while maintaining significantly lower costs over relevant baselines. We demonstrate PINSAT by evaluating it on 6 DoF kinodynamic manipulation planning with obstacles.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frdt4">
             <b>
              FrDT4
             </b>
            </a>
           </td>
           <td class="r">
            Room 4
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frdt4" title="Click to go to the Program at a Glance">
             <b>
              Biomimetics
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#206398" title="Click to go to the Author Index">
             Kawaharazuka, Kento
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#180884" title="Click to go to the Author Index">
             Sartoretti, Guillaume Adrien
            </a>
           </td>
           <td class="r">
            National University of Singapore (NUS)
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt4_01">
             17:30-17:45, Paper FrDT4.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1099'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Wing Twist and Folding Work in Synergy to Propel Flapping Wing Animals and Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291551" title="Click to go to the Author Index">
             Fan, Xiaozhou
            </a>
           </td>
           <td class="r">
            Caltech
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392827" title="Click to go to the Author Index">
             Gehrke, Alexander
            </a>
           </td>
           <td class="r">
            Brown University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291649" title="Click to go to the Author Index">
             Breuer, Kenneth
            </a>
           </td>
           <td class="r">
            Brown University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1099" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#biomimetics" title="Click to go to the Keyword Index">
               Biomimetics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We designed and built a three degrees-of-freedom (DOF) flapping wing robot, Flapperoo, to study the aerodynamic benefits of wing folding and twisting. Forces and moments of this physical model are measured in wind tunnel experiments over a Strouhal number range of St = 0.2â€“0.4 - typical for animal flight. We perform particle image velocimetry (PIV) measurements to visualize the air jet produced by wing clapping under the ventral side of the body when wing folding is at the extreme. The results show that this jet can be directed by controlling the wing twist at the moment of clapping, which leads to greatly enhanced cycle-averaged thrust, especially at high St or low flight speeds. Additional benefits of more thrust and less negative lift are gained during upstroke using wing twist. Remarkably, less total actuating force, or less total power, is required during upstroke with wing twist. These findings emphasize the benefits of critical wing articulation for the future flapping wing/fin robots and for an accurate test platform to study natural flapping wing flight or underwater vehicles.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt4_02">
             17:45-18:00, Paper FrDT4.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('283'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Efficient Position Reconfiguration Approach for Maximizing Lifetime of Fixed-Wing Swarm Drones
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#360851" title="Click to go to the Author Index">
             Liu, Han
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391120" title="Click to go to the Author Index">
             Liu, Tian
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#266617" title="Click to go to the Author Index">
             Cui, Mingyue
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205818" title="Click to go to the Author Index">
             Shan, Yunxiao
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372656" title="Click to go to the Author Index">
             Zhao, Shuai
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#193739" title="Click to go to the Author Index">
             Huang, Kai
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab283" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#biomimetics" title="Click to go to the Keyword Index">
               Biomimetics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             With the development and application of swarm drones, some researchers have tried to replicating the migration patterns of geese in drones swarm formation to extend their lifetime. However, the problem of performing appropriate position reconfiguration based on the battery energy still remains an unsolved issue. This paper proposes an efficient position reconfiguration approach that reduces the energy consumption imbalance of the swarm and prolongs the lifetime. The approach includes: (1) a two-step MIP (mixed-integer programming)-based optimization method. (2) a two-step heuristic algorithm that can run in pseudo-polynomial time and without the need for optimization solver. The approach provides a complete position reconfiguration solution that determines (i) the number of position reconfiguration; (ii) which drones need to exchange positions in every position reconfiguration; (iii) the length of time to maintain each position before next reconfiguration. Finally, the approach is compared with other three methods in experiments which demonstrate the effectiveness of it.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt4_03">
             18:00-18:15, Paper FrDT4.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1893'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Patterned Structure Muscle : Arbitrary Shaped Wire-Driven Artificial Muscle Utilizing Anisotropic Flexible Structure for Musculoskeletal Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354208" title="Click to go to the Author Index">
             Yoshimura, Shunnosuke
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#309648" title="Click to go to the Author Index">
             Miki, Akihiro
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#321044" title="Click to go to the Author Index">
             Miyama, Kazuhiro
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#383006" title="Click to go to the Author Index">
             Sahara, Yuta
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#206398" title="Click to go to the Author Index">
             Kawaharazuka, Kento
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106350" title="Click to go to the Author Index">
             Okada, Kei
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106348" title="Click to go to the Author Index">
             Inaba, Masayuki
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1893" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#biomimetics" title="Click to go to the Keyword Index">
               Biomimetics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#tendon_wire_mechanism" title="Click to go to the Keyword Index">
               Tendon/Wire Mechanism
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Muscles of the human body are composed of tiny actuators made up of myosin and actin filaments. They can exert force in various shapes such as curved or flat, under contact forces and deformations from the environment. On the other hand, muscles in musculoskeletal robots so far have faced challenges in generating force in such shapes and environments. To address this issue, we propose Patterned Structure Muscle (PSM), artificial muscles for musculoskeletal robots. PSM utilizes patterned structures with anisotropic characteristics, wire-driven mechanisms, and is made of flexible material Thermoplastic Polyurethane (TPU) using FDM 3D printing. This method enables the creation of various shapes of muscles, such as simple 1 degree-of-freedom (DOF) muscles, Multi- DOF wide area muscles, joint-covering muscles, and branched muscles.We created an upper arm structure using these muscles to demonstrate wide range of motion, lifting heavy objects, and movements through environmental contact. These experiments show that the proposed PSM is capable of operating in various shapes and environments, and is suitable for the muscles of musculoskeletal robots.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt4_04">
             18:15-18:30, Paper FrDT4.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2189'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning-Based Hierarchical Control: Emulating the Central Nervous System for Bio-Inspired Legged Robot Locomotion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#293824" title="Click to go to the Author Index">
             Sun, Ge
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205571" title="Click to go to the Author Index">
             Shafiee, Milad
            </a>
           </td>
           <td class="r">
            EPFL
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379074" title="Click to go to the Author Index">
             Li, Peizhuo
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#216565" title="Click to go to the Author Index">
             Bellegarda, Guillaume
            </a>
           </td>
           <td class="r">
            EPFL
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105018" title="Click to go to the Author Index">
             Ijspeert, Auke
            </a>
           </td>
           <td class="r">
            EPFL
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#180884" title="Click to go to the Author Index">
             Sartoretti, Guillaume Adrien
            </a>
           </td>
           <td class="r">
            National University of Singapore (NUS)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2189" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#biomimetics" title="Click to go to the Keyword Index">
               Biomimetics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Animals possess a remarkable ability to navigate challenging terrains, achieved through the interplay of various pathways between the brain, central pattern generators (CPGs) in the spinal cord, and musculoskeletal system. Traditional bioinspired control frameworks often rely on a singular control policy that models both higher (supraspinal) and spinal cord functions. In this work, we build upon our previous research by introducing two distinct neural networks: one tasked with modulating the frequency and amplitude of CPGs to generate the basic locomotor rhythm (referred to as the spinal policy), and the other responsible for receiving environmental perception data and directly modulating the rhythmic output from the spinal policy to execute precise movements on challenging terrains (referred to as the descending modulation policy). This division of labor more closely mimics the hierarchical locomotor control systems observed in legged animals, thereby enhancing the robot's ability to navigate various uneven surfaces, including steps, high obstacles, and terrains with gaps. Additionally, we investigate the impact of sensorimotor delays within our framework, validating several biological assumptions about animal locomotion systems. Specifically, we demonstrate that spinal circuits play a crucial role in generating the basic locomotor rhythm, while descending pathways are essential for enabling appropriate gait modifications to accommodate uneven terrain. Notably, our findings also reveal that the multi-layered control inherent in animals exhibits remarkable robustness against sensorimotor delays. These findings advance our understanding of the fundamental principles governing the interplay between spinal and supraspinal mechanisms in biological locomotion. Moreover, they inform the design of bioinspired locomotion controllers that emulate these biological structures, facilitating natural movement in complex and realistic environments.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frdt5">
             <b>
              FrDT5
             </b>
            </a>
           </td>
           <td class="r">
            Room 5
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frdt5" title="Click to go to the Program at a Glance">
             <b>
              Tactile Sensing
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#101975" title="Click to go to the Author Index">
             Althoefer, Kaspar
            </a>
           </td>
           <td class="r">
            Queen Mary University of London
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#101327" title="Click to go to the Author Index">
             Kudoh, Shunsuke
            </a>
           </td>
           <td class="r">
            The University of Electro-Communications
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt5_01">
             17:30-17:45, Paper FrDT5.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('110'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Large-Scale Deployment of Vision-Based Tactile Sensors on Multi-Fingered Grippers
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#241349" title="Click to go to the Author Index">
             Wang, Meng
            </a>
           </td>
           <td class="r">
            Beijing Institute for General Artificial Intelligence
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#239988" title="Click to go to the Author Index">
             Li, Wanlin
            </a>
           </td>
           <td class="r">
            Beijing Institute for General Artificial Intelligence (BIGAI)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390687" title="Click to go to the Author Index">
             Liang, Hao
            </a>
           </td>
           <td class="r">
            Beijing Institute for General Artificial Intelligence (BIGAI)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#163585" title="Click to go to the Author Index">
             Li, Boren
            </a>
           </td>
           <td class="r">
            BIGAI
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101975" title="Click to go to the Author Index">
             Althoefer, Kaspar
            </a>
           </td>
           <td class="r">
            Queen Mary University of London
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#209690" title="Click to go to the Author Index">
             Su, Yao
            </a>
           </td>
           <td class="r">
            Beijing Institute for General Artificial Intelligence
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196468" title="Click to go to the Author Index">
             Liu, Hangxin
            </a>
           </td>
           <td class="r">
            Beijing Institute for General Artificial Intelligence (BIGAI)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab110" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Vision-based Tactile Sensors (VBTSs) show significant promise in that they can leverage image measurements to provide high-spatial-resolution human-like performance. However, current VBTS designs, typically confined to the fingertips of robotic grippers, prove somewhat inadequate, as many grasping and manipulation tasks require multiple contact points with the object. With an end goal of enabling large-scale, multi-surface tactile sensing via VBTS, our research (i) develops a synchronized image acquisition system with minimal latency, (ii) proposes a modularized VBTS design for easy integration into finger phalanges, and (iii) devises a zero-shot calibration approach to improve data efficiency in the simultaneous calibration of multiple VBTSs. In validating the system within a miniature 3-fingered robotic gripper equipped with 7 VBTSs we demonstrate improved tactile perception performance by covering the contact surfaces of both gripper fingers and palm. Additionally, we show that our VBTS design can be seamlessly integrated into various end-effector morphologies significantly reducing the data requirements for calibration.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt5_02">
             17:45-18:00, Paper FrDT5.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('573'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multidirectional Slip Detection and Avoidance Using Dynamic 3D Tactile Meshes from Visuotactile Sensors
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#219387" title="Click to go to the Author Index">
             Song, Peng
            </a>
           </td>
           <td class="r">
            Agile Robots
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#117338" title="Click to go to the Author Index">
             Corrales Ramon, Juan Antonio
            </a>
           </td>
           <td class="r">
            Universidade De Santiago De Compostela
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#105837" title="Click to go to the Author Index">
             Mezouar, Youcef
            </a>
           </td>
           <td class="r">
            Clermont Auvergne INP - SIGMA Clermont
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab573" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visuotactile sensors have gained attention during the last years in robotics because they are able to reconstruct with high precision the 3D contact shape (or mesh) between the robotic fingers and the object. A new slip detection and avoidance algorithm is proposed based on the dynamic variation of the height of the contact mesh. Firstly, the contact mesh is reconstructed in real time by applying a neural network that estimates normal vectors from color variations along all the pixels of the images recorded by the camera inside the tactile sensor. The contact mesh corresponding to this height map is used for detecting slip with higher success rates in comparison with previous approaches based on machine learning methods directly applied to contact images or the analysis of markers integrated into the sensor's surface. The proposed algorithm is validated experimentally in multiple directions not only for different types of objects (volumetric/planar/linear, deformable/rigid) but also with different resolutions of the contact mesh.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt5_03">
             18:00-18:15, Paper FrDT5.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1514'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Incipient Slip with GelSight Sensors: Attention Classification with Video Vision Transformers
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#312779" title="Click to go to the Author Index">
             Parag, Amit
            </a>
           </td>
           <td class="r">
            Sintef Ocean AS
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#162234" title="Click to go to the Author Index">
             Adelson, Edward
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#204295" title="Click to go to the Author Index">
             Misimi, Ekrem
            </a>
           </td>
           <td class="r">
            SINTEF Ocean
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1514" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             An important aspect of robotic grasping is the ability to detect incipient slip based on real time information through tactile sensors. In this paper, we propose to use Video Vision Transformers to detect the onset of slip in grasping scenarios. The dynamic nature of slip makes Video Vision Transformers well-suited for capturing temporal correlations with relatively small datasets. The training data is acquired through two GelSight tactile sensors attached to the generic finger grippers of a Panda Franka Emika robot arm that grasps, lifts and shakes 30 everyday objects in order to induce slip. We further conducted an ablation study by considering 5, 4, 3, and 2 frames prior to slip onset, revealing consistent prediction accuracies. Our approach demonstrates the capability to predict slips well in advance, even up to the 5th frame before the onset. This underscores the predictive capability of our approach, indicating its effectiveness in slip detection well ahead of its occurrence. This advance prediction capability may be a valuable tool for undertaking preemptive corrective actions, such as implementing a more secure gripper closure. We evaluate the efficiency of our approach to predict onset of slip on 10 previously-unseen objects and achieve a zero-shot mean prediction accuracy of 99%.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt5_04">
             18:15-18:30, Paper FrDT5.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1873'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Fingertip Tactile Sensor for Detecting Rope Slip
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#368621" title="Click to go to the Author Index">
             Koga, Takayuki
            </a>
           </td>
           <td class="r">
            The University of Electro-Communications
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350433" title="Click to go to the Author Index">
             Sato, Junya
            </a>
           </td>
           <td class="r">
            Japan Aviation Electronics Industry, Limited
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#350759" title="Click to go to the Author Index">
             Daigo, Takuya
            </a>
           </td>
           <td class="r">
            Japan Aviation Electronics Industry
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#177784" title="Click to go to the Author Index">
             Kimura, Kohei
            </a>
           </td>
           <td class="r">
            The University of Electro-Communications
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101327" title="Click to go to the Author Index">
             Kudoh, Shunsuke
            </a>
           </td>
           <td class="r">
            The University of Electro-Communications
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1873" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             When a robot manipulates a flexible object, a delicate grasp is required. Slip is an important indicator that can enable a robotic manipulator to delicately grasp an object. Therefore, we created a 3 Ã— 3 tactile sensor matrix covered with a elastomer grip, intended to be used on a robotic fingertip, to detect slip. We obtained tactile sensor values corresponding to the slip and nonslip states in advance and created a training dataset with several patterns. Random Forest Classifiers were trained on the datasets, and the results were compared. All nine sensor elements in the sensor matrix could detect slips with practical accuracy in the real-time robot experiments. In time periods wherein no slip occurred, no nonslip states were erroneously determined as slip states under any of the tested conditions. The slip detector created in this study was demonstrated to be applicable to types of rope that were not used to train the detector.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frdt6">
             <b>
              FrDT6
             </b>
            </a>
           </td>
           <td class="r">
            Room 6
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frdt6" title="Click to go to the Program at a Glance">
             <b>
              Towards Robot Autonomy
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#106001" title="Click to go to the Author Index">
             Bonsignorio, Fabio
            </a>
           </td>
           <td class="r">
            FER, University of Zagreb
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#103188" title="Click to go to the Author Index">
             Kyriakopoulos, Kostas
            </a>
           </td>
           <td class="r">
            New York University - Abu Dhabi
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt6_01">
             17:30-17:45, Paper FrDT6.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1637'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Toward Universal and Scalable Road Graph Partitioning for Efficient Multi-Robot Path Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#299256" title="Click to go to the Author Index">
             Han, Xingyao
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#396967" title="Click to go to the Author Index">
             Cao, Bo
            </a>
           </td>
           <td class="r">
            MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai J
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#147237" title="Click to go to the Author Index">
             Liu, Zhe
            </a>
           </td>
           <td class="r">
            University of Cambridge
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#352741" title="Click to go to the Author Index">
             Zhou, Shunbo
            </a>
           </td>
           <td class="r">
            Huawei
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#242365" title="Click to go to the Author Index">
             Zhang, Heng
            </a>
           </td>
           <td class="r">
            Huawei
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103003" title="Click to go to the Author Index">
             Wang, Hesheng
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1637" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             To date, multi-robot path planning has primarily been addressed by centralized solvers, typically aiming to maintain optimality. However, given its NP-hard nature, directly applying existing solvers in large and complex scenarios proves inefficient. A promising alternative lies in adopting a divide-and-conquer strategy to break down the problem into manageable sub-problems. In this work, we propose a systematic, universal and scalable graph partitioning method, aiming to automatically divide any real-world environment into multiple regions. Building upon this, we convert the path planning on the entire graph into distributed sub-region path planning and devise corresponding inter-regional strategies. Our work can be easily implementable in practical systems and effectively enhances the scalability of existing solvers. Experimentally, our approach contributes to a tenfold improvement in computational efficiency while only sacrificing about 10% of optimality.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt6_02">
             17:45-18:00, Paper FrDT6.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1324'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Uncertainty-Aware Deep Imitation Learning and Deployment for Autonomous Navigation through Crowded Intersections
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#267000" title="Click to go to the Author Index">
             Zhu, Zeyu
            </a>
           </td>
           <td class="r">
            Key Labarotary of Machine Perception, Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375123" title="Click to go to the Author Index">
             Wang, Shuai
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#103401" title="Click to go to the Author Index">
             Zhao, Huijing
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1324" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#control_architectures_and_programming" title="Click to go to the Keyword Index">
               Control Architectures and Programming
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Navigation through crowded intersections is a challenge for autonomous vehicles, where uncertainty arises from interaction with other road users, encountering new scenes and weathers, etc. Recent end-to-end autonomous control deep models learned from human drivers have shown promising driving performance, whereas they are not as transparent and safe as traditional rule-based systems. When facing situations that they are unfamiliar with or uncertain about, the deep models' predictions could be unsafe and untrustworthy. Without the ability to identify these situations and issue warnings beforehand, cascading errors of deep models may result in catastrophes. Therefore, this work combines the strengths of both data-driven and traditional rule-based approaches to achieve better driving quality and safety. We propose a heterogeneity uncertainty quantification method based on imitation learning, where both data and model uncertainties of the lateral and longitudinal control tasks are quantified. We also propose a policy deployment strategy where a safety indicator is developed upon estimated uncertainty to bridge the data-driven performance layer and the rule-based fallback layer. We learned from human driving demonstrations and conducted extensive closed-loop tests. Results demonstrate the effectiveness and importance of the proposed uncertainty quantification method and policy deployment strategy.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt6_03">
             18:00-18:15, Paper FrDT6.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3502'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Continual Learning for Autonomous Robots: A Prototype-Based Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#345441" title="Click to go to the Author Index">
             Hajizada, Elvin
            </a>
           </td>
           <td class="r">
            Technical University of Munich; Intel
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#399241" title="Click to go to the Author Index">
             Swaminathan, Balachandran
            </a>
           </td>
           <td class="r">
            Pennsylvania State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#138144" title="Click to go to the Author Index">
             Sandamirskaya, Yulia
            </a>
           </td>
           <td class="r">
            ZHAW
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3502" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#bioinspired_robot_learning" title="Click to go to the Keyword Index">
               Bioinspired Robot Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#continual_learning" title="Click to go to the Keyword Index">
               Continual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Humans and animals learn throughout their lives from limited amounts of sensed data, both with and without supervision. Autonomous, intelligent robots of the future are often expected to do the same. The existing continual learning (CL) methods are usually not directly applicable to robotic settings: they typically require buffering and a balanced replay of training data. A few-shot online continual learning (FS-OCL) setting has been proposed to address more realistic scenarios where robots must learn from a non-repeated sparse data stream. To enable truly autonomous life-long learning, an additional challenge of detecting novelties and learning new items without supervision needs to be addressed. We address this challenge with our new prototype-based approach called Continually Learning Prototypes (CLP). In addition to being capable of FS-OCL learning, CLP also detects novel objects and learns from them without supervision. To mitigate forgetting, CLP utilizes a novel metaplasticity mechanism that adapts the learning rate individually per prototype. CLP is rehearsal-free, hence does not require a memory buffer, and is compatible with neuromorphic hardware, characterized by ultra-low power consumption, real-time processing abilities, and on-chip learning. Indeed, we have open-sourced both the PyTorch implementation of CLP and a simpler version in the neuromorphic software framework Lava, targetting Intel's neuromorphic chip Loihi 2. We evaluate CLP on a robotic vision dataset, OpenLORIS. In a low-instance FS-OCL scenario, CLP shows state-of-the-art results. In the open world, CLP detects novelties with superior precision and recall and learns features of the detected novel classes without supervision, achieving a strong baseline of 99% base class and 65%/76% (5-shot/10-shot) novel class accuracy.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt6_04">
             18:15-18:30, Paper FrDT6.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             A Framework for Reproducible Benchmarking and Performance Diagnosis of SLAM Systems
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378065" title="Click to go to the Author Index">
             Radulov, Nikola
            </a>
           </td>
           <td class="r">
            University of Manchester
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#378147" title="Click to go to the Author Index">
             Zhang, Yuhao
            </a>
           </td>
           <td class="r">
            University of Manchester
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#238590" title="Click to go to the Author Index">
             Bujanca, Mihai
            </a>
           </td>
           <td class="r">
            University of Manchester
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#329670" title="Click to go to the Author Index">
             Ye, Ruiqi
            </a>
           </td>
           <td class="r">
            The University of Manchester
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#179609" title="Click to go to the Author Index">
             LujÃ¡n, Mikel
            </a>
           </td>
           <td class="r">
            University of Manchester
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frdt7">
             <b>
              FrDT7
             </b>
            </a>
           </td>
           <td class="r">
            Room 7
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frdt7" title="Click to go to the Program at a Glance">
             <b>
              Physical Human-Robot Interaction
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#218105" title="Click to go to the Author Index">
             Rajaei, Nader
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt7_01">
             17:30-17:45, Paper FrDT7.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1835'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Four-Axis Adaptive Fingers Hand for Object Insertion: FAAF Hand
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#137744" title="Click to go to the Author Index">
             Fukaya, Naoki
            </a>
           </td>
           <td class="r">
            Preferred Networks, Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#347163" title="Click to go to the Author Index">
             Yamane, Koki
            </a>
           </td>
           <td class="r">
            University of Tsukuba
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#232615" title="Click to go to the Author Index">
             Masuda, Shimpei
            </a>
           </td>
           <td class="r">
            Preferred Networks, Inc / University of Tsukuba
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#277693" title="Click to go to the Author Index">
             Ummadisingu, Avinash
            </a>
           </td>
           <td class="r">
            Preferred Networks, Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237464" title="Click to go to the Author Index">
             Maeda, Shin-ichi
            </a>
           </td>
           <td class="r">
            Preferred Networks
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#173446" title="Click to go to the Author Index">
             Takahashi, Kuniyuki
            </a>
           </td>
           <td class="r">
            Preferred Networks, Inc
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1835" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robots operating in the real world face significant but unavoidable issues in object localization that must be dealt with. A typical approach to address this is the addition of compliance mechanisms to hardware to absorb and compensate for some of these errors. However, for fine-grained manipulation tasks, the location and choice of appropriate compliance mech- anisms are critical for success. For objects to be inserted in a target site on a flat surface, the object must first be successfully aligned with the opening of the slot, as well as correctly oriented along its central axis, before it can be inserted. We developed the Four-Axis Adaptive Finger Hand (FAAF hand) that is equipped with fingers that can passively adapt in four axes (x, y, z, yaw) enabling it to perform insertion tasks including lid fitting in the presence of significant localization errors. Furthermore, this adaptivity allows the use of simple control methods without requiring contact sensors or other devices. Our results confirm the ability of the FAAF hand on challenging insertion tasks of square and triangle-shaped pegs (or prisms) and placing of container lids in the presence of position errors in all directions and rotational error along the objectâ€™s central axis, using a simple control scheme.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt7_02">
             17:45-18:00, Paper FrDT7.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1302'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Unified Interaction Control Framework for Safe Robotic Ultrasound Scanning with Human-Intention-Aware Compliance
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#299375" title="Click to go to the Author Index">
             Yan, Xiangjie
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#247794" title="Click to go to the Author Index">
             Shaqi, Luo
            </a>
           </td>
           <td class="r">
            State Key Laboratory of Mechanical Transmissions, College of Mec
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#333148" title="Click to go to the Author Index">
             Jiang, Yongpeng
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#297309" title="Click to go to the Author Index">
             Yu, Mingrui
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#312191" title="Click to go to the Author Index">
             Chen, Chen
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#134442" title="Click to go to the Author Index">
             Zhu, Senqiang
            </a>
           </td>
           <td class="r">
            Midea Group
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#240983" title="Click to go to the Author Index">
             Huang, Gao
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#244251" title="Click to go to the Author Index">
             Song, Shiji
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#132634" title="Click to go to the Author Index">
             Li, Xiang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1302" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#compliance_and_impedance_control" title="Click to go to the Keyword Index">
               Compliance and Impedance Control
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The ultrasound scanning robot operates in environments where frequent human-robot interactions occur. Most existing control methods for ultrasound scanning address only one specific interaction situation or implement hard switches between controllers for different situations, which compromises both safety and efficiency. In this paper, we propose a unified interaction control framework for ultrasound scanning robots capable of handling all common interactions, distinguishing both human-intended and unintended types, and adapting with appropriate compliance. Specifically, the robot suspends or modulates its ongoing main task if the interaction is intended, e.g., when the doctor grasps the robot to lead the end effector actively. Furthermore, it can identify unintended interactions and avoid potential collision in the null space beforehand. Even if that collision has happened, it can become compliant with the collision in the null space and try to reduce its impact on the main task (where the scan is ongoing) kinematically and dynamically. The multiple situations are integrated into a unified controller with a smooth transition to deal with the interactions by exhibiting human-intention-aware compliance. Experimental results validate the frameworkâ€™s ability to cope with all common interactions including intended intervention and unintended collision in a collaborative carotid artery ultrasound scanning task.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt7_03">
             18:00-18:15, Paper FrDT7.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2387'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Towards Unconstrained Collision Injury Protection Data Sets: Initial Surrogate Experiments for the Human Hand
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#221953" title="Click to go to the Author Index">
             Kirschner, Robin Jeanne
            </a>
           </td>
           <td class="r">
            TU Munich, Institute for Robotics and Systems Intelligence
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398193" title="Click to go to the Author Index">
             Yang, Jinyu
            </a>
           </td>
           <td class="r">
            TU MÃ¼nchen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394676" title="Click to go to the Author Index">
             Elshani, Edonis
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372633" title="Click to go to the Author Index">
             Micheler, Carina M.
            </a>
           </td>
           <td class="r">
            Technical University of Munich, TUM School of Medicine, Klinikum
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397653" title="Click to go to the Author Index">
             Leibbrand, Tobias
            </a>
           </td>
           <td class="r">
            TU MÃ¼nchen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#397971" title="Click to go to the Author Index">
             MÃ¼ller, Dirk
            </a>
           </td>
           <td class="r">
            Department of Orthopaedics and Sports Orthopaedics, Klinikum Rec
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#373134" title="Click to go to the Author Index">
             Glowalla, Claudio
            </a>
           </td>
           <td class="r">
            Department of Orthopaedics and Sports Orthopaedics, Klinikum Rec
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#218105" title="Click to go to the Author Index">
             Rajaei, Nader
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#140417" title="Click to go to the Author Index">
             Burgkart, Rainer
            </a>
           </td>
           <td class="r">
            Technische UniversitÃ¤t MÃ¼nchen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108317" title="Click to go to the Author Index">
             Haddadin, Sami
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2387" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#safety_in_hri" title="Click to go to the Keyword Index">
               Safety in HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Safety for physical human-robot interaction (pHRI) is a major concern for all application domains. While current standardization for industrial robot applications provide safety constraints that address the onset of pain in blunt impacts, these impact thresholds are difficult to use on edged or pointed impactors. The most severe injuries occur in constrained contact scenarios, where crushing is possible. Nevertheless, situations potentially resulting in constrained contact only occur in certain areas of a workspace and design or organisational approaches can be used to avoid them. What remains are risks to the human physical integrity caused by unconstrained accidental contacts, which are difficult to avoid while maintaining robot motion efficiency. Nevertheless, the probability and severity of injuries occurring with edged or pointed impacting objects in unconstrained collisions is hardly researched. In this paper, we propose an experimental setup and procedure using two pendulums modeling human hands and arms and robots to understand the injury potential of unconstrained collisions of human hands with edged objects. Based on our previous studies, we use pig feet as ex vivo surrogate samples - as these closely resemble the physiological characteristics of human hands - to create an initial injury database on the severity of injuries caused by unconstrained edged or pointed impacts. The use of such experimental setups and procedures in addition to other research on the occurrence of injuries in humans will eventually lead to a complete understanding of the biomechanical injury potential in pHRI.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt7_04">
             18:15-18:30, Paper FrDT7.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('674'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Tactile Comfort: Lowering Heart Rate through Interactions with a Pocket Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#244953" title="Click to go to the Author Index">
             Frederiksen, Morten Roed
            </a>
           </td>
           <td class="r">
            IT-University of Copenhagen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#108002" title="Click to go to the Author Index">
             Stoy, Kasper
            </a>
           </td>
           <td class="r">
            IT University of Copenhagen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106165" title="Click to go to the Author Index">
             Mataric, Maja
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab674" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#touch_in_hri" title="Click to go to the Keyword Index">
               Touch in HRI
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#wearable_robotics" title="Click to go to the Keyword Index">
               Wearable Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Children diagnosed with anxiety disorders are taught a range of strategies to navigate situations of heightened anxiety. Techniques such as deep breathing and repetition of mantras are commonly employed, as they are known to be calming and reduce elevated heart rates. Although these strategies are often effective, their successful application relies on prior training of the children for successful use when faced with challenging situations. This paper investigates a pocket- sized companion robot designed to offer a relaxation technique requiring no prior training, with a focus on immediate impact on the userâ€™s heart rate. The robot utilizes a tactile game to divert the userâ€™s attention, thereby promoting relaxation. We conducted two studies with children who were not diagnosed with anxiety: a 14-day pilot study with two children (age 8) and a main study with 18 children (ages 5-7). Both studies employed a within-subjects design and focused on measuring heart rate during tactile interaction with the robot and during non-use. Interacting with the robot was found to significantly lower the study participantsâ€™ heart rate (p&lt;0.01) compared to the non- use condition, indicating a consistent calming effect across all participants. These results suggest that tactile companion robots have the potential to enhance the therapeutic value of relaxation techniques.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frdt8">
             <b>
              FrDT8
             </b>
            </a>
           </td>
           <td class="r">
            Room 8
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frdt8" title="Click to go to the Program at a Glance">
             <b>
              Space Robotics
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#190182" title="Click to go to the Author Index">
             Hamaza, Salua
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt8_01">
             17:30-17:45, Paper FrDT8.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('294'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Rocket Landing Control with Random Annealing Jump Start Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335702" title="Click to go to the Author Index">
             Jiang, Yuxuan
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335333" title="Click to go to the Author Index">
             Yang, Yujie
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391686" title="Click to go to the Author Index">
             Lan, Zhiqian
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336888" title="Click to go to the Author Index">
             Zhan, Guojian
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#297960" title="Click to go to the Author Index">
             Li, Shengbo Eben
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391691" title="Click to go to the Author Index">
             Sun, Qi
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391694" title="Click to go to the Author Index">
             Ma, Jian
            </a>
           </td>
           <td class="r">
            LandSpace Technology Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391697" title="Click to go to the Author Index">
             Yu, Tianwen
            </a>
           </td>
           <td class="r">
            LandSpace Technology Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#391698" title="Click to go to the Author Index">
             Zhang, Changwu
            </a>
           </td>
           <td class="r">
            LandSpace Technology Corporation
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab294" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Rocket recycling is a crucial pursuit in aerospace technology, aimed at reducing costs and environmental impact in space exploration. The primary focus centers on rocket landing control, involving the guidance of a nonlinear underactuated rocket with limited fuel in real-time. This challenging task prompts the application of reinforcement learning (RL), yet goal-oriented nature of the problem poses difficulties for standard RL algorithms due to the absence of intermediate reward signals. This paper, for the first time, significantly elevates the success rate of rocket landing control from 8% with a baseline controller to 97% on a high-fidelity rocket model using RL. Our approach, called Random Annealing Jump Start (RAJS), is tailored for real-world goal-oriented problems by leveraging prior feedback controllers as guide policy to facilitate environmental exploration and policy learning in RL. In each episode, the guide policy navigates the environment for the guide horizon, followed by the exploration policy taking charge to complete remaining steps. This jump-start strategy prunes exploration space, rendering the problem more tractable to RL algorithms. The guide horizon is sampled from a uniform distribution, with its upper bound annealing to zero based on performance metrics, mitigating distribution shift and mismatch issues in existing methods. Additional enhancements, including cascading jump start, refined reward and terminal condition, and action smoothness regulation, further improve policy performance and practical applicability. The proposed method is validated through extensive evaluation and Hardware-in-the-Loop testing, affirming the effectiveness, real-time feasibility, and smoothness of the proposed controller.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt8_02">
             17:45-18:00, Paper FrDT8.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1857'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DRIFT: Deep Reinforcement Learning for Intelligent Floating Platforms Trajectories
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#375057" title="Click to go to the Author Index">
             El Hariry, Matteo
            </a>
           </td>
           <td class="r">
            University of Luxembourg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#243358" title="Click to go to the Author Index">
             Richard, Antoine
            </a>
           </td>
           <td class="r">
            University of Luxembourg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#341353" title="Click to go to the Author Index">
             Muralidharan, Vivek
            </a>
           </td>
           <td class="r">
            University of Luxembourg
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#166569" title="Click to go to the Author Index">
             Geist, Matthieu
            </a>
           </td>
           <td class="r">
            UniversitÃ© De Lorraine
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#127610" title="Click to go to the Author Index">
             Olivares-Mendez, Miguel A.
            </a>
           </td>
           <td class="r">
            Interdisciplinary Centre for Security, Reliability and Trust - U
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1857" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This investigation introduces a novel deep reinforcement learning-based suite to control floating platforms in both simulated and real-world environments. Floating platforms serve as versatile test-beds to emulate microgravity environments on Earth, useful to test autonomous navigation systems for space applications. Our approach addresses the system and environmental uncertainties in controlling such platforms by training policies capable of precise maneuvers amid dynamic and unpredictable conditions. Leveraging Deep Reinforcement Learning (DRL) techniques, our suite achieves robustness, adaptability, and good transferability from simulation to reality. Our deep reinforcement learning framework provides advantages such as fast training times, large-scale testing capabilities, rich visualization options, and ROS bindings for integration with real-world robotic systems. Being open access, our suite serves as a comprehensive platform for practitioners who want to replicate similar research in their own simulated environments and labs.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt8_03">
             18:00-18:15, Paper FrDT8.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2116'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Mobility Performance Characterization of Transformable Nano Rover for Lunar Exploration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#145544" title="Click to go to the Author Index">
             Sutoh, Masataku
            </a>
           </td>
           <td class="r">
            Japan Aerospace Exploration Agency
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#148000" title="Click to go to the Author Index">
             Hirano, Daichi
            </a>
           </td>
           <td class="r">
            Japan Aerospace Exploration Agency
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#256754" title="Click to go to the Author Index">
             Inazawa, Mariko
            </a>
           </td>
           <td class="r">
            Japan Aerospace Exploration Agency
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372015" title="Click to go to the Author Index">
             Kawai, Yuta
            </a>
           </td>
           <td class="r">
            Japan Aerospace Exploration Agency
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#143321" title="Click to go to the Author Index">
             Sawada, Hirotaka
            </a>
           </td>
           <td class="r">
            JAXA
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2116" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In January 2024, a Japanese lunar lander successfully touched down on the moon as part of the Smart Lander for Investigating Moon (SLIM) mission. Accompanying the SLIM on its journey were two small rovers named lunar excursion vehicles (LEV-1 and 2). LEV-2, a transformable nano rover, was particularly designed to capture images of the SLIM on the lunar surface. During the mission, LEV-2 successfully maneuvered and captured images of the lander. Understanding the mobility characteristics of LEV-2 was crucial for the success of this task. This study analyzed the mobility characteristics of LEV-2 through numerical simulation and traveling tests. In the numerical simulation, a dynamics model of LEV-2 was first developed. Subsequently, the motion behaviors of LEV-2 were analyzed by utilizing the discrete element method. Traveling tests were then conducted using the LEV-2 engineering model on various terrains covered with a lunar regolith simulant. The results of both the numerical simulations and experiments revealed consistent trends across different moving modes of LEV-2. Furthermore, the simulation results indicated no significant deterioration in the mobility performance of LEV-2 on the moon when compared to that on the Earth. Based on the characteristics predicted from the simulation and the quantitative data obtained from the experiments, it was concluded that LEV-2 is supposed to travel at least 15 degrees slopes on the moon.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt8_04">
             18:15-18:30, Paper FrDT8.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3455'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Thermally-Resilient Soft Gripper for On-Orbit Operations
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#318222" title="Click to go to the Author Index">
             Ruiz Vincueria, Fernando
            </a>
           </td>
           <td class="r">
            Universidad De Sevilla
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#151196" title="Click to go to the Author Index">
             Arrue, BegoÃ±a C.
            </a>
           </td>
           <td class="r">
            Universidad De Sevilla
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104455" title="Click to go to the Author Index">
             Ollero, Anibal
            </a>
           </td>
           <td class="r">
            AICIA. G41099946
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3455" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Research in soft manipulator technology has significantly enhanced capabilities for interacting with objects, thanks to its adaptability to various shapes and sizes. Applying this technology to on-orbit servicing, especially during the capture and containment stages of active space debris removal missions, might offer secure, adaptable, and cost-effective object capture compared to the trend of increasing the degrees of freedom and complexity of the manipulator by benchmark companies like ClearSpace or Astroscale. This work aims to conduct an experimental proof of concept, for which challenges such as radiation, vacuum, and microgravity are significant, but the predominant issue is ensuring effective operation in the extreme temperature swings, where flexible materials may exhibit cryogenic crystallization or drastic shifts in their elasticity. This work addresses this challenge through an initial stage of analytical modeling of the thermal dynamics inside the manipulator in orbit; which is then used for the development of a first experimental prototype tested with liquid nitrogen and heat guns. The multi-layered design for Low Earth Orbit (LEO) leverages the properties of TPU at low infill rates for lightweight inherent flexibility, silicone rubber ensuring structural integrity, PTFE (Teflon) for unparalleled thermal stability, and aerogel for insulation. The tendon-actuated servo-driven gripper is tested in the laboratory by varying the shape and size of objects during the grasping. The results, based on servomotor force metrics to assess the flexible manipulator's adaptability and object capture efficiency across temperature changes, affirm the concept's viability. Forces increase up to 220% in cryogenic conditions and decrease by no more than 50% at high temperatures.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frdt9">
             <b>
              FrDT9
             </b>
            </a>
           </td>
           <td class="r">
            Room 9
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frdt9" title="Click to go to the Program at a Glance">
             <b>
              Planning, Scheduling and Coordination II
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#141359" title="Click to go to the Author Index">
             Indelman, Vadim
            </a>
           </td>
           <td class="r">
            Technion - Israel Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#275357" title="Click to go to the Author Index">
             Dionigi, Alberto
            </a>
           </td>
           <td class="r">
            University of Perugia
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt9_01">
             17:30-17:45, Paper FrDT9.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2204'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Priority-Based Deadlock Recovery for Distributed Swarm Obstacle Avoidance in Cluttered Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#355529" title="Click to go to the Author Index">
             He, Jiacheng
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#354526" title="Click to go to the Author Index">
             Zhao, Fangguo
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336335" title="Click to go to the Author Index">
             Zhu, Shaohao
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#230382" title="Click to go to the Author Index">
             Li, Shuo
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#141995" title="Click to go to the Author Index">
             Xu, Jinming
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2204" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose a novel hierarchical priority mechanism for deadlock recovery of distributed swarm via on-demand collision avoidance in cluttered dynamic environments. The proposed priority mechanism dynamically assigns certain priority and an optimized detour point for each agent based on its spatial context to avoid deadlocks which are predicted by properly designed deadlock conditions; as a byproduct, this priority mechanism allows us to effectively resolve livelocks as well. The resulting optimization problem is then solved by polar reformulation and alternating minimization methods. Simulation results demonstrate that, in both static and dynamic environments, our method (termed PriDRAM) outperforms the baseline Alternating Minimization Swarm (AMSwarm) method which does not explicitly account for deadlock recovery, with a 10.5% improvement in average smoothness and a 4.8% reduction in flight time. Moreover, for narrow passages, our method shows a superior performance against the Distributed Linear Safe Corridor (DLSC) method, with a more reasonable passing order and an achievement of up to 40% reduction in flight path length. Finally, we verify the efficacy of our proposed method with a Crazyflie 2.1 quadrotor swarm.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt9_02">
             17:45-18:00, Paper FrDT9.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2223'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Fast and Communication-Efficient Multi-UAV Exploration Via Voronoi Partition on Dynamic Topological Graph
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#338532" title="Click to go to the Author Index">
             Dong, Qianli
            </a>
           </td>
           <td class="r">
            Nankai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395012" title="Click to go to the Author Index">
             Xi, Haobo
            </a>
           </td>
           <td class="r">
            Nankai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#330026" title="Click to go to the Author Index">
             Zhang, Shiyong
            </a>
           </td>
           <td class="r">
            Nankai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#390505" title="Click to go to the Author Index">
             Bi, Qingchen
            </a>
           </td>
           <td class="r">
            NanKai
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#296816" title="Click to go to the Author Index">
             Li, Tianyi
            </a>
           </td>
           <td class="r">
            Nankai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395011" title="Click to go to the Author Index">
             Wang, Ziyu
            </a>
           </td>
           <td class="r">
            Nankai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#122338" title="Click to go to the Author Index">
             Zhang, Xuebo
            </a>
           </td>
           <td class="r">
            Nankai University,
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2223" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Efficient data transmission and reasonable task allocation are important to improve multi-robot exploration efficiency. However, most communication data types typically contain redundant information and thus require massive communication volume. Moreover, exploration-oriented task allocation is far from trivial and becomes even more challenging for resource-limited unmanned aerial vehicles (UAVs). In this paper, we propose a fast and communication-efficient multi-UAV exploration method for exploring large environments. We first design a multi-robot dynamic topological graph (MR-DTG) consisting of nodes representing the explored and exploring regions and edges connecting nodes. Supported by MR-DTG, our method achieves efficient communication by only transferring the necessary information required by exploration planning. To further improve the exploration efficiency, a hierarchical multi-UAV exploration method is devised using MR-DTG. Specifically, the graph Voronoi partition is used to allocate MR-DTG's nodes to the closest UAVs, considering the actual motion cost, thus achieving reasonable task allocation. To our knowledge, this is the first work to address multi-UAV exploration using graph Voronoi partition. The proposed method is compared with a state-of-the-art method in simulations. The results show that the proposed method is able to reduce the exploration time and communication volume by up to 38.3% and 95.5%, respectively. Finally, the effectiveness of our method is validated in the real-world experiment with 6 UAVs. We will release the source code to benefit the community.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt9_03">
             18:00-18:15, Paper FrDT9.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('364'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Slices Perspective for Incremental Nonparametric Inference in High Dimensional State Spaces
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#286383" title="Click to go to the Author Index">
             Shienman, Moshe
            </a>
           </td>
           <td class="r">
            Israel Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#374051" title="Click to go to the Author Index">
             Levy-Or, Ohad
            </a>
           </td>
           <td class="r">
            Technion, Israel Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104298" title="Click to go to the Author Index">
             Kaess, Michael
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#141359" title="Click to go to the Author Index">
             Indelman, Vadim
            </a>
           </td>
           <td class="r">
            Technion - Israel Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab364" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#probabilistic_inference" title="Click to go to the Keyword Index">
               Probabilistic Inference
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce an innovative method for incremental nonparametric probabilistic inference in high-dimensional state spaces. Our approach leverages slices from high-dimensional surfaces to efficiently approximate posterior distributions of any shape. Unlike many existing graph-based methods, our slices perspective eliminates the need for additional intermediate reconstructions, maintaining a more accurate representation of posterior distributions. Additionally, we propose a novel heuristic to balance between accuracy and efficiency, enabling real-time operation in nonparametric scenarios. In empirical evaluations on synthetic and real-world datasets, our slices approach consistently outperforms other state-of-the-art methods. It demonstrates superior accuracy and achieves a significant reduction in computational complexity, often by an order of magnitude.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt9_04">
             18:15-18:30, Paper FrDT9.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2748'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Infrastructure-Less UWB-Based Active Relative Localization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#333194" title="Click to go to the Author Index">
             Brunacci, Valerio
            </a>
           </td>
           <td class="r">
            University of Perugia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#275357" title="Click to go to the Author Index">
             Dionigi, Alberto
            </a>
           </td>
           <td class="r">
            University of Perugia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#398077" title="Click to go to the Author Index">
             De Angelis, Alessio
            </a>
           </td>
           <td class="r">
            University of Perugia
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#150020" title="Click to go to the Author Index">
             Costante, Gabriele
            </a>
           </td>
           <td class="r">
            University of Perugia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2748" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In multi-robot systems, relative localization between platforms plays a crucial role in many tasks, such as leader following, target tracking, or cooperative maneuvering. State of the Art (SotA) approaches either rely on infrastructure-based or on infrastructure-less setups. The former typically achieve high localization accuracy but require fixed external structures. The latter provide more flexibility, however, most of the works use cameras or lidars that require Line-of-Sight (LoS) to operate. Ultra Wide Band (UWB) devices are emerging as a viable alternative to build infrastructure-less solutions that do not require LoS. These approaches directly deploy the UWB sensors on the robots. However, they require that at least one of the platforms is static, limiting the advantages of an infrastructure-less setup. In this work, we remove this constraint and introduce an active method for infrastructure-less relative localization. Our approach allows the robot to adapt its position to minimize the relative localization error of the other platform. To this aim, we first design a specialized anchor placement for the active localization task. Then, we propose a novel UWB Relative Localization Loss that adapts the Geometric Dilution Of Precision metric to the infrastructure-less scenario. Lastly, we leverage this loss function to train an active Deep Reinforcement Learning-based controller for UWB relative localization. An extensive simulation campaign and real-world experiments validate our method, showing up to a 60% reduction of the localization error compared to current SotA approaches.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frdt10">
             <b>
              FrDT10
             </b>
            </a>
           </td>
           <td class="r">
            Room 10
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frdt10" title="Click to go to the Program at a Glance">
             <b>
              Perception and Semantics
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#104490" title="Click to go to the Author Index">
             Myung, Hyun
            </a>
           </td>
           <td class="r">
            KAIST (Korea Advanced Institute of Science and Technology)
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#233262" title="Click to go to the Author Index">
             Hosseinzadeh, Mehdi
            </a>
           </td>
           <td class="r">
            The Australian Institute for Machine Learning (AIML) -- the University of Adelaide
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt10_01">
             17:30-17:45, Paper FrDT10.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1797'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              HeLiMOS: A Dataset for Moving Object Segmentation in 3D Point Clouds from Heterogeneous LiDAR Sensors
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#227869" title="Click to go to the Author Index">
             Lim, Hyungtae
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#384838" title="Click to go to the Author Index">
             Jang, Seoyeon
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#288232" title="Click to go to the Author Index">
             Mersch, Benedikt
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#137262" title="Click to go to the Author Index">
             Behley, Jens
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#104490" title="Click to go to the Author Index">
             Myung, Hyun
            </a>
           </td>
           <td class="r">
            KAIST (Korea Advanced Institute of Science and Technology)
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101642" title="Click to go to the Author Index">
             Stachniss, Cyrill
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1797" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Moving object segmentation (MOS) using a 3D light detection and ranging (LiDAR) sensor is crucial for scene understanding and identification of moving objects. Despite the availability of various types of 3D LiDAR sensors in the market, MOS research still predominantly focuses on 3D point clouds from mechanically spinning omnidirectional LiDAR sensors. Thus, we are, for example, lacking a dataset with MOS labels for point clouds from solid-state LiDAR sensors which have irregular scanning patterns. In this paper, we present a labeled dataset, called HeLiMOS, that enables to test MOS approaches on four heterogeneous LiDAR sensors, including two solid-state LiDAR sensors. Furthermore, we introduce a novel automatic labeling method to substantially reduce the labeling effort required from human annotators. To this end, our framework exploits an instance-aware static map building approach and tracking-based false label filtering. Finally, we provide experimental results regarding the performance of commonly used state-of-the-art MOS approaches on HeLiMOS that suggest a new direction for a sensor-agnostic MOS, which generally works regardless of the type of LiDAR sensors used to capture 3D point clouds.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt10_02">
             17:45-18:00, Paper FrDT10.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1870'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning from Spatio-Temporal Correlation for Semi-Supervised LiDAR Semantic Segmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392116" title="Click to go to the Author Index">
             Lee, Seungho
            </a>
           </td>
           <td class="r">
            Yonsei University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392449" title="Click to go to the Author Index">
             Lee, Hwijeong
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392108" title="Click to go to the Author Index">
             Shim, Hyunjung
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1870" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We address the challenges of the semi-supervised LiDAR segmentation (SSLS) problem, particularly in low-budget scenarios. The two main issues in low-budget SSLS are the poor-quality pseudo-labels for unlabeled data, and the performance drops due to the significant imbalance between ground-truth and pseudo-labels. This imbalance leads to a vicious training cycle. To overcome these challenges, we leverage the spatio-temporal prior by recognizing the substantial overlap between temporally adjacent LiDAR scans. We propose a proximity-based label estimation, which generates highly accurate pseudo-labels for unlabeled data by utilizing semantic consistency with adjacent labeled data. Additionally, we enhance this method by progressively expanding the pseudo-labels from the nearest unlabeled scans, which helps significantly reduce errors linked to dynamic classes. Additionally, we employ a dual-branch structure to mitigate performance degradation caused by data imbalance. Experimental results demonstrate remarkable performance in low-budget settings (i.e., â‰¤ 5%) and meaningful improvements in normal budget settings (i.e., 5 - 50%). Finally, our method has achieved new state-of-the-art results on SemanticKITTI and nuScenes in semi-supervised LiDAR segmentation. With only 5% labeled data, it offers competitive results against fully-supervised counterparts. Moreover, it surpasses the performance of the previous state-of-the-art at 100% labeled data (75.2%) using only 20% of labeled data (76.0%) on nuScenes. The code will be made publicly available.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt10_03">
             18:00-18:15, Paper FrDT10.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2168'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              TeFF: Tracking-Enhanced Forgetting-Free Few-Shot 3D LiDAR Semantic Segmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#339445" title="Click to go to the Author Index">
             Zhou, Junbao
            </a>
           </td>
           <td class="r">
            Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#234105" title="Click to go to the Author Index">
             Mei, Jilin
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#353488" title="Click to go to the Author Index">
             Wu, Pengze
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology, Chinese Academy of Science
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#395603" title="Click to go to the Author Index">
             Chen, Liang
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology: Beijing, CN
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#216058" title="Click to go to the Author Index">
             Zhao, Fangzhou
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#234107" title="Click to go to the Author Index">
             Zhao, Xijun
            </a>
           </td>
           <td class="r">
            China North Vehicle Research Institute, China North Artificial I
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#207125" title="Click to go to the Author Index">
             Hu, Yu
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2168" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In autonomous driving, 3D LiDAR playing a crucial role in understanding the vehicle's surroundings. However, the newly emerged, unannotated objects presents few-shot learning problem for semantic segmentation. This paper addresses the limitations of current few-shot semantic segmentation by exploiting the temporal continuity of LiDAR data. Employing a tracking model to generate pseudo-ground-truths from a sequence of LiDAR frames, our method significantly augments the dataset, enhancing the model's ability to learn on novel classes. However, this approach introduces a data imbalance biased to novel data that presents a new challenge of catastrophic forgetting. To mitigate this, we incorporate LoRA, a technique that reduces the number of trainable parameters, thereby preserving the model's performance on base classes while improving its adaptability to novel classes. This work represents a significant step forward in the application of few-shot semantic segmentation to the domain of autonomous driving. Our code is available at https://github.com/BowmanChow/Track-no-forgetting.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt10_04">
             18:15-18:30, Paper FrDT10.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3464'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              BEVPose: Unveiling Scene Semantics through Pose-Guided Multi-Modal BEV Alignment
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#233262" title="Click to go to the Author Index">
             Hosseinzadeh, Mehdi
            </a>
           </td>
           <td class="r">
            The Australian Institute for Machine Learning (AIML) -- the Univ
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106056" title="Click to go to the Author Index">
             Reid, Ian
            </a>
           </td>
           <td class="r">
            University of Adelaide
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3464" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the field of autonomous driving and mobile robotics, there has been a significant shift in the methods used to create Bird's Eye View (BEV) representations. This shift is characterised by using transformers and learning to fuse measurements from disparate vision sensors, mainly lidar and cameras, into a 2D planar ground-based representation. However, these learning-based methods for creating such maps often rely heavily on extensive annotated data, presenting notable challenges, particularly in diverse or non-urban environments where large-scale datasets are scarce. In this work, we present BEVPose, a framework that integrates BEV representations from camera and lidar data, using sensor pose as a guiding supervisory signal. This method notably reduces the dependence on costly annotated data. By leveraging pose information, we align and fuse multi-modal sensory inputs, facilitating the learning of latent BEV embeddings that capture both geometric and semantic aspects of the environment. Our pretraining approach demonstrates promising performance in BEV map segmentation tasks, outperforming fully-supervised state-of-the-art methods, while necessitating only a minimal amount of annotated data. This development not only confronts the challenge of data efficiency in BEV representation learning but also broadens the potential for such techniques in a variety of domains, including off-road and indoor environments.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frdt11">
             <b>
              FrDT11
             </b>
            </a>
           </td>
           <td class="r">
            Room 11
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frdt11" title="Click to go to the Program at a Glance">
             <b>
              Mobility and Locomotion
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#203089" title="Click to go to the Author Index">
             Guadarrama-Olvera, J. Rogelio
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#150740" title="Click to go to the Author Index">
             Piranda, Benoit
            </a>
           </td>
           <td class="r">
            UniversitÃ© De Franche-ComtÃ© / FEMTO-ST Institute
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt11_01">
             17:30-17:45, Paper FrDT11.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('785'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Efficient Balance Detection for Modular Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#394000" title="Click to go to the Author Index">
             Yazidi, C45
            </a>
           </td>
           <td class="r">
            FEMTO-ST Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#150740" title="Click to go to the Author Index">
             Piranda, Benoit
            </a>
           </td>
           <td class="r">
            UniversitÃ© De Franche-ComtÃ© / FEMTO-ST Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#224025" title="Click to go to the Author Index">
             Ouisse, Morvan
            </a>
           </td>
           <td class="r">
            FEMTO-ST Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#137202" title="Click to go to the Author Index">
             Bourgeois, Julien
            </a>
           </td>
           <td class="r">
            Institut FEMTO-ST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab785" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we explore the field of self-reconfigurable modular robots, representing a significant advance in robotic technology. These robots have many capabilities, offering high adaptability and flexibility for a variety of applications. However, computing the stability is challenging as it is computationally intensive, it needs to be distributed and fast, as close as possible of real-time.
             <p>
              In this article, we introduce a distributed algorithm designed to overcome these challenges while taking mechanical constraints into account. At the heart of this algorithm is the notion of the "support polygon", which enables the stability of a modular robot to be assessed in real time. The algorithm is based on a fully distributed tree partitioning approach, facilitating efficient communication and collaboration between modules. The algorithm also uses a polygon merging approach to reduce the number of messages when creating the polygon support, thus significantly reducing response time. In fact, the response time of the method used is very small compared to other research. We also present simulation results on a simulator, VisibleSim, as well as experimental validation on real robotic modules, which underlines the practical viability of the approach. Overall, this work lays a solid base for further advances aiming to guarantee the stability of modular robots.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt11_02">
             17:45-18:00, Paper FrDT11.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1391'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SCOML: Trajectory Planning Based on Self-Correcting Meta-Reinforcement Learning in Hybird Terrain for Mobile Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#316985" title="Click to go to the Author Index">
             Yang, Andong
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#284456" title="Click to go to the Author Index">
             Li, Wei
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#207125" title="Click to go to the Author Index">
             Hu, Yu
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1391" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Trajectory is important for ground robots to achieve safe and efficient autonomous navigation in unstructured outdoor environments. Most existing methods treat each terrain as a single type. However, in the real world, a ground usually consists of hybrid terrains. In this paper, we propose a novel trajectory planning network that handles hybrid terrain. To further enhance safety, we have designed a self-correcting structure based on historical planning data. This structure can correct the trajectory when an inappropriate one is planned. To train the network, we introduce a two-stage training scheme based on Offline Meta-Reinforcement Learning, which can train the network with pre-collected non-optimal datasets and reduce the occurrence of hazardous planning. The proposed approach has been evaluated on both simulated datasets and a real robot platform. Compared to state-of-the-art baseline methods, the proposed approach reduces hazardous planning by 59.3% in hybrid terrains.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt11_03">
             18:00-18:15, Paper FrDT11.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('924'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Reconfigurable Robot Identification from Motion Data
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#287877" title="Click to go to the Author Index">
             Hu, Yuhang
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372436" title="Click to go to the Author Index">
             Wang, Yunzhe
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372461" title="Click to go to the Author Index">
             Liu, Ruibo
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#372496" title="Click to go to the Author Index">
             Shen, Zhou
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#199580" title="Click to go to the Author Index">
             Lipson, Hod
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab924" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#hardware_software_integration_in_robotics" title="Click to go to the Keyword Index">
               Hardware-Software Integration in Robotics
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#embodied_cognitive_science" title="Click to go to the Keyword Index">
               Embodied Cognitive Science
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#bioinspired_robot_learning" title="Click to go to the Keyword Index">
               Bioinspired Robot Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Integrating Large Language Models (LLMs) or Vision-Language Models (VLMs) with robotic systems enables robots to process and understand complex natural language instructions and visual information. However, a fundamental challenge remains: for robots to fully capitalize on these advancements, they must have a deep understanding of their physical embodiment. The gap between AI models' cognitive capabilities and the understanding of physical embodiment leads to the following question: Can a robot autonomously understand and adapt to its physical form and functionalities through interaction with its environment? This question underscores the transition towards developing self-modeling robots without reliance on external sensory or pre-programmed knowledge about their structure. Here, we propose a meta-self-modeling that can deduce robot morphology through proprioceptionâ€”the robot's internal sense of its body's position and movement. Our study introduces a 12-DoF reconfigurable legged robot, accompanied by a diverse dataset of 200k unique configurations, to systematically investigate the relationship between robotic motion and robot morphology. Utilizing a deep neural network model comprising a robot signature encoder and a configuration decoder, we demonstrate the capability of our system to accurately predict robot configurations from proprioceptive signals. This research contributes to the field of robotic self-modeling, aiming to enhance robot's understanding of their physical embodiment and adaptability in real-world scenarios.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt11_04">
             18:15-18:30, Paper FrDT11.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('380'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Contact Stability Control of Stepping Over Partial Footholds Using Plantar Tactile Feedback
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#203089" title="Click to go to the Author Index">
             Guadarrama-Olvera, J. Rogelio
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#102023" title="Click to go to the Author Index">
             Kajita, Shuuji
            </a>
           </td>
           <td class="r">
            Chubu University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101850" title="Click to go to the Author Index">
             Kanehiro, Fumio
            </a>
           </td>
           <td class="r">
            National Inst. of AIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101793" title="Click to go to the Author Index">
             Cheng, Gordon
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab380" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#body_balancing" title="Click to go to the Keyword Index">
               Body Balancing
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_based_control" title="Click to go to the Keyword Index">
               Sensor-based Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work presents a novel method to keep stable contact and balance while stepping over partial footholds for biped humanoid robots with flat feet. We exploit plantar tactile feedback to detect the geometry of the terrain and reconstruct online the new supporting polygon after landing every step. Plantar tactile feedback detects early contacts to stop the swing foot motion. Then we compute the convex hull of the cluster of contact points detected by distributed normal force sensors over the foot soles. The centroid of the supporting polygon is then used for retargeting the reference ZMP and DCM positions. Finally, the supporting polygon is used to define constraints for ZMP balance feedback control. These methods were implemented in two biped humanoid robots running different walking controllers.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frdt12">
             <b>
              FrDT12
             </b>
            </a>
           </td>
           <td class="r">
            Room 12
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frdt12" title="Click to go to the Program at a Glance">
             <b>
              Reinforcement Learning and Multi-Robot Systems
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#106824" title="Click to go to the Author Index">
             Kelly, Jonathan
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt12_01">
             17:30-17:45, Paper FrDT12.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('293'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Efficient Global Trajectory Planning for Multi-Robot System with Affinely Deformable Formation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#335394" title="Click to go to the Author Index">
             Sha, Hao
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#291053" title="Click to go to the Author Index">
             Cui, Yuxiang
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#377808" title="Click to go to the Author Index">
             Lu, Wangtao
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#276057" title="Click to go to the Author Index">
             Zhang, Dongkun
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#209413" title="Click to go to the Author Index">
             Wang, Chaoqun
            </a>
           </td>
           <td class="r">
            Shandong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113218" title="Click to go to the Author Index">
             Wu, Jun
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#113216" title="Click to go to the Author Index">
             Xiong, Rong
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#156231" title="Click to go to the Author Index">
             Wang, Yue
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab293" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Global trajectory planning is crucial for long-range formation navigation tasks of multi-robot systems in efficiency improvement and energy saving, whose main challenges are the joint space constraints of the whole team and the long-range deployment. To overcome the above difficulties, we reformulate the original problem into an affine formation planning problem in parameter space. Further, we propose a front-end &amp; back-end framework for global trajectory planning of Multi-Robot Systems (MRS) with affinely deformable formation. For the front-end, an RL-steering affine formation RRT* method is designed to search a global formation-level trajectory in affine parameter space, combining the efficient BVP-solving capability of RL and the global guidance and generalizing ability of RRT*. For the back-end, we propose a formation-level affine parameter trajectory optimization method to refine the front-end trajectory, and further transform it into per-agent trajectories for execution. Extensive benchmarks and ablation experiments in simulation show the effectiveness of our framework for the global trajectory generation of a multi-UAV system with affinely deformable formation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt12_02">
             17:45-18:00, Paper FrDT12.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('766'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MFC-EQ: Mean-Field Control with Envelope Q-Learning for Moving Decentralized Agents in Formation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#348571" title="Click to go to the Author Index">
             Lin, Qiushi
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#196849" title="Click to go to the Author Index">
             Ma, Hang
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab766" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We study a decentralized version of Moving Agents in Formation (MAiF), a variant of Multi-Agent Path Finding aiming to plan collision-free paths for multiple agents with the dual objectives of reaching their goals quickly while maintaining a desired formation. The agents must balance these objectives under conditions of partial observation and limited communication. The formation maintenance depends on the joint state of all agents, whose dimensionality increases exponentially with the number of agents, rendering the learning process intractable. Additionally, learning a single policy that can accommodate different linear preferences for these two objectives presents a significant challenge. In this paper, we propose Mean-Field Control with Envelop Q-learning (MFC-EQ), a scalable and adaptable learning framework for this bi-objective multi-agent task. We approximate the dynamics of all agents using mean-field theory while learning a universal preference-agnostic policy through envelop Q-learning. Our empirical evaluation of MFC-EQ across numerous instances shows that it outperforms state-of-the-art centralized MAiF baselines. Furthermore, MFC-EQ effectively handles more complex scenarios where the desired formation changes dynamicallyâ€”a challenge that existing MAiF planners cannot address.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt12_03">
             18:00-18:15, Paper FrDT12.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2477'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Equivariant Ensembles and Regularization for Reinforcement Learning in Map-Based Path Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237756" title="Click to go to the Author Index">
             Theile, Mirco
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#323402" title="Click to go to the Author Index">
             Cao, Hongpeng
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237765" title="Click to go to the Author Index">
             Caccamo, Marco
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#208421" title="Click to go to the Author Index">
             Sangiovanni Vincentelli, Alberto
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2477" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In reinforcement learning (RL), exploiting environmental symmetries can significantly enhance efficiency, robustness, and performance. However, ensuring that the deep RL policy and value networks are respectively equivariant and invariant to exploit these symmetries is a substantial challenge. Related works try to design networks that are equivariant and invariant by construction, limiting them to a very restricted library of components, which in turn hampers the expressiveness of the networks. This paper proposes a method to construct equivariant policies and invariant value functions without specialized neural network components, which we term equivariant ensembles. We further add a regularization term for adding inductive bias during training. In a map-based path planning case study, we show how equivariant ensembles and regularization benefit sample efficiency and performance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt12_04">
             18:15-18:30, Paper FrDT12.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2499'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Competitive Multi-Team Behavior in Dynamic Flight Scenarios
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#185268" title="Click to go to the Author Index">
             Seyde, Tim Niklas
            </a>
           </td>
           <td class="r">
            MIT, ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#237728" title="Click to go to the Author Index">
             Lechner, Mathias
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#379967" title="Click to go to the Author Index">
             Rountree, Joshua
            </a>
           </td>
           <td class="r">
            United States Air Force
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101388" title="Click to go to the Author Index">
             Rus, Daniela
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2499" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Efficiently learning strategic multi-agent behavior remains a challenge for robotic systems deployed in real-world scenarios, especially when considering underactuated or dynamically unstable systems. Such systems demand an integrated approach that informs long-term strategic planning with constraints imposed by reactive control, and vice versa, to effectively accomplish task objectives in competitive scenarios. In this paper, we introduce a hierarchical control model to address this: a high-level controller synthesizes strategic guidance from aggregated team experiences, while a low-level controller formulates corresponding task-specific continuous controls. We apply this concept to coordination of competitive multi-team behavior in dynamic flight scenarios with F-16 aircraft. This work introduces a hierarchical reinforcement learning approach for multi-agent coordination, leveraging decoupled distributional value representations at the high-level together with goal-conditioned policy learning at the low-level, providing a control structure that integrates long-horizon strategic planning with short-horizon dynamic control. We further provide a parallel simulator for efficient learning with multi-agent F-16 dynamics.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frdt13">
             <b>
              FrDT13
             </b>
            </a>
           </td>
           <td class="r">
            Room 13
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frdt13" title="Click to go to the Program at a Glance">
             <b>
              RGB-D Perception
             </b>
            </a>
           </td>
           <td class="r">
            Regular session
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#100088" title="Click to go to the Author Index">
             Siegwart, Roland
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt13_01">
             17:30-17:45, Paper FrDT13.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('770'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              PoCo: Point Context Cluster for RGBD Indoor Place Recognition
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#269549" title="Click to go to the Author Index">
             Liang, Jing
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#337657" title="Click to go to the Author Index">
             Deng, Zhuo
            </a>
           </td>
           <td class="r">
            Amazon
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205734" title="Click to go to the Author Index">
             Zhou, Zheming
            </a>
           </td>
           <td class="r">
            Amazon.com LLC
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#337644" title="Click to go to the Author Index">
             Ghasemalizadeh, Omid
            </a>
           </td>
           <td class="r">
            Amazon Lab126
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#106235" title="Click to go to the Author Index">
             Manocha, Dinesh
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#220492" title="Click to go to the Author Index">
             Sun, Min
            </a>
           </td>
           <td class="r">
            National Tsing Hua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#310158" title="Click to go to the Author Index">
             Kuo, Cheng-Hao
            </a>
           </td>
           <td class="r">
            Amazon
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#336589" title="Click to go to the Author Index">
             Sen, Arnab
            </a>
           </td>
           <td class="r">
            Amazon
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab770" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a novel end-to-end algorithm (PoCo) for the indoor RGB-D place recognition task, aimed at identifying the most likely match for a given query frame within a reference database. The task presents inherent challenges attributed to the constrained field of view and limited range of perception sensors. We propose a new network architecture, which generalizes the recent Context of Clusters (CoCs) to extract global descriptors directly from the noisy point clouds through end-to-end learning. Moreover, we develop the architecture by integrating both color and geometric modalities into the point features to enhance the global descriptor representation. We conducted evaluations on public datasets ScanNet-PR and ARKit with 807 and 5047 scenarios, respectively. PoCo achieves SOTA performance: on ScanNet-PR, we achieve R@1 of 64.63%, a 5.7% improvement from the best-published result CGis (61.12%); on Arkit, we achieve R@1 of 45.12%, a 13.3% improvement from the best-published result CGis (39.82%). In addition, PoCo shows higher efficiency than CGis in inference time (1.75X-faster), and we demonstrate the effectiveness of PoCo in recognizing places within a real-world laboratory environment.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt13_02">
             17:45-18:00, Paper FrDT13.2
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1214'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DMFuser: Distilled Multi-Task Learning for End-To-End Transformer-Based Sensor Fusion in Autonomous Driving
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#221160" title="Click to go to the Author Index">
             Agand, Pedram
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#248096" title="Click to go to the Author Index">
             Mahdavian, Mohammad
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#268266" title="Click to go to the Author Index">
             Savva, Manolis
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#205553" title="Click to go to the Author Index">
             Chen, Mo
            </a>
           </td>
           <td class="r">
            Simon Fraser University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1214" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In end-to-end autonomous driving, current sensor fusion and navigational control techniques used by imitation learning algorithms are insufficient in challenging scenarios involving multiple dynamic agents and result in poor driving capabilities. To tackle this issue, we introduce DMFuser, a transformer-based algorithm that employs knowledge distillation between multi-task student and single-task teachers and combines attention and convolutions to fuse multiple RGB-D camera representations to produce vehicular navigational commands (throttle, steering and brake). Our model incorporates two modules. The first module, perception, encodes data from RGB-D cameras for tasks like semantic segmentation, semantic depth cloud (SDC) mapping, and traffic light state recognition. To enhance feature extraction and fusion from both RGB and depth sources, we harness local and global capabilities of convolution and transformer modules. We employ an attention-CNN fusion structure to effectively learn and fuse RGB and SDC map features. Subsequently, the control module decodes these features along with supplementary data, containing environmentâ€™s static and dynamic information, to predict waypoints and vehicular control actions. We evaluate the model and conduct a comparative analysis, in various scenarios, weather conditions, and traffic situations, spanning from normal to adversarial in the CARLA simulator. We achieve better or comparable results in term of driving score (DS) and other metrics with respect to our baselines. Also, our ablation studies demonstrate the effectiveness of our contributions to improve the driving skills. Our code is available at the following github page: https://github.com/pagand/e2etransfuser
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt13_03">
             18:00-18:15, Paper FrDT13.3
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1499'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Efficient Multimodal Semantic Segmentation Via Dual-Prompt Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392390" title="Click to go to the Author Index">
             Dong, Shaohua
            </a>
           </td>
           <td class="r">
            University of North Texas
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392424" title="Click to go to the Author Index">
             Feng, Yunhe
            </a>
           </td>
           <td class="r">
            University of North Texas
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392430" title="Click to go to the Author Index">
             Yang, Qing
            </a>
           </td>
           <td class="r">
            University of North Texas
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#392536" title="Click to go to the Author Index">
             Huang, Yan
            </a>
           </td>
           <td class="r">
            University of North Texas
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#275131" title="Click to go to the Author Index">
             Liu, Dongfang
            </a>
           </td>
           <td class="r">
            Rochester Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#204190" title="Click to go to the Author Index">
             Fan, Heng
            </a>
           </td>
           <td class="r">
            University of North Texas
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1499" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multimodal (e.g., RGB-Depth/RGB-Thermal) fusion has shown great potential for improving semantic segmentation in complex scenes (e.g., indoor/low-light conditions). Existing approaches often fully fine-tune a dual-branch encoder-decoder framework with a complicated feature fusion strategy for achieving multimodal semantic segmentation, which is training-costly due to the massive parameter updates in feature extraction and fusion. To address this issue, we propose a surprisingly simple yet effective dual-prompt learning network (dubbed DPLNet) for training-efficient multimodal (e.g., RGB-D/T) semantic segmentation. The core of DPLNet is to directly adapt a frozen pre-trained RGB model to multimodal semantic segmentation, reducing parameter updates. For this purpose, we present two prompt learning modules, comprising multimodal prompt generator (MPG) and multimodal feature adapter (MFA). MPG works to fuse the features from different modalities in a compact manner and is inserted from shallow to deep stages to generate the multi-level multimodal prompts that are injected into the frozen backbone, while MFA adapts prompted multimodal features in the frozen backbone for better multimodal semantic segmentation. Since both the MPG and MFA are lightweight, only a few trainable parameters (3.88M, 4.4% of the pre-trained backbone parameters) are introduced for multimodal feature fusion and learning. Using a simple decoder (3.27M parameters), DPLNet achieves new state-of-the-art performance or is on a par with other complex approaches on four RGB-D/T semantic segmentation datasets while satisfying parameter efficiency. Moreover, we show DPLNet is general and applicable to other multimodal segmentation tasks. Without special design, DPLNet outperforms many complicated models. The source code can be found at https://github.com/ShaohuaDong2021/DPLNet.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frdt13_04">
             18:15-18:30, Paper FrDT13.4
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2791'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Zero123-6D: Zero-Shot Novel View Synthesis for RGB Category-Level 6D Pose Estimation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#344194" title="Click to go to the Author Index">
             Di Felice, Francesco
            </a>
           </td>
           <td class="r">
            Mechanical Intelligence Institute, Sant'Anna School of Advanced
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#344193" title="Click to go to the Author Index">
             Remus, Alberto
            </a>
           </td>
           <td class="r">
            Sant'Anna School of Advanced Studies
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#279836" title="Click to go to the Author Index">
             Gasperini, Stefano
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#292855" title="Click to go to the Author Index">
             Busam, Benjamin
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#142888" title="Click to go to the Author Index">
             Ott, Lionel
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#123306" title="Click to go to the Author Index">
             Tombari, Federico
            </a>
           </td>
           <td class="r">
            Technische UniversitÃ¤t MÃ¼nchen
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#100088" title="Click to go to the Author Index">
             Siegwart, Roland
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101830" title="Click to go to the Author Index">
             Avizzano, Carlo Alberto
            </a>
           </td>
           <td class="r">
            Scuola Superiore Sant'Anna
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2791" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="IROS24_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="IROS24_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Estimating the pose of objects through vision is essential to make robotic platforms interact with the environment. Yet, it presents many challenges, often related to the lack of flexibility and generalizability of state-of-the-art solutions. Diffusion models are a cutting-edge neural architecture transforming 2D and 3D computer vision, outlining remarkable performances in zero-shot novel-view synthesis. Such a use case is particularly intriguing for reconstructing 3D objects. However, localizing objects in unstructured environments is rather unexplored. To this end, this work presents Zero123- 6D, the first work to demonstrate the utility of Diffusion Model-based novel-view-synthesizers in enhancing RGB 6D pose estimation at category-level, by integrating them with feature extraction techniques. Novel View Synthesis allows to obtain a coarse pose that is refined through an online optimization method introduced in this work to deal with intra-category geometric differences. In such a way, the outlined method shows reduction in data requirements, removal of the necessity of depth information in zero-shot category-level 6D pose estimation task, and increased performance, quantitatively demonstrated through experiments on the CO3D dataset.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="fri7n">
             <b>
              FrI7N
             </b>
            </a>
           </td>
           <td class="r">
            Poster Area
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#fri7n" title="Click to go to the Program at a Glance">
             <b>
              Interactive Session 7 - Late Breaking Results
             </b>
            </a>
           </td>
           <td class="r">
            Interactive Poster session
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frf12o">
             <b>
              FrF12O
             </b>
            </a>
           </td>
           <td class="r">
            Auditorium
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frf12o" title="Click to go to the Program at a Glance">
             <b>
              Forum 12 - Industrial Opportunities and Socio-Economic Impact of Medical
              <br/>
              Robotics
             </b>
            </a>
           </td>
           <td class="r">
            Forum
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#101894" title="Click to go to the Author Index">
             Stefanini, Cesare
            </a>
           </td>
           <td class="r">
            Scuola Superiore Sant'Anna
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#250675" title="Click to go to the Author Index">
             Ciuti, Gastone
            </a>
           </td>
           <td class="r">
            Scuola Superiore Sant'Anna
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frf12o_01">
             15:30-18:30, Paper FrF12O.1
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Industrial Opportunities and Socio-Economic Impact of Medical Robotics
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101894" title="Click to go to the Author Index">
             Stefanini, Cesare
            </a>
           </td>
           <td class="r">
            Scuola Superiore Sant'Anna
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#250675" title="Click to go to the Author Index">
             Ciuti, Gastone
            </a>
           </td>
           <td class="r">
            Scuola Superiore Sant'Anna
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td>
            <a name="frf13o">
             <b>
              FrF13O
             </b>
            </a>
           </td>
           <td class="r">
            Room 17/18
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="IROS24_ProgramAtAGlanceWeb.html#frf13o" title="Click to go to the Program at a Glance">
             <b>
              Forum 13 - Robots for a Better Tomorrow: Well-Being through Advanced
              <br/>
              Technology
             </b>
            </a>
           </td>
           <td class="r">
            Forum
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="IROS24_AuthorIndexWeb.html#107662" title="Click to go to the Author Index">
             Menezes, Paulo
            </a>
           </td>
           <td class="r">
            Institute of Systems and Robotics
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="IROS24_AuthorIndexWeb.html#101896" title="Click to go to the Author Index">
             Cavallo, Filippo
            </a>
           </td>
           <td class="r">
            University of Florence
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="frf13o_">
             , Paper FrF13O.
            </a>
           </td>
           <td class="r">
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Robots for a Better Tomorrow: Wellbeing through Advanced Technology
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#107662" title="Click to go to the Author Index">
             Menezes, Paulo
            </a>
           </td>
           <td class="r">
            Institute of Systems and Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="IROS24_AuthorIndexWeb.html#101896" title="Click to go to the Author Index">
             Cavallo, Filippo
            </a>
           </td>
           <td class="r">
            University of Florence
           </td>
          </tr>
         </table>
        </div>
        <p>
         <br/>
        </p>
        <p>
         <br/>
        </p>
        <p>
         <p>
         </p>
        </p>
       </td>
       <td height="100%" style="background-color:#9F7F59;" width="5">
       </td>
      </tr>
      <tr>
       <td alt="" border="0" colspan="4" height="16" style="background-color:#9F7F59;" valign="center" width="100%">
        <p align="center">
         <span style="font-size:8pt;line-height:10pt;color:#ffffff;">
          Technical Content Â© IEEE Robotics &amp; Automation Society
         </span>
        </p>
       </td>
      </tr>
      <tr>
       <td colspan="4" width="100%">
        <p align="right">
         <span style="text-decoration:none;">
          <img align="right" border="0" src="/images/pc_logo_small.jpg" style="margin-left: 10px; margin-right: 10px"/>
          This site is protected
by copyright and trademark laws under US and International law.
          <br/>
          All rights
reserved. Â© 2002-2024 PaperCept, Inc.
          <br/>
          Page generated 2024-10-05Â Â 01:22:01 PST
          <a href="" onclick="window.open('/conferences/scripts/about.pl','tc','width=1000,scrollbars=yes'); return false">
           Terms of use
          </a>
         </span>
        </p>
       </td>
      </tr>
     </table>
    </body>
   </div>
  </form>
 </body>
</html>
