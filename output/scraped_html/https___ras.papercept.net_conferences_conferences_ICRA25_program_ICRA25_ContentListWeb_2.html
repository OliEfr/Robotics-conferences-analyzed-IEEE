<!DOCTYPE HTML>
<html>
 <head>
  <meta content="en-us" http-equiv="Content-Language"/>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
  <meta content="width=device-width" name="viewport"/>
  <script src="https://ras.papercept.net/conferences/scripts/dom-drag.js" type="text/javascript">
  </script>
  <script src="jquery-1.11.1.min.js">
  </script>
  <title>
   ICRA 2025 Program | Wednesday May 21, 2025
  </title>
  <style type="text/css">
   body, table, td, th{
	Font-Family : sans-serif;
	Font-Size : 10pt;
}
.r {text-align: right}
.blue {color: #0000FF;}
td {vertical-align: top; text-align: left}
.c {text-align: center}
table.s {
	border-collapse:collapse;
	border-width: 1px;
}
table.s td{
	border-width: 1px;
	padding: 4px;
	border-style: solid;
	border-color: gray;
}
table.t {
	border-collapse: collapse;
	border-width: 0px;
}
table.t td{
	border-width: 0px;
	padding: 4px;
	border-style: solid;
	border-color: gray;
}
.dots {
    background:url('./images/dot.gif') repeat-x center;
}
.field {
    background-color: #FFFFFF;
}
#pTitle { /* Page title */
   font-size: 14pt;
   line-height: 1.5em;
}
#pSubTitle { /* Page subtitle */
   color: #909090;
   font-size: 10pt; 
   line-height: 1.5em;
}
#container {
	position: absolute;
	width: 100%;
	margin-top: 2px;
/*	overflow: hidden; */
}

.sHdr {   /* Session header Content list */
   background-color: #F0E68C
}
      
.sSHdr {   /* Subsession header Content list */
   background-color: #f8f3c6 
}
      
table.trk { /* Track table Content list */
   border-collapse: collapse;
   border-width: 0px;
   margin: auto;
/**   width: 640px; **/
   width: 720px;
}
table.trk td{
   border-width: 0px;
   padding: 4px;
   border-style: solid;
   border-color: gray;
 }
      
.pHdr {  /* Paper header Content list */
   background-color: #E6E6FA;
   color: black;
}
hr.thin { /* Horizontal rule content list */
   border: 0px; 
   height: .8px; 
   background-color: #8888FF;
}
      
.pTtl {  /* Paper title Content list */
   font-size: 11pt;
   font-style: italic;
}
      
.ssHdr {  /* Subsession header container session Content list */
   background-color: #DDDDDD;
   color: black;
}
      
.ssTtl {  /* Subsession title container session Content list */
   font-size: 10pt;
   font-style: normal;
   font-weight: bold;
}
  </style>
  <script language="JavaScript">
   function initXMLHttp(){
   var oRequest = false;
   try {
      oRequest = new XMLHttpRequest();
   }  catch (trymicrosoft) {
      try {
         oRequest = new ActiveXObject("Msxml2.XMLHTTP");
      }  catch (othermicrosoft) {
         try {
            oRequest = new ActiveXObject("Microsoft.XMLHTTP");
         }  catch (failed) {
            oRequest = false;
         }
      }
   }
   if (!oRequest){
      alert("Error initializing XMLHttpRequest! Your browser does not support AJAX");
   }
   return oRequest;
}
function modify(number,kk){
   var check = document.getElementById('mod' + kk).checked;
   if (check){
      action = 'Add';
   }
   else{
      action = 'Delete';
   }
   
//   url = 'https://ras.papercept.net/conferences/scripts/myprogram.pl?ConfID=479&' + action + number;
//   window.open(url,'myprogrampage');

   modifyItem("https://ras.papercept.net/conferences/scripts/myprogram_aja.pl","479",action,number)

}


function modifyItem(url,ConfID,action,number){
   var oRequest = initXMLHttp();
   if (!oRequest){return;}
   
   // Send the request

   oRequest.open("post",url, true);
   var sParams = 'ConfID=' + ConfID + '&Action=' + action + '&Number=' + number;
   document.body.style.cursor = 'wait';
   oRequest.send(sParams);

   // Process the response
   
   oRequest.onreadystatechange = function(){ 
      if (oRequest && oRequest.readyState && oRequest.readyState == 4){
         document.body.style.cursor = 'auto';
         var responseText = oRequest.responseText;
         if (responseText.substring(0,5) == 'Error'){
            alert(responseText);
         }
         else{
         
//            alert(responseText);

         }
      }
   } 
}

var iIntervalId;  // Global variable
function modsession(id,kk){
   var check = document.getElementById('mod' + kk).checked;
   if (check){
      action = 'AddSession';
   }
   else{
      action = 'DelSession';
   }

//   url = 'https://ras.papercept.net/conferences/scripts/myprogram.pl?ConfID=479&' + action + id;
//   window.open(url,'myprogrampage');

   modifySession("https://ras.papercept.net/conferences/scripts/myprogram_aja.pl","479",action,id)

}

function modifySession(url,ConfID,action,id){
   var oRequest = initXMLHttp();
   if (!oRequest){return;}
   
   // Send the request

   oRequest.open("post",url, true);
   var sParams = 'ConfID=' + ConfID + '&Action=' + action + '&ID=' + id;
   document.body.style.cursor = 'wait';
   oRequest.send(sParams);

   // Process the response
   
   oRequest.onreadystatechange = function(){ 
      if (oRequest && oRequest.readyState && oRequest.readyState == 4){
         document.body.style.cursor = 'auto';
         var responseText = oRequest.responseText;
         if (responseText.substring(0,5) == 'Error'){
            alert(responseText);
         }
         else{
         
//            alert(responseText);

         }
      }
   } 
}

function getCookie(sName){
   var sRE = "(?:; )?" + sName + "=([^;]*);?";   
   var oRE = new RegExp(sRE);
   if (oRE.test(document.cookie)){
      return decodeURIComponent(RegExp["$1"]);}
   else{
      return null;
   }
}
function loadprogram(){
   var list = getCookie("ICRA25");
   if (list){
      var List = list.split(",");
      for (var i=0; i<List.length; i++){
         var names = document.getElementsByName('modify' + List[i]);
         if (names.length){
            for (var j=0; j<names.length; j++){
               names[j].checked = true;
            }
         }
      }
   }
}
function reset(){

   // Uncheck all modify and addsession checkboxes

   var ins = document.getElementsByTagName('input');
   for (var i=0; i<ins.length; i++){
      if (ins[i].type == 'checkbox' && ins[i].id && ins[i].id.substring(0,3) == 'mod'){
         ins[i].checked = false;
      }
   }
   
   // Reload the program
   
   loadprogram();
}
function startreset(){
   iIntervalId = setInterval(reset,2000);
}
function viewAbstract(number){
   var box = document.getElementById('Ab' + number);
   if (box.style.display == 'block'){
      box.style.display = 'none';
   }
   else if (box && box.style.display == 'none'){
      box.style.display = 'block';
   }
}
function openAllAbstracts(){
   var d = document.getElementsByTagName('div');
   var count = d.length;
   if (count == 0){return;}
   for (var i=0; i<d.length; i++){
      if (d[i].id && d[i].id.substring(0,2) == 'Ab' && d[i].style.display == 'none'){
         d[i].style.display = 'block';
      }
   }
}
function closeAllAbstracts(){
   var d = document.getElementsByTagName('div');
   for (var i=0; i<d.length; i++){
      if (d[i].id && d[i].id.substring(0,2) == 'Ab'){
         d[i].style.display = 'none';
      }
   }
}
var uhash;
var pColor;
$(function() { 

   // Check for URL hash

   uhash = location.hash.substring(1);
   if (uhash.slice(-1) == '_'){
      uhash = null;
   }
   if (uhash){
   
      // Mark the session
   
      pColor = $('#' + uhash).parent().css('backgroundColor');
      $('#' + uhash).parent().css('backgroundColor','#FF8888');
   }
});
  </script>
 </head>
 <body onload="loadprogram(); startreset()">
  <form action="https://ras.papercept.net/conferences/scripts/myprogram.pl" name="myprogram">
   <div id="container">
    <body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0">
     <table border="0" cellpadding="0" cellspacing="0" width="100%">
      <tr>
       <td height="140" style="background-color:#2C1A77;" width="100%">
        <img alt="" border="0" height="100" src="/images/icra/icra25_logo.webp" style="position:absolute;left:20px;top:20px;z-index:1;"/>
        <img alt="" border="0" height="140" src="/images/icra/icra25.webp" style="position:absolute;right:0px;top:0px;"/>
        <span style="font-size: 32px; font-family: Arial, sans serif; color: #E86950; text-align: left; position: absolute; left: 150px; top: 10px">
        </span>
        <span style="font-size: 16px; font-family: Arial, sans serif; color: #000; text-align: left; position: absolute; left: 150px; top: 80px">
        </span>
        <span style="font-size: 16px; font-family: Arial, sans serif; color: #E86950; text-align: left; position: absolute; left: 150px; top: 115px">
        </span>
       </td>
      </tr>
     </table>
     <table border="0" cellpadding="0" cellspacing="0" height="80%" width="100%">
      <tr>
       <td height="100%" style="background-color:#2C1A77;" width="5">
       </td>
       <td width="5">
       </td>
       <td height="100%" valign="top" width="100%">
        <br/>
        <div class="c" id="TheTop">
         <span id="pTitle">
          <a href="http://2025.ieee-icra.org" target="_blank">
           <b>
            2025 IEEE International Conference on Robotics and Automation (ICRA)
           </b>
          </a>
          <br/>
         </span>
         <span id="pSubTitle">
          <b>
           May 19-23, 2025, Atlanta, USA
          </b>
         </span>
         <br/>
         <br/>
        </div>
        <div class="c" style="position: relative">
         <a href="ICRA25_ProgramAtAGlanceWeb.html">
          Program at a Glance
         </a>
         <a href="ICRA25_ContentListWeb_1.html">
          Tuesday
         </a>
         <a href="ICRA25_ContentListWeb_2.html">
          Wednesday
         </a>
         <a href="ICRA25_ContentListWeb_3.html">
          Thursday
         </a>
         <a href="ICRA25_AuthorIndexWeb.html">
          Author Index
         </a>
         <a href="ICRA25_KeywordIndexWeb.html">
          Keyword Index
         </a>
         <a href="#TheTop" onclick="window.open('https://ras.papercept.net/conferences/scripts/myprogram.pl?ConfID=479','myprogrampage')">
          My Program
         </a>
        </div>
        <div class="c">
         <p style="color: gray">
          Last updated on May 14, 2025. This conference program is tentative and subject to change
         </p>
        </div>
        <div class="c">
         <h3>
          Technical Program for Wednesday May 21, 2025
         </h3>
        </div>
        <p class="c">
        </p>
        <div class="c">
         <span style="color:gray ">
          To show or hide the keywords and abstract (text summary) of a paper (if available), click on the paper title
         </span>
         <br/>
         <a href="javascript:openAllAbstracts()" title="Click to open all abstracts">
          Open all abstracts
         </a>
         <a href="javascript:closeAllAbstracts()" title="Click to close all abstracts">
          Close all abstracts
         </a>
        </div>
        <div class="c">
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat1">
             <b>
              WeAT1
             </b>
             Regular Session, 302
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod769" name="modifyWeAT1" onclick="modsession(649,769)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat1" title="Click to go to the Program at a Glance">
             <b>
              Award Finalists 5
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#123478" title="Click to go to the Author Index">
             Hauser, Kris
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#145482" title="Click to go to the Author Index">
             Wang, Michael Yu
            </a>
           </td>
           <td class="r">
            Xian Jiaotong University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat1_01">
             08:30-08:35, Paper WeAT1.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod770" name="modify4353" onclick="modify(4353,770)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4353'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Full-Order Sampling-Based MPC for Torque-Level Locomotion Control Via Diffusion-Style Annealing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#355073" title="Click to go to the Author Index">
             Xue, Haoru
            </a>
           </td>
           <td class="r">
            University of California Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339400" title="Click to go to the Author Index">
             Pan, Chaoyi
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#384468" title="Click to go to the Author Index">
             Yi, Zeji
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418840" title="Click to go to the Author Index">
             Qu, Guannan
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#236627" title="Click to go to the Author Index">
             Shi, Guanya
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4353" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Due to high dimensionality and non-convexity, real-time optimal control using full-order dynamics models for legged robots is challenging.	Therefore, Nonlinear Model Predictive Control (NMPC) approaches are often limited to reduced-order models. Sampling-based MPC has shown potential in nonconvex even discontinuous problems, but often yields suboptimal solutions with high variance, which limits its applications in high-dimensional locomotion. This work introduces DIAL-MPC (Diffusion-Inspired Annealing for Legged MPC), a sampling-based MPC framework with a novel diffusion-style annealing process. Such an annealing process is supported by the theoretical landscape analysis of Model Predictive Path Integral Control (MPPI) and the connection between MPPI and single-step diffusion. Algorithmically, DIAL-MPC iteratively refines solutions online and achieves both global coverage and local convergence. In quadrupedal torque-level control tasks, DIAL-MPC reduces the tracking error of standard MPPI by 13.4 times and outperforms reinforcement learning (RL) policies by 50% in challenging climbing tasks without any training. In particular, DIAL-MPC enables precise real-world quadrupedal jumping with payload. To the best of our knowledge, DIAL-MPC is the first training-free method that optimizes over full-order quadruped dynamics in real-time.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat1_02">
             08:35-08:40, Paper WeAT1.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod771" name="modify3346" onclick="modify(3346,771)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3346'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              D(R, O) Grasp: A Unified Representation of Robot and Object Interaction for Cross-Embodiment Dexterous Grasping
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425430" title="Click to go to the Author Index">
             Wei, Zhenyu
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351843" title="Click to go to the Author Index">
             Xu, Zhixuan
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#406912" title="Click to go to the Author Index">
             Guo, Jingxiang
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#340589" title="Click to go to the Author Index">
             Hou, Yiwen
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#285264" title="Click to go to the Author Index">
             Gao, Chongkai
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#427987" title="Click to go to the Author Index">
             Cai, Zhehao
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#427971" title="Click to go to the Author Index">
             Luo, Jiayu
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#217322" title="Click to go to the Author Index">
             Shao, Lin
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3346" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Dexterous grasping is a fundamental yet challenging skill in robotic manipulation, requiring precise interaction between robotic hands and objects. In this paper, we present D(R,O) Grasp, a novel framework that models the interaction between the robotic hand in its grasping pose and the object, enabling broad generalization across various robot hands and object geometries. Our model takes the robot hand's description and object point cloud as inputs and efficiently predicts kinematically valid and stable grasps, demonstrating strong adaptability to diverse robot embodiments and object geometries. Extensive experiments conducted in both simulated and real-world environments validate the effectiveness of our approach, with significant improvements in success rate, grasp diversity, and inference speed across multiple robotic hands. Our method achieves an average success rate of 87.53% in simulation in less than one second, tested across three different dexterous robotic hands. In real-world experiments using the LeapHand, the method also demonstrates an average success rate of 89%. D(R,O) Grasp provides a robust solution for dexterous grasping in complex and varied environments. The code, appendix, and videos are available on our project website at https://nus-lins-lab.github.io/drograspweb/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat1_03">
             08:40-08:45, Paper WeAT1.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod772" name="modify2514" onclick="modify(2514,772)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2514'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              TrofyBot: A Transformable Rolling and Flying Robot with High Energy Efficiency
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415351" title="Click to go to the Author Index">
             Lai, Mingwei
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417210" title="Click to go to the Author Index">
             Ye, Yuqian
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415372" title="Click to go to the Author Index">
             Wu, Hanyu
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#396905" title="Click to go to the Author Index">
             Xuan, Chice
            </a>
           </td>
           <td class="r">
            Huzhou Institute of Zhejiang University, Huzhou
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#275156" title="Click to go to the Author Index">
             Zhang, Ruibin
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#373958" title="Click to go to the Author Index">
             Ren, Qiuyu
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#213352" title="Click to go to the Author Index">
             Xu, Chao
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#200893" title="Click to go to the Author Index">
             Gao, Fei
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#178926" title="Click to go to the Author Index">
             Cao, Yanjun
            </a>
           </td>
           <td class="r">
            Zhejiang University, Huzhou Institute of Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2514" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Terrestrial and aerial bimodal vehicles have gained significant interest due to their energy efficiency and versatile maneuverability across different domains. However, most existing passive-wheeled bimodal vehicles rely on attitude regulation to generate forward thrust, which inevitably results in energy waste on producing lifting force. In this work, we propose a novel passive-wheeled bimodal vehicle called TrofyBot that can rapidly change the thrust direction with a single servo motor and a transformable parallelogram linkage mechanism (TPLM). Cooperating with a bidirectional force generation module (BFGM) for motors to produce bidirectional thrust, the robot achieves flexible mobility as a differential driven rover on the ground. This design achieves 95.37% energy saving efficiency in terrestrial locomotion, allowing the robot continuously move on the ground for more than two hours in current setup. Furthermore, the design obviates the need for attitude regulation and therefore provides a stable sensor field of view (FoV). We model the bimodal dynamics for the system, analyze its differential flatness property, and design a controller based on hybrid model predictive control for trajectory tracking. A prototype is built and extensive experiments are conducted to verify the design and the proposed controller, which achieves high energy efficiency and seamless transition between modes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat1_04">
             08:45-08:50, Paper WeAT1.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod773" name="modify1913" onclick="modify(1913,773)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1913'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Geometric Design and Gait Co-Optimization for Soft Continuum Robots Swimming at Low and High Reynolds Numbers
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#314998" title="Click to go to the Author Index">
             Yang, Yanhao
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#111301" title="Click to go to the Author Index">
             Hatton, Ross
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1913" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#nonholonomic_motion_planning" title="Click to go to the Keyword Index">
               Nonholonomic Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#flexible_robotics" title="Click to go to the Keyword Index">
               Flexible Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent advancements in soft actuators have enabled soft continuum swimming robots to achieve higher efficiency and more closely mimic the behaviors of real marine animals. However, optimizing the design and control of these soft continuum robots remains a significant challenge. In this paper, we present a practical framework for the co-optimization of the design and control of soft continuum robots, approached from a geometric locomotion analysis perspective. This framework is based on the principles of geometric mechanics, accounting for swimming at both low and high Reynolds numbers. By generalizing geometric principles to continuum bodies, we achieve efficient geometric variational co-optimization of designs and gaits across different power consumption metrics and swimming environments. The resulting optimal designs and gaits exhibit greater efficiencies at both low and high Reynolds numbers compared to three-link or serpenoid swimmers with the same degrees of freedom, approaching or even surpassing the efficiencies of infinitely flexible swimmers and those with higher degrees of freedom.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat1_05">
             08:50-08:55, Paper WeAT1.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod774" name="modify2163" onclick="modify(2163,774)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2163'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ShadowTac: Dense Measurement of Shear and Normal Deformation of a Tactile Membrane from Colored Shadows
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#340713" title="Click to go to the Author Index">
             Vitrani, Giuseppe
            </a>
           </td>
           <td class="r">
            Delft University of Technology (TU Delft)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422069" title="Click to go to the Author Index">
             Pasquale, Basile
            </a>
           </td>
           <td class="r">
            École Polytechnique Fédérale De Lausanne
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#140419" title="Click to go to the Author Index">
             Wiertlewski, Michael
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2163" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             To robustly handle objects, robots must perceive mechanical interactions through touch with sufficient richness. New tactile sensors leverage miniature cameras to provide dense measurements of these interactions, allowing for the extraction of material properties and frictional information. Among the plethora of solutions, retrographic sensing is popular for its ability to finely resolve the shape of the object being touched. This sensor uses a reflective membrane, illuminated at a shallow angle by three RGB lights, which cast colored shadows. From the illumination pattern of the deformed membrane, both the normal deformation and fine surface details can be recovered. However, these retrographic sensors cannot detect the lateral displacement of the membrane and, therefore, overlook frictional information, which is crucial for grasping and manipulation. Embedding and tracking opaque markers has been a makeshift solution, but these markers occlude the membrane and are difficult to manufacture. In this paper, we introduce ShadowTac, a tactile sensor that combines retrographic illumination with non-intrusive markers created by colored shadows. We patterned the retrographic surface with a dense array of submillimeter dimples, which are small enough not to obstruct the view yet cast shadows large enough to be visible to the camera. ShadowTac captures a dense image of both the normal displacement field with fine details and a precise lateral displacement field by tracking the markers. Additionally, our sensor is easy to manufacture, as the dimple pattern can simply be molded. We evaluated the measurement reliability of ShadowTac and its effectiveness in estimating the incipient slip of arbitrary objects. The dense measurement of both the normal and shear deformation that the sensor captures makes it ideal for tracking dynamic interactions between robotic fingertips and manipulated objects.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat1_06">
             08:55-09:00, Paper WeAT1.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod775" name="modify3349" onclick="modify(3349,775)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3349'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Occlusion-Aware 6D Pose Estimation with Depth-Guided Graph Encoding and Cross-Semantic Fusion for Robotic Grasping
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425274" title="Click to go to the Author Index">
             Liu, Jingyang
            </a>
           </td>
           <td class="r">
            Shanxi University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#184347" title="Click to go to the Author Index">
             Lu, Zhenyu
            </a>
           </td>
           <td class="r">
            South China University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#181914" title="Click to go to the Author Index">
             Chen, Lu
            </a>
           </td>
           <td class="r">
            Shanxi University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#371041" title="Click to go to the Author Index">
             Yang, Jing
            </a>
           </td>
           <td class="r">
            Shanxi University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107047" title="Click to go to the Author Index">
             Yang, Chenguang
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3349" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Reliable 6D pose estimation is crucial for robotic tasks but presents significant challenges in environments with occlusion. Recent approaches tend to directly predict pose parameters of object with deep neural networks, lacking the modeling ability of non-adjacent and complex relationships of surface points in occluded scenarios. To solve this problem, we propose a novel occlusion-aware 6D pose estimation framework, which uses depth-guided graph neural network (GNN) to model potential relationships from RGBD input. Two semantic information, which are mask and binary code of object, are adaptively fused to extract 2D-3D correspondence related features in an effective manner. Both enhanced graph features and fused semantic information contribute to the performance improvement of pose estimation with occlusion. Extensive experiments indicate that our approach outperforms comparative methods by 1.2% and 1.9% on LMO and YCBV datasets (up to 30% for certain objects) and its validity is also verified under real-world pose estimation test.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat2">
             <b>
              WeAT2
             </b>
             Regular Session, 301
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod776" name="modifyWeAT2" onclick="modsession(513,776)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat2" title="Click to go to the Program at a Glance">
             <b>
              SLAM 3
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#105562" title="Click to go to the Author Index">
             Civera, Javier
            </a>
           </td>
           <td class="r">
            Universidad De Zaragoza
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#305540" title="Click to go to the Author Index">
             Kwon, Cheolhyeon
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat2_01">
             08:30-08:35, Paper WeAT2.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod777" name="modify451" onclick="modify(451,777)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('451'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              JPG-SLAM: Joint Point-Gaussian Splatting Representation for Dense Dynamic SLAM
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405477" title="Click to go to the Author Index">
             Huang, Kunrui
            </a>
           </td>
           <td class="r">
            Wuhan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405816" title="Click to go to the Author Index">
             Yang, Wennan
            </a>
           </td>
           <td class="r">
            Wuhan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#438330" title="Click to go to the Author Index">
             Zhou, Pengwei
            </a>
           </td>
           <td class="r">
            Affiliation (University, Organization, Company)*
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#322774" title="Click to go to the Author Index">
             Li, Li
            </a>
           </td>
           <td class="r">
            Wuhan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#211094" title="Click to go to the Author Index">
             Yao, Jian
            </a>
           </td>
           <td class="r">
            Wuhan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab451" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a simultaneous localization and mapping (SLAM) system to provide accurate pose estimation and dynamic scene reconstruction. Our approach proposes a Joint Point-Gaussian Splatting representation, which fully integrates the robustness of isotropic feature points in pose estimation and the flexibility of anisotropic 3D Gaussians in scene representation. This system does not need to suppress the anisotropic representation of Gaussian elements, which enables the mapping module to achieve finer scene representation with lower memory consumption. Additionally, in order to enhance the adaptability of the system in dynamic environments, we introduced a dynamic region recognition module and utilized 3D Gaussian Splatting and 4D Gaussian Splatting representations to represent static and dynamic regions respectively. Furthermore, we developed a local map management strategy for Gaussian Splatting mapping, effectively reducing the memory and computational resource usage in the mapping process. Experiments on public datasets demonstrate that our system achieves state-of-the-art tracking and mapping accuracy compared to existing baselines.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat2_02">
             08:35-08:40, Paper WeAT2.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod778" name="modify980" onclick="modify(980,778)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('980'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              FMCW-LIO: A Doppler LiDAR-Inertial Odometry
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#376539" title="Click to go to the Author Index">
             Zhao, Mingle
            </a>
           </td>
           <td class="r">
            University of Macau
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339476" title="Click to go to the Author Index">
             Wang, Jiahao
            </a>
           </td>
           <td class="r">
            University of Macau
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#373326" title="Click to go to the Author Index">
             Gao, Tianxiao
            </a>
           </td>
           <td class="r">
            University of Macao
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#259738" title="Click to go to the Author Index">
             Xu, Chengzhong
            </a>
           </td>
           <td class="r">
            University of Macau
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#204275" title="Click to go to the Author Index">
             Kong, Hui
            </a>
           </td>
           <td class="r">
            University of Macau
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab980" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Conventional LiDAR-inertial odometry (LIO) or SLAM methods heavily rely on geometric features of environments, as LiDARs primarily provide range measurements instead of motion measurements. From now on, however, the situation changes thanks to the novel Frequency Modulated Continuous Wave (FMCW) LiDARs. FMCW LiDARs not only offer the point range with high resolution but also capture the instant point Doppler velocity through the Doppler effect. In the letter, we propose FMCW-LIO, a novel and robust LIO, leveraging intrinsic Doppler measurements from FMCW LiDARs. To correctly exploit Doppler velocities, a motion compensation method is designed, and a Doppler-aided observation model is applied for on-manifold state estimation. Then, dynamic points can be effectively removed by the Doppler criteria, deriving more consistent geometric observations. FMCW-LIO eventually achieves accurate state estimation and static mapping, even in structure-degenerated environments. Extensive experiments in diverse scenes are performed and FMCW-LIO outperforms other algorithms on both accuracy and robustness.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat2_03">
             08:40-08:45, Paper WeAT2.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod779" name="modify1216" onclick="modify(1216,779)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1216'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Submodular Optimization for Keyframe Selection &amp; Usage in SLAM
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378639" title="Click to go to the Author Index">
             Thorne, David
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419645" title="Click to go to the Author Index">
             Chan, Nathan
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419660" title="Click to go to the Author Index">
             Ma, Yanlong
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#238753" title="Click to go to the Author Index">
             Robison, Christopher, Christa
            </a>
           </td>
           <td class="r">
            Army Research Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#150496" title="Click to go to the Author Index">
             Osteen, Philip
            </a>
           </td>
           <td class="r">
            U.S. Army Research Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#192998" title="Click to go to the Author Index">
             Lopez, Brett
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1216" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Keyframes are LiDAR scans saved for future reference in Simultaneous Localization And Mapping (SLAM), but despite their central importance most algorithms leave choices of which scans to save and how to use them to wasteful heuristics. This work proposes two novel keyframe selection strategies for localization and map summarization, as well as a novel approach to submap generation which selects keyframes that best constrain localization. Our results show that online keyframe identification and submap generation reduce the number of saved keyframes and improve per scan computation time without compromising localization performance. We also present a map summarization feature for quickly capturing environments under strict map size constraints.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat2_04">
             08:45-08:50, Paper WeAT2.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod780" name="modify1288" onclick="modify(1288,780)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1288'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Equivariant Filter Design for Range-Only SLAM
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#336358" title="Click to go to the Author Index">
             Ge, Yixiao
            </a>
           </td>
           <td class="r">
            Australian National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420978" title="Click to go to the Author Index">
             Pearce, Arthur
            </a>
           </td>
           <td class="r">
            Australian National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#241273" title="Click to go to the Author Index">
             van Goor, Pieter
            </a>
           </td>
           <td class="r">
            University of Twente
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105364" title="Click to go to the Author Index">
             Mahony, Robert
            </a>
           </td>
           <td class="r">
            Australian National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1288" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Range-only Simultaneous Localisation and Mapping (RO-SLAM) is of interest in the robotics community due to its practical applications; for example, ultra-wideband (UWB) and Bluetooth Low Energy (BLE) localisation in terrestrial and aerial applications and acoustic beacon localisation in marine applications. In this work, we consider a mobile robot equipped with an inertial measurement unit (IMU) and a range sensor that measures distances to a collection of fixed landmarks. We derive an equivariant filter (EqF) for the RO-SLAM problem based on a symmetry Lie group that is compatible with the range measurements. The proposed filter does not require bootstrapping or initialisation of landmark positions, and demonstrates robustness to the no-prior situation. The filter is demonstrated on a real-world dataset, and it is shown to significantly outperform a state-of-the-art EKF alternative in terms of both accuracy and robustness.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat2_05">
             08:50-08:55, Paper WeAT2.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod781" name="modify4788" onclick="modify(4788,781)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4788'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Toward Globally Optimal State Estimation Using Automatically Tightened Semidefinite Relaxations
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256420" title="Click to go to the Author Index">
             Dümbgen, Frederike
            </a>
           </td>
           <td class="r">
            ENS, PSL University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#321616" title="Click to go to the Author Index">
             Holmes, Connor
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#288783" title="Click to go to the Author Index">
             Agro, Ben
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#115139" title="Click to go to the Author Index">
             Barfoot, Timothy
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4788" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#global_optimality" title="Click to go to the Keyword Index">
               Global Optimality
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In recent years, semidefinite relaxations of common optimization problems in robotics have attracted growing attention due to their ability to provide globally optimal solutions. In many cases, it was shown that specific handcrafted redundant constraints are required to obtain tight relaxations, and thus global optimality. These constraints are formulation-dependent and typically identified through a lengthy manual process. Instead, the present article suggests an automatic method to find a set of sufficient redundant constraints to obtain tightness, if they exist. We first propose an efficient feasibility check to determine if a given set of variables can lead to a tight formulation. Second, we show how to scale the method to problems of bigger size. At no point of the process do we have to find redundant constraints manually. We showcase the effectiveness of the approach, in simulation and on real datasets, for range-based localization and stereo-based pose estimation. We also reproduce semidefinite relaxations presented in recent literature and show that our automatic method always finds a smaller set of constraints sufficient for tightness than previously considered.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat2_06">
             08:55-09:00, Paper WeAT2.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod782" name="modify4858" onclick="modify(4858,782)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4858'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Viewpoint-Aware Visibility Scoring for Point Cloud Registration in Loop Closure
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372974" title="Click to go to the Author Index">
             Yoon, Ilseung
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372969" title="Click to go to the Author Index">
             Islam, Tariq
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372975" title="Click to go to the Author Index">
             Kim, Kwangrok
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#305540" title="Click to go to the Author Index">
             Kwon, Cheolhyeon
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4858" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Abstract—Lidar-based Simultaneous Localization and Mapping (SLAM) encounters a substantial challenge in the form of accumulating errors, which can adversely impact its reliability. Loop closing techniques have been extensively employed to counteract this issue. Nonetheless, the loop closing conundrum remains difficult to resolve, as point clouds often exhibit partial overlap due to disparities in scanning pose (viewpoints). This renders the conventional point cloud registration such as Iterative Closest Point (ICP) algorithm problematic. To overcome this challenge, this paper proposes a two-stage viewpoint-aware point cloud registration technique that assigns suitable weights to the correspondence pairs associating two point clouds from different viewpoints. The weights account for the visibility of points from their respective viewpoint as well as from the viewpoint of the counterpart point cloud, making the registration more relying on commonly visible points from the both viewpoints. Experimental results, utilizing the KITTI and Apollo-SouthBay dataset, indicate that the proposed technique delivers more precise and robust performance compared to the baseline techniques.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat3">
             <b>
              WeAT3
             </b>
             Regular Session, 303
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod783" name="modifyWeAT3" onclick="modsession(301,783)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat3" title="Click to go to the Program at a Glance">
             <b>
              Mechanism Design 1
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#168993" title="Click to go to the Author Index">
             Whitney, John Peter
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#319823" title="Click to go to the Author Index">
             Herneth, Christopher
            </a>
           </td>
           <td class="r">
            Technical University Munich
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat3_01">
             08:30-08:35, Paper WeAT3.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod784" name="modify1047" onclick="modify(1047,784)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1047'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Tension Dependent Twisted String Actuator Modelling and Efficacy Benchmarking in Force and Impedance Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#319823" title="Click to go to the Author Index">
             Herneth, Christopher
            </a>
           </td>
           <td class="r">
            Technical University Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417019" title="Click to go to the Author Index">
             Cheng, Yi
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#223070" title="Click to go to the Author Index">
             Ganguly, Amartya
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#108317" title="Click to go to the Author Index">
             Haddadin, Sami
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1047" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#force_control" title="Click to go to the Keyword Index">
               Force Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#tendon_wire_mechanism" title="Click to go to the Keyword Index">
               Tendon/Wire Mechanism
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study presents a comprehensive experimental analysis of Twisted String Actuators (TSA), focused on enhancing contraction modelling accuracy and establishing a baseline for TSA tension and impedance control efficacy. A novel TSA string radius function is introduced, computing effective radii for multi-strand bundles based on axial actuator tension. The proposed model was validated in physical experiments, resulting in a reduction of maximal errors between measured and simulated actuator contraction trajectories from up to 60% in established models to around 10% in our work. Additionally, the tension-dependent radius modification effectively reduced errors between the estimated and the measured bundle tension by an order of magnitude, marking an essential step towards TSA control independent of bundle tension measurements. TSA tension control was assessed based on four metrics: accuracy, precision, impact stability, and bandwidth, following ISO 9283:1998 standards. The quality of tension control was found to be dependent on bundle tension, twisting angle and strand quantity, whereas impact stability was maintained in all configurations. Joint impedance control with TSA was evaluated for perturbation stability and position control bandwidth, where the latter was enhanced with increasing joint stiffness. The presented analysis informs designers about the capabilities of TSAs in different configurations, and their respective suitability for desired applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat3_02">
             08:35-08:40, Paper WeAT3.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod785" name="modify1206" onclick="modify(1206,785)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1206'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Novel Twisted-Winching String Actuator for Robotic Applications: Design and Validation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#295645" title="Click to go to the Author Index">
             Poon, Ryan
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#299640" title="Click to go to the Author Index">
             Padia, Vineet
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#113743" title="Click to go to the Author Index">
             Hunter, Ian
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1206" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#tendon_wire_mechanism" title="Click to go to the Keyword Index">
               Tendon/Wire Mechanism
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a novel actuator system combining a twisted string actuator (TSA) with a winch mechanism. Relative to traditional hydraulic and pneumatic systems in robotics, TSAs are compact and lightweight but face limitations in stroke length and force-transmission ratios. Our integrated TSA-winch system overcomes these constraints by providing variable transmission ratios through dynamic adjustment. It increases actuator stroke by winching instead of overtwisting, and it improves force output by twisting. The design features a rotating turret that houses a winch, which is mounted on a bevel gear assembly driven by a through-hole drive shaft. Mathematical models are developed for the combined displacement and velocity control of this system. Experimental validation demonstrates the actuator's ability to achieve a wide range of transmission ratios and precise movement control. We present performance data on movement precision and generated forces, discussing the results in the context of existing literature. This research contributes to the development of more versatile and efficient actuation systems for advanced robotic applications and improved automation solutions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat3_03">
             08:40-08:45, Paper WeAT3.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod786" name="modify1716" onclick="modify(1716,786)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1716'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design and Evaluation of High-Performance Motion-Decoupled Cable Transmission Modules
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422027" title="Click to go to the Author Index">
             Takei, Ryo
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#205418" title="Click to go to the Author Index">
             Frishman, Samuel
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#168993" title="Click to go to the Author Index">
             Whitney, John Peter
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1716" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#tendon_wire_mechanism" title="Click to go to the Keyword Index">
               Tendon/Wire Mechanism
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Cable transmissions are commonly used in robotics for remote force transmission, offering a lightweight, compact, and efficient solution for transmitting high forces between input and output. However, cables in flexible compression housings (Bowden cables), exhibit high static friction, which increases exponentially with total bend angle. Alternatively, internally routed ball-bearing supported cable capstan transmissions are low friction, but complex and present challenges in routing multiple sets of cables. In this paper, we propose motion-decoupled cable transmission modules that address these challenges, occupying the middle ground, functioning as discrete-joint ball-bearing supported Bowden cables. Our rolling-plus-twist joint design decouples pairs of routed cables from changing significantly in tension, length, or friction during large angle motion of the linked transmission. Using sub-1 mm diameter high-strength synthetic cable, the transmission exhibits a maximum coupling motion of only 0.15 mm over the full range of motion of the cable-transmission mechanism, approximately 10% of pretension in combined hysteresis and friction, a transmission stiffness of 10 N/mm, weighing just 9 g per rolling joint and 5 g per twist joint. Two applications are demonstrated: cable routing alongside a robot arm for, say, gripper remote actuation, and remote needle advancement for an MRI-safe needle biopsy robot.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat3_04">
             08:45-08:50, Paper WeAT3.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod787" name="modify3018" onclick="modify(3018,787)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3018'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Advanced Xθ Reluctance Electromagnetic Micropositioning System for Precision Motion Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#290998" title="Click to go to the Author Index">
             Pumphrey, Michael Joseph
            </a>
           </td>
           <td class="r">
            University of Guelph
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#257001" title="Click to go to the Author Index">
             Alatawneh, Natheer
            </a>
           </td>
           <td class="r">
            University of Guelph
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#132899" title="Click to go to the Author Index">
             Al Janaideh, Mohammad
            </a>
           </td>
           <td class="r">
            University of Guelph
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3018" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study examines a novel setup of a micropositioning trajectory manipulator in Xθ, energized by a reluctance actuator (RA) and two accompanying moving magnet actuators (MMA). The design is characterized by a C-core RA, which features asymmetrical air gaps between the mover and the stator elements when under angular θ rotation. When the stator coil is energized, a magnetic flux induces a force in the mover. Two MMAs can add force and torque dynamics to the system via solenoid and permanent magnet (PM) pairs to offer additional corrective actions. Facilitating control of a translational x and rotational θ two-degree-of-freedom (2DOF) actuation system. Flexure hinges aid in the retraction force of the mover element and provide needed stiffness to the system without frictional effects. This was modeled analytically and optimized to achieve outlined performance objectives. The system was validated experimentally through triangle, and sinusoidal trajectories in open loop control. The most relevant application is scanning mirror systems where specific targeted rotational and translational trajectories can benefit light beam positioning. This system allows both translation and rotation specifications of a selected trajectory to be realized in one actuation unit, opening up more design possibilities for controlling precision positioning systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat3_05">
             08:50-08:55, Paper WeAT3.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod788" name="modify4574" onclick="modify(4574,788)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4574'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Cycloidal Quasi-Direct Drive Actuator Designs with Learning-Based Torque Estimation for Legged Robotics
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#410540" title="Click to go to the Author Index">
             Zhu, Alvin
            </a>
           </td>
           <td class="r">
            University of California Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#275673" title="Click to go to the Author Index">
             Tanaka, Yusuke
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#274068" title="Click to go to the Author Index">
             Rafeedi, Fadi
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106488" title="Click to go to the Author Index">
             Hong, Dennis
            </a>
           </td>
           <td class="r">
            UCLA
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4574" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a novel approach through the design and implementation of Cycloidal Quasi-Direct Drive actuators for legged robotics. The cycloidal gear mechanism, with its inherent high torque density and mechanical robustness, offers significant advantages over conventional designs. By integrating cycloidal gears into the Quasi-Direct Drive framework, we aim to enhance the performance of legged robots, particularly in tasks demanding high torque and dynamic loads, while still keeping them lightweight. Additionally, we develop a torque estimation framework for the actuator using an Actuator Network, which effectively reduces the sim-to-real gap introduced by the cycloidal drive’s complex dynamics. This integration is crucial for capturing the complex dynamics of a cycloidal drive, which contributes to improved learning efficiency, agility, and adaptability for reinforcement learning.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat3_06">
             08:55-09:00, Paper WeAT3.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod789" name="modify4862" onclick="modify(4862,789)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4862'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Compact Modular Robotic Wrist with Variable Stiffness Capability
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#318756" title="Click to go to the Author Index">
             Sun, Hyunsoo
            </a>
           </td>
           <td class="r">
            Korea Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#252199" title="Click to go to the Author Index">
             Park, Sungwoo
            </a>
           </td>
           <td class="r">
            Korea University, KIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#181916" title="Click to go to the Author Index">
             Hwang, Donghyun
            </a>
           </td>
           <td class="r">
            Korea Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4862" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#compliant_joint_mechanism" title="Click to go to the Keyword Index">
               Compliant Joint/Mechanism
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robotic_wrist" title="Click to go to the Keyword Index">
               Robotic Wrist
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We have developed a two-degree-of-freedom robotic wrist with variable stiffness capability, designed for situations where collisions between the end-effector and the environment are inevitable. To enhance environmental adaptability and prevent physical damage, the wrist can operate in a low-stiffness mode. However, the flexibility of this mode might negatively impact stable and precise manipulation. To address this, we proposed a robotic wrist that switches between a passive low-stiffness mode for environmental adaptation and an active high-stiffness mode for precise manipulation. Initially, we developed a functional prototype that could manually switch between these modes, demonstrating the wrist's passive low-stiffness and active high-stiffness states. This prototype was designed as a lightweight, flat-type modular device, incorporating a sheet-type flexure as the motion guide and embedding all essential components, including actuators, sensors, and a control unit, into the wrist module. Based on the functional prototype, we developed an improved version to enhance durability and functionality. The resulting wrist module incorporates a three-axis F/T sensor and an impedance control system to control the stiffness. It measures 55 mm in height, weighs 200 g, and offers a 232.4-fold active stiffness variation.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat4">
             <b>
              WeAT4
             </b>
             Regular Session, 304
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod790" name="modifyWeAT4" onclick="modsession(617,790)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat4" title="Click to go to the Program at a Glance">
             <b>
              Vision Applications
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#419576" title="Click to go to the Author Index">
             Xiang, Lirong
            </a>
           </td>
           <td class="r">
            North Carolina State University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#172836" title="Click to go to the Author Index">
             Wang, Zhenzhou
            </a>
           </td>
           <td class="r">
            Huaibei Normal University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat4_01">
             08:30-08:35, Paper WeAT4.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod791" name="modify231" onclick="modify(231,791)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('231'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Natural-Neighbor-Interpolant-Based Pattern Modeling Method for Robust Decoding of the Structured Light Pattern (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#172836" title="Click to go to the Author Index">
             Wang, Zhenzhou
            </a>
           </td>
           <td class="r">
            Huaibei Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#414461" title="Click to go to the Author Index">
             Liu, Shuo
            </a>
           </td>
           <td class="r">
            Fujian Normal University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab231" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_manufacturing" title="Click to go to the Keyword Index">
               Computer Vision for Manufacturing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Active stereo vision (ASV) computes the parallax and depth information from the coded structured light patterns. Thus, it could overcome the difficulties of measuring objects without textures and colors. However, decoding of the structured light patterns at locations of color crosstalk, specular reflection and occlusion remains challenging. In this paper, we propose a natural-neighbor-interpolant-based pattern modeling method to decode the structured light point pattern robustly. The robustness is achieved in the sense of hundred percent point segmentation completeness. Due to the hundred percent completeness, the points in the corresponding blocks are matched directly according to their indexes. Experimental results verified the effectiveness of the proposed method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat4_02">
             08:35-08:40, Paper WeAT4.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod792" name="modify862" onclick="modify(862,792)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('862'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Automated Video Object Detection of Motile Cells under Microscopy
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#359152" title="Click to go to the Author Index">
             Song, Haocong
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#266836" title="Click to go to the Author Index">
             Chen, Wenyuan
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#236008" title="Click to go to the Author Index">
             Shan, Guanqiao
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#328080" title="Click to go to the Author Index">
             Sun, Chen
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#353557" title="Click to go to the Author Index">
             Wan, Bingqing
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#218946" title="Click to go to the Author Index">
             Dai, Changsheng
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#310898" title="Click to go to the Author Index">
             Liu, Hang
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419486" title="Click to go to the Author Index">
             Wang, Shanshan
            </a>
           </td>
           <td class="r">
            Nanjing Drum Tower Hospital, Affiliated Hospital of Medical Scho
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101247" title="Click to go to the Author Index">
             Sun, Yu
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab862" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Video object detection (VOD) of motile cells (e.g., bacteria and sperm) under microscopy is challenging due to motion blur, sporadic out-of-focus, and pose variations. Compared with VOD in generic scenes, the lower contrast and smaller color space of microscopy imaging further introduce feature overlap between the foreground objects and the background objects (e.g., impurity cells and contaminants). Transformer-based methods have achieved great success in the VOD of generic scenes by utilizing object queries to model the inner-frame objects and the inter-frame objects. However, the appearance overlap problem in microscopy video frames significantly compromises the inter-frame query aggregation by introducing background features into the object query. To tackle this challenge, this paper reports a static-dynamic query-based VOD network that treats object queries of the current video frame and reference video frames differently. Specifically, a two-stage framework is implemented that first generates high-quality object queries of reference frames with a static Transformer decoder pre-trained on a still image dataset. The network is then trained on a per-frame annotated dataset using a dynamic Transformer decoder to model the object queries of the current frame. A Reference Query Relation Module is further proposed to enhance the reference queries for more effective aggregation with the current query. Experiments on clinically collected biopsied sperm datasets validated the effectiveness of the proposed method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat4_03">
             08:40-08:45, Paper WeAT4.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod793" name="modify1125" onclick="modify(1125,793)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1125'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Vision-Based Movement Primitives for Lunar Hazard Avoidance
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#238365" title="Click to go to the Author Index">
             Cloud, Joseph
            </a>
           </td>
           <td class="r">
            NASA Kennedy Space Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#157520" title="Click to go to the Author Index">
             Beksi, William J.
            </a>
           </td>
           <td class="r">
            The University of Texas at Arlington
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420566" title="Click to go to the Author Index">
             Schuler, Jason
            </a>
           </td>
           <td class="r">
            NASA Kennedy Space Center
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1125" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mining_robotics" title="Click to go to the Keyword Index">
               Mining Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             To support sustainable infrastructure on the Moon, NASA is developing the In-Situ Resource Utilization (ISRU) Pilot Excavator (IPEx) to extract and transport lunar regolith for processing and construction. During its mission, IPEx will execute various driving patterns, primarily cycling between excavation and unloading sites, with additional maneuvers such as circular traverses around the lander and raster scans for environmental mapping. In this work, dynamic movement primitives (DMPs) are used to represent these patterns. We augment the DMPs with a vision-based real-time obstacle avoidance system to navigate surface hazards, such as rocks, encountered during traversal. Our approach is evaluated in a high-fidelity simulation replicating the challenging environment of the lunar south pole to demonstrate IPEx’s ability to adapt to surface hazards while fulfilling its operational tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat4_04">
             08:45-08:50, Paper WeAT4.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod794" name="modify1516" onclick="modify(1516,794)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1516'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LAFNET: Lightweight Aerial Fire Detection Model for Onboard Edge Computing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416546" title="Click to go to the Author Index">
             Zhai, Haozhou
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419100" title="Click to go to the Author Index">
             Yan, Weiming
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309862" title="Click to go to the Author Index">
             Wang, Xiaohan
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418720" title="Click to go to the Author Index">
             Zhao, Tuhao
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#115512" title="Click to go to the Author Index">
             Hu, Tianjiang
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1516" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Fire poses significant threats to life and property, necessitating efficient inspection and accurate identification. Although aerial computer vision algorithms hold great promise, the computational limitations of onboard platforms prevent existing algorithms from meeting high standards of accuracy and real-time performance. To address this challenge, we propose an lightweight aerial fire detection model, LAFNET. This model incorporates the EffiDarknetLight backbone, optimized for lightweight design, integrates specially designed LG block components within the LG PAN neck, resulting in a model Params of only 1.3M. Experimental results demonstrate that our method attains a good trade-off between lightweight design and detection accuracy. Compared to the smallest standard YOLO series' model YOLOv5n, LAFNET improves MAP by 2.1%, while reducing Params and FLOPs by 27.8% and 29.3%, the inference speed on Nvidia Orin Nano edge computing side improves 24.8%.	These experiments indicate that LAFNET offers a highly efficient solution for aerial fire detection, combining speed and accuracy.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat4_05">
             08:50-08:55, Paper WeAT4.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod795" name="modify3726" onclick="modify(3726,795)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3726'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              UDSV: Unsupervised Deep Stitching for Tractor-Trailer Surround View
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424399" title="Click to go to the Author Index">
             Sun, Leyao
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#324113" title="Click to go to the Author Index">
             Liang, Hao
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#350140" title="Click to go to the Author Index">
             Dong, Zhipeng
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#128868" title="Click to go to the Author Index">
             Yang, Yi
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#128869" title="Click to go to the Author Index">
             Fu, Mengyin
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3726" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#omnidirectional_vision" title="Click to go to the Keyword Index">
               Omnidirectional Vision
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In recent years, with the rapid development of Advanced Driver Assistance Systems (ADAS), the demand for the precise and efficient surround view stitching system has significantly increased. Traditional stitching methods perform well in small single-unit vehicles with stable camera poses. However, the stitching quality sharply degrades when applied to large tractor-trailers due to the continuous pose changes caused by the non-rigid connection between the tractor and trailer. In detail, first, the extended length of tractor-trailers results in low overlap between cameras, making feature extraction and matching challenging. Additionally, the stitched images often appear irregular, detracting from visual quality. Besides, even if static stitching looks natural, it causes jitter in dynamic scenarios due to random feature extraction. In this paper, we propose an unsupervised deep stitching method for tractortrailer surround view system. We introduce a feature extraction module for tractor-trailer scenarios (FMT) to enhance feature extraction in low-overlap situations. Besides, we design a spatiotemporally consistent control point constraint strategy (STCC) to achieve spatial shape preservation and temporal smoothing effects, resulting in visually consistent and stable stitched sequences. Experimental results from both public and real dataset show that our method efficiently completes tractortrailer surround view stitching, producing well-aligned and natural panoramic images compared to previous methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat4_06">
             08:55-09:00, Paper WeAT4.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod796" name="modify4942" onclick="modify(4942,796)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4942'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Think Step by Step: Chain-Of-Gesture Prompting for Error Detection in Robotic Surgical Videos
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#386498" title="Click to go to the Author Index">
             Shao, Zhimin
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#410394" title="Click to go to the Author Index">
             Xu, Jialang
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#128031" title="Click to go to the Author Index">
             Stoyanov, Danail
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203999" title="Click to go to the Author Index">
             Mazomenos, Evangelos
            </a>
           </td>
           <td class="r">
            UCL
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#269301" title="Click to go to the Author Index">
             Jin, Yueming
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4942" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Despite advancements in robotic systems and surgical data science, ensuring safe execution in robot-assisted minimally invasive surgery (RMIS) remains challenging. Current methods for surgical error detection typically involve two parts: identifying gestures and then detecting errors within each gesture clip. These methods often overlook the rich contextual and semantic information inherent in surgical videos, with limited performance due to reliance on accurate gesture identification. Inspired by the chain-of-thought prompting in natural language processing, this letter presents a novel and real-time end-to-end error detection framework, Chain-of-Gesture (COG) prompting, integrating contextual information from surgical videos step by step. This encompasses two reasoning modules that simulate expert surgeons' decision-making: a Gestural-Visual Reasoning module using transformer and attention architectures for gesture prompting and a Multi-Scale Temporal Reasoning module employing a multi-stage temporal convolutional network with slow and fast paths for temporal information extraction. We validate our method on the JIGSAWS dataset and show improvements over the state-of-the-art, achieving 4.6% higher F1 score, 4.6% higher Accuracy, and 5.9% higher Jaccard index, with an average frame processing time of 6.69 milliseconds. This demonstrates our approach's potential to enhance RMIS safety and surgical education efficacy. The code is available at https://github.com/jinlab-imvr/Chain-of-Gesture.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat5">
             <b>
              WeAT5
             </b>
             Regular Session, 305
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod797" name="modifyWeAT5" onclick="modsession(15,797)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat5" title="Click to go to the Program at a Glance">
             <b>
              Aerial Manipulation 1
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#142369" title="Click to go to the Author Index">
             Loianno, Giuseppe
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#104455" title="Click to go to the Author Index">
             Ollero, Anibal
            </a>
           </td>
           <td class="r">
            AICIA. G41099946
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat5_01">
             08:30-08:35, Paper WeAT5.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod798" name="modify41" onclick="modify(41,798)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('41'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              The Palletrone Cart: Human-Robot Interaction-Based Aerial Cargo Transportation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#390866" title="Click to go to the Author Index">
             Park, Geonwoo
            </a>
           </td>
           <td class="r">
            Seoul National University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#390960" title="Click to go to the Author Index">
             Park, Hyungeun
            </a>
           </td>
           <td class="r">
            Seoul National University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#347166" title="Click to go to the Author Index">
             Park, Wooyong
            </a>
           </td>
           <td class="r">
            Seoul National University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256238" title="Click to go to the Author Index">
             Lee, Dongjae
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#114738" title="Click to go to the Author Index">
             Kim, Murim
            </a>
           </td>
           <td class="r">
            Korea Institute of Robot and Convergence
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#191737" title="Click to go to the Author Index">
             Lee, Seung Jae
            </a>
           </td>
           <td class="r">
            Seoul National University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab41" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a new cargo transportation solution based on physical human-robot interaction utilizing a novel fully-actuated multirotor platform called Palletrone. The platform is designed with a spacious upper flat surface for easy cargo loading, complemented by a rear-mounted handle reminiscent of a shopping cart. Flight trajectory control is achieved by a human operator gripping the handle and applying three-dimensional forces and torques while maintaining a stable cargo transport with zero roll and pitch attitude throughout the
             <p>
              flight. To facilitate physical human-robot interaction, we employ an admittance control technique. Instead of relying on complex force estimation methods, like in most admittance control implementations, we
              <p>
               introduce a simple yet effective estimation technique based on a disturbance observer robust control algorithm. We conducted an analysis
               <p>
                of the flight stability and performance in response to changes in system mass resulting from arbitrary cargo loading. Ultimately, we demonstrate that individuals can effectively control the system trajectory by applying appropriate interactive forces and torques. Furthermore, we showcase the performance of the system through various experimental scenarios.
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat5_02">
             08:35-08:40, Paper WeAT5.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod799" name="modify129" onclick="modify(129,799)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('129'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design of a Suspended Manipulator with Aerial Elliptic Winding
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395892" title="Click to go to the Author Index">
             Niddam, Ethan
            </a>
           </td>
           <td class="r">
            University of Strasbourg, ICube
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#189433" title="Click to go to the Author Index">
             Dumon, Jonathan
            </a>
           </td>
           <td class="r">
            GIPSA-LAB
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105667" title="Click to go to the Author Index">
             Cuvillon, Loic
            </a>
           </td>
           <td class="r">
            University of Strasbourg
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#184532" title="Click to go to the Author Index">
             Durand, Sylvain
            </a>
           </td>
           <td class="r">
            INSA Strasbourg &amp; ICube
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#396360" title="Click to go to the Author Index">
             Querry, Stephane
            </a>
           </td>
           <td class="r">
            Polyvionics
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104099" title="Click to go to the Author Index">
             Hably, Ahmad
            </a>
           </td>
           <td class="r">
            Grenoble-Inp
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105657" title="Click to go to the Author Index">
             Gangloff, Jacques
            </a>
           </td>
           <td class="r">
            University of Strasbourg
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab129" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#art_and_entertainment_robotics" title="Click to go to the Keyword Index">
               Art and Entertainment Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#tendon_wire_mechanism" title="Click to go to the Keyword Index">
               Tendon/Wire Mechanism
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Art is one of the oldest forms of human expression, constantly evolving, taking new forms and using new techniques. With their increased accuracy and versatility, robots can be considered as a new class of tools to perform works of art. The STRAD (STReet Art Drone) project aims to perform a 10-meter- high painting on a vertical surface with sub-centimetric precision. To achieve this goal we introduce a new design for an aerial manipulator with elastic suspension capable of moving from one equilibrium position to another using only its thrusters and an elliptic pulley-counterweight system. A feedback linearization control law is implemented to perform fast and accurate winding and unwinding of an elastic cable.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat5_03">
             08:40-08:45, Paper WeAT5.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod800" name="modify755" onclick="modify(755,800)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('755'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Autonomous Heavy Object Pushing Using a Coaxial Tiltrotor (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338500" title="Click to go to the Author Index">
             Hwang, Sunwoo
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256238" title="Click to go to the Author Index">
             Lee, Dongjae
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#216299" title="Click to go to the Author Index">
             Kim, Changhyeon
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103663" title="Click to go to the Author Index">
             Kim, H. Jin
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab755" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Aerial physical interaction (APhI) with a multirotor-based platform such as pushing a heavy object demands generation of a sufficiently large interaction force while maintaining the stability. Such requirement can cause rotor saturation, because the rotor thrust enlarged for interaction force may leave a reduced margin for attitude stabilization. We first design an H -shaped coaxial tiltrotor that can generate a sufficiently large interaction force than a conventional multirotor. We then propose an overall framework composed of high-level robust controller and low-level control allocation for the coaxial tiltrotor to ensure robustness against uncertain motion of the unknown interacting object and to overcome the saturation issue. To guarantee the robustness at all time, we design a controller based on a nonlinear disturbance observer (DOB). Then, we formulate a problem of computing low-level actuator inputs avoiding rotor saturation as a tractable nonlinear optimization problem, which can be solved real-time. The proposed framework is validated in extensive real-world experiments where the 3.3 kg tiltrotor successfully pushes a cart weighing up to 60 kg. An ablation study with the tiltrotor shows effectiveness of the proposed control allocation law in avoiding rotor saturation. Furthermore, a comparative experiment with a conventional multirotor shows failure in the same setting, which validates the use of the coaxial tiltrotor. An experimental video can be found at htt
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat5_04">
             08:45-08:50, Paper WeAT5.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod801" name="modify819" onclick="modify(819,801)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('819'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Aerial Grasping by Multi-Limbed Flying Robot SPIDAR Based on Vectored Thrust Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#164284" title="Click to go to the Author Index">
             Zhao, Moju
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab819" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Delivery by aerial robots is an emerging topic in many scenarios, such as logistics, construction industry, and disaster response. Compared to the standard styles that deploy cage or sling, grasping style by gripper can handle objects in various shapes. A multi-limbed structure with distributed vectorable rotors called SPIDAR shows a higher potential to grasp large object in a three-dimensional manner. Therefore, in this paper, we focus on the advanced usage of the vectored thrust forces to achieve aerial grasping by this robot. First, a vectored thrust control to avoid the aerointerference on the underwind segments (e.g., grasped object) during ﬂight is proposed. Then, an optimization-based planning method that utilizes redundant vectored thrust forces for ﬁrm grasping is developed. Finally, we demonstrate the feasibility of the proposed ﬂight control and grasp planning by performing challenging grasping and transporting motion with a spherical object of which the diameter is 0.6m. To the best of our knowledge, this work is the ﬁrst to achieve multi-ﬁnger-like grasping to carry a large object in midair.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat5_05">
             08:50-08:55, Paper WeAT5.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod802" name="modify1335" onclick="modify(1335,802)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1335'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hook-Based Aerial Payload Grasping from a Moving Platform
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#361032" title="Click to go to the Author Index">
             Antal, Peter
            </a>
           </td>
           <td class="r">
            Institute for Computer Science and Control (SZTAKI)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#360811" title="Click to go to the Author Index">
             Péni, Tamás
            </a>
           </td>
           <td class="r">
            SZTAKI Institute for Computer Science and Control
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#359465" title="Click to go to the Author Index">
             Toth, Roland
            </a>
           </td>
           <td class="r">
            Eindhoven University of Technology (TU/e)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1335" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning_under_uncertainty" title="Click to go to the Keyword Index">
               Planning under Uncertainty
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper investigates payload grasping from a moving platform using a hook-equipped aerial manipulator. First, a computationally efficient trajectory optimization based on complementarity constraints is proposed to determine the optimal grasping time. To enable application in complex, dynamically changing environments, the future motion of the payload is predicted using a physics simulator-based model. The success of payload grasping under model uncertainties and external disturbances is formally verified through a robustness analysis method based on integral quadratic constraints. The proposed algorithms are evaluated in a high-fidelity physical simulator, and in real flight experiments using a custom-designed aerial manipulator platform.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat5_06">
             08:55-09:00, Paper WeAT5.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod803" name="modify4870" onclick="modify(4870,803)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4870'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Human-Aware Physical Human-Robot Collaborative Transportation and Manipulation with Multiple Aerial Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#218133" title="Click to go to the Author Index">
             Li, Guanrui
            </a>
           </td>
           <td class="r">
            Worcester Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#331624" title="Click to go to the Author Index">
             Xinyang, Liu
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#142369" title="Click to go to the Author Index">
             Loianno, Giuseppe
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4870" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Human-robot interaction will play an essential role in various industries and daily tasks, enabling robots to effectively collaborate with humans and reduce their physical workload. This paper proposes a novel approach for physical human- robot collaborative transportation and manipulation of a cable- suspended payload with multiple aerial robots. The proposed method enables smooth and intuitive interaction between the transported objects and a human worker. In the same time, we consider distance constraints during the operations by exploiting the internal redundancy of the multi-robot transportation system. We validate the approach through extensive simulation and real-world experiments. These include scenarios where the robot team assists the human in transporting and manipulating a load, or where the human helps the robot team navigate the environment. We experimentally demonstrate for the first time, to the best of our knowledge, that our approach enables a quadrotor team to physically collaborate with a human in manipulating a payload in all 6 DoF in collaborative human- robot transportation and manipulation tasks.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat6">
             <b>
              WeAT6
             </b>
             Regular Session, 307
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod804" name="modifyWeAT6" onclick="modsession(621,804)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat6" title="Click to go to the Program at a Glance">
             <b>
              Vision-Based Navigation 1
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#107391" title="Click to go to the Author Index">
             Zhang, Fumin
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#106618" title="Click to go to the Author Index">
             Tzes, Anthony
            </a>
           </td>
           <td class="r">
            New York University Abu Dhabi
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat6_01">
             08:30-08:35, Paper WeAT6.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod805" name="modify472" onclick="modify(472,805)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('472'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              VLN-KHVR: Knowledge-And-History Aware Visual Representation for Continuous Vision-And-Language Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354037" title="Click to go to the Author Index">
             Kong, Ping
            </a>
           </td>
           <td class="r">
            Tianjin University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354136" title="Click to go to the Author Index">
             Liu, Ruonan
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420870" title="Click to go to the Author Index">
             Xie, Zongxia
            </a>
           </td>
           <td class="r">
            Tianjin University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421125" title="Click to go to the Author Index">
             Pang, Zhibo
            </a>
           </td>
           <td class="r">
            KTH Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab472" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Vision-and-Language Navigation in Continuous Environments (VLN-CE) requires agents to navigate with low-level actions following natural language instructions in 3D environments. Most existing approaches utilize observation features from the current step to represent the viewpoint. However, these representations often conflate redundant and essential information for navigation, introducing ambiguity into the agent's action prediction. To address the problem of inadequate representation, we propose a Knowledge-and-History Aware Visual Representation for Continuous Vision-and-Language Navigation (VLN-KHVR). The proposed approach constructs enriched visual representations tailored to navigation instructions, enhancing agents’ navigation performance. Specifically, VLN-KHVR extracts image features from the current observation, retrieves relevant knowledge in the knowledge base, and obtains the history of the navigation episode. Subsequently, the knowledge and history features are filtered to eliminate the information irrelevant to navigation instruction. These refined features are integrated with the instruction for further interaction. Finally, the aggregated features are used to guide navigation. Our model outperforms previous methods on the VLN-CE benchmark, demonstrating the effectiveness of the proposed method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat6_02">
             08:35-08:40, Paper WeAT6.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod806" name="modify497" onclick="modify(497,806)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('497'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LiteVLoc: Map-Lite Visual Localization for Image Goal Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#212673" title="Click to go to the Author Index">
             Jiao, Jianhao
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#222258" title="Click to go to the Author Index">
             He, Jinhao
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372341" title="Click to go to the Author Index">
             Liu, Changkun
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#396401" title="Click to go to the Author Index">
             Aegidius, Sebastian
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#294285" title="Click to go to the Author Index">
             Hu, Xiangcheng
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372650" title="Click to go to the Author Index">
             Braud, Tristan
            </a>
           </td>
           <td class="r">
            HKUST
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#147896" title="Click to go to the Author Index">
             Kanoulas, Dimitrios
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab497" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents LiteVLoc, a hierarchical vi-sual localization framework that uses a lightweight topo-metric map to represent the environment. The method consists of three sequential modules that estimate camera poses in a coarse-to-fine manner. Unlike dense 3D mapping methods, LiteVLoc reduces storage by avoiding geometric reconstruction. It uses a learning-based feature matcher to establish dense corre-spondences between sparse keyframes and observations, and then refines poses with a geometric solver, enabling robustness to viewpoint changes. The system assumes depth sensors or stereo camera for deployment. A novel dataset for the map-free relocalization task is also introduced. Extensive experiments including localization and navigation in both simulated and real-world scenarios have validate the system’s performance and demonstrated its precision and efficiency for large-scale de-ployment. Code and data will be made publicly available at the webpage: https://rpl-cs-ucl.github.io/LiteVLoc.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat6_03">
             08:40-08:45, Paper WeAT6.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod807" name="modify2196" onclick="modify(2196,807)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2196'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              BEINGS: Bayesian Embodied Image-Goal Navigation with Gaussian Splatting
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#386335" title="Click to go to the Author Index">
             Meng, Wugang
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#386896" title="Click to go to the Author Index">
             Wu, Tianfu
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#218647" title="Click to go to the Author Index">
             Yin, Huan
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107391" title="Click to go to the Author Index">
             Zhang, Fumin
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2196" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#search_and_rescue_robots" title="Click to go to the Keyword Index">
               Search and Rescue Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#probabilistic_inference" title="Click to go to the Keyword Index">
               Probabilistic Inference
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Image-goal navigation enables a robot to reach the location where a target image was captured, using visual cues for guidance. However, current methods either rely heavily on data and computationally expensive learning-based approaches or lack efficiency in complex environments due to insufficient exploration strategies. To address these limitations, we propose Bayesian Embodied Image-goal Navigation Using Gaussian Splatting, a novel method that formulates ImageNav as an optimal control problem within a model predictive control framework. BEINGS leverages 3D Gaussian Splatting as a scene prior to predict future observations, enabling efficient, real-time navigation decisions grounded in the robot’s sensory experiences. By integrating Bayesian updates, our method dynamically refines the robot's strategy without requiring extensive prior experience or data. Our algorithm is validated through extensive simulations and physical experiments, showcasing its potential for embodied robot systems in visually complex scenarios. Project Page: www.mwg.ink/BEINGS-web.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat6_04">
             08:45-08:50, Paper WeAT6.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod808" name="modify3193" onclick="modify(3193,808)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3193'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              FLAF: Focal Line and Feature-Constrained Active View Planning for Visual Teach and Repeat
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#318981" title="Click to go to the Author Index">
             Fu, Changfei
            </a>
           </td>
           <td class="r">
            SUSTech
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#199170" title="Click to go to the Author Index">
             Chen, Weinan
            </a>
           </td>
           <td class="r">
            Guangdong University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#191573" title="Click to go to the Author Index">
             Xu, Wenjun
            </a>
           </td>
           <td class="r">
            Peng Cheng Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100155" title="Click to go to the Author Index">
             Zhang, Hong
            </a>
           </td>
           <td class="r">
            SUSTech
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3193" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#view_planning_for_slam" title="Click to go to the Keyword Index">
               View Planning for SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents FLAF, a focal line and feature-constrained active view planning method for tracking failure avoidance in feature-based visual navigation of mobile robots. FLAF is built on a feature-based visual teach and repeat (VT&amp;R) framework, which supports robotic applications by teaching robots to cruise various paths that fulfill many daily autonomous navigation requirements. However, tracking failures in feature-based Visual Simultaneous Localization and Mapping (VSLAM), particularly in textureless regions common in human-made environments, poses a significant challenge to the real-world deployment of VT&amp;R. To address this problem, the proposed view planner is integrated into a feature-based VSLAM system, creating an active VT&amp;R solution that mitigates tracking failures. Our system features a Pan-Tilt Unit (PTU)-based active mounted on a mobile robot. Using FLAF, the active camera-based VSLAM (AC-SLAM) operates during the teaching phase to construct a complete path map and in the repeating phase to maintain stable localization. FLAF actively directs the camera toward more map points to avoid mapping failures during path learning and toward more feature-identifiable map points while following the learned trajectory. Experimental results in real scenarios show that FLAF significantly outperforms existing methods by accounting for feature identifiability, particularly the view angle of the features. While effectively dealing with low-texture regions in active view planning, considering feature identifiability enables our active VT&amp;R system to perform well in challenging environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat6_05">
             08:50-08:55, Paper WeAT6.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod809" name="modify4519" onclick="modify(4519,809)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4519'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Ground-Level Viewpoint Vision-And-Language Navigation in Continuous Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418797" title="Click to go to the Author Index">
             Li, Zerui
            </a>
           </td>
           <td class="r">
            Adelaide University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417478" title="Click to go to the Author Index">
             Zhou, Gengze
            </a>
           </td>
           <td class="r">
            University of Adelaide
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417479" title="Click to go to the Author Index">
             Hong, Haodong
            </a>
           </td>
           <td class="r">
            The University of Queensland
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#353442" title="Click to go to the Author Index">
             Shao, Yanyan
            </a>
           </td>
           <td class="r">
            Zhejiang University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417582" title="Click to go to the Author Index">
             Lyu, Wenqi
            </a>
           </td>
           <td class="r">
            The University of Adelaide
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#370117" title="Click to go to the Author Index">
             Qiao, Yanyuan
            </a>
           </td>
           <td class="r">
            The University of Adelaide
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#314849" title="Click to go to the Author Index">
             Wu, Qi
            </a>
           </td>
           <td class="r">
            University of Adelaide
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4519" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Vision-and-Language Navigation (VLN) empowers agents to associate time-sequenced visual observations with corresponding instructions to make sequential decisions. However, dealing with visually diverse scenes or transitioning from simulated environments to real-world deployment is still challenging. In this paper, we address the mismatch between human-centric instructions and quadruped robots with a low-height field of view, proposing a Ground-level Viewpoint Navigation (GVNav) approach to mitigate this issue. This work represents the first attempt to highlight the generalization gap in VLN across varying heights of visual observation in realistic robot deployments. Our approach leverages weighted historical observations as enriched spatiotemporal contexts for instruction following, effectively managing feature collisions within cells by assigning appropriate weights to identical features across different viewpoints. This enables low-height robots to overcome challenges such as visual obstructions and perceptual mismatches. Additionally, we transfer the connectivity graph from the HM3D and Gibson datasets as an extra resource to enhance spatial priors and a more comprehensive representation of real-world scenarios, leading to improved performance and generalizability of the waypoint predictor in real-world environments. Extensive experiments demonstrate that our Ground-level Viewpoint Navigation (GVnav) approach significantly improves performance in both simulated environments and real-world deployments with quadruped robots.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat6_06">
             08:55-09:00, Paper WeAT6.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod810" name="modify4890" onclick="modify(4890,810)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4890'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              NavTr: Object-Goal Navigation with Learnable Transformer Queries
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#297319" title="Click to go to the Author Index">
             Mao, Qiuyu
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#251631" title="Click to go to the Author Index">
             Jikai, Wang
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China, Department of Aut
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#273782" title="Click to go to the Author Index">
             Xu, Meng
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#116127" title="Click to go to the Author Index">
             Chen, Zonghai
            </a>
           </td>
           <td class="r">
            University of Sciences and Technology of China
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4890" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces Navigation Transformer (NavTr), a novel framework for object-goal navigation using Transformer queries to enhance the learning and representation of environment states. By integrating semantic information, object positions, and neighborhood information, NavTr creates a unified, comprehensive, and extensible state representation for the object-goal navigating task. In the framework, the Transformer queries implicitly learn inter-object relationships, which facilitates high-level understanding of the environment. Additionally, NavTr implements target-oriented supervisory signals, such as rotation rewards and spatial loss, which improve exploration efficiency in the reinforcement learning framework. NavTr outperforms popular graph-based and Attention-based methods by a large margin in terms of success rate (SR) and success weighted by path length (SPL). Extensive experiments on the AI2-THOR dataset demonstrate the effectiveness of our approach.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat7">
             <b>
              WeAT7
             </b>
             Regular Session, 309
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod811" name="modifyWeAT7" onclick="modsession(293,811)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat7" title="Click to go to the Program at a Glance">
             <b>
              Marine Robotics 3
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#102606" title="Click to go to the Author Index">
             Rekleitis, Ioannis
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#316673" title="Click to go to the Author Index">
             Drupt, Juliette
            </a>
           </td>
           <td class="r">
            University of Montpellier
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat7_01">
             08:30-08:35, Paper WeAT7.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod812" name="modify100" onclick="modify(100,812)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('100'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Shape BoW: Generalized Bag of Words for Appearance-Based Loop Closure Detection in Bathymetric SLAM
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#390150" title="Click to go to the Author Index">
             Zhang, Qianyi
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#162950" title="Click to go to the Author Index">
             Kim, Jinwhan
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab100" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Existing bathymetric simultaneous localization and mapping (SLAM) methods predominantly rely on odometry information for loop closure detection, which has a deteriorating performance when handling unreliable odometry data or conducting large-scale mapping missions. This letter introduces a novel generalized Bag of Words (BoW) named Shape BoW (S-BoW) for appearance-based loop closure detection in bathymetric SLAM. S-BoW is trained from the collection of the terrain gradient features extracted from existing bathymetric datasets and can be used in various bathymetric scenarios. We integrated the loop closure detection method using S-BoW into a feature-based bathymetric SLAM method called TTT SLAM, and we evaluated its performance against three existing bathymetric SLAM methods using two datasets. The results indicate that S-BoW not only serves as a generalized BoW but also enhances the efficiency of the integrated SLAM method, achieving accuracy comparable to the original TTT SLAM while offering a 37% speed improvement in a large-scale sea trial dataset. To the best of our knowledge, S-BoW is the first generalized BoW that can be used to realize effective appearance-based loop closure detection in bathymetric SLAM.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat7_02">
             08:35-08:40, Paper WeAT7.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod813" name="modify417" onclick="modify(417,813)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('417'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ODYSSEE: Oyster Detection Yielded by Sensor Systems on Edge Electronics
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#301815" title="Click to go to the Author Index">
             Lin, Xiaomin
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416923" title="Click to go to the Author Index">
             Mange, Vivek Dharmesh
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416946" title="Click to go to the Author Index">
             Suresh, Arjun
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416927" title="Click to go to the Author Index">
             Palnitkar, Aadi
            </a>
           </td>
           <td class="r">
            University of Maryland College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#255567" title="Click to go to the Author Index">
             Neuberger, Bernhard
            </a>
           </td>
           <td class="r">
            TU Wien
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416924" title="Click to go to the Author Index">
             Campbell, Brendan
            </a>
           </td>
           <td class="r">
            University of Delaware School of Marine Science and Policy
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#367284" title="Click to go to the Author Index">
             Williams, Alan
            </a>
           </td>
           <td class="r">
            University of Maryland Center for Environmental Science
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#269997" title="Click to go to the Author Index">
             Baxevani, Kleio
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416938" title="Click to go to the Author Index">
             Mallette, Jeremy
            </a>
           </td>
           <td class="r">
            Independent Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416925" title="Click to go to the Author Index">
             Vera Gonzalez, Alhim Adonai
            </a>
           </td>
           <td class="r">
            University of Cincinnati
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102411" title="Click to go to the Author Index">
             Vincze, Markus
            </a>
           </td>
           <td class="r">
            Vienna University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102606" title="Click to go to the Author Index">
             Rekleitis, Ioannis
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101649" title="Click to go to the Author Index">
             Tanner, Herbert G.
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#118557" title="Click to go to the Author Index">
             Aloimonos, Yiannis
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab417" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Oysters are an important keystone species in coastal ecosystems that provide several economic, environmental, and cultural benefits. Given the array of utilities derived from oysters, the application of autonomous robotic systems for oyster detection and monitoring grows increasingly relevant. However, current monitoring strategies for assessing oyster assemblages are mostly destructive. While manually identifying and monitoring oysters from video footage is nondestructive, is it tedious and requires expert input.
             <p>
              An alternative to human monitoring is deploying trained object detection models on edge devices, such as the Aqua2 robot, to enable real-time monitoring of oysters directly in the field. Yet training these models to maximum efficacy requires an extensive dataset that accurately represents the domain, and it is difficult to obtain such high-quality training data due to the complications inherent to underwater environments. To address these complications, we introduce a novel method leveraging stable diffusion to generate high-quality synthetic data for the marine domain. We exploit diffusion models to create photorealistic oyster imagery, using ControlNet inputs to ensure consistency with the segmentation ground-truth mask, the geometry of the scene, and the target domain of real oyster images. This large dataset is used to train a vision model, specifically based on YOLOv10. The trained model is then deployed and tested on an edge platform, the Aqua2, in an underwater robotics system. We achieve state-of-the-art (0.657 mAP@50) for oyster detection, which can pave the way for autonomous oyster habitat monitoring and increase the efficiency of on-bottom oyster aquaculture
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat7_03">
             08:40-08:45, Paper WeAT7.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod814" name="modify495" onclick="modify(495,814)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('495'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              IBURD: Image Blending for Underwater Robotic Detection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#226265" title="Click to go to the Author Index">
             Hong, Jungseok
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354480" title="Click to go to the Author Index">
             Singh, Sakshi
            </a>
           </td>
           <td class="r">
            University of Minnesota
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104325" title="Click to go to the Author Index">
             Sattar, Junaed
            </a>
           </td>
           <td class="r">
            University of Minnesota
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab495" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present an image blending pipeline, IBURD, that creates realistic synthetic images to assist in the training of deep detectors for use on underwater autonomous vehicles (AUVs) for marine debris detection tasks. Specifically, IBURD generates both images of underwater debris and their pixel-level annotations, using source images of debris objects, their annotations, and target background images of marine environments. With Poisson editing and style transfer techniques, IBURD is even able to robustly blend transparent objects into arbitrary backgrounds and automatically adjust the style of blended images using the blurriness metric of target background images. These generated images of marine debris in actual underwater backgrounds address the data scarcity and data variety problems faced by deep-learned vision algorithms in challenging underwater conditions, and can enable the use of AUVs for environmental cleanup missions. Both quantitative and robotic evaluations of IBURD demonstrate the efficacy of the proposed approach for robotic detection of marine debris.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat7_04">
             08:45-08:50, Paper WeAT7.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod815" name="modify1013" onclick="modify(1013,815)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1013'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              3DSSDF: Underwater 3D Sonar Reconstruction Using Signed Distance Functions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417708" title="Click to go to the Author Index">
             Archieri, Simon
            </a>
           </td>
           <td class="r">
            Heriot-Watt University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#316673" title="Click to go to the Author Index">
             Drupt, Juliette
            </a>
           </td>
           <td class="r">
            University of Montpellier
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418193" title="Click to go to the Author Index">
             Cinar, Ahmet Fatih
            </a>
           </td>
           <td class="r">
            Frontier Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#367715" title="Click to go to the Author Index">
             Grimaldi, Michele
            </a>
           </td>
           <td class="r">
            University of Girona
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#293055" title="Click to go to the Author Index">
             Carlucho, Ignacio
            </a>
           </td>
           <td class="r">
            University of Edinburgh
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#243216" title="Click to go to the Author Index">
             Scharff Willners, Jonatan
            </a>
           </td>
           <td class="r">
            Heriot-Watt University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#113794" title="Click to go to the Author Index">
             Petillot, Yvan R.
            </a>
           </td>
           <td class="r">
            Heriot-Watt University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1013" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Underwater autonomous robotic operations require online localization and 3D mapping. Because of the absence of absolute positioning underwater, these tasks strongly rely on embedded sensors, including proprioceptive or navigation sensors — which can be fused for an odometry, — and exteroceptive sensors. One of the most popular exteroceptive sensors for underwater is the imaging sonar, which emits a large fan-shaped acoustic signal and estimates the position of the surrounding obstacles from a measure of the reflected signal. This paper addresses underwater online localization and 3D mapping using a forward looking, wide-aperture imaging sonar and vehicle’s intrinsic navigation estimates. We introduce 3DSSDF (3D Sonar Reconstruction Using Signed Distance Functions), a new localization and 3D mapping algorithm based on signed distance functions, which is evaluated in simulation and on real data, in man-made and natural environments. Comparisons to reference trajectories and maps demonstrate that, in our tests, 3DSSDF efficiently corrects navigation drift and that trajectory and map accuracy is always below 1 m and below 1% of the distanced travelled, which can be sufficient for the safe inspection of natural or artificial underwater structures.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat7_05">
             08:50-08:55, Paper WeAT7.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod816" name="modify4464" onclick="modify(4464,816)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4464'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Cascade IPG Observer for Underwater Robot State Estimation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#294593" title="Click to go to the Author Index">
             Joshi, Kaustubh
            </a>
           </td>
           <td class="r">
            University of Maryland College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#325860" title="Click to go to the Author Index">
             Liu, Tianchen
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#112727" title="Click to go to the Author Index">
             Chopra, Nikhil
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4464" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a novel cascade nonlinear observer framework for inertial state estimation. It tackles the problem of intermediate state estimation when external localization is unavailable or in the event of a sensor outage. The proposed observer comprises two nonlinear observers based on a recently developed iteratively preconditioned gradient descent (IPG) algorithm. It takes the inputs via an IMU preintegration model where the first observer is a quaternion-based IPG. The output for the first observer is the input for the second observer, estimating the velocity and, consequently, the position. The proposed observer is validated on a public underwater dataset and a real-world experiment using our robot platform. The estimation is compared with an extended Kalman filter (EKF) and an invariant extended Kalman filter (InEKF). Results demonstrate that our method outperforms these methods regarding better positional accuracy and lower variance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat7_06">
             08:55-09:00, Paper WeAT7.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod817" name="modify4888" onclick="modify(4888,817)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4888'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ResiVis: A Holistic Underwater Motion Planning Approach for Robust Active Perception under Uncertainties
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#192519" title="Click to go to the Author Index">
             Xanthidis, Marios
            </a>
           </td>
           <td class="r">
            SINTEF Ocean
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378915" title="Click to go to the Author Index">
             Skaldebø, Martin
            </a>
           </td>
           <td class="r">
            SINTEF Ocean
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#384023" title="Click to go to the Author Index">
             Haugaløkken, Bent
            </a>
           </td>
           <td class="r">
            SINTEF Ocean
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#204300" title="Click to go to the Author Index">
             Evjemo, Linn Danielsen
            </a>
           </td>
           <td class="r">
            SINTEF Ocean AS
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#132933" title="Click to go to the Author Index">
             Alexis, Kostas
            </a>
           </td>
           <td class="r">
            NTNU - Norwegian University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#138305" title="Click to go to the Author Index">
             Kelasidi, Eleni
            </a>
           </td>
           <td class="r">
            NTNU
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4888" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning_under_uncertainty" title="Click to go to the Keyword Index">
               Planning under Uncertainty
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Motion planning for autonomous active perception in cluttered environments remains a challenging problem, requiring real-time solutions that both maximize safety and achieve a desired behavior. In dynamic underwater environments, such as in aquaculture operations, the robots are additionally expected to deal with state and motion uncertainty and errors, dynamic and deformable obstacles, currents, and disturbances. Previous work has introduced real-time frameworks that provided safe navigation in cluttered environments, active perception in static environments, and robust navigation in uncertain dynamic environments. This paper introduces a new real-time approach called ResiVis, which leverages the best aspects of the aforementioned techniques along with a new formulation that further enhances underwater autonomy by enabling active perception of static and dynamic target objects from desired distances. The proposed method utilizes path-optimization for real-time response with constraints guaranteeing continuous collision safety, and computes paths with clearance adaptive to both the conditions of the environments and the performance of the path follower. An improved new constraint encourages observations of dynamic objects with the planner adapting to satisfy desired observation distances and their projected future positions. ResiVis is validated with challenging simulation experiments and with hardware-in-the-loop trials in real industrial-scale aquaculture facilities.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat8">
             <b>
              WeAT8
             </b>
             Regular Session, 311
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod818" name="modifyWeAT8" onclick="modsession(433,818)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat8" title="Click to go to the Program at a Glance">
             <b>
              Planinng and Control for Legged Robots 1
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#171554" title="Click to go to the Author Index">
             Gan, Zhenyu
            </a>
           </td>
           <td class="r">
            Syracuse University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#128007" title="Click to go to the Author Index">
             Remy, C. David
            </a>
           </td>
           <td class="r">
            University of Stuttgart
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat8_01">
             08:30-08:35, Paper WeAT8.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod819" name="modify446" onclick="modify(446,819)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('446'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Energy-Optimal Asymmetrical Gait Selection for Quadrupedal Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354189" title="Click to go to the Author Index">
             Alqaham, Yasser G.
            </a>
           </td>
           <td class="r">
            Syracuse University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#216951" title="Click to go to the Author Index">
             Cheng, Jing
            </a>
           </td>
           <td class="r">
            Syracuse University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#171554" title="Click to go to the Author Index">
             Gan, Zhenyu
            </a>
           </td>
           <td class="r">
            Syracuse University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab446" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Symmetrical gaits, such as trotting, are com- monly employed in quadrupedal robots for their simplicity and stability. However, the potential of asymmetrical gaits, such as bounding and galloping—which are prevalent in their natural counterparts at high speeds or over long distances—is less clear in the design of locomotion controllers for legged machines. In these asymmetrical gaits, the system dynamics are more complex because the front and rear leg pairs exhibit different motions, which are coupled by the rotational motion of the torso. This study systematically examines five distinct asymmetrical quadrupedal gaits on a legged robot, aiming to uncover the fundamental differences in footfall sequences and the consequent energetics across a broad range of speeds. Utilizing a full-body model of a quadrupedal robot (Unitree A1), we developed a hybrid system for each gait, incorporating the desired footfall sequence and rigid impacts. To identify the most energy-optimal gait, we applied optimal control methods, framing it as a trajectory optimization problem with specific constraints and a work-based cost of transport as an objective function. Our results show that, in the context of asymmetrical gaits, when minimizing cost of transport across the entire stride, the front leg pair primarily propels the system forward, while the rear leg pair acts more like an inverted pendulum, contributing significantly less to the energetic output. Addi- tionally, while bounding—characterized by two aerial phases per cycle—is the most energy-optimal gait at higher speeds, the energy expenditure of gaits at speeds below 1 m/s depend heavily on the robot’s specific design.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat8_02">
             08:35-08:40, Paper WeAT8.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod820" name="modify2429" onclick="modify(2429,820)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2429'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Bipedal Walking with Continuously Compliant Robotic Legs
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335473" title="Click to go to the Author Index">
             Bendfeld, Robin
            </a>
           </td>
           <td class="r">
            University of Stuttgart
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#128007" title="Click to go to the Author Index">
             Remy, C. David
            </a>
           </td>
           <td class="r">
            University of Stuttgart
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2429" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#compliant_joints_and_mechanisms" title="Click to go to the Keyword Index">
               Compliant Joints and Mechanisms
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In biomechanics and robotics, elasticity plays a crucial role in enhancing locomotion efficiency and stability. Traditional approaches in legged robots often employ series elastic actuators (SEA) with discrete rigid components, which, while effective, add weight and complexity. This paper presents an innovative alternative by integrating continuously compliant structures into the lower legs of a bipedal robot, fundamentally transforming the SEA concept. Our approach replaces traditional rigid segments with lightweight, deformable materials, reducing overall mass and simplifying the actuation design. This novel design introduces unique challenges in modeling, sensing, and control, due to the infinite dimensionality of continuously compliant elements. We address these challenges through effective approximations and control strategies. The paper details the design and modeling of the compliant leg structure, presents low-level force and kinematics controllers, and introduces a high-level posture controller with a gait scheduler. Experimental results demonstrate successful bipedal walking using this new design.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat8_03">
             08:40-08:45, Paper WeAT8.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod821" name="modify2697" onclick="modify(2697,821)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2697'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Optimal Torque Distribution Via Dynamic Adaptation for Quadrupedal Locomotion on Slippery Terrains
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#290944" title="Click to go to the Author Index">
             Argiropoulos, Despina-Ekaterini
            </a>
           </td>
           <td class="r">
            (a) Institute of Computer Science Foundation for Research and T
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#325077" title="Click to go to the Author Index">
             Maravgakis, Michael
            </a>
           </td>
           <td class="r">
            Foundation for Research and Technology - Hellas (FORTH)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405279" title="Click to go to the Author Index">
             Tian, Changda
            </a>
           </td>
           <td class="r">
            FORTH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#180009" title="Click to go to the Author Index">
             Papageorgiou, Dimitrios
            </a>
           </td>
           <td class="r">
            Hellenic Mediterranean University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#116891" title="Click to go to the Author Index">
             Trahanias, Panos
            </a>
           </td>
           <td class="r">
            Foundation for Research and Technology – Hellas (FORTH)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2697" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_contact_whole_body_motion_planning_and_control" title="Click to go to the Keyword Index">
               Multi-Contact Whole-Body Motion Planning and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             As legged robots continue to evolve, new control methods are being developed to provide fast, robust, accurate and computationally efficient algorithms for traversing challenging environments. This paper presents a real-time adaptive locomotion controller for quadrupeds, designed to maintain stability and controllability on various surfaces, including highly slippery terrains. The proposed approach optimizes control effort distribution based on the probability of slippage by utilizing a surface-independent adaptation layer. By balancing the robot's redundant kinematic system through rank relaxation—similar to loosening constraints in optimization problems—this method demonstrates significant performance improvements. Unlike Reinforcement Learning (RL) approaches, which depend on pre-trained policies and may struggle to adapt velocity tracking control across different terrains, our method rapidly adjusts to changing conditions, as validated by extensive simulation experiments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat8_04">
             08:45-08:50, Paper WeAT8.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod822" name="modify2936" onclick="modify(2936,822)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2936'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Adaptive Energy Regularization for Autonomous Gait Transition and Energy-Efficient Quadruped Locomotion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309175" title="Click to go to the Author Index">
             Liang, Boyuan
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#254317" title="Click to go to the Author Index">
             Sun, Lingfeng
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#246683" title="Click to go to the Author Index">
             Zhu, Xinghao
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#242746" title="Click to go to the Author Index">
             Zhang, Bike
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#439479" title="Click to go to the Author Index">
             Xiong, Ziyin
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#358483" title="Click to go to the Author Index">
             Wang, Yixiao
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309158" title="Click to go to the Author Index">
             Li, Chenran
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#138299" title="Click to go to the Author Index">
             Sreenath, Koushil
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100071" title="Click to go to the Author Index">
             Tomizuka, Masayoshi
            </a>
           </td>
           <td class="r">
            University of California
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2936" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#natural_machine_motion" title="Click to go to the Keyword Index">
               Natural Machine Motion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In reinforcement learning for legged robot locomotion, crafting effective reward strategies is crucial. Predefined gait patterns and complex reward systems are widely used to stabilize policy training. Drawing from the natural locomotion behaviors of humans and animals, which adapt their gaits to minimize energy consumption, we investigate the impact of incorporating an energy-efficient reward term that prioritizes distance-averaged energy consumption into the reinforcement learning framework. Our findings demonstrate that this simple addition enables quadruped robots to autonomously select appropriate gaits—such as four-beat walking at lower speeds and trotting at higher speeds—without the need for explicit gait regularizations. Furthermore, we provide a guideline for tuning the weight of this energy-efficient reward, facilitating its application in real-world scenarios. The effectiveness of our approach is validated through simulations and on a real Unitree Go1 robot. This research highlights the potential of energy-centric reward functions to simplify and enhance the learning of adaptive and efficient locomotion in quadruped robots. Videos and more details are at https://sites.google.com/berkeley.edu/efficient-locomotion.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat8_05">
             08:50-08:55, Paper WeAT8.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod823" name="modify2990" onclick="modify(2990,823)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2990'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Music-Driven Legged Robots: Synchronized Walking to Rhythmic Beats
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335367" title="Click to go to the Author Index">
             Hou, Taixian
            </a>
           </td>
           <td class="r">
            FuDan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#392313" title="Click to go to the Author Index">
             Zhang, Yueqi
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#373615" title="Click to go to the Author Index">
             Wei, Xiaoyi
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267858" title="Click to go to the Author Index">
             Dong, Zhiyan
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405338" title="Click to go to the Author Index">
             Yi, Jiafu
            </a>
           </td>
           <td class="r">
            Hainan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267891" title="Click to go to the Author Index">
             Zhai, Peng
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267890" title="Click to go to the Author Index">
             ZHang, Lihua
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2990" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#biomimetics" title="Click to go to the Keyword Index">
               Biomimetics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We address the challenge of effectively controlling the locomotion of legged robots by incorporating precise frequency and phase characteristics, which is often ignored in locomotion policies that do not account for the periodic nature of walking. We propose a hierarchical architecture that integrates a low-level phase tracker, oscillators, and a high-level phase modulator. This controller allows quadruped robots to walk in a natural manner that is synchronized with external musical rhythms. Our method generates diverse gaits across different frequencies and achieves real-time synchronization with music in the physical world. This research establishes a foundational framework for enabling real-time execution of accurate rhythmic motions in legged robots. The video and code are available at https://music-walker.github.io/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat8_06">
             08:55-09:00, Paper WeAT8.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod824" name="modify3531" onclick="modify(3531,824)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3531'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Mobile-TeleVision: Predictive Motion Priors for Humanoid Whole-Body Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425512" title="Click to go to the Author Index">
             Lu, Chenhao
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#291333" title="Click to go to the Author Index">
             Cheng, Xuxin
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#316015" title="Click to go to the Author Index">
             Li, Jialong
            </a>
           </td>
           <td class="r">
            UCSD
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#367790" title="Click to go to the Author Index">
             Yang, Shiqi
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#386085" title="Click to go to the Author Index">
             Ji, Mazeyu
            </a>
           </td>
           <td class="r">
            UCSD
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378193" title="Click to go to the Author Index">
             Yuan, Chengjing
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354897" title="Click to go to the Author Index">
             Yang, Ge
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#238161" title="Click to go to the Author Index">
             Yi, Sha
            </a>
           </td>
           <td class="r">
            UC San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#280419" title="Click to go to the Author Index">
             Wang, Xiaolong
            </a>
           </td>
           <td class="r">
            UC San Diego
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3531" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#humanoid_robot_systems" title="Click to go to the Keyword Index">
               Humanoid Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensorimotor_learning" title="Click to go to the Keyword Index">
               Sensorimotor Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Humanoid robots require both robust lower-body locomotion and precise upper-body manipulation. While recent Reinforcement Learning (RL) approaches provide whole-body loco-manipulation policies, they lack precise manipulation with high DoF arms. In this paper, we propose decoupling upper-body control from locomotion, using inverse kinematics (IK) and motion retargeting for precise manipulation, while RL focuses on robust lower-body locomotion. We introduce PMP (Predictive Motion Priors), trained with Conditional Variational Autoencoder (CVAE) to effectively represent upper-body motions. The locomotion policy is trained and conditioned on this upper-body motion representation, ensuring that the system remains robust with both manipulation and locomotion. We show that CVAE features are crucial for stability and robustness, and significantly outperforms RL-based whole-body control in precise manipulation. With precise upper-body motion and robust lower-body locomotion control, operators can remotely control the humanoid to walk around and explore different environments, while performing diverse manipulation tasks.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat9">
             <b>
              WeAT9
             </b>
             Regular Session, 312
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod825" name="modifyWeAT9" onclick="modsession(355,825)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat9" title="Click to go to the Program at a Glance">
             <b>
              Multi-Robot Planning and Navigation
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#103595" title="Click to go to the Author Index">
             Nieto-Granda, Carlos
            </a>
           </td>
           <td class="r">
            DEVCOM U.S. Army Research Laboratory
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#148235" title="Click to go to the Author Index">
             Moore, Joseph
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat9_01">
             08:30-08:35, Paper WeAT9.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod826" name="modify29" onclick="modify(29,826)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('29'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Distributed Safe Navigation of Multi-Agent Systems Using Control Barrier Function-Based Controllers
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#389459" title="Click to go to the Author Index">
             Mestres, Pol
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103595" title="Click to go to the Author Index">
             Nieto-Granda, Carlos
            </a>
           </td>
           <td class="r">
            DEVCOM U.S. Army Research Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107125" title="Click to go to the Author Index">
             Cortes, Jorge
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab29" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes a distributed controller synthesis framework for safe navigation of multi-agent systems. We leverage control barrier functions to formulate collision avoidance with obstacles and teammates as constraints on the control input for a state-dependent network optimization problem that encodes team formation and the navigation task. Our algorithmic solution is valid under general assumptions for nonlinear dynamics and state-dependent network optimization problems with convex constraints and strongly convex objectives. The resulting controller is distributed, satisfies the safety constraints at all times, and asymptotically converges to the solution of the state-dependent network optimization problem. We illustrate its performance in a team of differential-drive robots in a variety of complex environments, both in simulation and in hardware.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat9_02">
             08:35-08:40, Paper WeAT9.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod827" name="modify658" onclick="modify(658,827)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('658'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hybrid Decision Making for Scalable Multi-Agent Navigation: Integrating Semantic Maps, Discrete Coordination, and Model Predictive Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#337560" title="Click to go to the Author Index">
             de Vos, Koen
            </a>
           </td>
           <td class="r">
            Eindhoven University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#282007" title="Click to go to the Author Index">
             Torta, Elena
            </a>
           </td>
           <td class="r">
            Eindhoven University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100187" title="Click to go to the Author Index">
             Bruyninckx, Herman
            </a>
           </td>
           <td class="r">
            KU Leuven
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#162025" title="Click to go to the Author Index">
             López Martínez, César Augusto
            </a>
           </td>
           <td class="r">
            Eindhoven University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#127625" title="Click to go to the Author Index">
             van de Molengraft, Marinus Jacobus Gerardus
            </a>
           </td>
           <td class="r">
            University of Technology Eindhoven
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab658" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#constrained_motion_planning" title="Click to go to the Keyword Index">
               Constrained Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a framework for multi-agent navigation in structured but dynamic environments, integrating three key components: a shared semantic map encoding metric and semantic environmental knowledge, a claim policy for coordinating access to areas within the environment, and a Model Predictive Controller for generating motion trajectories that respect environmental and coordination constraints. The main advantages of this approach include: (i) enforcing area occupancy constraints derived from specific task requirements; (ii) enhancing computational scalability by eliminating the need for collision avoidance constraints between robotic agents; and (iii) the ability to anticipate and avoid deadlocks between agents. The paper includes both simulations and physical experiments demonstrating the framework’s effectiveness in various representative scenarios
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat9_03">
             08:40-08:45, Paper WeAT9.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod828" name="modify1747" onclick="modify(1747,828)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1747'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Decentralized Nonlinear Model Predictive Control for Safe Collision Avoidance in Quadrotor Teams with Limited Detection Range
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#382693" title="Click to go to the Author Index">
             Goarin, Manohari
            </a>
           </td>
           <td class="r">
            New York University, Tandon School of Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#218133" title="Click to go to the Author Index">
             Li, Guanrui
            </a>
           </td>
           <td class="r">
            Worcester Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#320007" title="Click to go to the Author Index">
             Saviolo, Alessandro
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#142369" title="Click to go to the Author Index">
             Loianno, Giuseppe
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1747" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-quadrotor systems face significant challenges in decentralized control, particularly with safety and coordination under sensing and communication limitations. State-of-the-art methods leverage Control Barrier Functions (CBFs) to provide safety guarantees but often neglect actuation constraints and limited detection range. To address these gaps, we propose a novel decentralized Nonlinear Model Predictive Control (NMPC) that integrates Exponential CBFs (ECBFs) to enhance safety and optimality in multi-quadrotor systems. We provide both conservative and practical minimum bounds of the range that preserve the safety guarantees of the ECBFs. We validate our approach through extensive simulations with up to 10 quadrotors and 20 obstacles, as well as real-world experiments with 3 quadrotors. Results demonstrate the effectiveness of the proposed framework in realistic settings, highlighting its potential for reliable quadrotor teams operations.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat9_04">
             08:45-08:50, Paper WeAT9.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod829" name="modify2218" onclick="modify(2218,829)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2218'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SIGMA: Sheaf-Informed Geometric Multi-Agent Pathfinding
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#352672" title="Click to go to the Author Index">
             Liao, Shuhao
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417252" title="Click to go to the Author Index">
             Xia, Weihang
            </a>
           </td>
           <td class="r">
            Zijin Mining
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#305152" title="Click to go to the Author Index">
             Cao, Yuhong
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#293823" title="Click to go to the Author Index">
             Dai, Weiheng
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378195" title="Click to go to the Author Index">
             He, Chengyang
            </a>
           </td>
           <td class="r">
            National University Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#323461" title="Click to go to the Author Index">
             Wu, Wenjun
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#180884" title="Click to go to the Author Index">
             Sartoretti, Guillaume Adrien
            </a>
           </td>
           <td class="r">
            National University of Singapore (NUS)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2218" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The Multi-Agent Path Finding (MAPF) problem aims to determine the shortest and collision-free paths for multiple agents in a known, potentially obstacle-ridden environment. It is the core challenge for robotic deployments in large-scale logistics and transportation. Decentralized learning-based approaches have shown great potential for addressing the MAPF problems, offering more reactive and scalable solutions. However, existing learning-based MAPF methods usually rely on agents making decisions based on a limited field of view (FOV), resulting in short-sighted policies and inefficient cooperation in complex scenarios. There, a critical challenge is to achieve consensus on potential movements between agents based on limited observations and communications. To tackle this challenge, we introduce a new framework that applies sheaf theory to decentralized deep reinforcement learning, enabling agents to learn geometric cross-dependencies between each other through local consensus and utilize them for tightly cooperative decision-making. In particular, sheaf theory provides a mathematical proof of conditions for achieving global consensus through local observation. Inspired by this, we incorporate a neural network to approximately model the consensus in latent space based on sheaf theory and train it through self-supervised learning. During the task, in addition to normal features for MAPF as in previous works, each agent distributedly reasons about a learned consensus feature, leading to efficient cooperation on pathfinding and collision avoidance. As a result, our proposed method demonstrates significant improvements over state-of-the-art learning-based MAPF planners, especially in relatively large and complex scenarios, demonstrating its superiority over baselines in various simulations and real-world robot experiments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat9_05">
             08:50-08:55, Paper WeAT9.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod830" name="modify3055" onclick="modify(3055,830)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3055'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Efficient NSGA-II-Based Algorithm for Multi-Robot Coverage Path Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#403972" title="Click to go to the Author Index">
             Foster, Ashley
            </a>
           </td>
           <td class="r">
            University of Plymouth
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#283505" title="Click to go to the Author Index">
             Gianni, Mario
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#146592" title="Click to go to the Author Index">
             Aly, Amir
            </a>
           </td>
           <td class="r">
            University of Plymouth
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#314264" title="Click to go to the Author Index">
             Samani, Hooman
            </a>
           </td>
           <td class="r">
            University of the Arts London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3055" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work presents an algorithm based on the Nondominated Sorting Genetic Algorithm II (NSGA-II) to solve multi-objective offline Multi-Robot Coverage Path Planning (MCPP) problems. The proposed algorithm embeds a donation-mutation operator and a multiple-parent crossover that generates solutions which maintain the longest path while minimizing the average path length. The algorithm also uses a library of elitism-selected high-fitness robot paths, and tournament-selected high min-max fitness paths, to construct high multi-objective fitness offspring. We evaluate the performance of our proposed algorithm against the state-of-the-art NSGA-II extended with an improved Heuristic Genetic Algorithm Crossover, and we demonstrate that for different instances of the MCPP problem, the Pareto-fronts of our proposed algorithm are not dominated by any of the points of the fronts generated by the state-of-the-art NSGA-II. A comparison has also been performed in a virtual environment simulating five drones inspecting three wind turbines. Results show that our approach exhibits a higher convergence rate for higher values of the ratio between the number of points to visit and the number of drones.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat9_06">
             08:55-09:00, Paper WeAT9.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod831" name="modify3154" onclick="modify(3154,831)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3154'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Iterative Approach for Heterogeneous Multi-Agent Route Planning with Resource Transportation Uncertainty and Temporal Logic Goals
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#237209" title="Click to go to the Author Index">
             Cardona, Gustavo A.
            </a>
           </td>
           <td class="r">
            Lehigh University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#285303" title="Click to go to the Author Index">
             Liang, Kaier
            </a>
           </td>
           <td class="r">
            Lehigh University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#145765" title="Click to go to the Author Index">
             Vasile, Cristian Ioan
            </a>
           </td>
           <td class="r">
            Lehigh University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3154" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#formal_methods_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Formal Methods in Robotics and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents an iterative approach for heterogeneous multi-agent route planning in environments with unknown resource distributions. We focus on a team of robots with diverse capabilities tasked with executing missions specified using Capability Temporal Logic (CaTL), a formal framework built on Signal Temporal Logic to handle spatial, temporal, capability, and resource constraints. The key challenge arises from the uncertainty in the initial distribution and quantity of resources in the environment. To address this, we introduce an iterative algorithm that dynamically balances exploration and task fulfillment. Robots are guided to explore the environment, identifying resource locations and quantities while progressively refining their understanding of the resource landscape. At the same time, they aim to maximally satisfy the mission objectives based on the current information, adapting their strategies as new data is uncovered. This approach provides a robust solution for planning in dynamic, resource-constrained environments, enabling efficient coordination of heterogeneous teams even under conditions of uncertainty. Our method's effectiveness and performance are demonstrated through simulated case studies.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat10">
             <b>
              WeAT10
             </b>
             Regular Session, 313
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod832" name="modifyWeAT10" onclick="modsession(349,832)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat10" title="Click to go to the Program at a Glance">
             <b>
              Multi-Robot Path Planning 1
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#102362" title="Click to go to the Author Index">
             Akella, Srinivas
            </a>
           </td>
           <td class="r">
            University of North Carolina at Charlotte
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#378509" title="Click to go to the Author Index">
             Delgado, Carmen
            </a>
           </td>
           <td class="r">
            I2CAT Foundation
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat10_01">
             08:30-08:35, Paper WeAT10.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod833" name="modify7" onclick="modify(7,833)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('7'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Connectivity-Preserving Distributed Informative Path Planning for Mobile Robot Networks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#294797" title="Click to go to the Author Index">
             Nguyen, Thanh Binh
            </a>
           </td>
           <td class="r">
            TAMUCC
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#175427" title="Click to go to the Author Index">
             Nghiem, Truong Xuan
            </a>
           </td>
           <td class="r">
            University of Central Florida
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#172593" title="Click to go to the Author Index">
             Nguyen, Linh
            </a>
           </td>
           <td class="r">
            Federation University Australia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#119108" title="Click to go to the Author Index">
             La, Hung
            </a>
           </td>
           <td class="r">
            University of Nevada at Reno
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#254430" title="Click to go to the Author Index">
             Nguyen, Thang
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University-Corpus Christi
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab7" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This letter addresses the distributed informative path planning (IPP) problem for a mobile robot network to optimally explore a spatial field. Each robot is able to gather noisy environmental measurements while navigating the environment and build its own model of a spatial phenomenon using the Gaussian process and local data. The IPP optimization problem is formulated in an informative way through a multi-step prediction scheme constrained by connectivity preservation and collision avoidance. The shared hyperparameters of the local Gaussian process models are also arranged to be optimally computed in the path planning optimization problem. By the use of the proximal alternating direction method of multiplier, the optimization problem can be effectively solved in a distributed manner. It theoretically proves that the connectivity in the network is maintained over time whilst the solution of the optimization problem converges to a stationary point. The effectiveness of the proposed approach is verified in synthetic experiments by utilizing a real-world dataset.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat10_02">
             08:35-08:40, Paper WeAT10.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod834" name="modify42" onclick="modify(42,834)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('42'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Hierarchical Framework for Solving the Constrained Multiple Depot Traveling Salesman Problem
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#385049" title="Click to go to the Author Index">
             Yang, Ruixiao
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#217837" title="Click to go to the Author Index">
             Fan, Chuchu
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab42" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The Multiple Depot Traveling Salesman Problem (MDTSP) is a variant of the NP-hard Traveling Salesman Problem (TSP) with more than one salesman to jointly visit all destinations, commonly found in task planning in multi-agent robotic systems. Traditional MDTSP overlooks practical constraints like limited battery level and inter-agent conflicts, often leading to infeasible or unsafe solutions in reality. In this work, we incorporate energy and resource consumption constraints to form the Constrained MDTSP (CMDTSP). We design a novel hierarchical framework to obtain high-quality solutions with low computational complexity. The framework decomposes a given CMDTSP instance into manageable sub-problems, each handled individually via a TSP solver and heuristic search to generate tours. The tours are then aggregated and processed through a Mixed-Integer Linear Program (MILP), which contains significantly fewer variables and constraints than the MILP for the exact CMDTSP, to form a feasible solution efficiently. We demonstrate the performance of our framework on both real-world and synthetic datasets. It reaches a mean 12.48% optimality gap and 41.7x speedup over the exact method on common instances and a 5.22%sim14.84% solution quality increase with more than 79.8x speedup over the best baseline on large instances where the exact method times out.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat10_03">
             08:40-08:45, Paper WeAT10.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod835" name="modify870" onclick="modify(870,835)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('870'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Fully Differentiable Adaptive Informative Path Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#310637" title="Click to go to the Author Index">
             Jakkala, Kalvik
            </a>
           </td>
           <td class="r">
            University of North Carolina at Charlotte
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102362" title="Click to go to the Author Index">
             Akella, Srinivas
            </a>
           </td>
           <td class="r">
            University of North Carolina at Charlotte
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab870" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#environment_monitoring_and_management" title="Click to go to the Keyword Index">
               Environment Monitoring and Management
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous robots can survey and monitor large environments. However, these robots often have limited computational and power resources, making it crucial to develop an efficient and adaptive informative path planning (IPP) algorithm. Such an algorithm must quickly adapt to environmental data to maximize the information collected while accommodating path constraints, such as distance budgets and boundary limitations.
             <p>
              Current approaches to this problem often rely on maximizing mutual information using methods such as greedy algorithms, Bayesian optimization, and genetic algorithms. These methods can be slow and do not scale well to large or 3D environments. We present an adaptive IPP approach that is fully differentiable, significantly faster than previous methods, and scalable to 3D spaces. Our approach also supports continuous sensing robots, which collect data continuously along the entire path, by leveraging streaming sparse Gaussian processes.
              <p>
               Benchmark results on two real-world datasets demonstrate that our approach yields solutions that are on par with or better than baseline methods while being up to two orders of magnitude faster. Additionally, we showcase our adaptive IPP approach in a 3D space using a system-on-chip embedded computer with minimal computational resources. Our code is available in the SGP-Tools Python library with a companion ROS 2 package for deployment on ArduPilot-based robots.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat10_04">
             08:45-08:50, Paper WeAT10.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod836" name="modify1253" onclick="modify(1253,836)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1253'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Online Informative Motion Planning for Active Information Gathering of a Non-Stationary Gaussian Process
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420854" title="Click to go to the Author Index">
             Mao, Kexiang
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#247284" title="Click to go to the Author Index">
             He, Jianping
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#270301" title="Click to go to the Author Index">
             Duan, Xiaoming
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1253" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#environment_monitoring_and_management" title="Click to go to the Keyword Index">
               Environment Monitoring and Management
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reactive_and_sensor_based_planning" title="Click to go to the Keyword Index">
               Reactive and Sensor-Based Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Information gathering focuses on designing strategies for a robot to collect data about a physical process, aiming for accurate field reconstruction. While many recent methods have been proposed to address this problem, they often assume the model of the physical process is a priori known and stationary—assumptions that rarely hold in practice. This paper presents a novel informative motion planning approach for online information gathering of a non-stationary Gaussian process. Our approach comprises two key components: an informative path planner that explores the physical field and an adaptive velocity planner that adjusts the robot's velocity profile exploiting the field's spatial variability. Additionally, we propose a path smoothing and tracking strategy to ensure continuous robot motion. Extensive simulations on a bathymetric mapping task demonstrate the effectiveness of our approach, showing superior performance in reconstructing non-stationary physical fields compared to several baseline methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat10_05">
             08:50-08:55, Paper WeAT10.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod837" name="modify2457" onclick="modify(2457,837)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2457'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              REACT: Multi Robot Energy-Aware Orchestrator for Indoor Search and Rescue Critical Tasks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#353197" title="Click to go to the Author Index">
             Maresca, Fabio
            </a>
           </td>
           <td class="r">
            NEC Laboratories Europe GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378493" title="Click to go to the Author Index">
             Romero, Arnau
            </a>
           </td>
           <td class="r">
            I2CAT Foundation
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378509" title="Click to go to the Author Index">
             Delgado, Carmen
            </a>
           </td>
           <td class="r">
            I2CAT Foundation
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#353202" title="Click to go to the Author Index">
             Sciancalepore, Vincenzo
            </a>
           </td>
           <td class="r">
            NEC Laboratories Europe GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423806" title="Click to go to the Author Index">
             Paradells, Josep
            </a>
           </td>
           <td class="r">
            Universitat Politecnica De Catalunya
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#352917" title="Click to go to the Author Index">
             Costa-Perez, Xavier
            </a>
           </td>
           <td class="r">
            NEC Laboratories Europe
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2457" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#search_and_rescue_robots" title="Click to go to the Keyword Index">
               Search and Rescue Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robotics_in_under_resourced_settings" title="Click to go to the Keyword Index">
               Robotics in Under-Resourced Settings
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Smart factories enhance production efficiency and sustainability, but emergencies like human errors, machinery failures and natural disasters pose significant risks. In critical situations, such as fires or earthquakes, collaborative robots can assist first-responders by entering damaged buildings and locating missing persons, mitigating potential losses. Unlike previous solutions that overlook the critical aspect of energy management, in this paper we propose REACT, a smart energy-aware orchestrator that optimizes the exploration phase, ensuring prolonged operational time and effective area coverage. Our solution leverages a fleet of collaborative robots equipped with advanced sensors and communication capabilities to explore and navigate unknown indoor environments, such as smart factories affected by fires or earthquakes, with high density of obstacles. By leveraging real-time data exchange and cooperative algorithms, the robots dynamically adjust their paths, minimize redundant movements and reduce energy consumption. Extensive simulations confirm that our approach significantly improves the efficiency and reliability of search and rescue missions in complex indoor environments, improving the exploration rate by 10% over existing methods and reaching a map coverage of 97% under time critical operations, up to nearly 100% under relaxed time constraint.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat10_06">
             08:55-09:00, Paper WeAT10.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod838" name="modify2891" onclick="modify(2891,838)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2891'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Agent Ergodic Exploration under Smoke-Based Time-Varying Visibility Constraints
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#341882" title="Click to go to the Author Index">
             Wittemyer, Elena
            </a>
           </td>
           <td class="r">
            Yale University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335001" title="Click to go to the Author Index">
             Rao, Ananya
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203745" title="Click to go to the Author Index">
             Abraham, Ian
            </a>
           </td>
           <td class="r">
            Yale University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104011" title="Click to go to the Author Index">
             Choset, Howie
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2891" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we consider the problem of multi-agent informative path planning (IPP) for robots whose sensor visibility evolves over time as a consequence of a time-varying natural phenomenon. We leverage ergodic trajectory optimization (ETO), which generates paths such that the amount of time an agent spends in an area is proportional to the expected information in that area. We focus specifically on the problem of multi-agent drone search of a wildfire, where we use the time-varying environmental process of smoke diffusion to construct a sensor visibility model. This sensor visibility model is used to repeatedly calculate an expected information distribution (EID) to be used in the ETO algorithm. Our experiments show that our exploration method achieves improved information gathering over both baseline search methods and naive ergodic search formulations.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat11">
             <b>
              WeAT11
             </b>
             Regular Session, 314
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod839" name="modifyWeAT11" onclick="modsession(525,839)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat11" title="Click to go to the Program at a Glance">
             <b>
              Safe Control 1
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#170087" title="Click to go to the Author Index">
             Francis, Jonathan
            </a>
           </td>
           <td class="r">
            Bosch Center for Artificial Intelligence
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#192661" title="Click to go to the Author Index">
             Aksaray, Derya
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat11_01">
             08:30-08:35, Paper WeAT11.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod840" name="modify35" onclick="modify(35,840)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('35'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DiffTune-MPC: Closed-Loop Learning for Model Predictive Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#385361" title="Click to go to the Author Index">
             Tao, Ran
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#231782" title="Click to go to the Author Index">
             Cheng, Sheng
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#325400" title="Click to go to the Author Index">
             Wang, Xiaofeng
            </a>
           </td>
           <td class="r">
            University of South Carolina
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#193952" title="Click to go to the Author Index">
             Wang, Shenlong
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#151876" title="Click to go to the Author Index">
             Hovakimyan, Naira
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab35" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Model predictive control (MPC) has been applied to many platforms in robotics and autonomous systems for its capability to predict a system's future behavior while incorporating constraints that a system may have. To enhance the performance of a system with an MPC controller, one can manually tune the MPC's cost function. However, it can be challenging due to the possibly high dimension of the parameter space as well as the potential difference between the open-loop cost function in MPC and the overall closed-loop performance metric function. This paper presents DiffTune-MPC, a novel learning method, to learn the cost function of an MPC in a closed-loop manner. The proposed framework is compatible with the scenario where the time interval for performance evaluation and MPC's planning horizon have different lengths. We show the auxiliary problem whose solution admits the analytical gradients of MPC and discuss its variations in different MPC settings, including nonlinear MPCs that are solved using sequential quadratic programming. Simulation results demonstrate the learning capability of DiffTune-MPC and the generalization capability of the learned MPC parameters.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat11_02">
             08:35-08:40, Paper WeAT11.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod841" name="modify2445" onclick="modify(2445,841)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2445'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Combined Modal Robust Cascade Control for Wheeled Self-Reconfigurable Robots under Drive Failure and Safety Threat
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#285518" title="Click to go to the Author Index">
             Jiang, Tao
            </a>
           </td>
           <td class="r">
            Chongqing University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421154" title="Click to go to the Author Index">
             Wang, Jianxiang
            </a>
           </td>
           <td class="r">
            Chongqing University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395041" title="Click to go to the Author Index">
             Zheng, Zhi
            </a>
           </td>
           <td class="r">
            Chongqing University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424230" title="Click to go to the Author Index">
             Mo, Rongqin
            </a>
           </td>
           <td class="r">
            Chongqing University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#290801" title="Click to go to the Author Index">
             Sun, Yizhuo
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2445" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             轮式自重构机器人 （WSRRs） 是一种新型的多机器人系统，具有灵活的配置和任务适应性，在非结构化任务环境中具有广泛的应用前景。该文基于非完整约束和拉格朗日方法，建立了具有任意重配置尺度的 WSRR 的组合模态运动学和动力学。在运动学层面，基于非完整约束，设计了基于安全地理围栏的平滑避障策略来确保安全。在动态层面，引入自适应容错机制，保证合理的扭矩分配，避免跟踪性能下降。同时，该文阐述了一种改进的扩展状态观测器（IESO），通过该算法可以抑制测量噪声的高频振荡和初始观测器误差的峰值现象，实现了未知集总扰动下鲁棒的速度跟踪控制
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat11_03">
             08:40-08:45, Paper WeAT11.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod842" name="modify2628" onclick="modify(2628,842)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2628'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CaDRE: Controllable and Diverse Generation of Safety-Critical Driving Scenarios Using Real-World Trajectories
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#217730" title="Click to go to the Author Index">
             Huang, Peide
            </a>
           </td>
           <td class="r">
            Apple Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#215848" title="Click to go to the Author Index">
             Ding, Wenhao
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#340619" title="Click to go to the Author Index">
             Stoler, Benjamin
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#170087" title="Click to go to the Author Index">
             Francis, Jonathan
            </a>
           </td>
           <td class="r">
            Bosch Center for Artificial Intelligence
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#326217" title="Click to go to the Author Index">
             Chen, Bingqing
            </a>
           </td>
           <td class="r">
            Bosch Center for AI
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203949" title="Click to go to the Author Index">
             Zhao, Ding
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2628" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Simulation is an indispensable tool in the development and testing of autonomous vehicles (AVs), offering an efficient and safe alternative to road testing. An outstanding challenge with simulation-based testing is the generation of safety-critical scenarios, which are essential to ensure that AVs can handle rare but potentially fatal situations. This paper addresses this challenge by introducing a novel framework, CaDRE, to generate realistic, diverse, and controllable safety-critical scenarios. Our approach optimizes for both the quality and diversity of scenarios by employing a unique formulation and algorithm that integrates real-world scenarios, domain knowledge, and black-box optimization. We validate the effectiveness of our framework through extensive testing in three representative types of traffic scenarios. The results demonstrate superior performance in generating diverse and high-quality scenarios with greater sample efficiency than existing reinforcement learning (RL) and sampling-based methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat11_04">
             08:45-08:50, Paper WeAT11.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod843" name="modify2645" onclick="modify(2645,843)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2645'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Certificated Actor-Critic: Hierarchical Reinforcement Learning with Control Barrier Functions for Safe Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415398" title="Click to go to the Author Index">
             Xie, Junjun
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen, China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421140" title="Click to go to the Author Index">
             Zhao, Shuhao
            </a>
           </td>
           <td class="r">
            School of Mechanical Engineering and Automation Harbin Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#280111" title="Click to go to the Author Index">
             Hu, Liang
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#170269" title="Click to go to the Author Index">
             Gao, Huijun
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2645" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Control Barrier Functions (CBFs) have emerged as a prominent approach to designing safe navigation systems of robots. Despite their popularity, current CBF-based methods exhibit some limitations: optimization-based safe control techniques tend to be either myopic or computationally intensive, and they rely on simplified system models; conversely, the learning-based methods suffer from the lack of quantitative indication in terms of navigation performance and safety. In this paper, we present a new model-free reinforcement learning algorithm called Certificated Actor-Critic (CAC), which introduces a hierarchical reinforcement learning framework and well-defined reward functions derived from CBFs. We carry out theoretical analysis and proof of our algorithm, and propose several improvements in algorithm implementation. Our analysis is validated by two simulation experiments, showing the effectiveness of our proposed CAC algorithm.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat11_05">
             08:50-08:55, Paper WeAT11.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod844" name="modify2942" onclick="modify(2942,844)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2942'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Exact Imposition of Safety Boundary Conditions in Neural Reachable Tubes
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398465" title="Click to go to the Author Index">
             Singh, Aditya
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology, Patna
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309792" title="Click to go to the Author Index">
             Feng, Zeyuan
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#220606" title="Click to go to the Author Index">
             Bansal, Somil
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2942" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Hamilton-Jacobi (HJ) reachability analysis is a widely adopted verification tool to provide safety and performance guarantees for autonomous systems. However, it involves solving a partial differential equation (PDE) to compute a safety value function, whose computational and memory complexity scales exponentially with the state dimension, making its direct application to large-scale systems intractable. To overcome these challenges, DeepReach,a recently proposed learning-based approach, approximates high-dimensional reachable tubes using neural networks (NNs). While shown to be effective, the accuracy of the learned solution decreases with system complexity. One of the reasons for this degradation is a soft imposition of safety constraints during the learning process, which corresponds to the boundary conditions of the PDE, resulting in inaccurate value functions. In this work, we propose ExactBC, a variant of DeepReach that imposes safety constraints exactly during the learning process by restructuring the overall value function as a weighted sum of the boundary condition and the NN output. Moreover, the proposed variant no longer needs a boundary loss term during the training process, thus eliminating the need to balance different loss terms. We demonstrate the efficacy of the proposed approach in significantly improving the accuracy of the learned value function for four challenging reachability tasks: a rimless wheel system with state resets, collision avoidance in a cluttered environment, autonomous rocket landing, and multi-aircraft collision avoidance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat11_06">
             08:55-09:00, Paper WeAT11.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod845" name="modify3281" onclick="modify(3281,845)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3281'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RelAIBotiX: Reliability Assessment for AI-Controlled Robotic Systems
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#357721" title="Click to go to the Author Index">
             Grimmeisen, Philipp
            </a>
           </td>
           <td class="r">
            University of Stuttgart
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#357730" title="Click to go to the Author Index">
             Golwalkar, Rucha
            </a>
           </td>
           <td class="r">
            University of Lübeck
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397431" title="Click to go to the Author Index">
             Sautter, Friedrich
            </a>
           </td>
           <td class="r">
            IAS, Uni Stuttgart
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#357830" title="Click to go to the Author Index">
             Morozov, Andrey
            </a>
           </td>
           <td class="r">
            University of Stuttgart
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3281" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#probability_and_statistical_methods" title="Click to go to the Keyword Index">
               Probability and Statistical Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             AI-controlled robotic systems can introduce significant risks to both humans and the environment. Traditional reliability assessment methods fall short in addressing the complexities of these systems, particularly when dealing with black-box or dynamically changing control policies. The traditional approaches are applied manually and do not consider frequent software updates. In this paper, we present RelAIBotiX, a new methodology that enables dynamic and continuous reliability assessment, specifically tailored for robotic systems controlled by AI-Algorithms. RelAIBotiX is a dynamic reliability assessment framework that combines four methods: (i) Skill Detection that automatically identifies executed skills using deep learning techniques, (ii) Behavioral Analysis that creates an operational profile of the robotic system containing information about the skill execution sequence, active components for each skill, and their utilization intensity that influence their failure rate, (iii) Reliability Model Generation that automatically transforms the operational profile and reliability data of robotic hardware components into quantitative hybrid reliability models, and (iv) Reliability Model Solver for the numerical evaluation of the generated reliability models. Our evaluation included computing the reliability of the system, the probability of failure of individual skills, and component sensitivity analysis. We validated the applicability of the proposed framework in five simulative and real-world setups.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat12">
             <b>
              WeAT12
             </b>
             Regular Session, 315
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod846" name="modifyWeAT12" onclick="modsession(171,846)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat12" title="Click to go to the Program at a Glance">
             <b>
              Human-Robot Interaction 3
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#160571" title="Click to go to the Author Index">
             Fitter, Naomi T.
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#172670" title="Click to go to the Author Index">
             Yuan, Wenzhen
            </a>
           </td>
           <td class="r">
            University of Illinois
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat12_01">
             08:30-08:35, Paper WeAT12.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod847" name="modify640" onclick="modify(640,847)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('640'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Adaptive Emotional Expression in Social Robots: A Multimodal Approach to Dynamic Emotion Modeling
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#276443" title="Click to go to the Author Index">
             Park, Haeun
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#297831" title="Click to go to the Author Index">
             Lee, Jiyeon
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#116054" title="Click to go to the Author Index">
             Lee, Hui Sung
            </a>
           </td>
           <td class="r">
            UNIST (Ulsan National Institute of Science and Technology)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab640" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#emotional_robotics" title="Click to go to the Keyword Index">
               Emotional Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#gesture__posture_and_facial_expressions" title="Click to go to the Keyword Index">
               Gesture, Posture and Facial Expressions
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robot_companions" title="Click to go to the Keyword Index">
               Robot Companions
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Social robots have been extensively studied in recent decades, with many researchers exploring the use of modalities such as facial expressions to achieve more natural emotions in robots. Various methods have been attempted to generate and express robot emotions, including computational models that define an affect space and show dynamic emotion changes. However, the implementation of multimodal expression in previous models is ambiguous, and the generation of emotions in response to stimuli relies on heuristic methods. In this paper, we present a framework that enables robots to naturally express their emotions in a multimodal way, where the emotion can change over time based on the given stimulus values. By representing the robot’s emotion as a position in an affect space of a computational emotion model, we consider the given stimuli values as driving forces that can shift the emotion position dynamically. In order to examine the feasibility of our proposed method, a mobile robot prototype was implemented that can recognize touch and express different emotions with facial expressions and movements. The experiment demonstrated that the emotion elicited by a given stimulus is contingent upon the robot’s previous state, thereby imparting the impression that the robot possesses a distinctive emotion model. Furthermore, the Godspeed survey results indicated that our model was rated significantly higher than the baseline, which did not include a computational emotion model, in terms of anthropomorphism, animacy, and perceived intelligence. Notably, the unpredictabil ity of emotion switching contributed to a perception of greater lifelikeness, which in turn enhanced the overall interaction experience.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat12_02">
             08:35-08:40, Paper WeAT12.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod848" name="modify665" onclick="modify(665,848)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('665'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CAS: Fusing DNN Optimization &amp; Adaptive Sensing for Energy-Efficient Multi-Modal Inference
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#320709" title="Click to go to the Author Index">
             Weerakoon Mudiyanselage, Dulanga Kaveesha Weerakoon
            </a>
           </td>
           <td class="r">
            Singapore-MIT Alliance for Research &amp; Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#321848" title="Click to go to the Author Index">
             Subbaraju, Vigneshwaran
            </a>
           </td>
           <td class="r">
            Agency for Science Technology and Research (A*STAR)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#219082" title="Click to go to the Author Index">
             Lim, Joo Hwee
            </a>
           </td>
           <td class="r">
            I2R A*STAR
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#164087" title="Click to go to the Author Index">
             Misra, Archan
            </a>
           </td>
           <td class="r">
            Singapore Management University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab665" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_modal_perception_for_hri" title="Click to go to the Keyword Index">
               Multi-Modal Perception for HRI
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#embedded_systems_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Embedded Systems for Robotic and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Intelligent virtual agents are used to accomplish complex multi-modal tasks such as human instruction comprehension in mixed-reality environments by increasingly adopting richer, energy-intensive sensors and processing pipelines. In such applications, the context for activating sensors and processing blocks required to accomplish a given task instance is usually manifested via multiple sensing modes. Based on this observation, we introduce a novel Commit-and-Switch (CAS) paradigm that simultaneously seeks to reduce both sensing and processing energy. In CAS, we first commit to a low-energy computational pipeline with a subset of available sensors. Then, the task context estimated by this pipeline is used to optionally switch to another energy-intensive DNN pipeline and activate additional sensors. We demonstrate how CAS’s paradigm of interweaving DNN computation and sensor triggering can be instantiated principally by constructing multi-head DNN models and jointly optimizing the accuracy and sensing costs associated with different heads. We exemplify CAS via the development of the RealGIN-MH model for multi-modal target acquisition tasks, a core enabler of immersive human-agent interaction. RealGIN-MH achieves 12.9x reduction in energy overheads, while outperforming baseline dynamic model optimization approaches.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat12_03">
             08:40-08:45, Paper WeAT12.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod849" name="modify2914" onclick="modify(2914,849)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2914'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              "Oh! It's Fun Chatting with You!" a Humor-Aware Social Robot Chat Framework
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#271540" title="Click to go to the Author Index">
             Zhang, Heng
            </a>
           </td>
           <td class="r">
            ENSTA Paris, Institut Polytechnique De Paris
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#221311" title="Click to go to the Author Index">
             Saood, Adnan
            </a>
           </td>
           <td class="r">
            ENSTA Paris - Institute Polytechnique De Paris
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398029" title="Click to go to the Author Index">
             García Cárdenas, Juan José
            </a>
           </td>
           <td class="r">
            ENSTA - Institute Polytechinique De Paris
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#290413" title="Click to go to the Author Index">
             Hei, Xiaoxuan
            </a>
           </td>
           <td class="r">
            ENSTA Paris, Institut Polytechnique De Paris
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106757" title="Click to go to the Author Index">
             Tapus, Adriana
            </a>
           </td>
           <td class="r">
            ENSTA Paris, Institut Polytechnique De Paris
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2914" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Humor is a key element in human interactions, essential for building connections and rapport. To enhance human-robot communication, we developed a humor-aware chat framework that enables robots to deliver contextually appropriate humor. This framework takes into account the interaction environment, and user’s profile as well as emotional state. Two GPT models are used to generate responses. The initial one, named sensor-GPT, processes contextual data from the sensor along with the user’s response and conversation history to create prompts for the second one, chat-GPT. These prompts can guide the model on how to integrate appropriate humor elements into the conversation, ensuring that the dialogue is both contextually relevant and humorous. Our experiment compared the effectiveness of humor expression between our framework and the GPT-4o model. The results demonstrate that robots using our framework significantly outperform those using GPT-4o in humor expression, extending conversations, and improving overall interaction quality.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat12_04">
             08:45-08:50, Paper WeAT12.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod850" name="modify3945" onclick="modify(3945,850)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3945'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Social Gesture Recognition in SpHRI: Leveraging Fabric-Based Tactile Sensing on Humanoid Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425075" title="Click to go to the Author Index">
             Crowder, Dakarai
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425079" title="Click to go to the Author Index">
             Vandyck, Kojo Egyir
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#409996" title="Click to go to the Author Index">
             Sun, Xiping
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign Champaign, IL ‧ Pu
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#284892" title="Click to go to the Author Index">
             McCann, James
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#172670" title="Click to go to the Author Index">
             Yuan, Wenzhen
            </a>
           </td>
           <td class="r">
            University of Illinois
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3945" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#touch_in_hri" title="Click to go to the Keyword Index">
               Touch in HRI
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Humans are able to convey different messages using only touch. Equipping robots with the ability to understand social touch adds another modality in which humans and robots can communicate. In this paper, we present a social gesture recognition system using a fabric-based, large-scale tactile sensor integrated onto the arms of a humanoid robot. We built a social gesture dataset using multiple participants and extracted temporal features for classification. By collecting real-world data on a humanoid robot, our system provides valuable insights into human-robot social touch, further advancing the development of spHRI systems for more natural and effective communication.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat12_05">
             08:50-08:55, Paper WeAT12.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod851" name="modify4188" onclick="modify(4188,851)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4188'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Seeing Eye to Eye: Design and Evaluation of a Custom Expressive Eye Display Module for the Stretch Mobile Manipulator
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354514" title="Click to go to the Author Index">
             Morales Mayoral, Rafael
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#360097" title="Click to go to the Author Index">
             Buchmeier, Sean
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426112" title="Click to go to the Author Index">
             Mockel, Stayce
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426117" title="Click to go to the Author Index">
             Chavez, Courtney J.
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#160571" title="Click to go to the Author Index">
             Fitter, Naomi T.
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4188" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#gesture__posture_and_facial_expressions" title="Click to go to the Keyword Index">
               Gesture, Posture and Facial Expressions
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intention_recognition" title="Click to go to the Keyword Index">
               Intention Recognition
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Mobile manipulators - robots with a moving base and an arm for grasping objects - are becoming more common in human-populated environments, such as hospitals, warehouses, and even homes. Yet most mobile manipulators lack clear ways to communicate intent to human interlocutors in a continuous, socially acceptable, and easy-to-interpret way. One possible solution for improving mobile manipulator communication is the addition of expressive eyes. This paper presents the design and evaluation of a custom expressive LED eye module for mobile manipulators, which can display both gaze and emotional expressions. Our evaluation study (N = 32) involved a mock teamwork task alongside a Hello Robot Stretch RE2 mobile manipulator with the custom LED eye module. The results showed that both gaze and emotional expressions supported better participant performance in the task and more feelings of social closeness. Emotional eye expressions also yielded higher ratings of robot social warmth and competence. This work can inform mobile manipulator design for smoother integration into human-populated spaces.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat12_06">
             08:55-09:00, Paper WeAT12.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod852" name="modify4352" onclick="modify(4352,852)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4352'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              UGotMe: An Embodied System for Affective Human-Robot Interaction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426456" title="Click to go to the Author Index">
             Li, Peizhen
            </a>
           </td>
           <td class="r">
            Macquarie University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426454" title="Click to go to the Author Index">
             Cao, Longbing
            </a>
           </td>
           <td class="r">
            Macquarie University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#393048" title="Click to go to the Author Index">
             Wu, Xiao-Ming
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#330055" title="Click to go to the Author Index">
             Yu, Xiaohan
            </a>
           </td>
           <td class="r">
            Macquarie University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426570" title="Click to go to the Author Index">
             Runze, Yang
            </a>
           </td>
           <td class="r">
            Macquarie University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4352" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#gesture__posture_and_facial_expressions" title="Click to go to the Keyword Index">
               Gesture, Posture and Facial Expressions
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#emotional_robotics" title="Click to go to the Keyword Index">
               Emotional Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Equipping humanoid robots with the capability to understand emotional states of human interactants and express emotions appropriately according to situations is essential for affective human-robot interaction. However, enabling current vision-aware multimodal emotion recognition models for affective human-robot interaction in the real-world raises embodiment challenges: addressing the environmental noise issue and meeting real-time requirements. First, in multiparty conversation scenarios, the noises inherited in the visual observation of the robot, which may come from either 1)distracting objects in the scene or 2) inactive speakers appearing in the field of view of the robot, hinder the models from extracting emotional cues from vision inputs. Secondly, realtime response, a desired feature for an interactive system, is also challenging to achieve. To tackle both challenges, we introduce an affective human-robot interaction system called UGotMe designed specifically for multiparty conversations. Two denoising strategies are proposed and incorporated into the system to solve the first issue. Specifically, to filter out distracting objects in the scene, we propose extracting face images of the speakers from the raw images and introduce a customized active face extraction strategy to rule out inactive speakers. As for the second issue, we employ efficient data transmission from the robot to the local server to improve realtime response capability. We deploy UGotMe on a human robot named Ameca to validate its real-time inference capabilities in practical scenarios. Videos demonstrating real-world deployment are available at https://lipzh5.github.io/HumanoidVLE/
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat13">
             <b>
              WeAT13
             </b>
             Regular Session, 316
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod853" name="modifyWeAT13" onclick="modsession(549,853)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat13" title="Click to go to the Program at a Glance">
             <b>
              Soft Robotic Grasping 1
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#148019" title="Click to go to the Author Index">
             Ichnowski, Jeffrey
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#235693" title="Click to go to the Author Index">
             Stewart-Height, Abriana
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat13_01">
             08:30-08:35, Paper WeAT13.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod854" name="modify906" onclick="modify(906,854)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('906'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SCU-Hand: Soft Conical Universal Robotic Hand for Scooping Granular Media from Containers of Various Sizes
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#255961" title="Click to go to the Author Index">
             Takahashi, Tomoya
            </a>
           </td>
           <td class="r">
            OMRON SINIC X Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#165436" title="Click to go to the Author Index">
             Beltran-Hernandez, Cristian Camilo
            </a>
           </td>
           <td class="r">
            OMRON SINIC X Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#230819" title="Click to go to the Author Index">
             Kuroda, Yuki
            </a>
           </td>
           <td class="r">
            OMRON SINIC X Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#158337" title="Click to go to the Author Index">
             Tanaka, Kazutoshi
            </a>
           </td>
           <td class="r">
            OMRON SINIC X Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#178939" title="Click to go to the Author Index">
             Hamaya, Masashi
            </a>
           </td>
           <td class="r">
            OMRON SINIC X Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#169052" title="Click to go to the Author Index">
             Ushiku, Yoshitaka
            </a>
           </td>
           <td class="r">
            OMRON SINIC X Corpolation
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab906" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robotics_and_automation_in_life_sciences" title="Click to go to the Keyword Index">
               Robotics and Automation in Life Sciences
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Automating small-scale experiments in materials science presents challenges due to the heterogeneous nature of experimental setups. This study introduces the SCU-Hand (Soft Conical Universal Robot Hand), a novel end-effector designed to automate the task of scooping powdered samples from various container sizes using a robotic arm. The SCU-Hand employs a flexible, conical structure that adapts to different container geometries through deformation, maintaining consistent contact without complex force sensing or machine learning-based control methods. Its reconfigurable mechanism allows for size adjustment, enabling efficient scooping from diverse container types. By combining soft robotics principles with a sheet-morphing design, our end-effector achieves high flexibility while retaining the necessary rigidity for effective powder manipulation. We detail the design principles, fabrication process, and experimental validation of the SCU-Hand. Experimental validation showed that the scooping capacity is about 20% higher than that of a commercial tool, with a scooping performance of more than 95% for containers of sizes between 67 mm to 110 mm. This research contributes to laboratory automation by offering a cost-effective, easily implementable solution for automating tasks such as materials synthesis and characterization processes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat13_02">
             08:35-08:40, Paper WeAT13.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod855" name="modify1093" onclick="modify(1093,855)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1093'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              VSB - Variable Stiffness Based on Bowden Cables: A Simple Mechanism for Soft Robotic Hands
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#178758" title="Click to go to the Author Index">
             Puhlmann, Steffen
            </a>
           </td>
           <td class="r">
            TU Berlin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101628" title="Click to go to the Author Index">
             Albu-Schäffer, Alin
            </a>
           </td>
           <td class="r">
            DLR - German Aerospace Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#140759" title="Click to go to the Author Index">
             Höppner, Hannes
            </a>
           </td>
           <td class="r">
            Berliner Hochschule Für Technik, BHT
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1093" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#compliant_joints_and_mechanisms" title="Click to go to the Keyword Index">
               Compliant Joints and Mechanisms
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft robotic hands compensate for uncertainty in perception and actuation by leveraging passive deformation in their intrinsically compliant hardware, facilitating robust and dexterous interactions with their environment. The ability to adjust the level of compliance during operation has the potential to further improve the performance of these hands by enabling novel interaction strategies. However, achieving variable stiffness mechanically typically requires significant engineering complexity, making these systems difficult to manufacture, prone to error, and expensive. We present a novel, very simple mechanism for achieving variable stiffness. This mechanism employs tendon-driven antagonistic actuation, with Bowden cables connecting elastic elements to servomotors. It supports compact actuator designs, while the Bowden cables facilitate flexible component placement within a robotic system. Following our approach, variable stiffness actuators can be easily manufactured at low-cost from readily available materials. Despite its simplicity, we demonstrate that our mechanism provides consistent and precise control over stiffness levels and contact torques, showcasing its potential for a broad range of applications in soft robotic systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat13_03">
             08:40-08:45, Paper WeAT13.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod856" name="modify1963" onclick="modify(1963,856)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1963'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design and Experimental Validation of Woodwork-Inspired Soft Pneumatic Grippers
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#235693" title="Click to go to the Author Index">
             Stewart-Height, Abriana
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339264" title="Click to go to the Author Index">
             Bolli, Roberto
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#290372" title="Click to go to the Author Index">
             Kamienski, Emily
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100069" title="Click to go to the Author Index">
             Asada, Harry
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1963" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a novel design concept of a pair of soft gripper hands that can establish a secure connection between them for bearing a large load with a low air pressure. The design was inspired by dovetail joints in carpentry that enable a tight, strong connection between two pieces of wood. We propose to mimic the dovetail joint mechanism by using soft robotic fingers that interlace to each other for secure connection. The work was motivated by the need for securing a connection between two soft robotic arms for holding a balance-impaired older adult in case of losing balance. First, the design principle of dovetail-like secure soft finger connection is presented, and its potential application to a portable fall prevention system is described. Details of the dovetail soft finger design, its rapid inflation method, and other implementation issues are then discussed. Through experiments of a proof-of-concept prototype, it is validated that the dovetail soft fingers can bear at least 18 kg of load with only 52 kPa of air chamber pressure filled in 250 ms of charging time. At the end, the proposed method is compared to alternative methods using a Pugh chart.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat13_04">
             08:45-08:50, Paper WeAT13.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod857" name="modify2504" onclick="modify(2504,857)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2504'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Variable Stiffness and Transformable Entanglement Soft Robotic Gripper
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#385089" title="Click to go to the Author Index">
             Zhang, Huayu
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#224052" title="Click to go to the Author Index">
             Pan, Tianle Flippy
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#208757" title="Click to go to the Author Index">
             Zhou, Jianshu
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309175" title="Click to go to the Author Index">
             Liang, Boyuan
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#244048" title="Click to go to the Author Index">
             Shu, Jing
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#391422" title="Click to go to the Author Index">
             Zhu, Puchen
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#249450" title="Click to go to the Author Index">
             An, Jiajun
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100055" title="Click to go to the Author Index">
             Liu, Yunhui
            </a>
           </td>
           <td class="r">
            Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#234095" title="Click to go to the Author Index">
             Ma, Xin
            </a>
           </td>
           <td class="r">
            Chinese Univerisity of HongKong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2504" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             For objects with complex topological and geometrical features, stochastic topological grasping can be executed without the necessity for feedback or precise planning. However, this grasping method has two significant limitations. First, the technique’s effectiveness is reduced when interacting with topologically and geometrically simple objects like spheres, cubes, and cylinders, due to the inherent variability in grasping patterns. Additionally, the method’s low stiffness restricts its ability to securely handling heavier objects. To address these challenges, this paper proposes an entanglement soft robotic gripper with variable stiffness and two transformed grasping modes (entanglement and clamping modes). The gripper contains three filaments, which can enhance the stiffness through the mechanism of layer jamming. Furthermore, the entanglement mode and the clamping mode, can be transformed by adjusting the working length of the filaments. The grasping performance comparison with and without variable stiffness was carried out, and the results indicated that the implementation of variable stiffness led to a 149 % increase in payload weight. Through experimental validation, we successfully employed the gripper in variable stiffness and transformed modes to grasp items with various shapes and weights. Demonstration of grasping heavier objects and transforming between two grasping modes were also conducted to showcase the adaptability and versatility of the gripper.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat13_05">
             08:50-08:55, Paper WeAT13.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod858" name="modify3608" onclick="modify(3608,858)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3608'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Soft Robotic Dynamic In-Hand Pen Spinning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#375790" title="Click to go to the Author Index">
             Yao, Yunchao
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#218931" title="Click to go to the Author Index">
             Yoo, Uksang
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#179403" title="Click to go to the Author Index">
             Oh, Jean
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101843" title="Click to go to the Author Index">
             Atkeson, Christopher
            </a>
           </td>
           <td class="r">
            CMU
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#148019" title="Click to go to the Author Index">
             Ichnowski, Jeffrey
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3608" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#in_hand_manipulation" title="Click to go to the Keyword Index">
               In-Hand Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Dynamic in-hand manipulation remains a challenging task for soft robotic systems that have demonstrated advantages in safe compliant interactions but struggle with high-speed dynamic tasks. In this work, we present SoftSpin, a system for dynamic spinning using a soft and compliant robotic hand. Unlike previous works that rely on quasi-static actions and precise object models, the proposed system learns to spin a pen through trial-and-error using only real-world data without requiring explicit prior knowledge of the pen’s physical attributes. With self-labeled trials sampled from the real world, the system discovers the set of pen grasping and spinning primitive parameters that enables a soft hand to spin the pen robustly and reliably. After 130 sampled actions, SoftSpin achieves 100 % success rate across three pens with different weights and weight distributions, demonstrating the system’s generalizability and robustness to changes in object properties. The results highlight the potential for soft robotic end-effectors to perform dynamic tasks including rapid in-hand manipulation. We also demonstrate that SoftSpin generalizes to spinning tools with different shapes and weights such as a brush and a screwdriver which we spin with 10/10 and 5/10 success rates respectively. Videos, data, and code are available at https://soft-spin.github.io
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat13_06">
             08:55-09:00, Paper WeAT13.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod859" name="modify5063" onclick="modify(5063,859)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5063'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Kinetostatics and Retention Force Analysis of Soft Robot Grippers with External Tendon Routing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#272228" title="Click to go to the Author Index">
             Gunderman, Anthony
            </a>
           </td>
           <td class="r">
            University of Arkansas
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#307176" title="Click to go to the Author Index">
             Wang, Yifan
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#412785" title="Click to go to the Author Index">
             Gunderman, Benjamin
            </a>
           </td>
           <td class="r">
            University of Arkansas
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338268" title="Click to go to the Author Index">
             Qiu, Alex
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#310655" title="Click to go to the Author Index">
             Azizkhani, Milad
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#383965" title="Click to go to the Author Index">
             Sommer, Joseph
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#178841" title="Click to go to the Author Index">
             Chen, Yue
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5063" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft robots (SR) are a class of continuum robots that enable safe human interaction with task versatility beyond rigid robots. This has resulted in their rapid adoption in a number of applications that require manipulation of delicate and irregular objects. Despite their advantages, SR grippers typically require case-specific experimental characterization for shape and gripper retention force estimation. This letter presents a kinetostatic modeling approach based on strain energy minimization subject to mechanics and geometric constraints for shape estimation of SR grippers with external tendon routing (ETR), including those with composite structures. Additionally, Castigliano's First Theorem is used to estimate the retention force of the gripper. These models are evaluated across four different ETR SR grippers. The mechanics model predicted the fingertip position and orientation with an accuracy of 1.06±0.62 mm (1.79%±1.05% of length) and 3.58°±2.82° with respect to tendon force and 0.72±0.45 mm (1.22%±0.76% of length) and 2.86°±2.11° with respect to tendon retraction. The retention force of the gripper was predicted with an average error of 0.20±0.12 N.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat14">
             <b>
              WeAT14
             </b>
             Regular Session, 402
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod860" name="modifyWeAT14" onclick="modsession(601,860)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat14" title="Click to go to the Program at a Glance">
             <b>
              Teleoperation and Human-Robot Interaction
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#180653" title="Click to go to the Author Index">
             Charbonneau, Marie
            </a>
           </td>
           <td class="r">
            University of Calgary
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#106691" title="Click to go to the Author Index">
             Asama, Hajime
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat14_01">
             08:30-08:35, Paper WeAT14.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod861" name="modify364" onclick="modify(364,861)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('364'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Ego-A3: Adaptive Fusion-Based Disentangled Transformer for Egocentric Action Anticipation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#373977" title="Click to go to the Author Index">
             Kim, Min Hyuk
            </a>
           </td>
           <td class="r">
            Chonnam National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#369998" title="Click to go to the Author Index">
             Jung, JongWon
            </a>
           </td>
           <td class="r">
            CHONNAM University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416522" title="Click to go to the Author Index">
             Lee, Eungi
            </a>
           </td>
           <td class="r">
            Chonnam National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#361903" title="Click to go to the Author Index">
             Yoo, Seok Bong
            </a>
           </td>
           <td class="r">
            Chonnam National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab364" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#wearable_robotics" title="Click to go to the Keyword Index">
               Wearable Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recently, egocentric action anticipation for wearable robotics cameras has gained considerable attention due to its capability to analyze nouns and verbs from a first-person view. However, this field encounters challenges due to various uncertainties, such as action-irrelevant information and semantically fused representations of verbs and nouns. To overcome these issues, we introduce Ego-A3, designed to improve the robustness and reliability of egocentric action anticipation systems. Ego-A3 adaptively extracts action-relevant data to efficiently utilize additional information beyond visual data. Additionally, Ego-A3 produces effective disentangled representations for verbs and nouns by employing learnable verb and noun queries. Experiments on the EpicKitchens-100 and EGTEA Gaze+ datasets demonstrate that Ego-A3 outperforms existing methods in top-1 accuracy and mean top-5 recall. Our code is publicly available at https://github.com/alsgur0720/egocentric_anticipation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat14_02">
             08:35-08:40, Paper WeAT14.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod862" name="modify1380" onclick="modify(1380,862)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1380'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A New Variable-Gain Sliding Mode Filter and Its Application to Velocity Filtering
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#225730" title="Click to go to the Author Index">
             Aung, Myo Thant Sin
            </a>
           </td>
           <td class="r">
            Yangon Technological University, Myanmar
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102446" title="Click to go to the Author Index">
             Kikuuwe, Ryo
            </a>
           </td>
           <td class="r">
            Hiroshima University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#365899" title="Click to go to the Author Index">
             Paing, Soe Lin
            </a>
           </td>
           <td class="r">
            North Carolina State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#317226" title="Click to go to the Author Index">
             Yang, Jun
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107709" title="Click to go to the Author Index">
             Yu, Haoyong
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1380" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#haptics_and_haptic_interfaces" title="Click to go to the Keyword Index">
               Haptics and Haptic Interfaces
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes a new variable gain sliding mode filter augmented by variable windowing for achieving smooth and reactive response over a broad range of input frequencies. The proposed filter can be seen as a synergistic combination of Kikuuwe et al.’s [1] sliding mode filter with varying gain and sliding surfaces and a novel varying-length moving-window algorithm. In all schemes, the estimated input speed is employed for rendering the filter parameters between low and high settings. The discrete-time algorithm of the proposed filter does not suffer from chattering due to implicit (backward) Euler method. The effectiveness of the proposed filter in achieving better trade-off between noise attenuation and signal preservation is validated in both simulation and experimental scenarios by using the velocity signal obtained by differentiation of quantized position data.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat14_03">
             08:40-08:45, Paper WeAT14.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod863" name="modify1569" onclick="modify(1569,863)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1569'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Comparative Study between a Virtual Wand and a One-To-One Approach for the Teleoperation of a Nearby Robotic Manipulator
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#290960" title="Click to go to the Author Index">
             Poignant, Alexis
            </a>
           </td>
           <td class="r">
            Sorbonne Université, ISIR UMR 7222 CNRS
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104642" title="Click to go to the Author Index">
             Morel, Guillaume
            </a>
           </td>
           <td class="r">
            Sorbonne Université, CNRS, INSERM
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106021" title="Click to go to the Author Index">
             Jarrassé, Nathanael
            </a>
           </td>
           <td class="r">
            Sorbonne Université, ISIR UMR 7222 CNRS
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1569" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#physically_assistive_devices" title="Click to go to the Keyword Index">
               Physically Assistive Devices
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The prevailing and most effective approach to teleoperate a robotic arm involves a direct position-to-position mapping, imposing robotic end-effector movements that mirrors those of the user. However, due to this one-to-one mapping, the robot's motions are limited by the user's capability, particularly in translation. Drawing inspiration from head pointers utilized in the 1980s, originally designed to enable drawing with limited head motions for tetraplegic individuals, we proposed a "virtual wand" mapping which could be used by participants with reduced mobility. This mapping employs a virtual rigid linkage between the hand and the robot's end-effector. With this approach, rotations produce amplified translations through a lever arm, creating a "rotation-to-position" coupling and expanding the translation workspace at the expense of a reduced rotation space.
             <p>
              In this study, we compare the virtual wand approach to the one-to-one position mapping through the realization of 6-DoF reaching tasks. Results indicate that the two different mappings perform comparably well, are equally well-received by users, and exhibit similar motor control behaviors. Nevertheless, the virtual wand mapping is anticipated to outperform in tasks characterized by large translations and minimal effector rotations, whereas direct mapping is expected to demonstrate advantages in large rotations with minimal translations. These results pave the way for new interactions and interfaces, particularly in disability assistance utilizing residual body movements (instead of hands) as control input. Leveraging body parts with substantial rotations could enable the accomplishment of tasks previously deemed infeasible with standard direct coupling interfaces.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat14_04">
             08:45-08:50, Paper WeAT14.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod864" name="modify3265" onclick="modify(3265,864)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3265'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Novel Telelocomotion Framework with CoM Estimation for Scalable Locomotion on Humanoid Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424859" title="Click to go to the Author Index">
             He, An-Chi
            </a>
           </td>
           <td class="r">
            Virginia Tech
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#312874" title="Click to go to the Author Index">
             Li, Junheng
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425314" title="Click to go to the Author Index">
             Park, Jungsoo
            </a>
           </td>
           <td class="r">
            Virginia Tech
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#404732" title="Click to go to the Author Index">
             Kolt, Omar
            </a>
           </td>
           <td class="r">
            University Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#251393" title="Click to go to the Author Index">
             Beiter, Benjamin
            </a>
           </td>
           <td class="r">
            Virginia Polytechnic Institute and State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#136444" title="Click to go to the Author Index">
             Leonessa, Alexander
            </a>
           </td>
           <td class="r">
            Virginia Tech
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203386" title="Click to go to the Author Index">
             Nguyen, Quan
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#134267" title="Click to go to the Author Index">
             Akbari Hamed, Kaveh
            </a>
           </td>
           <td class="r">
            Virginia Tech
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3265" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#haptics_and_haptic_interfaces" title="Click to go to the Keyword Index">
               Haptics and Haptic Interfaces
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Teleoperated humanoid robot systems have made substantial advancements in recent years, offering a physical avatar that harnesses human skills and decision-making while safeguarding users from hazardous environments. However, current telelocomotion interfaces often fail to accurately represent the robot's environment, limiting the user’s ability to effectively navigate the robot through unstructured terrain. This paper presents an initial telelocomotion framework that integrates the ForceBot locomotion interface with the small-sized humanoid robot, HECTOR V2. The framework utilizes ForceBot to simulate walking motion and estimate the user’s Center of Mass (CoM) trajectory, which serves as a tracking reference for the robot. On the robot side, a model predictive control (MPC) approach, based on a reduced-order single rigid body model, is employed to track the user’s scaled trajectory. We present experimental results on ForceBot’s CoM estimation and the robot’s tracking performance, demonstrating the feasibility of this approach.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat14_05">
             08:50-08:55, Paper WeAT14.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod865" name="modify4233" onclick="modify(4233,865)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4233'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Stiffness Regulation Co-Pilot in Bilateral Teleimpedance Control: A Preliminary User Study
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423777" title="Click to go to the Author Index">
             Gomez Hernandez, Pedro
            </a>
           </td>
           <td class="r">
            Aarhus University Herning
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423789" title="Click to go to the Author Index">
             Jakobsen, Jonas Mariager
            </a>
           </td>
           <td class="r">
            SDU Robotics, the Maersk Mc-Kinney Moller Institute, University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#138065" title="Click to go to the Author Index">
             Pacchierotti, Claudio
            </a>
           </td>
           <td class="r">
            Centre National De La Recherche Scientifique (CNRS)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#132564" title="Click to go to the Author Index">
             Chinello, Francesco
            </a>
           </td>
           <td class="r">
            Aarhus University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#150140" title="Click to go to the Author Index">
             Fang, Cheng
            </a>
           </td>
           <td class="r">
            University of Southern Denmark
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4233" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#haptics_and_haptic_interfaces" title="Click to go to the Keyword Index">
               Haptics and Haptic Interfaces
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Variable stiffness of a remote robot is crucial for a teleoperation system to deal with challenging tasks. External stiffness command interfaces have emerged as a promising solution to regulating the remote robot stiffness because of the benefits of their accuracy, ergonomics, and avoidance of the "coupling effect" that usually exists in muscle activity-based stiffness interfaces. However, the use of an external stiffness command interface requires good coordination between two limbs of an operator, which take care of the teleoperation task and the stiffness regulation task, respectively, at the same time, which is demanding for novice operators in dynamic situations necessitating agile and timely stiffness adjustments. In this paper, a new concept of Stiffness Regulation Co-pilot was proposed to facilitate the use of these interfaces. A co-pilot is a virtual agent that consists of a Stiffness Regulation Policy, which infers a reasonable stiffness regulation action from the task performance, and a feedback modality, which conveys the suggested stiffness regulation action to the operator. A preliminary user study was conducted to evaluate the efficacy of the co-pilot and the effect of different modalities of the co-pilot. The results showed that the cutaneous feedback or combined with another modality can potentially improve the task performance of the system and reduce the cognitive load of the operator compared to a teleoperation system without using the co-pilot.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat14_06">
             08:55-09:00, Paper WeAT14.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod866" name="modify4780" onclick="modify(4780,866)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4780'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Adaptive Neural Network Synchronous Tracking Control for Teleoperation Robots under Event-Triggered Mechanism
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#176542" title="Click to go to the Author Index">
             Wang, Fujie
            </a>
           </td>
           <td class="r">
            Dongguan University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#404020" title="Click to go to the Author Index">
             Yu, Yuanjia
            </a>
           </td>
           <td class="r">
            Shenzhen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#361383" title="Click to go to the Author Index">
             Li, Xing
            </a>
           </td>
           <td class="r">
            School of Electrical Engineering &amp; Intelligentization, Dongguan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#404030" title="Click to go to the Author Index">
             Luo, Junxuan
            </a>
           </td>
           <td class="r">
            Dongguan University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#404031" title="Click to go to the Author Index">
             Zhong, Jinming
            </a>
           </td>
           <td class="r">
            Shenzhen University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4780" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes an adaptive neural network synchronous tracking control strategy that can be suitable for event-triggered mechanism in response to the modeling uncertainties and communication delays in bilateral teleoperation systems. Through introducing the event-triggered mechanism with the aim of reducing the network communication frequency in teleoperation system, the master and slave robots communicate with each other only when the triggering conditions are fulfilled, which enhances the efficiency of the network communication. This control strategy can guarantee the exponential convergence of the position synchronization tracking error of the master-slave robot end-effector. Moreover, the event-triggered conditions do not require any empirical design, but can be derived inversely with the aid of the Lyapunov stability theory. And the triggering time interval between two neighboring events is verified to be non-zero. It is demonstrated by utilizing the Lyapunov principle that the presented adaptive neural network control strategy ensures the final asymptotic convergence and exponential convergence of the position synchronization tracking error for master-slave robots under the designed event-triggered mechanisms. Eventually, the feasibility and effectiveness of the developed control strategy are validated by comparative cases.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat15">
             <b>
              WeAT15
             </b>
             Regular Session, 403
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod867" name="modifyWeAT15" onclick="modsession(83,867)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat15" title="Click to go to the Program at a Glance">
             <b>
              Bimanual Manipulation 1
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#267278" title="Click to go to the Author Index">
             Liu, Shuijing
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#137912" title="Click to go to the Author Index">
             Johns, Edward
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat15_01">
             08:30-08:35, Paper WeAT15.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod868" name="modify510" onclick="modify(510,868)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('510'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Visuotactile Skills with Two Multifingered Hands
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395586" title="Click to go to the Author Index">
             Lin, Toru
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395577" title="Click to go to the Author Index">
             Zhang, Yu
            </a>
           </td>
           <td class="r">
            University of California Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#204961" title="Click to go to the Author Index">
             Li, Qiyang
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#294264" title="Click to go to the Author Index">
             Qi, Haozhi
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#233716" title="Click to go to the Author Index">
             Yi, Brent
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#156706" title="Click to go to the Author Index">
             Levine, Sergey
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#205586" title="Click to go to the Author Index">
             Malik, Jitendra
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab510" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#bimanual_manipulation" title="Click to go to the Keyword Index">
               Bimanual Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Aiming to replicate human-like dexterity, perceptual experiences, and motion patterns, we explore learning from human demonstrations using a bimanual system with multifingered hands and visuotactile data. Two significant challenges exist: the lack of an affordable and accessible teleoperation system suitable for a dual-arm setup with multifingered hands, and the scarcity of multifingered hand hardware equipped with touch sensing. To tackle the first challenge, we develop HATO, a low-cost hands-arms teleoperation system that leverages off-the-shelf electronics, complemented with a software suite that enables efficient data collection; the comprehensive software suite also supports multimodal data processing, scalable policy learning, and smooth policy deployment. To tackle the latter challenge, we introduce a novel hardware adaptation by repurposing two prosthetic hands equipped with touch sensors for research. Using visuotactile data collected from our system, we learn skills to complete long-horizon, high-precision tasks which are difficult to achieve without multifingered dexterity and touch feedback. Furthermore, we empirically investigate the effects of dataset size, sensing modality, and visual input preprocessing on policy learning. Our results mark a promising step forward in bimanual multifingered manipulation from visuotactile data. Videos, code, and datasets can be found on: https://toruowo.github.io/hato
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat15_02">
             08:35-08:40, Paper WeAT15.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod869" name="modify1565" onclick="modify(1565,869)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1565'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Coordinated Bimanual Manipulation Policies Using State Diffusion and Inverse Dynamics Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267284" title="Click to go to the Author Index">
             Chen, Haonan
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417317" title="Click to go to the Author Index">
             Xu, Jiaming
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417278" title="Click to go to the Author Index">
             Sheng, Lily
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#280226" title="Click to go to the Author Index">
             Ji, Tianchen
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267278" title="Click to go to the Author Index">
             Liu, Shuijing
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#237816" title="Click to go to the Author Index">
             Li, Yunzhu
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#180408" title="Click to go to the Author Index">
             Driggs-Campbell, Katherine
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1565" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#bimanual_manipulation" title="Click to go to the Keyword Index">
               Bimanual Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             When performing tasks like laundry, humans naturally coordinate both hands to manipulate objects and anticipate how their actions will change the state of the clothes. However, achieving such coordination in robotics remains challenging due to the need to model object movement, predict future states, and generate precise bimanual actions. In this work, we address these challenges by infusing the predictive nature of human manipulation strategies into robot imitation learning. Specifically, we disentangle task-related state transitions from agent-specific inverse dynamics modeling to enable effective bimanual coordination. Using a demonstration dataset, we train a diffusion model to predict future states given historical observations, envisioning how the scene evolves. Then, we use an inverse dynamics model to compute robot actions that achieve the predicted states. Our key insight is that modeling object movement can help learning policies for bimanual coordination manipulation tasks. Evaluating our framework across diverse simulation and real-world manipulation setups, including multimodal goal configurations, bimanual manipulation, deformable objects, and multi-object setups, we find that it consistently outperforms state-of-the-art state-to-action mapping policies. Our method demonstrates a remarkable capacity to navigate multimodal goal configurations and action distributions, maintain stability across different control modes, and synthesize a broader range of behaviors than those present in the demonstration dataset.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat15_03">
             08:40-08:45, Paper WeAT15.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod870" name="modify1708" onclick="modify(1708,870)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1708'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              BiFold: Bimanual Cloth Folding with Language Guidance
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#381725" title="Click to go to the Author Index">
             Barbany, Oriol
            </a>
           </td>
           <td class="r">
            IRI (CSIC-UPC)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#154922" title="Click to go to the Author Index">
             Colomé, Adrià
            </a>
           </td>
           <td class="r">
            Institut De Robòtica I Informàtica Industrial (CSIC-UPC), Q28180
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104003" title="Click to go to the Author Index">
             Torras, Carme
            </a>
           </td>
           <td class="r">
            Csic - Upc
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1708" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Cloth folding is a complex task due to the inevitable self-occlusions of clothes, their complicated dynamics, and the disparate materials, geometries, and textures that garments can have. In this work, we learn folding actions conditioned on text commands. Translating high-level, abstract instructions into precise robotic actions requires sophisticated language understanding and manipulation capabilities. To do that, we leverage a pre-trained vision-language model and repurpose it to predict manipulation actions. Our model, BiFold, can take context into account and achieves stateof-the-art performance on an existing language-conditioned folding benchmark. To address the lack of annotated bimanual folding data, we introduce a novel dataset with automatically parsed actions and language-aligned instructions, enabling better learning of text-conditioned manipulation. BiFold attains the best performance on our dataset and demonstrates strong generalization to new instructions, garments, and environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat15_04">
             08:45-08:50, Paper WeAT15.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod871" name="modify3420" onclick="modify(3420,871)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3420'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              One-Shot Dual-Arm Imitation Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425045" title="Click to go to the Author Index">
             Wang, Yilong
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#137912" title="Click to go to the Author Index">
             Johns, Edward
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3420" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#dual_arm_manipulation" title="Click to go to the Keyword Index">
               Dual Arm Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_servoing" title="Click to go to the Keyword Index">
               Visual Servoing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce One-Shot Dual-Arm Imitation Learning (ODIL), which enables dual-arm robots to learn precise and coordinated everyday tasks from just a single demonstration of the task. ODIL uses a new three-stage visual servoing (3-VS) method for precise alignment between the end-effector and target object, after which replay of the demonstration trajectory is sufficient to perform the task. This is achieved without requiring prior task or object knowledge, or additional data collection and training following the single demonstration. Furthermore, we propose a new dual-arm coordination paradigm for learning dual-arm tasks from a single demonstration. ODIL was tested on a real-world dual-arm robot, demonstrating state-of-the-art performance across six precise and coordinated tasks in both 4-DoF and 6-DoF settings, and showing robustness in the presence of distractor objects and partial occlusions. Videos are available at https://www.robot-learning.uk/one-shot-dual-arm.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat15_05">
             08:50-08:55, Paper WeAT15.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod872" name="modify3650" onclick="modify(3650,872)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3650'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              In the Wild Ungraspable Object Picking with Bimanual Nonprehensile Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#233985" title="Click to go to the Author Index">
             Wu, Albert
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#160611" title="Click to go to the Author Index">
             Kruse, Daniel
            </a>
           </td>
           <td class="r">
            Rensselaer Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3650" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#dual_arm_manipulation" title="Click to go to the Keyword Index">
               Dual Arm Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Picking diverse objects in the real world is a fundamental robotics skill. However, many objects in such settings are bulky, heavy, or irregularly shaped, making them ungraspable by conventional end effectors like suction grippers and parallel jaw grippers (PJGs). In this paper, we expand the range of pickable items without hardware modifications using bimanual nonprehensile manipulation. We focus on a grocery shopping scenario, where a bimanual mobile manipulator equipped with a suction gripper and a PJG is tasked with re- trieving ungraspable items from tightly packed grocery shelves. From visual observations, our method first identifies optimal grasp points based on force closure and friction constraints. If the grasp points are occluded, a series of nonprehensile nudging motions are performed to clear the obstruction. A bimanual grasp utilizing contacts on the side of the end effectors is then executed to grasp the target item. In our replica grocery store, we achieved a 90% success rate over 102 trials in uncluttered scenes, and a 66% success rate over 45 trials in cluttered scenes. We also deployed our system to a real-world grocery store and successfully picked previously unseen items. Our results highlight the potential of bimanual nonprehensile manipulation for in-the-wild robotic picking tasks. A video summarizing this work can be found at
             <i>
              youtu.be/g0hOrDuK8jM
             </i>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat15_06">
             08:55-09:00, Paper WeAT15.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod873" name="modify4875" onclick="modify(4875,873)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4875'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Bimanual Grasp Synthesis for Dexterous Robot Hands
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#410070" title="Click to go to the Author Index">
             Shao, Yanming
            </a>
           </td>
           <td class="r">
            ShanghaiTech University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#253916" title="Click to go to the Author Index">
             Xiao, Chenxi
            </a>
           </td>
           <td class="r">
            ShanghaiTech University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4875" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#bimanual_manipulation" title="Click to go to the Keyword Index">
               Bimanual Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Humans naturally perform bimanual skills to handle large and heavy objects. To enhance a robot's object manipulation capabilities, generating effective bimanual grasp poses is essential. Nevertheless, bimanual grasp synthesis for dexterous hand manipulators remains underexplored. To bridge this gap, we propose the BimanGrasp algorithm for synthesizing bimanual grasps on 3D objects. The BimanGrasp algorithm generates grasp poses by optimizing an energy function that considers grasp stability and feasibility. Furthermore, the quality of the synthesized grasps is verified using the Isaac Gym physics simulation engine. These verified grasp poses form the BimanGrasp-Dataset, which is the first synthesized bimanual dexterous hand grasp pose dataset to our knowledge. The dataset comprises over 150k verified grasps on 900 objects, facilitating the synthesis of bimanual grasps through a data-driven approach. Last, we propose a diffusion model (BimanGrasp-DDPM) trained on the BimanGrasp-Dataset. This model achieved a grasp synthesis success rate of 69.87% and significant acceleration in computational speed compared to BimanGrasp algorithm.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat16">
             <b>
              WeAT16
             </b>
             Regular Session, 404
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod874" name="modifyWeAT16" onclick="modsession(145,874)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat16" title="Click to go to the Program at a Glance">
             <b>
              Grasping 1
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#169824" title="Click to go to the Author Index">
             Kasaei, Hamidreza
            </a>
           </td>
           <td class="r">
            University of Groningen
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#153073" title="Click to go to the Author Index">
             Thondiyath, Asokan
            </a>
           </td>
           <td class="r">
            IIT Madras
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat16_01">
             08:30-08:35, Paper WeAT16.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod875" name="modify458" onclick="modify(458,875)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('458'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Efficient 7-DoF Grasp for Target-Driven Object in Dense Cluttered Scenes
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417235" title="Click to go to the Author Index">
             Lei, Tianjiao
            </a>
           </td>
           <td class="r">
            Chongqing University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#290801" title="Click to go to the Author Index">
             Sun, Yizhuo
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417236" title="Click to go to the Author Index">
             Huang, Yi
            </a>
           </td>
           <td class="r">
            Chongqing University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#149631" title="Click to go to the Author Index">
             Huang, Jiangshuai
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#285518" title="Click to go to the Author Index">
             Jiang, Tao
            </a>
           </td>
           <td class="r">
            Chongqing University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab458" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#cyborgs" title="Click to go to the Keyword Index">
               Cyborgs
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Achieving a real-time precise grasp of a specified target object in densely cluttered environments is an essential capability for autonomous robot operation. Recently, considerable investigations on planar and spatial grasp have been carried out, and significant results have been obtained. However,these point cloud-based grasp prediction methods often fail to ensure that the generated grasp configurations meet the precise requirements of the task. Additionally, some of the existing grasp pipelines are too time-consuming to meet the demand for real-time robot response. In more challenging cluttered scenes,the quality of pose and gripper jaw opening estimation in highdimensional space requires further improvement. Therefore,this paper introduces a data- and model-independent and efficient method to generate 7-DoF grasp configurations for arbitrary target objects from single-view point cloud data in dense cluttered scenes. In addition, this paper proposes a grasp framework that generates the grasp configuration for the target object while reducing the time consumed during the grasp process, to enable robots to efficiently grasp target objects for designated tasks. The grasp pipeline focuses on guided regions via target detection and rapidly adjusts grasp configurations through multi-region point cloud distribution perception. Extensive real-world robot experiments have demonstrated the effectiveness of the proposed method in grasping target objects in cluttered scenes, achieving higher success rates and reduced runtime compared to baseline methods.The realized code and video are available at https://github.com/L-tj/7DGCG.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat16_02">
             08:35-08:40, Paper WeAT16.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod876" name="modify1645" onclick="modify(1645,876)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1645'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Task-Oriented 6-DoF Grasp Pose Detection in Clutters
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#394598" title="Click to go to the Author Index">
             Wang, An-Lan
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#390403" title="Click to go to the Author Index">
             Chen, Nuo
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398750" title="Click to go to the Author Index">
             Lin, Kun-Yu
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398843" title="Click to go to the Author Index">
             Yuan-Ming, Li
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#312220" title="Click to go to the Author Index">
             Zheng, Wei-Shi
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1645" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In general, humans would grasp an object differently for different tasks, e.g., ``grasping the handle of a knife to cut'' vs. ``grasping the blade to hand over''. In the field of robotic grasp pose detection research, some existing works consider this task-oriented grasping and made some progress, but they are generally constrained by low-DoF gripper type or non-cluttered setting, which is not applicable for human assistance in real life. With an aim to get more general and practical grasp models, in this paper, we investigate a new problem named Task-Oriented 6-DoF Grasp Pose Detection in Clutters (TO6DGC), which extends the task-oriented problem to a more general 6-DOF Grasp Pose Detection in Cluttered (multi-object) scenario. To this end, we construct a large-scale 6-DoF task-oriented grasping dataset, 6-DoF Task Grasp (6DTG), which features 4391 cluttered scenes with over 2 million 6-DoF grasp poses. Each grasp is annotated with a specific task, involving 6 tasks and 198 objects in total. Moreover, we propose One-Stage TaskGrasp (OSTG), a strong baseline to address the TO6DGC problem. Our OSTG adopts a task-oriented point selection strategy to detect where to grasp, and a task-oriented grasp generation module to decide how to grasp given a specific task. To evaluate the effectiveness of OSTG, extensive experiments are conducted on 6DTG. The results show that our method outperforms various baselines on multiple metrics. Real robot experiments also verify that our OSTG has a better perception of the task-oriented grasp points and 6-DoF grasp poses.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat16_03">
             08:40-08:45, Paper WeAT16.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod877" name="modify2185" onclick="modify(2185,877)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2185'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              QuickGrasp: Lightweight Antipodal Grasp Planning with Point Clouds
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423512" title="Click to go to the Author Index">
             Ravie, Navin Sriram
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology Madras
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423407" title="Click to go to the Author Index">
             Murugan, Keerthi Vasan
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology Madras
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#153073" title="Click to go to the Author Index">
             Thondiyath, Asokan
            </a>
           </td>
           <td class="r">
            IIT Madras
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#206818" title="Click to go to the Author Index">
             Sebastian, Bijo
            </a>
           </td>
           <td class="r">
            IIT Madras
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2185" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Grasping has been a long-standing challenge in facilitating the final interface between a robot and the environment. As environments and tasks become complicated, the need to embed higher intelligence to infer from the surroundings and act on them has become necessary. Although most methods utilize techniques to estimate grasp pose by treating the problem via pure sampling-based approaches in the six-degree-of-freedom space or as a learning problem, they usually fail in real-life settings owing to poor generalization across domains. In addition, the time taken to generate the grasp plan and the lack of repeatability, owing to sampling inefficiency and the probabilistic nature of existing grasp planning approaches, severely limits their application in real-world tasks. This paper presents a lightweight analytical approach towards robotic grasp planning, particularly antipodal grasps, with little to no sampling in the six-degree-of-freedom space. The proposed grasp planning algorithm is formulated as an optimization problem towards estimating grasp points on the object surface instead of directly estimating the end-effector pose. To this extent, a soft-region-growing algorithm is presented for effective plane segmentation, even in the case of curved surfaces. An optimization-based quality metric is then used for evaluation of grasp points to ensure indirect force closure. The proposed grasp framework is compared with existing state-of-the-art grasp planning approach Grasp pose detection (GPD) as baseline over multiple simulated objects. The effectiveness of the proposed approach in comparison to GPD is also evaluated in real-world setting using image and point-cloud data, with the planned grasps being executed using a ROBOTIQ gripper and UR5 manipulator. The proposed approach shows better performance in terms of higher probability for force closure with a complete repeatability.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat16_04">
             08:45-08:50, Paper WeAT16.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod878" name="modify2308" onclick="modify(2308,878)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2308'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Behavioral Manifolds: Representing the Landscape of Grasp Affordances in Relative Pose Space
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#269555" title="Click to go to the Author Index">
             Zechmair, Michael
            </a>
           </td>
           <td class="r">
            Maastricht University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#120357" title="Click to go to the Author Index">
             Morel, Yannick
            </a>
           </td>
           <td class="r">
            Maastricht University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2308" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The use of machine learning to investigate grasp affordances has received extensive attention over the past several decades. The existing literature provides a robust basis to build upon, though a number of aspects may be improved. Results commonly work in terms of grasp configuration, with little consideration for the manner in which the grasp may be (re-)produced, from a reachability and trajectory planning perspective. We propose a different perspective on grasp affordance learning, explicitly accounting for grasp synthesis; that is, the manner in which manipulator kinematics are used to allow materialization of grasps. The approach allows to explicitly map the grasp policy space in terms of generated grasp types and associated grasp quality. Results of application to a range of objects illustrate merit of the method and highlight the manner in which it may promote a greater degree of explainability for otherwise intransparent reinforcement processes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat16_05">
             08:50-08:55, Paper WeAT16.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod879" name="modify2335" onclick="modify(2335,879)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2335'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              NeRF-Based Transparent Object Grasping Enhanced by Shape Priors
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351342" title="Click to go to the Author Index">
             Han, Yi
            </a>
           </td>
           <td class="r">
            Shenzhen Technology University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351412" title="Click to go to the Author Index">
             Lin, Zixin
            </a>
           </td>
           <td class="r">
            Shenzhen Technology University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#369637" title="Click to go to the Author Index">
             Li, DongJie
            </a>
           </td>
           <td class="r">
            Shenzhen Technology University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423069" title="Click to go to the Author Index">
             Chen, Lvping
            </a>
           </td>
           <td class="r">
            Shenzhen Technology Universit
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338957" title="Click to go to the Author Index">
             Shi, Yongliang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#146324" title="Click to go to the Author Index">
             Ma, Gan
            </a>
           </td>
           <td class="r">
            Shenzhen Technology University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2335" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Transparent object grasping remains a persistent challenge in robotics, largely due to the difficulty of acquiring precise 3D information. Conventional optical 3D sensors struggle to capture transparent objects, and machine learning methods are often hindered by their reliance on high-quality datasets. Leveraging NeRF’s capability for continuous spatial opacity modeling, our proposed architecture integrates a NeRF-based approach for reconstructing the 3D information of transparent objects. Despite this, certain portions of the reconstructed 3D information may remain incomplete. To address these deficiencies, we introduce a shape-prior-driven completion mechanism, further refined by a geometric pose estimation method we have developed. This allows us to obtain a complete and reliable 3D information of transparent objects. Utilizing this refined data, we perform scene-level grasp prediction and deploy the results in real-world robotic systems. Experimental validation demonstrates the efficacy of our architecture, showcasing its capability to reliably capture 3D information of various transparent objects in cluttered scenes, and correspondingly, achieve high-quality, stable, and executable grasp predictions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat16_06">
             08:55-09:00, Paper WeAT16.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod880" name="modify4614" onclick="modify(4614,880)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4614'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Center Direction Network for Grasping Point Localization on Cloths
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309330" title="Click to go to the Author Index">
             Tabernik, Domen
            </a>
           </td>
           <td class="r">
            University of Ljubljana
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#246225" title="Click to go to the Author Index">
             Muhovič, Jon
            </a>
           </td>
           <td class="r">
            Faculty of Electrical Engineering, University of Ljubljana
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#392779" title="Click to go to the Author Index">
             Urbas, Matej
            </a>
           </td>
           <td class="r">
            University of Ljubljana, Faculty of Computer and Information Sci
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#118854" title="Click to go to the Author Index">
             Skocaj, Danijel
            </a>
           </td>
           <td class="r">
            University of Ljubljana
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4614" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Object grasping is a fundamental challenge in robotics and computer vision, critical for advancing robotic manipulation capabilities. Deformable objects, like fabrics and cloths, pose additional challenges due to their non-rigid nature. In this work, we introduce CeDiRNet-3DoF, a deep-learning model for grasp point detection, with a particular focus on cloth objects. CeDiRNet-3DoF employs center direction regression alongside a localization network, attaining first place in the perception task of ICRA 2023's Cloth Manipulation Challenge. Recognizing the lack of standardized benchmarks in the literature that hinder effective method comparison, we present the ViCoS Towel Dataset. This extensive benchmark dataset comprises 8,000 real and 12,000 synthetic images, serving as a robust resource for training and evaluating contemporary data-driven deep-learning approaches. Extensive evaluation revealed CeDiRNet-3DoF's robustness in real-world performance, outperforming state-of-the-art methods, including the latest transformer-based models. Our work bridges a crucial gap, offering a robust solution and benchmark for cloth grasping in computer vision and robotics.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat17">
             <b>
              WeAT17
             </b>
             Regular Session, 405
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod881" name="modifyWeAT17" onclick="modsession(257,881)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat17" title="Click to go to the Program at a Glance">
             <b>
              Localization 3
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#217084" title="Click to go to the Author Index">
             Joerger, Mathieu
            </a>
           </td>
           <td class="r">
            Virginia Tech
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#107192" title="Click to go to the Author Index">
             Halperin, Dan
            </a>
           </td>
           <td class="r">
            Tel Aviv University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat17_01">
             08:30-08:35, Paper WeAT17.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod882" name="modify51" onclick="modify(51,882)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('51'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              How Safe Is Particle Filtering-Based Localization for Mobile Robots? an Integrity Monitoring Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#237143" title="Click to go to the Author Index">
             Abdul Hafez, Osama
            </a>
           </td>
           <td class="r">
            American University of Madaba
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#217084" title="Click to go to the Author Index">
             Joerger, Mathieu
            </a>
           </td>
           <td class="r">
            Virginia Tech
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106228" title="Click to go to the Author Index">
             Spenko, Matthew
            </a>
           </td>
           <td class="r">
            Illinois Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab51" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#probability_and_statistical_methods" title="Click to go to the Keyword Index">
               Probability and Statistical Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Deriving safe bounds on particle filter estimate is a research problem that, if solved, could greatly benefit robots in life-critical applications, a field that is facing increasing interest as more robots are being deployed near humans. In response, this paper introduces a new fault detector and derives a performance measure for particle filter: integrity risk. Integrity risk is defined as the probability of having large estimate errors without triggering an alarm, all while considering measurement faults, unknown deterministic errors that cannot be modeled via normal white noise. In this work, the faults come in the form of incorrectly associated features when using the local nearest neighbors. Simulations and experiments assess the efficiency of the introduced safety metric. The results show that safety improves as map density increases as long as the number of particles is sufficient to shape the error distribution and the landmarks are well separated. Also, the results indicate that, when landmarks are poorly separated, particle filter is safer than Kalman filter, whereas, when landmarks are well separated, particle filter is often, but not always, safer than Kalman filter.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat17_02">
             08:35-08:40, Paper WeAT17.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod883" name="modify184" onclick="modify(184,883)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('184'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Lighthouse Localization of Miniature Wireless Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#312718" title="Click to go to the Author Index">
             Alvarado-Marin, Said
            </a>
           </td>
           <td class="r">
            INRIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#371874" title="Click to go to the Author Index">
             Huidobro-Marin, Cristobal
            </a>
           </td>
           <td class="r">
            INRIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#312721" title="Click to go to the Author Index">
             Balbi, Martina
            </a>
           </td>
           <td class="r">
            INRIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#312723" title="Click to go to the Author Index">
             Savic, Trifun
            </a>
           </td>
           <td class="r">
            INRIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#185863" title="Click to go to the Author Index">
             Watteyne, Thomas
            </a>
           </td>
           <td class="r">
            Inria
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#312717" title="Click to go to the Author Index">
             Maksimovic, Filip
            </a>
           </td>
           <td class="r">
            INRIA
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab184" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we apply lighthouse localization, originally designed for virtual reality motion tracking, to positioning and localization of indoor robots. We first present a lighthouse decoding and tracking algorithm on a low-power wireless microcontroller with hardware implemented in a cm-scale form factor. One-time scene solving is performed on a computer using a variety of standard computer vision tech-niques. Three different robotic localization scenarios are analyzed in this work. The first is a planar scene with a single lighthouse with a four-point pre-calibration. The second is a planar scene with two light-houses that self calibrates with either multiple robots in the experiment or a single robot in motion. The third extends to a 3D scene with two lighthouses and a self-calibration algorithm. The absolute accuracy, measured against a camera-based tracking system, was found to be 7.25 mm RMS for the 2D case and 11.2 mm RMS for the 3D case, respectively. This demonstrates the viability of lighthouse tracking both for small-scale robotics and as an inexpensive and compact alternative to camera-based setups.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat17_03">
             08:40-08:45, Paper WeAT17.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod884" name="modify791" onclick="modify(791,884)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('791'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              EVLoc: Event-Based Visual Localization in LiDAR Maps Via Event-Depth Registration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#375040" title="Click to go to the Author Index">
             Chen, Kuangyi
            </a>
           </td>
           <td class="r">
            Graz University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#269537" title="Click to go to the Author Index">
             Zhang, Jun
            </a>
           </td>
           <td class="r">
            Graz University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#109260" title="Click to go to the Author Index">
             Fraundorfer, Friedrich
            </a>
           </td>
           <td class="r">
            Graz University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab791" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Event cameras are bioinspired sensors with some notable features, including high dynamic range and low latency, which makes them exceptionally suitable for perception in challenging scenarios such as high-speed motion and extreme lighting conditions. In this paper, we explore their potential for localization within pre-existing LiDAR maps, a critical task for applications that require precise navigation and mobile manipulation. Our framework follows a paradigm based on the refinement of an initial pose. Specifically, we first project LiDAR points into 2D space based on a rough initial pose to obtain depth maps, and then employ an optical flow estimation network to align events with LiDAR points in 2D space, followed by camera pose estimation using a PnP solver. To enhance geometric consistency between these two inherently different modalities, we develop a novel frame-based event representation that improves structural clarity. Additionally, given the varying degrees of bias observed in the ground truth poses, we design a module that predicts an auxiliary variable as a regularization term to mitigate the impact of this bias on network convergence. Experimental results on several public datasets demonstrate the effectiveness of our proposed method. To facilitate future research, both the code and the pre-trained models are made available online.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat17_04">
             08:45-08:50, Paper WeAT17.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod885" name="modify1908" onclick="modify(1908,885)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1908'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MambaGlue: Fast and Robust Local Feature Matching with Mamba
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#386877" title="Click to go to the Author Index">
             Ryoo, Kihwan
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#227869" title="Click to go to the Author Index">
             Lim, Hyungtae
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104490" title="Click to go to the Author Index">
             Myung, Hyun
            </a>
           </td>
           <td class="r">
            KAIST (Korea Advanced Institute of Science and Technology)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1908" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In recent years, robust matching methods using deep learning-based approaches have been actively studied and improved in computer vision tasks. However, there remains a persistent demand for both robust and fast matching techniques. To address this, we propose a novel Mamba-based local feature matching approach, called MambaGlue, where Mamba is an emerging state-of-the-art architecture rapidly gaining recognition for its superior speed in both training and inference, and promising performance compared with Transformer architectures. In particular, we propose two modules: a) MambaAttention mixer to simultaneously and selectively understand the local and global context through the Mamba-based self-attention structure and b) deep confidence score regressor, which is a multi-layer perceptron (MLP)-based architecture that evaluates a score indicating how confidently matching predictions correspond to the ground-truth correspondences. Consequently, our MambaGlue achieves a balance between robustness and efficiency in real-world applications. As verified on various public datasets, we demonstrate that our MambaGlue yields a substantial performance improvement over baseline approaches while maintaining fast inference speed. Our code will be available on https://github.com/url-kaist/MambaGlue.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat17_05">
             08:50-08:55, Paper WeAT17.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod886" name="modify2573" onclick="modify(2573,886)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2573'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ULOC: Learning to Localize in Complex Large-Scale Environments with Ultra-Wideband Ranges
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#210732" title="Click to go to the Author Index">
             Nguyen, Thien-Minh
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#352827" title="Click to go to the Author Index">
             Yang, Yizhuo
            </a>
           </td>
           <td class="r">
            Nangyang Technological Univercity
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420932" title="Click to go to the Author Index">
             Nguyen, Tien-Dat
            </a>
           </td>
           <td class="r">
            Ho Chi Minh City University of Technology (HCMUT), VNU-HCM
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#185927" title="Click to go to the Author Index">
             Yuan, Shenghai
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#115410" title="Click to go to the Author Index">
             Xie, Lihua
            </a>
           </td>
           <td class="r">
            NanyangTechnological University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2573" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             While UWB-based methods can achieve high localization accuracy in small-scale areas, their accuracy and reliability are significantly challenged in large-scale environments. In this paper, we propose a learning-based framework for Ultra-Wideband (UWB) based localization in such complex large-scale environments, named ULOC. First, anchors are deployed in the environment without knowledge of their actual position. Then, UWB observations are collected when the vehicle travels in the environment. At the same time, map-consistent pose estimates are developed from registering (onboard self-localization) data with the prior map to provide the training labels. We then propose a recurrent neural network (RNN) based on MAMBA that learns the ranging patterns of UWBs over a complex large-scale environment. The experiment demonstrates that our solution can ensure high localization accuracy on a large scale compared to the state-of-the-art. We release our source code to benefit the community at https://github.com/brytsknguyen/uloc.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat17_06">
             08:55-09:00, Paper WeAT17.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod887" name="modify2622" onclick="modify(2622,887)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2622'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Indoor Localization of UAVs Using Only Few Measurements by Output-Sensitive Preimage Intersection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#340805" title="Click to go to the Author Index">
             Bilevich, Michael M.
            </a>
           </td>
           <td class="r">
            Tel Aviv University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#412846" title="Click to go to the Author Index">
             Buber, Tomer
            </a>
           </td>
           <td class="r">
            Tel Aviv University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107192" title="Click to go to the Author Index">
             Halperin, Dan
            </a>
           </td>
           <td class="r">
            Tel Aviv University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2622" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a deterministic approach for the localization of an Unmanned Aerial Vehicle (UAV) in a known indoor environment by using only a few downward distance measurements and the corresponding odometries between measurements. For each distance measurement and odometry, we look at the preimage of that distance measurement under the downwards distance function combined with the corresponding odometry where the motion between every two measurements has four degrees of freedom: three of translation and one of azimuth change. The intersection of these preimages yields the set of all possible locations for the UAV. In this work, we present an efficient method for approximating that intersection of preimages. We perform a spatial subdivision search, which splits only voxels containing that intersection. We present a novel technique, based on geometric insights, for correctly evaluating whether a voxel indeed contains a true localization. This technique is also robust under different kinds of errors that might occur. Our method is guaranteed to contain the ground truth location, and its runtime complexity is output sensitive, in the Hausdorff dimension and measure of the resulting intersection of preimages. We demonstrate the effectiveness of this method in various indoor scenarios, showing that it can be used to significantly decrease the uncertainty of localization when solving the kidnapped robot problem in simulation and on a physical drone. Our method can be performed in real-time. Furthermore, our method requires only a map of the environment, odometry and ToF sensors, which is advantageous in terms of cost, privacy and transmission bandwidth. Our open-source software and supplementary materials are available at https://github.com/TAU-CGL/uav-fdml-public.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat18">
             <b>
              WeAT18
             </b>
             Regular Session, 406
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod888" name="modifyWeAT18" onclick="modsession(561,888)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat18" title="Click to go to the Program at a Glance">
             <b>
              Software Tools 1
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#109688" title="Click to go to the Author Index">
             Kroeger, Torsten
            </a>
           </td>
           <td class="r">
            Intrinsic Innovation LLC
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#104237" title="Click to go to the Author Index">
             Moon, Hyungpil
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat18_01">
             08:30-08:35, Paper WeAT18.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod889" name="modify212" onclick="modify(212,889)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('212'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Motion Comparator: Visual Comparison of Robot Motions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#214972" title="Click to go to the Author Index">
             Wang, Yeping
            </a>
           </td>
           <td class="r">
            University of Wisconsin-Madison
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#385478" title="Click to go to the Author Index">
             Peseckis, Alexander
            </a>
           </td>
           <td class="r">
            University of Wisconsin -- Madison
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#385433" title="Click to go to the Author Index">
             Jiang, Zelong
            </a>
           </td>
           <td class="r">
            University of Wisconsin-Madison
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#178409" title="Click to go to the Author Index">
             Gleicher, Michael
            </a>
           </td>
           <td class="r">
            University of Wisconsin - Madison
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab212" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#software_tools_for_robot_programming" title="Click to go to the Keyword Index">
               Software Tools for Robot Programming
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#software_tools_for_benchmarking_and_reproducibility" title="Click to go to the Keyword Index">
               Software Tools for Benchmarking and Reproducibility
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Roboticists compare robot motions for tasks such as parameter tuning, troubleshooting, and deciding between possible motions. However, most existing visualization tools are designed for individual motions and lack the features necessary to facilitate robot motion comparison. In this paper, we follow a rigorous design process to create Motion Comparator, a web-based tool that facilitates the comprehension, comparison, and communication of robot motions. Our design process identified roboticists' needs, articulated design challenges, and provided corresponding strategies. Motion Comparator includes several key features such as multi-view coordination, quaternion visualization, time warping, and comparative designs. To demonstrate the applications of Motion Comparator, we discuss four case studies in which our tool is used for motion selection, troubleshooting, parameter tuning, and motion review.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat18_02">
             08:35-08:40, Paper WeAT18.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod890" name="modify626" onclick="modify(626,890)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('626'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Text2Robot: Evolutionary Robot Design from Text Descriptions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#215820" title="Click to go to the Author Index">
             Chen, Boyuan
            </a>
           </td>
           <td class="r">
            Duke University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418323" title="Click to go to the Author Index">
             Charlick, Zachary Samuel Charlick
            </a>
           </td>
           <td class="r">
            Duke University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418330" title="Click to go to the Author Index">
             Ringel, Ryan
            </a>
           </td>
           <td class="r">
            Duke University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418295" title="Click to go to the Author Index">
             Liu, Jiaxun
            </a>
           </td>
           <td class="r">
            Duke University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#278387" title="Click to go to the Author Index">
             Xia, Boxi
            </a>
           </td>
           <td class="r">
            Duke University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab626" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#methods_and_tools_for_robot_system_design" title="Click to go to the Keyword Index">
               Methods and Tools for Robot System Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#evolutionary_robotics" title="Click to go to the Keyword Index">
               Evolutionary Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robot design has traditionally been costly and labor-intensive. Despite advancements in automated processes, it remains challenging to navigate a vast design space while producing physically manufacturable robots. We introduce Text2Robot, a framework that converts user text specifications and performance preferences into physical quadrupedal robots. Within minutes, Text2Robot can use text-to-3D models to provide strong initializations of diverse morphologies. Within a day, our geometric processing algorithms and body-control co-optimization produce a walking robot by explicitly considering real-world electronics and manufacturability. Text2Robot enables rapid prototyping and opens new opportunities for robot design with generative models.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat18_03">
             08:40-08:45, Paper WeAT18.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod891" name="modify978" onclick="modify(978,891)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('978'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              QueryCAD: Grounded Question Answering for CAD Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#396314" title="Click to go to the Author Index">
             Kienle, Claudius
            </a>
           </td>
           <td class="r">
            ArtiMinds Robotics GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#284885" title="Click to go to the Author Index">
             Alt, Benjamin
            </a>
           </td>
           <td class="r">
            ArtiMinds Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#181134" title="Click to go to the Author Index">
             Katic, Darko
            </a>
           </td>
           <td class="r">
            HFT STUTTGART
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#132630" title="Click to go to the Author Index">
             Jäkel, Rainer
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104326" title="Click to go to the Author Index">
             Peters, Jan
            </a>
           </td>
           <td class="r">
            Technische Universität Darmstadt
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab978" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#engineering_for_robotic_systems" title="Click to go to the Keyword Index">
               Engineering for Robotic Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#software_tools_for_robot_programming" title="Click to go to the Keyword Index">
               Software Tools for Robot Programming
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             CAD models are widely used in industry and are essential for robotic automation processes. However, these models are rarely considered in novel AI-based approaches, such as the automatic synthesis of robot programs, as there are no readily available methods that would allow CAD models to be incorporated for the analysis, interpretation, or extraction of information. To address these limitations, we propose QueryCAD, the first system designed for CAD question answering, enabling the extraction of precise information from CAD models using natural language queries. QueryCAD incorporates SegCAD, an open-vocabulary instance segmentation model we developed to identify and select specific parts of the CAD model based on part descriptions. We further propose a CAD question answering benchmark to evaluate QueryCAD and establish a foundation for future research. Lastly, we integrate QueryCAD within an automatic robot program synthesis framework, validating its ability to enhance deep-learning solutions for robotics by enabling them to process CAD models.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat18_04">
             08:45-08:50, Paper WeAT18.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod892" name="modify2489" onclick="modify(2489,892)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2489'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              HeRo: A State Machine-Based, Fault-Tolerant Framework for Heterogeneous Multi-Robot Collaboration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419958" title="Click to go to the Author Index">
             Tang, Ruijie
            </a>
           </td>
           <td class="r">
            Institute of Software, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420091" title="Click to go to the Author Index">
             Wu, Guoquan
            </a>
           </td>
           <td class="r">
            Institute of Software, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420162" title="Click to go to the Author Index">
             Wang, Tao
            </a>
           </td>
           <td class="r">
            Institute of Software, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420174" title="Click to go to the Author Index">
             Chen, Wei
            </a>
           </td>
           <td class="r">
            Institute of Software, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420151" title="Click to go to the Author Index">
             Wei, Jun
            </a>
           </td>
           <td class="r">
            Institute of Software, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2489" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#software_tools_for_robot_programming" title="Click to go to the Keyword Index">
               Software Tools for Robot Programming
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#software__middleware_and_programming_environments" title="Click to go to the Keyword Index">
               Software, Middleware and Programming Environments
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Heterogeneous robots can work together to accomplish a variety of complex tasks and have shown great potential in many fields. There are many efforts to make robot task orchestration more efficient. However, current methods still have some limitations, including the lack of a high-level abstraction for programming method and fault handling mechanism. In this paper, we design a state machine-based, fault-tolerant framework for heterogeneous multi-robot collaboration named HeRo, to effectively support the development of heterogeneous multi-robot systems. HeRo has three key techniques: (1) a state machine-based programming language to flexibly model robot behaviors and tasks; (2) a state synchronization mechanism to achieve information exchange and maintain the consistency among heterogeneous robots in distributed environments; (3) a fault detection and recovery mechanism to monitor the system's runtime states and use Large Language Model (LLM) combined with Planning Domain Definition Language (PDDL) to enable automated recovery. We evaluate the effectiveness and fault recovery capability of the framework by setting up manufacturing task and fault scenarios with varying difficulty in the ARIAC simulation environment, achieving a 100% task completion rate, with low system overhead and flexible scalability.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat18_05">
             08:50-08:55, Paper WeAT18.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod893" name="modify2639" onclick="modify(2639,893)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2639'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Kinematics Optimization Framework with Improved Computational Efficiency for Task-Based Optimum Design of Serial Manipulators in Cluttered Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424331" title="Click to go to the Author Index">
             Petkov, Nikola
            </a>
           </td>
           <td class="r">
            United Kingdom Atomic Energy Authority
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#147599" title="Click to go to the Author Index">
             Tokatli, Ozan
            </a>
           </td>
           <td class="r">
            UKAEA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#361932" title="Click to go to the Author Index">
             Zhang, Kaiqiang
            </a>
           </td>
           <td class="r">
            UK Atomic Energy Authority
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#146645" title="Click to go to the Author Index">
             Wu, Huapeng
            </a>
           </td>
           <td class="r">
            Lappeenranta University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#222928" title="Click to go to the Author Index">
             Skilton, Robert Mark
            </a>
           </td>
           <td class="r">
            UK Atomic Energy Authority
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2639" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#methods_and_tools_for_robot_system_design" title="Click to go to the Keyword Index">
               Methods and Tools for Robot System Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#engineering_for_robotic_systems" title="Click to go to the Keyword Index">
               Engineering for Robotic Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             It is challenging to find optimum kinematic designs for non-standard robotic manipulators, e.g., medical, nuclear, and space manipulators, which are demanded to adapt to arbitrary complex tasks in constraints. Such design optimization can be modelled as a multi-dimensional non-convex optimization problem with nonlinear constrained conditions. However, it is non-trivial to ensure the essential reachability condition, i.e., the existence of continuous trajectories between demand positions for serial articulated manipulators, given complex spatial constraints, like obstacles and boundaries. Traditional solutions integrate standard motion planning or inverse kinematics algorithms within a kinematic-design optimization process, resulting in significant demand for time and computing resources. To accelerate design optimization at improved efficiency, we design a novel robust design framework built on a new kinematic design synthesis, which allows for simultaneously optimizing dimension and topology of a serial manipulator's kinematics for arbitrary tasks in constrained environments, using a generalised parametric kinematic model. Significantly, in contrast to standard solutions, we develop a novel computationally effective reachability verification method, which rapidly aborts infeasible motions by exploiting efficient collision checks, based on the Rapidly-exploring Random Tree (RRT) algorithm. The effectiveness of the proposed design framework is verified and evaluated by comparing to baseline benchmarks. Results demonstrate the novel design framework can accelerate kinematic design optimization by an order of magnitude compared to the current state-of-the-art, and optimise link dimension and joint type simultaneously of serial robots for cluttered environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat18_06">
             08:55-09:00, Paper WeAT18.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod894" name="modify4960" onclick="modify(4960,894)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4960'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Survey on Small-Scale Testbeds for Connected and Automated Vehicles and Robot Swarms
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#308378" title="Click to go to the Author Index">
             Mokhtarian, Armin
            </a>
           </td>
           <td class="r">
            RWTH Aachen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#410985" title="Click to go to the Author Index">
             Xu, Jianye
            </a>
           </td>
           <td class="r">
            Chair of Embedded Software (Informatik 11), RWTH Aachen Universi
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#333714" title="Click to go to the Author Index">
             Scheffe, Patrick
            </a>
           </td>
           <td class="r">
            RWTH Aachen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#384388" title="Click to go to the Author Index">
             Kloock, Maximilian
            </a>
           </td>
           <td class="r">
            RWTH Aachen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#384445" title="Click to go to the Author Index">
             Schäfer, Simon
            </a>
           </td>
           <td class="r">
            RWTH Aachen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#253072" title="Click to go to the Author Index">
             Bang, Heeseung
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#317406" title="Click to go to the Author Index">
             Le, Viet-Anh
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#361453" title="Click to go to the Author Index">
             Ulhas, Sangeet
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#268360" title="Click to go to the Author Index">
             Betz, Johannes
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#190455" title="Click to go to the Author Index">
             Wilson, Sean
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology, Georgia Tech Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102710" title="Click to go to the Author Index">
             Berman, Spring
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#136946" title="Click to go to the Author Index">
             Paull, Liam
            </a>
           </td>
           <td class="r">
            Université De Montréal
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#124025" title="Click to go to the Author Index">
             Prorok, Amanda
            </a>
           </td>
           <td class="r">
            University of Cambridge
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#287282" title="Click to go to the Author Index">
             Alrifaee, Bassam
            </a>
           </td>
           <td class="r">
            University of the Bundeswehr Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4960" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#embedded_systems_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Embedded Systems for Robotic and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#engineering_for_robotic_systems" title="Click to go to the Keyword Index">
               Engineering for Robotic Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#methods_and_tools_for_robot_system_design" title="Click to go to the Keyword Index">
               Methods and Tools for Robot System Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Connected and automated vehicles and robot swarms hold transformative potential for enhancing safety, efficiency, and sustainability in the transportation and manufacturing sectors. Extensive testing and validation of these technologies is crucial for their deployment in the real world. While simulations are essential for initial testing, they often have limitations in capturing the complex dynamics of real-world interactions. This limitation underscores the importance of small-scale testbeds. These testbeds provide a realistic, cost-effective, and controlled environment for testing and validating algorithms, acting as an essential intermediary between simulation and full-scale experiments. This work serves to facilitate researchers' efforts in identifying existing small-scale testbeds suitable for their experiments and provide insights for those who want to build their own. In addition, it delivers a comprehensive survey of the current landscape of these testbeds. We derive 62 characteristics of testbeds based on the well-known sense-plan-act paradigm and offer an online table comparing 23 small-scale testbeds based on these characteristics. The online table is hosted on our designated public webpage https://bassamlab.github.io/testbeds-survey, and we invite testbed creators and developers to contribute to it. We closely examine nine testbeds in this paper, demonstrating how the derived characteristics can be used to present testbeds. Furthermore, we discuss three ongoing ch
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat19">
             <b>
              WeAT19
             </b>
             Regular Session, 407
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod895" name="modifyWeAT19" onclick="modsession(587,895)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat19" title="Click to go to the Program at a Glance">
             <b>
              Tactile Sensing 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#134555" title="Click to go to the Author Index">
             Spiers, Adam
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#162864" title="Click to go to the Author Index">
             Kaboli, Mohsen
            </a>
           </td>
           <td class="r">
            Eindhoven University of Technology ( TU/e) &amp; BMW Group Research
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat19_01">
             08:30-08:35, Paper WeAT19.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod896" name="modify692" onclick="modify(692,896)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('692'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ACROSS: A Deformation-Based Cross-Modal Representation for Robotic Tactile Perception
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#282521" title="Click to go to the Author Index">
             Zai El Amri, Wadhah
            </a>
           </td>
           <td class="r">
            L3S Research Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#410170" title="Click to go to the Author Index">
             Kuhlmann, Malte Fabian
            </a>
           </td>
           <td class="r">
            L3S Research Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#160127" title="Click to go to the Author Index">
             Navarro-Guerrero, Nicolás
            </a>
           </td>
           <td class="r">
            Leibniz Universität Hannover
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab692" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#transfer_learning" title="Click to go to the Keyword Index">
               Transfer Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Tactile perception is essential for human interaction with the environment and is becoming increasingly crucial in robotics. Tactile sensors like the BioTac mimic human fingertips and provide detailed interaction data. Despite its utility in applications like slip detection and object identification, this sensor is now deprecated, making many valuable datasets obsolete. However, recreating similar datasets with newer sensor technologies is both tedious and time-consuming. Therefore, adapting these existing datasets for use with new setups and modalities is crucial. In response, we introduce ACROSS, a novel framework for translating data between tactile sensors by exploiting sensor deformation information. We demonstrate the approach by translating BioTac signals into the DIGIT sensor. Our framework consists of first converting the input signals into 3D deformation meshes. We then transition from the 3D deformation mesh of one sensor to the mesh of another, and finally convert the generated 3D deformation mesh into the corresponding output space. We demonstrate our approach to the most challenging problem of going from a low-dimensional tactile representation to a high-dimensional one. In particular, we transfer the tactile signals of a BioTac sensor to DIGIT tactile images. Our approach enables the continued use of valuable datasets and data exchange between groups with different setups.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat19_02">
             08:35-08:40, Paper WeAT19.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod897" name="modify1231" onclick="modify(1231,897)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1231'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning to Double Guess: An Active Perception Approach for Estimating the Center of Mass of Arbitrary Object
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#393269" title="Click to go to the Author Index">
             Jin, Shengmiao
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#340231" title="Click to go to the Author Index">
             Mo, Yuchen
            </a>
           </td>
           <td class="r">
            University of Illinois, Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#172670" title="Click to go to the Author Index">
             Yuan, Wenzhen
            </a>
           </td>
           <td class="r">
            University of Illinois
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1231" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#perception_action_coupling" title="Click to go to the Keyword Index">
               Perception-Action Coupling
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Manipulating arbitrary objects in unstructured environments is a significant challenge in robotics, primarily due to difficulties in determining an object's center of mass. This paper introduces U-GRAPH: Uncertainty-Guided Rotational Active Perception with Haptics, a novel framework to enhance the center of mass estimation using active perception. Traditional methods often rely on singular interactions and are limited by the inherent inaccuracies of Force-Torque (F/T) sensors. Our approach circumvents these limitations by integrating a Bayesian Neural Network (BNN) to quantify uncertainty and guide the robotic system through multiple, information-rich interactions via grid search and ActiveNet. We demonstrate the remarkable generalizability and transferability of our method with training on a small dataset with limited variation yet still perform well on unseen complex real-world objects.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat19_03">
             08:40-08:45, Paper WeAT19.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod898" name="modify1644" onclick="modify(1644,898)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1644'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning In-Hand Translation Using Tactile Skin with Shear and Normal Force Sensing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#219913" title="Click to go to the Author Index">
             Yin, Jessica
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#294264" title="Click to go to the Author Index">
             Qi, Haozhi
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#205586" title="Click to go to the Author Index">
             Malik, Jitendra
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#294881" title="Click to go to the Author Index">
             Pikul, James
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101787" title="Click to go to the Author Index">
             Yim, Mark
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#189501" title="Click to go to the Author Index">
             Hellebrekers, Tess
            </a>
           </td>
           <td class="r">
            Meta AI Research
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1644" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#in_hand_manipulation" title="Click to go to the Keyword Index">
               In-Hand Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent progress in reinforcement learning (RL) and tactile sensing has significantly advanced dexterous manipulation. However, these methods often utilize simplified tactile signals due to the gap between tactile simulation and the real world. We introduce a sensor model for tactile skin that enables zero-shot sim-to-real transfer of ternary shear and binary normal forces. Using this model, we develop an RL policy that leverages sliding contact for dexterous in-hand translation. We conduct extensive real-world experiments to assess how tactile sensing facilitates policy adaptation to various unseen object properties and robot hand orientations. We demonstrate that our 3-axis tactile policies consistently outperform baselines that use only shear forces, only normal forces, or only proprioception. Videos and details available on the project website.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat19_04">
             08:45-08:50, Paper WeAT19.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod899" name="modify4214" onclick="modify(4214,899)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4214'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Contrastive Touch-To-Touch Pretraining
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#384627" title="Click to go to the Author Index">
             Rodriguez, Samanta
            </a>
           </td>
           <td class="r">
            University of Michigan - Ann Arbor
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426226" title="Click to go to the Author Index">
             Dou, Yiming
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#341921" title="Click to go to the Author Index">
             van den Bogert, William
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#345747" title="Click to go to the Author Index">
             Oller, Miquel
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#344886" title="Click to go to the Author Index">
             So, Kevin
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405156" title="Click to go to the Author Index">
             Owens, Andrew
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#191587" title="Click to go to the Author Index">
             Fazeli, Nima
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4214" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Tactile sensors differ greatly in design, making it challenging to develop general-purpose methods for processing tactile feedback. In this paper, we introduce a contrastive self-supervised learning approach that represents tactile feedback across different sensor types. Our method utilizes paired tactile data—where two distinct sensors, in our case Soft Bubbles and GelSlims, grasp the same object in the same configuration—to learn a unified latent representation. Unlike current approaches that focus on reconstruction or task-specific supervision, our method employs contrastive learning to create a latent space that captures shared information between sensors. By treating paired tactile signals as positives and unpaired signals as negatives, we show that our model effectively learns a rich, sensor-agnostic representation. Despite significant differences between Soft Bubble and GelSlim sensors, the learned representation enables strong downstream task performance, including zero-shot and few-shot classification and pose estimation. This work provides a scalable solution for integrating tactile data across diverse sensor modalities, advancing the development of generalizable tactile representations.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat19_05">
             08:50-08:55, Paper WeAT19.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod900" name="modify4837" onclick="modify(4837,900)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4837'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ViTract: Robust Object Shape Perception Via Active Visuo-Tactile Interaction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#200694" title="Click to go to the Author Index">
             Dutta, Anirvan
            </a>
           </td>
           <td class="r">
            BMW Group and Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102286" title="Click to go to the Author Index">
             Burdet, Etienne
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#162864" title="Click to go to the Author Index">
             Kaboli, Mohsen
            </a>
           </td>
           <td class="r">
            Eindhoven University of Technology ( TU/e) &amp; BMW Group Research
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4837" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             An essential problem in robotic systems that are to be deployed in unstructured environments is the accurate and autonomous perception of the shapes of previously unseen objects. Existing methods for shape estimation or reconstruction have leveraged either visual or tactile interactive exploration techniques, or have relied on comprehensive visual or tactile information acquired in an offline manner. In this work, a novel visuo-tactile interactive perception framework - ViTract is introduced for shape estimation of unseen objects. Our framework estimates the shape of diverse objects robustly using low-dimensional, efficient, and generalizable shape primitives, which are superquadrics.
             <p>
              The probabilistic formulation within our framework takes advantage of the complementary information provided by vision and tactile observations while accounting for associated noise. As part of our framework, we propose a novel modality-specific information gain to select the most informative and reliable exploratory action (using vision/tactile) to obtain iterative visuo/tactile information. Our real-robot experiments demonstrate superior and robust performance compared to state-of-the-art visuo-tactile-based shape estimation techniques.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat19_06">
             08:55-09:00, Paper WeAT19.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod901" name="modify5055" onclick="modify(5055,901)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5055'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Location and Orientation Super-Resolution Sensing with a Cost-Efficient and Repairable Barometric Tactile Sensor
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#388354" title="Click to go to the Author Index">
             Hou, Jian
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#295640" title="Click to go to the Author Index">
             Zhou, Xin
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#134555" title="Click to go to the Author Index">
             Spiers, Adam
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5055" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#barometric_sensing" title="Click to go to the Keyword Index">
               Barometric Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The adoption of tactile sensors in robotics is hindered by their high cost and fragility. We designed and validated a cost-effective and robust barometric tactile sensor array, whose material cost is below 80 USD. Unlike past work, we do not mold the rubber surface over the barometers but instead keep it as a separate element, leading to a design that is easy to fabricate and repair. Machine learning techniques are applied to enhance the sensor’s localization precision, increasing the effective resolution from 6 mm (the distance between adjacent barometers) to 0.284 mm. To investigate the localization model’s robustness, we utilized an E-TRoll robotic gripper to roll differently shaped prismatic objects across the sensing surface mounted on one finger. Under these uncontrolled settings, we achieved a satisfactory real-time localization resolution of within 2.68 mm. Furthermore, we demonstrate a novel practical application: The E-TRoll mimics a 1-DoF parallel gripper inferring a cube’s orientation relative to the sensor. The range of orientations is split into 4 classes, which a trained CNN-LSTM model can predict with an 86.91% five-fold cross-validated accuracy.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat20">
             <b>
              WeAT20
             </b>
             Regular Session, 408
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod902" name="modifyWeAT20" onclick="modsession(159,902)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat20" title="Click to go to the Program at a Glance">
             <b>
              Human Motion Sensing
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#114283" title="Click to go to the Author Index">
             Youcef-Toumi, Kamal
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#224101" title="Click to go to the Author Index">
             Cao, Muqing
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat20_01">
             08:30-08:35, Paper WeAT20.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod903" name="modify121" onclick="modify(121,903)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('121'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Person Re-Identification for Robot Person Following with Online Continual Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#320141" title="Click to go to the Author Index">
             Ye, Hanjing
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#313625" title="Click to go to the Author Index">
             Zhao, Jieting
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#380174" title="Click to go to the Author Index">
             Zhan, Yu
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#199170" title="Click to go to the Author Index">
             Chen, Weinan
            </a>
           </td>
           <td class="r">
            Guangdong University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#195587" title="Click to go to the Author Index">
             He, Li
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#317689" title="Click to go to the Author Index">
             Zhang, Hong
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab121" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_centered_automation" title="Click to go to the Keyword Index">
               Human-Centered Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#continual_learning" title="Click to go to the Keyword Index">
               Continual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robot person following (RPF) is a crucial capability in human-robot interaction (HRI) applications, allowing a robot to persistently follow a designated person. In practical RPF scenarios, the person can often be occluded by other objects or people. Consequently, it is necessary to re-identify the person when he/she reappears within the robot's field of view. Previous person re-identification (ReID) approaches to person following rely on a fixed feature extractor. Such an approach often fails to generalize to different viewpoints and lighting conditions in practical RPF environments. In other words, it suffers from the so-called domain shift problem where it cannot re-identify the person when his re-appearance is out of the domain modeled by the fixed feature extractor. To mitigate this problem, we propose a ReID framework for RPF where we use a feature extractor that is optimized online with both short-term and long-term experiences (i.e., recently and previously observed samples during RPF) using the online continual learning (OCL) framework. The long-term experiences are maintained by a memory manager to enable OCL to update the feature extractor. Our experiments demonstrate that even in the presence of severe appearance changes and distractions from visually similar people, the proposed method can still re-identify the person more accurately than the state-of-the-art methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat20_02">
             08:35-08:40, Paper WeAT20.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod904" name="modify468" onclick="modify(468,904)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('468'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              HelmetPoser: A Helmet-Mounted IMU Dataset for Data-Driven Estimation of Human Head Motion in Diverse Conditions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#375293" title="Click to go to the Author Index">
             Li, Jianping
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417292" title="Click to go to the Author Index">
             Leng, Qiutong
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#343110" title="Click to go to the Author Index">
             Liu, Jinxin
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#353500" title="Click to go to the Author Index">
             Xu, Xinhang
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#388426" title="Click to go to the Author Index">
             Jin, Tongxing
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#224101" title="Click to go to the Author Index">
             Cao, Muqing
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#210732" title="Click to go to the Author Index">
             Nguyen, Thien-Minh
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#185927" title="Click to go to the Author Index">
             Yuan, Shenghai
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#249612" title="Click to go to the Author Index">
             Cao, Kun
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#115410" title="Click to go to the Author Index">
             Xie, Lihua
            </a>
           </td>
           <td class="r">
            NanyangTechnological University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab468" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#datasets_for_human_motion" title="Click to go to the Keyword Index">
               Datasets for Human Motion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#wearable_robotics" title="Click to go to the Keyword Index">
               Wearable Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Helmet-mounted wearable positioning systems are crucial for enhancing safety and facilitating coordination in industrial, construction, and emergency rescue environments. These systems, including LiDAR-Inertial Odometry (LIO) and Visual-Inertial Odometry (VIO), often face challenges in localization due to adverse environmental conditions such as dust, smoke, and limited visual features. To address these limitations, we propose a novel head-mounted Inertial Measurement Unit (IMU) dataset with ground truth, aimed at advancing data-driven IMU pose estimation. Our dataset captures human head motion patterns using a helmet-mounted system, with data from ten participants performing various activities. We explore the application of neural networks, specifically Long Short-Term Memory (LSTM) and Transformer networks, to correct IMU biases and improve localization accuracy. Additionally, we evaluate the performance of these methods across different IMU data window dimensions, motion patterns, and sensor types. We release a publicly available dataset, demonstrate the feasibility of advanced neural network approaches for helmet-based localization, and provide evaluation metrics to establish a baseline for future studies in this field. Data and code can be found at url{https://lqiutong.github.io/HelmetPoser.github.io/}
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat20_03">
             08:40-08:45, Paper WeAT20.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod905" name="modify2632" onclick="modify(2632,905)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2632'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Relevance-Driven Decision Making for Safer and More Efficient Human Robot Collaboration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#246775" title="Click to go to the Author Index">
             Zhang, Xiaotong
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418817" title="Click to go to the Author Index">
             Huang, Dingcheng
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#114283" title="Click to go to the Author Index">
             Youcef-Toumi, Kamal
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2632" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#cognitive_modeling" title="Click to go to the Keyword Index">
               Cognitive Modeling
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Human brain possesses the ability to effectively focus on important environmental components, which enhances perception, learning, reasoning, and decision-making. Inspired by this cognitive mechanism, we introduced a novel concept termed relevance for Human-Robot Collaboration (HRC). Relevance is a dimensionality reduction process that incorporates a continuously operating perception module, evaluates cue sufficiency within the scene, and applies a flexible formulation and computation framework. In this paper, we present an enhanced two-loop framework that integrates real-time and asynchronous processing to quantify relevance and leverage it for safer and more efficient human-robot collaboration (HRC). The two-loop framework integrates an asynchronous loop, which leverages an LLM’s world knowledge to quantify relevance, and a real-time loop, which performs scene understanding, human intent prediction, and decision-making based on relevance. HRC decision-making is enhanced by a relevance-based task allocation method, as well as a motion generation and collision avoidance approach that incorporates human trajectory prediction. Simulations and experiments show that our methodology for relevance quantification can accurately and robustly predict the human objective and relevance, with an average accuracy of up to 0.90 for objective prediction and up to 0.96 for relevance prediction. Moreover, our motion generation methodology reduces collision cases by 63.76% and collision frames by 44.74% when compared with a state-of-the-art (SOTA) collision avoidance method. Our framework and methodologies, with relevance, guide the robot on how to best assist humans and generate safer and more efficient actions for HRC.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat20_04">
             08:45-08:50, Paper WeAT20.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod906" name="modify4315" onclick="modify(4315,906)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4315'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Back to the Cartesian: Pilot Study for Assessing Human Stiffness in 3D Cartesian Space by Transforming from Muscle Space in a Peg-In-Hole Scenario for Tele-Impedance
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#194474" title="Click to go to the Author Index">
             Thuerauf, Sabine
            </a>
           </td>
           <td class="r">
            Friedrich-Alexander-University Erlangen-Nuremberg
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426439" title="Click to go to the Author Index">
             Mehrkens, Florian
            </a>
           </td>
           <td class="r">
            FAU Erlangen-Nuernberg
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#112281" title="Click to go to the Author Index">
             Castellini, Claudio
            </a>
           </td>
           <td class="r">
            Friedrich-Alexander-Universität Erlangen-Nürnberg
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#310024" title="Click to go to the Author Index">
             Sierotowicz, Marek
            </a>
           </td>
           <td class="r">
            Friedrich-Alexander Universität Erlangen Nürnberg
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4315" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#compliance_and_impedance_control" title="Click to go to the Keyword Index">
               Compliance and Impedance Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intention_recognition" title="Click to go to the Keyword Index">
               Intention Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             For various teleoperation tasks, position-based control is not practical. An impedance-based control is superior e.g. for handling fragile objects, like harvesting fruits or grasping a paper cup. However, only a few researchers have focused on impedance control for teleoperation. In tele-impedance, the stiffness of a human is measured and transferred to a controller of a robot. Until now, human stiffness was mostly measured either for specific joints or in 2D Cartesian space. We introduce a new way of measuring Cartesian stiffness in 3D using electromyography. Users were asked to perform a peg-in-hole task in three different orientations (0°, 45°, 90°). Meanwhile, electromyography measurements at shoulder and elbow muscle groups are performed. In a proof-of-concept study, we showed that the measured stiffness matrix in Cartesian space differed significantly across the three differently oriented peg-in-hole scenarios. This demonstrates that human stiffness could be predicted in 3D Cartesian space based on the type of task at hand.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat20_05">
             08:50-08:55, Paper WeAT20.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod907" name="modify4398" onclick="modify(4398,907)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4398'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Systematic Comparison of Projection Methods for Monocular 3D Human Pose Estimation on Fisheye Images
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420165" title="Click to go to the Author Index">
             Käs, Stephanie
            </a>
           </td>
           <td class="r">
            RWTH Aachen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420166" title="Click to go to the Author Index">
             Peter, Sven
            </a>
           </td>
           <td class="r">
            RWTH Aachen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420247" title="Click to go to the Author Index">
             Thillmann, Henrik
            </a>
           </td>
           <td class="r">
            Chair for Computer Vision, RWTH Aachen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420172" title="Click to go to the Author Index">
             Burenko, Anton
            </a>
           </td>
           <td class="r">
            RWTH Aachen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#168421" title="Click to go to the Author Index">
             Adrian, David Benjamin
            </a>
           </td>
           <td class="r">
            Bosch Corporate Research &amp; Ulm University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426319" title="Click to go to the Author Index">
             Mack, Dennis
            </a>
           </td>
           <td class="r">
            Robert Bosch GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#167078" title="Click to go to the Author Index">
             Linder, Timm
            </a>
           </td>
           <td class="r">
            Robert Bosch GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#115270" title="Click to go to the Author Index">
             Leibe, Bastian
            </a>
           </td>
           <td class="r">
            RWTH Aachen University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4398" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#gesture__posture_and_facial_expressions" title="Click to go to the Keyword Index">
               Gesture, Posture and Facial Expressions
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_detection_and_tracking" title="Click to go to the Keyword Index">
               Human Detection and Tracking
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#omnidirectional_vision" title="Click to go to the Keyword Index">
               Omnidirectional Vision
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Fisheye cameras offer robots the ability to capture human movements across a wider field of view (FOV) than standard pinhole cameras, making them particularly useful for applications in human-robot interaction and automotive contexts. However, accurately detecting human poses in fisheye images is challenging due to the curved distortions inherent to fisheye optics. While various methods for undistorting fisheye images have been proposed, their effectiveness and limitations for poses that cover a wide FOV has not been systematically evaluated in the context of absolute human pose estimation from monocular fisheye images. To address this gap, we evaluate the impact of pinhole, equidistant and double sphere camera models, as well as cylindrical projection methods, on 3D human pose estimation accuracy. We find that in close-up scenarios, pinhole projection is inadequate, and the optimal projection method varies with the FOV covered by the human pose. The usage of advanced fisheye models like the double sphere model significantly enhances 3D human pose estimation accuracy. We propose a heuristic for selecting the appropriate projection model based on the detection bounding box to enhance prediction quality. Additionally, we introduce and evaluate on our novel FISHnCHIPS dataset, which features 3D human skeleton annotations in fisheye images, including images from unconventional angles, such as extreme close-ups, ground-mounted cameras, and wide-FOV poses.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat20_06">
             08:55-09:00, Paper WeAT20.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod908" name="modify4903" onclick="modify(4903,908)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4903'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              HuMAn – the Human Motion Anticipation Algorithm Based on Recurrent Neural Networks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#363520" title="Click to go to the Author Index">
             Noppeney, Victor
            </a>
           </td>
           <td class="r">
            University of São Paulo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#227640" title="Click to go to the Author Index">
             Escalante, Felix M
            </a>
           </td>
           <td class="r">
            São Paulo State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#342663" title="Click to go to the Author Index">
             Maggi, Lucas
            </a>
           </td>
           <td class="r">
            University of Sao Paulo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#131860" title="Click to go to the Author Index">
             Boaventura, Thiago
            </a>
           </td>
           <td class="r">
            University of Sao Paulo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4903" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#modeling_and_simulating_humans" title="Click to go to the Keyword Index">
               Modeling and Simulating Humans
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_and_humanoid_motion_analysis_and_synthesis" title="Click to go to the Keyword Index">
               Human and Humanoid Motion Analysis and Synthesis
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intention_recognition" title="Click to go to the Keyword Index">
               Intention Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Predicting human motion may lead to considerable advantages for human-robot interaction, particularly when precise synchronization between the robot’s motion and the user’s movement is imperative. The inherent stochastic nature of human behavior, combined with the restricted window of response, can give rise to residual and undesirable forces during interactions, potentially harming the user. Therefore, efficient prediction of human joint movements may enhance the performance of various interaction control frameworks used in wearable robots. This paper proposes the HuMAn algorithm for predicting human joint motion based on a recurrent neural network. This algorithm consists of a long-term memory network, used to interpret sequences of poses, and a prediction layer, employed to build the most likely future user poses within a specified time horizon. Network training was performed using datasets encompassing various subjects and types of motion. The results demonstrate the effectiveness of the proposed algorithm, as evidenced by average general prediction errors below 0.1 radians for predictive horizons of up to 500 milliseconds. Furthermore, a mean absolute error of 0.026 radians was achieved for a periodic treadmill walk. Simulation results demonstrate a large improvement in transparency control performance in a case study with an upper limb exoskeleton robot.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat21">
             <b>
              WeAT21
             </b>
             Regular Session, 410
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod909" name="modifyWeAT21" onclick="modsession(493,909)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat21" title="Click to go to the Program at a Glance">
             <b>
              Robot Foundation Models 1
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#252445" title="Click to go to the Author Index">
             Li, Hui
            </a>
           </td>
           <td class="r">
            Autodesk Research
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#171078" title="Click to go to the Author Index">
             Nguyen, Anh
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat21_01">
             08:30-08:35, Paper WeAT21.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod910" name="modify467" onclick="modify(467,910)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('467'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robotic-CLIP: Fine-Tuning CLIP on Action Data for Robotic Applications
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#391536" title="Click to go to the Author Index">
             Nguyen, Nghia
            </a>
           </td>
           <td class="r">
            FPT Software Company Limited
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#196876" title="Click to go to the Author Index">
             Vu, Minh Nhat
            </a>
           </td>
           <td class="r">
            TU Wien, Austria
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#217645" title="Click to go to the Author Index">
             Ta, Tung D.
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#234039" title="Click to go to the Author Index">
             Huang, Baoru
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351899" title="Click to go to the Author Index">
             Vo, Thieu
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351637" title="Click to go to the Author Index">
             Le, Ngan
            </a>
           </td>
           <td class="r">
            University of Arkansas
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#171078" title="Click to go to the Author Index">
             Nguyen, Anh
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab467" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#perception_action_coupling" title="Click to go to the Keyword Index">
               Perception-Action Coupling
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Vision language models have played a key role in extracting meaningful features for various robotic applications. Among these, Contrastive Language-Image Pretraining (CLIP) is widely used in robotic tasks that require both vision and natural language understanding. However, CLIP was trained solely on static images paired with text prompts and has not yet been fully adapted for robotic tasks involving dynamic actions. In this paper, we introduce Robotic-CLIP to enhance robotic perception capabilities. We first gather and label large-scale action data, and then build our Robotic-CLIP by fine-tuning CLIP on 309,433 videos (~7.4 million frames) of action data using contrastive learning. By leveraging action data, Robotic-CLIP inherits CLIP's strong image performance while gaining the ability to understand actions in robotic contexts. Intensive experiments show that our Robotic-CLIP outperforms other CLIP-based models across various language-driven robotic tasks. Additionally, we demonstrate the practical effectiveness of Robotic-CLIP in real-world grasping applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat21_02">
             08:35-08:40, Paper WeAT21.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod911" name="modify2008" onclick="modify(2008,911)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2008'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              In-Context Imitation Learning Via Next-Token Prediction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#311951" title="Click to go to the Author Index">
             Fu, Letian
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#245956" title="Click to go to the Author Index">
             Huang, Huang
            </a>
           </td>
           <td class="r">
            University of California at Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338160" title="Click to go to the Author Index">
             Datta, Gaurav
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#299850" title="Click to go to the Author Index">
             Chen, Lawrence Yunliang
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#328828" title="Click to go to the Author Index">
             Panitch, William
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#314029" title="Click to go to the Author Index">
             Liu, Fangchen
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#252445" title="Click to go to the Author Index">
             Li, Hui
            </a>
           </td>
           <td class="r">
            Autodesk Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107102" title="Click to go to the Author Index">
             Goldberg, Ken
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2008" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In-context imitation learning is the capability to perform novel tasks when prompted with task demonstration examples. In-Context Robot Transformer (ICRT) is a causal transformer that performs autoregressive prediction on sensorimotor trajectories, which include images, proprioceptive states, and actions. This approach supports flexible and trainingfree execution of new tasks at test time. Experiments with a Franka Emika robot demonstrate that ICRT can adapt to new environment configurations that differ from both the prompt and the training data. In a multi-task environment setup, ICRT significantly outperforms current state-of-the-art robot foundation models on generalization to unseen tasks. Code, data, and appendix are available on https://icrt.dev.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat21_03">
             08:40-08:45, Paper WeAT21.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod912" name="modify2649" onclick="modify(2649,912)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2649'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Data Augmentation for NeRFs in the Low Data Limit
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#387121" title="Click to go to the Author Index">
             Gaggar, Ayush
            </a>
           </td>
           <td class="r">
            Northwestern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104560" title="Click to go to the Author Index">
             Murphey, Todd
            </a>
           </td>
           <td class="r">
            Northwestern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2649" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#incremental_learning" title="Click to go to the Keyword Index">
               Incremental Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning_under_uncertainty" title="Click to go to the Keyword Index">
               Planning under Uncertainty
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Current methods based on Neural Radiance Fields fail in the low data limit, particularly when training on incomplete scene data. Prior works augment training data only in next-best-view applications, which lead to hallucinations and model collapse with sparse data. In contrast, we propose adding a set of views during training by rejection sampling from a posterior uncertainty distribution, generated by combining a volumetric uncertainty estimator with spatial coverage. We validate our results on partially observed scenes; on average, our method performs 39.9% better with 87.5% less variability across established scene reconstruction benchmarks, as compared to state of the art baselines. We further demonstrate that augmenting the training set by sampling from any distribution leads to better, more consistent scene reconstruction in sparse environments. This work is foundational for robotic tasks where augmenting a dataset with informative data is critical in resource-constrained,
             <i>
              a priori
             </i>
             unknown environments. Videos and source code are available at
             <a href='"https://murpheylab.github.io/low-data-nerf/"'>
              https://murpheylab.github.io/low-data-nerf
             </a>
             .
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat21_04">
             08:45-08:50, Paper WeAT21.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod913" name="modify3885" onclick="modify(3885,913)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3885'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Generalizable Imitation Learning through Pre-Trained Representations
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#211346" title="Click to go to the Author Index">
             Chang, Wei-Di
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#198199" title="Click to go to the Author Index">
             Hogan, Francois
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#229960" title="Click to go to the Author Index">
             Fujimoto, Scott
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102603" title="Click to go to the Author Index">
             Meger, David Paul
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102604" title="Click to go to the Author Index">
             Dudek, Gregory
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3885" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we leverage self-supervised vision transformer models and their emergent semantic abilities to improve the generalization abilities of imitation learning policies. We introduce DVK, an imitation learning algorithm that leverages rich pre-trained Visual Transformer patch-level embeddings to obtain better generalization when learning through demonstrations. Our learner sees the world by clustering appearance features into groups associated with semantic concepts, forming stable keypoints that generalize across a wide range of appearance variations and object types. We demonstrate how this representation enables generalized behaviour by evaluating imitation learning across a diverse dataset of object manipulation tasks. To facilitate further study of generalization in Imitation Learning, all of our code for the method and evaluation, as well as the dataset, is made available.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat21_05">
             08:50-08:55, Paper WeAT21.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod914" name="modify4308" onclick="modify(4308,914)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4308'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Beyond Sight: Finetuning Generalist Robot Policies with Heterogeneous Sensors Via Language Grounding
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423700" title="Click to go to the Author Index">
             Jones, Joshua
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#191594" title="Click to go to the Author Index">
             Mees, Oier
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#195795" title="Click to go to the Author Index">
             Sferrazza, Carmelo
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#308024" title="Click to go to the Author Index">
             Stachowicz, Kyle
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107568" title="Click to go to the Author Index">
             Abbeel, Pieter
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#156706" title="Click to go to the Author Index">
             Levine, Sergey
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4308" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#big_data_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Big Data in Robotics and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensorimotor_learning" title="Click to go to the Keyword Index">
               Sensorimotor Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Interacting with the world is a multi-sensory experience: achieving effective general-purpose interaction requires making use of all available modalities -- including vision, touch, and audio -- to fill in gaps from partial observation. For example, when vision is occluded reaching into a bag, a robot should rely on its senses of touch and sound. However, state-of-the-art generalist robot policies are typically trained on large datasets to predict robot actions solely from visual and proprioceptive observations. In this work, we propose FuSe, a novel approach that enables finetuning visuomotor generalist policies on heterogeneous sensor modalities for which large datasets are not readily available by leveraging natural language as a common cross-modal grounding. We combine a multimodal contrastive loss with a sensory-grounded language generation loss to encode high-level semantics. In the context of robot manipulation, we show that FuSe enables performing challenging tasks that require reasoning jointly over modalities such as vision, touch, and sound in a zero-shot setting, such as multimodal prompting, compositional cross-modal prompting, and descriptions of objects it interacts with. We show that the same recipe is applicable to widely different generalist policies, including both diffusion-based generalist policies and large vision-language-action (VLA) models. Extensive experiments in the real world show that FuSe is able to increase success rates by over 20% compared to all considered baselines.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat21_06">
             08:55-09:00, Paper WeAT21.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod915" name="modify4881" onclick="modify(4881,915)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4881'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Simultaneous Geometry and Pose Estimation of Held Objects Via 3D Foundation Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#238613" title="Click to go to the Author Index">
             Zhi, Weiming
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#404812" title="Click to go to the Author Index">
             Tang, Haozhan
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#266906" title="Click to go to the Author Index">
             Zhang, Tianyi
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#118789" title="Click to go to the Author Index">
             Johnson-Roberson, Matthew
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4881" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Humans have the remarkable ability to use held objects as tools to interact with their environment. For this to occur, humans internally estimate how hand movements affect the object's movement. We wish to endow robots with this capability. We contribute methodology to jointly estimate the geometry and pose of objects grasped by a robot, from RGB images captured by an external camera. Notably, our method transforms the estimated geometry into the robot's coordinate frame, while not requiring the extrinsic parameters of the external camera to be calibrated. Our approach leverages 3D foundation models, large models pre-trained on huge datasets for 3D vision tasks, to produce initial estimates of the in-hand object. These initial estimations do not have physically correct scales and are in the camera's frame. Then, we formulate, and efficiently solve, a coordinate-alignment problem to recover accurate scales, along with a transformation of the objects to the coordinate frame of the robot. Forward kinematics mappings can subsequently be defined from the manipulator's joint angles to specified points on the object. These mappings enable the estimation of points on the held object at arbitrary configurations, enabling robot motion to be designed with respect to coordinates on the grasped objects. We empirically evaluate our approach on a robot manipulator holding a diverse set of real-world objects.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat22">
             <b>
              WeAT22
             </b>
             Regular Session, 411
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod916" name="modifyWeAT22" onclick="modsession(239,916)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat22" title="Click to go to the Program at a Glance">
             <b>
              Learning for Robot Control
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#106001" title="Click to go to the Author Index">
             Bonsignorio, Fabio
            </a>
           </td>
           <td class="r">
            FER, University of Zagreb
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#196707" title="Click to go to the Author Index">
             P. Vinod, Abraham
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Research Laboratories
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat22_01">
             08:30-08:35, Paper WeAT22.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod917" name="modify114" onclick="modify(114,917)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('114'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Gradient Descent-Based Task-Orientation Robot Control Enhanced with Gaussian Process Predictions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#159606" title="Click to go to the Author Index">
             Roveda, Loris
            </a>
           </td>
           <td class="r">
            SUPSI-IDSIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#123466" title="Click to go to the Author Index">
             Pavone, Marco
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab114" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#compliance_and_impedance_control" title="Click to go to the Keyword Index">
               Compliance and Impedance Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes a novel force-based task-orientation controller for interaction tasks with environmental orientation uncertainties. The main aim of the controller is to align the robot tool along the main task direction (e.g., along screwing, insertion, polishing, etc.) without the use of any external sensors (e.g., vision systems), relying only on end-effector wrench measurements/estimations. We propose a gradient descent-based orientation controller, enhancing its performance with the orientation predictions provided by a Gaussian Process model. Derivation of the controller is presented, together with simulation results (considering a probing task) and experimental results involving various re-orientation scenarios, i.e., i) a task with the robot in interaction with a soft environment, ii) a task with the robot in interaction with a stiff and inclined environment, and iii) a task to enable the assembly of a gear into its shaft. The proposed controller is compared against a state-of-the-art approach, highlighting its ability to re-orient the robot tool even in complex tasks (where the state-of-the-art method fails).
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat22_02">
             08:35-08:40, Paper WeAT22.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod918" name="modify368" onclick="modify(368,918)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('368'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Model-Free Inverse H-Infinity Control for Imitation Learning (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#404050" title="Click to go to the Author Index">
             Xue, Wenqian
            </a>
           </td>
           <td class="r">
            University of Florida
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#403971" title="Click to go to the Author Index">
             Lian, Bosen
            </a>
           </td>
           <td class="r">
            Auburn University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416550" title="Click to go to the Author Index">
             Kartal, Yusuf
            </a>
           </td>
           <td class="r">
            Turkish Aerospace
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416552" title="Click to go to the Author Index">
             Fan, Jialu
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#136002" title="Click to go to the Author Index">
             Chai, Tianyou
            </a>
           </td>
           <td class="r">
            Northeastern University, Shenyang, China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#115182" title="Click to go to the Author Index">
             Lewis, Frank
            </a>
           </td>
           <td class="r">
            The University of Texas at Arlington
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab368" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes a data-driven model-free inverse reinforcement learning (IRL) algorithm tailored for solving an inverse H_infty control problem. In the problem, both an expert and a learner engage in H_infty control to reject disturbances and the learner's objective is to imitate the expert's behavior by reconstructing the expert's performance function through IRL techniques. Introducing zero-sum game principles, we first formulate a model-based single-loop IRL policy iteration algorithm that includes three key steps: updating the policy, action, and performance function using a new correction formula and the standard inverse optimal control principles. Building upon the model-based approach, we propose a model-free single-loop off-policy IRL algorithm that eliminates the need for initial stabilizing policies and prior knowledge of the dynamics of expert and learner. Also, we provide rigorous proof of convergence, stability, and Nash optimality to guarantee the effectiveness and reliability of the proposed algorithms. Furthermore, we showcase the efficiency of our algorithm through simulations and experiments, highlighting its advantages compared to the existing methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat22_03">
             08:40-08:45, Paper WeAT22.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod919" name="modify1103" onclick="modify(1103,919)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1103'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Object Properties Using Robot Proprioception Via Differentiable Robot-Object Interaction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#413730" title="Click to go to the Author Index">
             Chen, Peter Yichen
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#196497" title="Click to go to the Author Index">
             Liu, Chao
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#310703" title="Click to go to the Author Index">
             Ma, Pingchuan
            </a>
           </td>
           <td class="r">
            MIT CSAIL
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420534" title="Click to go to the Author Index">
             Eastman, John
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101388" title="Click to go to the Author Index">
             Rus, Daniela
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#377569" title="Click to go to the Author Index">
             Randle, Dylan Labatt
            </a>
           </td>
           <td class="r">
            Amazon Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#384628" title="Click to go to the Author Index">
             Ivanov, Yuri
            </a>
           </td>
           <td class="r">
            Amazon
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#219724" title="Click to go to the Author Index">
             Matusik, Wojciech
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1103" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensorimotor_learning" title="Click to go to the Keyword Index">
               Sensorimotor Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Differentiable simulation has become a powerful tool for system identification. While prior work has focused on identifying robot properties using robot-specific data or object properties using object-specific data, our approach calibrates object properties by using information from the robot, without relying on data from the object itself. Specifically, we utilize robot joint encoder information, which is commonly available in standard robotic systems. Our key observation is that by analyzing the robot's reactions to manipulated objects, we can infer properties of those objects, such as inertia and softness. Leveraging this insight, we develop differentiable simulations of robot-object interactions to inversely identify the properties of the manipulated objects. Our approach relies solely on proprioception — the robot’s internal sensing capabilities — and does not require external measurement tools or vision-based tracking systems. This general method is applicable to any articulated robot and requires only joint position information. We demonstrate the effectiveness of our method on a low-cost robotic platform, achieving accurate mass and elastic modulus estimations of manipulated objects with just a few seconds of computation on a laptop.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat22_04">
             08:45-08:50, Paper WeAT22.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod920" name="modify3174" onclick="modify(3174,920)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3174'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Reservoir Computing Encodes Physical Adaptations for Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425171" title="Click to go to the Author Index">
             Giannetto, Cross
            </a>
           </td>
           <td class="r">
            CCIR
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#303652" title="Click to go to the Author Index">
             Ibragim, Atadjanov
            </a>
           </td>
           <td class="r">
            Kyung Hee University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105049" title="Click to go to the Author Index">
             Iida, Fumiya
            </a>
           </td>
           <td class="r">
            University of Cambridge
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#356118" title="Click to go to the Author Index">
             Abdulali, Arsen
            </a>
           </td>
           <td class="r">
            Cambridge University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3174" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Adapting reinforcement learning (RL) policies to various robot body configurations is a significant challenge for creating flexible autonomous systems. This study presents a novel framework that integrates Reservoir Computing (RC) with the First-Order Reduced and Controlled Error (FORCE) learning rule to enhance policy adaptability in RL. The RC serves as a dynamic feature extractor, capturing temporal dependencies by pre-training on state transitions generated through random actions. This pre-training acts as regularization, reducing variance and preventing overfitting to specific configurations Subsequently, the control policy network is trained on a limited set of body variations using the enriched features from the RC. Experimental results across three distinct environments demonstrate that the proposed RC+FORCE framework significantly improves policy performance and adaptability to unseen robot configurations compared to traditional reinforcement learning through domain randomization. These findings highlight the effectiveness of combining RC-based feature extraction with FORCE-based training in developing robust RL agents.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat22_05">
             08:50-08:55, Paper WeAT22.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod921" name="modify3571" onclick="modify(3571,921)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3571'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Self-Supervised Meta-Learning for All-Layer DNN-Based Adaptive Control with Stability Guarantees
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#341903" title="Click to go to the Author Index">
             He, Guanqi
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#280795" title="Click to go to the Author Index">
             Choudhary, Yogita
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#236627" title="Click to go to the Author Index">
             Shi, Guanya
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3571" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A critical goal of adaptive control is enabling robots to rapidly adapt in dynamic environments. Recent studies have developed a meta-learning-based adaptive control scheme, which uses meta-learning to extract nonlinear features (represented by Deep Neural Networks (DNNs)) from offline data, and uses adaptive control to update linear coefficients online. However, such a scheme is fundamentally limited by the linear parameterization of uncertainties and does not fully unleash the capability of DNNs. This paper introduces a novel learning-based adaptive control framework that pretrains a DNN via self-supervised meta-learning (SSML) from offline trajectories and online adapts the full DNN via composite adaptation. In particular, the offline SSML stage leverages the time consistency in trajectory data to train the DNN to predict future disturbances from history, in a self-supervised manner without environment condition labels. The online stage carefully designs a control law and an adaptation law to update the full DNN with stability guarantees. Empirically, the proposed framework significantly outperforms (19-39%) various classic and learning-based adaptive control baselines, in challenging real-world quadrotor tracking problems under large dynamic wind disturbance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat22_06">
             08:55-09:00, Paper WeAT22.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod922" name="modify3898" onclick="modify(3898,922)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3898'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Residual Policy Learning for Perceptive Quadruped Control Using Differentiable Simulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425193" title="Click to go to the Author Index">
             Luo, Jing Yuan
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#277846" title="Click to go to the Author Index">
             Song, Yunlong
            </a>
           </td>
           <td class="r">
            University of Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#236286" title="Click to go to the Author Index">
             Klemm, Victor
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#206191" title="Click to go to the Author Index">
             Shi, Fan
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105662" title="Click to go to the Author Index">
             Scaramuzza, Davide
            </a>
           </td>
           <td class="r">
            University of Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#114045" title="Click to go to the Author Index">
             Hutter, Marco
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3898" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             First-order Policy Gradient (FoPG) algorithms such as Backpropagation through Time and Analytical Policy Gradients leverage local simulation physics to accelerate policy search, significantly improving sample efficiency in robot control compared to standard model-free reinforcement learning. However, FoPG algorithms can exhibit poor learning dynamics in contact-rich tasks like locomotion. Previous approaches address this issue by alleviating contact dynamics via algorithmic or simulation innovations. In contrast, we propose guiding the policy search by learning a residual over a simple baseline policy. For quadruped locomotion, we find that the role of residual policy learning in FoPG-based training (FoPG RPL) is primarily to improve asymptotic rewards, compared to improving sample efficiency for model-free RL. Additionally, we provide insights on applying FoPG's to pixel-based local navigation, training a point-mass robot to convergence within seconds. Finally, we showcase the versatility of FoPG RPL by using it to train locomotion and perceptive navigation end-to-end on a quadruped in minutes.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weat23">
             <b>
              WeAT23
             </b>
             Regular Session, 412
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod923" name="modifyWeAT23" onclick="modsession(67,923)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weat23" title="Click to go to the Program at a Glance">
             <b>
              Autonomous Vehicle Perception 3
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#193952" title="Click to go to the Author Index">
             Wang, Shenlong
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#255884" title="Click to go to the Author Index">
             Chen, Yong-Sheng
            </a>
           </td>
           <td class="r">
            National Yang Ming Chiao Tung University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat23_01">
             08:30-08:35, Paper WeAT23.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod924" name="modify1366" onclick="modify(1366,924)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1366'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              METDrive: Multimodal End-To-End Autonomous Driving with Temporal Guidance
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#377977" title="Click to go to the Author Index">
             Guo, Ziang
            </a>
           </td>
           <td class="r">
            Skolkovo Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421311" title="Click to go to the Author Index">
             Lin, Xinhao
            </a>
           </td>
           <td class="r">
            Insititute of Automation, Qilu University of Technology (Shandon
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#396315" title="Click to go to the Author Index">
             Yagudin, Zakhar
            </a>
           </td>
           <td class="r">
            Skolkovo Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#368162" title="Click to go to the Author Index">
             Lykov, Artem
            </a>
           </td>
           <td class="r">
            Skolkovo Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421305" title="Click to go to the Author Index">
             Wang, Yong
            </a>
           </td>
           <td class="r">
            Insititute of Automation, Qilu University of Technology (Shandon
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#228268" title="Click to go to the Author Index">
             Li, Yanqiang
            </a>
           </td>
           <td class="r">
            Institute of Automation, Qilu University of Technology (Shandong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#224247" title="Click to go to the Author Index">
             Tsetserukou, Dzmitry
            </a>
           </td>
           <td class="r">
            Skolkovo Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1366" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multimodal end-to-end autonomous driving has shown promising advancements in recent work. By embedding more modalities into end-to-end networks, the system’s understanding of both static and dynamic aspects of the driving environment is enhanced, thereby improving the safety of autonomous driving. In this paper, we introduce METDrive, an end-to-end system that leverages temporal guidance from the embedded time series features of ego states, including rotation angles, steering, throttle signals, and waypoint vectors. The geometric features derived from perception sensor data and the time series features of ego state data jointly guide the waypoint prediction with the proposed temporal guidance loss function. We evaluated METDrive on the CARLA leaderboard benchmarks, achieving a driving score of 70%, a route completion score of 94%, and an infraction score of 0.78.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat23_02">
             08:35-08:40, Paper WeAT23.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod925" name="modify1418" onclick="modify(1418,925)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1418'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Generalizing Motion Planners with Mixture of Experts for Autonomous Driving
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#324806" title="Click to go to the Author Index">
             Sun, Qiao
            </a>
           </td>
           <td class="r">
            Shanghai QiZhi Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419157" title="Click to go to the Author Index">
             Wang, Huimin
            </a>
           </td>
           <td class="r">
            Li Auto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420250" title="Click to go to the Author Index">
             Zhan, Jiahao
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372782" title="Click to go to the Author Index">
             Nie, Fan
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419384" title="Click to go to the Author Index">
             Wen, Xin
            </a>
           </td>
           <td class="r">
            Li Auto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419349" title="Click to go to the Author Index">
             Xu, Leimeng
            </a>
           </td>
           <td class="r">
            Li Auto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419719" title="Click to go to the Author Index">
             Zhan, Kun
            </a>
           </td>
           <td class="r">
            LiAuto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419810" title="Click to go to the Author Index">
             Jia, Peng
            </a>
           </td>
           <td class="r">
            Li Auto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#410945" title="Click to go to the Author Index">
             Lang, Xianpeng
            </a>
           </td>
           <td class="r">
            LiAuto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#207381" title="Click to go to the Author Index">
             Zhao, Hang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1418" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Large real-world driving datasets have sparked significant research into various aspects of learning-based motion planners for autonomous driving. These include data augmentation, model architecture, reward design, training strategies, and planner pipelines. In this paper, we review and benchmark previous methods. Experiments show that many of these approaches have limited generalization abilities in planning performance due to overly complex designs or training paradigms. Experiments further reveal that as models are appropriately scaled, many designs become redundant. Therefore, we introduce StateTransformer-2 (STR2), a scalable, decoder-only motion planner. STR2uses a Vision Transformer (ViT) encoder and a mix-of-experts (MoE) causal transformer architecture. The MoE backbone addresses modality collapse and reward balancing by expert routing during training. Extensive experiments on the NuPlan dataset show that our method generalizes better than previous approaches across different test sets and closed-loop simulations. We evaluate its scalability on billions of real-world urban driving scenarios, demonstrating consistent accuracy improvements as both data and model size grow.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat23_03">
             08:40-08:45, Paper WeAT23.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod926" name="modify1670" onclick="modify(1670,926)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1670'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Low-Rank Adaptation-Based All-Weather Removal for Autonomous Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417134" title="Click to go to the Author Index">
             Rajagopalan, Sudarshan
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#311506" title="Click to go to the Author Index">
             Patel, Vishal
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1670" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             All-weather image restoration (AWIR) is crucial for reliable autonomous navigation under adverse weather conditions. AWIR models are trained to address a specific set of weather conditions such as fog, rain, and snow. But this causes them to often struggle with out-of-distribution (OoD) samples or unseen degradations which limits their effectiveness for real-world autonomous navigation. To overcome this issue, existing models must either be retrained or fine-tuned, both of which are inefficient and impractical, with retraining needing access to large datasets, and fine-tuning involving many parameters. In this paper, we propose using Low-Rank Adaptation (LoRA) to efficiently adapt a pre-trained all-weather model to novel weather restoration tasks. Furthermore, we observe that LoRA lowers the performance of the adapted model on the pre-trained restoration tasks. To address this issue, we introduce a LoRA-based fine-tuning method called LoRA-Align (LoRA-A) which seeks to align the singular vectors of the fine-tuned and pre-trained weight matrices using Singular Value Decomposition (SVD). This alignment helps preserve the model's knowledge of its original tasks while adapting it to unseen tasks. We show that images restored with LoRA and LoRA-A can be effectively used for computer vision tasks in autonomous navigation, such as semantic segmentation and depth estimation. Project page: https://sudraj2002.github.io/loraapage/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat23_04">
             08:45-08:50, Paper WeAT23.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod927" name="modify2334" onclick="modify(2334,927)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2334'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Stands on Shoulders of Giants: Learning to Lift 2D Detection to 3D with Geometry-Driven Objectives
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#391879" title="Click to go to the Author Index">
             Chen, Jhih Rong
            </a>
           </td>
           <td class="r">
            National Yang Ming Chiao Tung University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#391820" title="Click to go to the Author Index">
             Chang, Che Yuan
            </a>
           </td>
           <td class="r">
            National Yang Ming Chiao Tung University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#391871" title="Click to go to the Author Index">
             Tseng, Szu Han
            </a>
           </td>
           <td class="r">
            Elan Microelectronics Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#391883" title="Click to go to the Author Index">
             Huang, Chih Sheng
            </a>
           </td>
           <td class="r">
            Elan Microelectronics Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#255884" title="Click to go to the Author Index">
             Chen, Yong-Sheng
            </a>
           </td>
           <td class="r">
            National Yang Ming Chiao Tung University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#238086" title="Click to go to the Author Index">
             Chiu, Wei-Chen
            </a>
           </td>
           <td class="r">
            National Chiao Tung University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2334" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             3D detection of vehicles is an essential component for autonomous driving applications. Nevertheless, collecting the supervised training data for learning 3D vehicle detectors would be costly (e.g. utilization of expensive LiDAR sensors) and labor-intensive (for human annotation). In comparison to 3D detection, 2D object detection has achieved a well-developed status, boosting stable and robust performance with widespread application in numerous fields, thanks to the large scale (i.e. amount of samples) of existing training datasets of 2D object detection. Hence, in our work, we propose to realize 3D detection via leveraging the robustness of 2D detectors and developing a network that lifts 2D detections to 3D. With the flexibility of building upon various backbone models (e.g. the models which take image regions detected by 2D detector as inputs to predict their corresponding 3D bounding boxes, or the existing monocular 3D detection models which have the intermediate output of 2D bounding boxes), we propose several geometry-driven objectives, including projection consistency loss, geometry depth loss, and opposite bin loss, to improve the training upon 2D-to-3D lifting. Our extensive experimental results demonstrate that our proposed geometry-driven objectives not only contribute to the superior results of 3D detection but also provide better generalizability across datasets.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat23_05">
             08:50-08:55, Paper WeAT23.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod928" name="modify2804" onclick="modify(2804,928)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2804'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LidarDM: Generative LiDAR Simulation in a Generated World
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#356344" title="Click to go to the Author Index">
             Zyrianov, Vlas
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422252" title="Click to go to the Author Index">
             Che, Henry
            </a>
           </td>
           <td class="r">
            University of Illinois, Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#291955" title="Click to go to the Author Index">
             Liu, Zhijian
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#193952" title="Click to go to the Author Index">
             Wang, Shenlong
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2804" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present LidarDM, a novel LiDAR generative model capable of producing realistic, layout-aware, physically plausible, and temporally coherent LiDAR videos. LidarDM stands out with two unprecedented capabilities in LiDAR generative modeling: (i) LiDAR generation guided by driving scenarios, offering significant potential for autonomous driving simulations, and (ii) 4D LiDAR point cloud generation, enabling the creation of realistic and temporally coherent sequences. At the heart of our model is a novel integrated 4D world generation framework. Specifically, we employ latent diffusion models to generate the 3D scene, combine it with dynamic actors to form the underlying 4D world, and subsequently produce realistic sensory observations within this virtual environment. Our experiments indicate that our approach outperforms competing algorithms in realism, temporal coherency, and layout consistency. We additionally show that LidarDM can be used as a generative world model simulator for training and testing perception models.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weat23_06">
             08:55-09:00, Paper WeAT23.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod929" name="modify3647" onclick="modify(3647,929)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3647'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RenderWorld: World Model with Self-Supervised 3D Label
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423744" title="Click to go to the Author Index">
             Yan, Ziyang
            </a>
           </td>
           <td class="r">
            University of Trento
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#370013" title="Click to go to the Author Index">
             Dong, Wenzhen
            </a>
           </td>
           <td class="r">
            The Chinese University of HongKong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#403962" title="Click to go to the Author Index">
             Shao, Yihua
            </a>
           </td>
           <td class="r">
            University of Science and Technology Beijing
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425028" title="Click to go to the Author Index">
             Lu, Yuhang
            </a>
           </td>
           <td class="r">
            ShanghaiTech University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423756" title="Click to go to the Author Index">
             Liu, Haiyang
            </a>
           </td>
           <td class="r">
            University of Science and Technology Beijing
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423748" title="Click to go to the Author Index">
             Liu, Jingwen
            </a>
           </td>
           <td class="r">
            University of Science and Technology Beijing
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423808" title="Click to go to the Author Index">
             Wang, Haozhe
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#311771" title="Click to go to the Author Index">
             Wang, Zhe
            </a>
           </td>
           <td class="r">
            Institute for AI Industry Research, Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351533" title="Click to go to the Author Index">
             Wang, Yan
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#374210" title="Click to go to the Author Index">
             Remondino, Fabio
            </a>
           </td>
           <td class="r">
            FBK
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#273850" title="Click to go to the Author Index">
             Ma, Yuexin
            </a>
           </td>
           <td class="r">
            ShanghaiTech University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3647" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             End-to-end autonomous driving with vision-only is not only more cost-effective compared to LiDAR-vision fusion but also more reliable than traditional methods. To achieve a economical and robust purely visual autonomous driving system, we propose RenderWorld, a vision-only end-to-end autonomous driving framework, which generates 3D occupancy labels using a self-supervised gaussian-based Img2Occ Module, then encodes the labels by AM-VAE, and use world model for forecasting and planning. RenderWorld employs Gaussian Splatting to represent 3D scenes and render 2D images greatly improves segmentation accuracy and reduces GPU memory consumption compared with NeRF-based methods. By applying AM-VAE to encode air and non-air separately, RenderWorld achieves more fine-grained scene element representation, lead- ing to state-of-the-art performance in both 4D occupancy forecasting and motion planning from autoregressive world model.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="welb1r">
             <b>
              WeLB1R
             </b>
             Poster Session, Hall A1/A2
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod930" name="modifyWeLB1R" onclick="modsession(671,930)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#welb1r" title="Click to go to the Program at a Glance">
             <b>
              Late Breaking Results 3
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_01">
             09:30-09:55, Paper WeLB1R.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod931" name="modify5232" onclick="modify(5232,931)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5232'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Dynamic Spring-Charging Locomotion Enabled by Mechanical Intelligence
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#291763" title="Click to go to the Author Index">
             Liu, Chang
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#192394" title="Click to go to the Author Index">
             Plecnik, Mark
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5232" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Repetitive subtasks of locomotion are offloaded from a conventional computer-actuator-sensor set-up to automatic mechanical processes. The subtasks considered are: (1) when out-of-contact with the environment, move a leg to a ready position in preparation for contact, and (2) when contact is detected, push off the ground. Using conventional closed loop control, subtask (1) would be accomplished by programming logic and a feedback loop onto a computer- motor-encoder system, and subtask (2) would be accomplished by sensing contact, then commanding the leg motor to push- off via programmed computer logic. We demonstrate how to transition this programmed logic from a computer processor to a mechanical processor. The mechanical processor as an example of mechanical intelligence performs preprogrammed actions based on combinations of components states, some of which are internal and some that interact with the environment. Because signals are not digital, but rather mechanical quantities of energy, position, and force; transitioning to a mechanical processor enables a third subtask not possible by the computer alone: that is, (3) the accumulation of elastic energy while out-of-contact with the environment, and its automatic release upon contact for a more powerful push-off motion. Migrating processing out of the computer allows for faster responses to dynamic events, and instantiates a high-powered reflex triggered by ground contact.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_02">
             09:30-09:55, Paper WeLB1R.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod932" name="modify5233" onclick="modify(5233,932)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5233'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Deep Learning-Based End-To-End Framework for Unified Locomotion on Powered Prostheses
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457222" title="Click to go to the Author Index">
             Shim, John
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#382389" title="Click to go to the Author Index">
             Nuesslein, Christoph
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#152924" title="Click to go to the Author Index">
             Young, Aaron
            </a>
           </td>
           <td class="r">
            Georgia Tech
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5233" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#wearable_robotics" title="Click to go to the Keyword Index">
               Wearable Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#physically_assistive_devices" title="Click to go to the Keyword Index">
               Physically Assistive Devices
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_performance_augmentation" title="Click to go to the Keyword Index">
               Human Performance Augmentation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present an end-to-end control framework for powered prostheses using temporal convolutional networks (TCNs) to map onboard sensor inputs directly to torque and position outputs. Unlike traditional hierarchical controllers that require extensive manual tuning, our approach offers a user-independent, deep learning-based solution for dynamic locomotion. Using data from 17 participants across five walking modes (i.e. level-ground, ramps, stairs), we trained two TCN models, validated via leave-one-subject-out cross-validation. Our models achieved torque RMSEs of 0.126 Nm/kg at the ankle and 0.348 Nm/kg at the knee, and position RMSEs of 2.87° and 5.64°, respectively. Corresponding R² values were 0.56 (ankle) and 0.54 (knee) for the torque model, and 0.66 (ankle) and 0.87 (knee) for the position model. The results suggest that TCNs can replicate impedance-based control outputs, taking a step closer to real-world deployability of powered prostheses.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_03">
             09:30-09:55, Paper WeLB1R.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod933" name="modify5235" onclick="modify(5235,933)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5235'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Wheel-Gripper: Multifunctional End-Effector for Wheel-Legged Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#454649" title="Click to go to the Author Index">
             Luo, Hao
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#454574" title="Click to go to the Author Index">
             Cui, Jiajun
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#192394" title="Click to go to the Author Index">
             Plecnik, Mark
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105795" title="Click to go to the Author Index">
             Goodwine, Bill
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5235" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Manipulation with legs on multi-pedal robots is not a new concept, but it has rarely been considered on wheel-legged robots due to their mechanical structure. This paper presents a mechanism that transitions between a wheel and a gripper, allowing wheel-legged robots to perform manipulation tasks with their legs. The mechanism uses the same motor for both wheeled locomotion and gripping, and no new actuator is needed for transitioning. It is capable of storing small objects, liquid, or soil while still functioning as a wheel. Our analysis showed that those distinctive modes corresponded to the factors of the complex kinematics polynomials of the mechanism. The two modes exist because the polynomials that govern the mechanism's kinematics factor. That is to say, its overall motion is the union of two lower degree irreducible components. A single-leg platform was built to demonstrate its ability to grasp objects and collect water or soil samples, and explore its capability as a contact force sensor through experiments. Such a design could enable wheel-legged robots to perform more diverse loco-manipulation tasks without installing additional limbs.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_04">
             09:30-09:55, Paper WeLB1R.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod934" name="modify5236" onclick="modify(5236,934)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5236'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              AIKIDO: Combining Inverse Kinematics and Rigid Constrained Dynamics for Online Collision Avoidance
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#333746" title="Click to go to the Author Index">
             Penzotti, Mattia
            </a>
           </td>
           <td class="r">
            The BioRobotics Institute, Scuola Superiore Sant'Anna
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#116688" title="Click to go to the Author Index">
             Controzzi, Marco
            </a>
           </td>
           <td class="r">
            Scuola Superiore Sant'Anna
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5236" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#constrained_motion_planning" title="Click to go to the Keyword Index">
               Constrained Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Artificial potential fields are used for safety in operational space control by generating repulsive forces near obstacles. They have significant limitations, like causing oscillations near obstacles or at high speeds, affecting dynamics away from unsafe areas, and needing extensive tuning to prevent local minima. Our proposed approach, AIKIDO, aims to maximise motion accuracy and minimise tuning effort, according to the principle that the collision scene geometry, plus the definition of a clearance value, naturally encodes in maximal coordinates safe and unsafe configurations and control inputs. Our key insight is that we can leverage iterative dynamics to test control inputs before applying them to the real system. In our method, the clearance value acts as an exact configurable (even at runtime) safety margin, which defines exactly the minimum allowable distance between collision shapes (e.g., a link and an obstacle). In a receding horizon fashion, we can iteratively predict near-future feasible states adhering closely to control inputs, up to necessary corrections (distance constraints). Through simulation experiments, we demonstrate unmatched motion accuracy in the proximity of obstacles and self-collisions, which enables our method to exhibit superior performance in challenging, general-purpose, arm positioning tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_05">
             09:30-09:55, Paper WeLB1R.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod935" name="modify5237" onclick="modify(5237,935)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5237'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              HARMONIC: Human-AI Robotic Team Member Operating with Natural Intelligence and Communication
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#275715" title="Click to go to the Author Index">
             Oruganti, Sanjay
            </a>
           </td>
           <td class="r">
            Rensselaer Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#410623" title="Click to go to the Author Index">
             Nirenburg, Sergei
            </a>
           </td>
           <td class="r">
            Rensselaer Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#410624" title="Click to go to the Author Index">
             McShane, Marjorie
            </a>
           </td>
           <td class="r">
            Rensselaer Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#410625" title="Click to go to the Author Index">
             English, Jesse
            </a>
           </td>
           <td class="r">
            Rensselaer Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#410626" title="Click to go to the Author Index">
             Roberts, Michael
            </a>
           </td>
           <td class="r">
            Rensselaer Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#410627" title="Click to go to the Author Index">
             Arndt, Christian
            </a>
           </td>
           <td class="r">
            Rensselaer Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#445362" title="Click to go to the Author Index">
             Kamireddy, Sahithi
            </a>
           </td>
           <td class="r">
            Rensselaer Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#211586" title="Click to go to the Author Index">
             Seo, Mingyo
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#269162" title="Click to go to the Author Index">
             Gonzalez Bolivar, Carlos Isaac
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#110037" title="Click to go to the Author Index">
             Sentis, Luis
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5237" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#cognitive_control_architectures" title="Click to go to the Keyword Index">
               Cognitive Control Architectures
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#embodied_cognitive_science" title="Click to go to the Keyword Index">
               Embodied Cognitive Science
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This poster introduces HARMONIC, a cognitive-robotic architecture that integrates the LEIA cognitive framework with general-purpose robot control systems applied to human-robot teaming (HRT). We also present a cognitive strategy for robots that incorporates metacognition, natural language communication, and explainability capabilities required for collaborative partnerships in HRT. Through our preliminary simulation experiments involving a joint search task performed by a heterogeneous team of a UGV, a drone, and a human operator, we demonstrate the system's ability to coordinate actions between robots with heterogeneous capabilities, adapt to complex scenarios, and facilitate natural human-robot communication. Evaluation results show that robots using the LEIA architecture within the HARMONIC framework can reason about plans, goals, and team member attitudes while providing clear explanations for their decisions, which are essential prerequisites for realistic human-robot teaming.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_06">
             09:30-09:55, Paper WeLB1R.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod936" name="modify5239" onclick="modify(5239,936)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5239'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enabling Seamless Teleoperation by Means of Shared Autonomy
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#333182" title="Click to go to the Author Index">
             Uliano, Manuela
            </a>
           </td>
           <td class="r">
            The BioRobotics Institute, Scuola Superiore Sant'Anna
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#116688" title="Click to go to the Author Index">
             Controzzi, Marco
            </a>
           </td>
           <td class="r">
            Scuola Superiore Sant'Anna
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5239" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Sharing control with an autonomous controller is a promising approach to reduce the operator's workload and enhance performance in the execution of complex tasks. To assist the operator, the autonomous controller must predict their intention, by monitoring biological signals. In natural manipulation, eye movements play an anticipatory role, making gaze a meaningful signal for decoding human intent. However, the role of gaze in teleoperation remains unclear. We investigated this by analyzing gaze behavior during a teleoperated task, finding that participants directed their gaze toward task-relevant areas, with fixations also on the hand or the moving object. Once the user’s intention is inferred, the robot should assist by autonomously executing actions such as grasping. To this end, we propose a human-inspired reasoning algorithm that reasons about the optimal grasping strategy. The agreement between the decisions of our reasoning algorithm and human behavior in grasping was assessed through a questionnaire in which participants expressed their preferences on how to grasp objects. A significant alignment was observed across most tested conditions. The observed misalignments highlight the importance of balancing the principles that guide human grasping with the needs of robots. In conclusion, by combining the prediction of the human intention with a human-inspired reasoning algorithm for grasp selection, we aim to enhance the collaboration between human operators and robots.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_07">
             09:30-09:55, Paper WeLB1R.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod937" name="modify5240" onclick="modify(5240,937)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5240'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhancing Sim-To-Real Transfer in High Gear Ratio Quadruped Robot Via Short-Term Temporal Information
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#211274" title="Click to go to the Author Index">
             Kang, Hansol
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#169507" title="Click to go to the Author Index">
             Lee, Hyunyong
            </a>
           </td>
           <td class="r">
            AIDIN ROBOTICS
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#281099" title="Click to go to the Author Index">
             Park, Ji Man
            </a>
           </td>
           <td class="r">
            SungKyunKwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395295" title="Click to go to the Author Index">
             Nam, SeongWon
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395143" title="Click to go to the Author Index">
             Son, YeongWoo
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395260" title="Click to go to the Author Index">
             Yi, Bumsu
            </a>
           </td>
           <td class="r">
            SungKyunKwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395262" title="Click to go to the Author Index">
             Oh, JaeYoung
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#404898" title="Click to go to the Author Index">
             Kim, Bogeun
            </a>
           </td>
           <td class="r">
            Sungkyunkwn University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#434275" title="Click to go to the Author Index">
             Song, Daegeun
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102438" title="Click to go to the Author Index">
             Choi, Hyouk Ryeol
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5240" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Reinforcement learning (RL)-based robot control has emerged as a promising approach. However, the transition between simulation and real situations remains a critical challenge, especially for robots equipped with high-speed actuators. To address this issue, we integrate an ideal BLDC motor model into the simulation and introduce Time Delay Neural Network (TDNN) that accumulates multiple observations over time. The motor modeling allows us to bridge the gap between simulation and reality, and the TDNN allows the policy to implicitly learn the internal nonlinearities of the actuators. In addition, we introduce an estimator network that simultaneously predicts the robot’s terrain height, foot-ground contact state, and body linear velocity. By combining this estimator with an asymmetric actor-critic architecture and concurrently training it, the trained policy demonstrates that the robot can climb stairs of 17 cm in height and descend stairs of up to 27.5 cm, demonstrating an effective transition from simulation to real situations.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_08">
             09:30-09:55, Paper WeLB1R.8
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod938" name="modify5241" onclick="modify(5241,938)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5241'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Phasing through the Flames: Rapid Motion Planning with the AGHF PDE for Arbitrary Objective Functions and Constraints
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#318368" title="Click to go to the Author Index">
             Enninful Adu, Challen
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#433692" title="Click to go to the Author Index">
             Ramos Chuquiure, Cesar Eduardo
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#279054" title="Click to go to the Author Index">
             Zhang, Bohao
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#187525" title="Click to go to the Author Index">
             Vasudevan, Ram
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5241" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#whole_body_motion_planning_and_control" title="Click to go to the Keyword Index">
               Whole-Body Motion Planning and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The generation of optimal trajectories for high-dimensional robotic systems under constraints remains computationally challenging due to the need to simultaneously satisfy dynamic feasibility, input limits, and task-specific objectives while searching over high-dimensional spaces. Recent approaches using the Affine Geometric Heat Flow (AGHF) Partial Differential Equation (PDE) have demonstrated promising results, generating dynamically feasible trajectories for complex systems like the Digit V3 humanoid within seconds. These methods efficiently solve trajectory optimization problems over a two-dimensional domain by evolving an initial trajectory to minimize control effort. However, these AGHF approaches are limited to a single type of optimal control problem (i.e., minimizing the integral of squared control norms) and typically require initial guesses that satisfy constraints to ensure satisfactory convergence. These limitations restrict the potential utility of the AGHF PDE especially when trying to synthesize trajectories for robotic systems. This paper generalizes the AGHF formulation to accommodate arbitrary cost functions, significantly expanding the classes of trajectories that can be generated. This work also introduces a Phase 1 - Phase 2 Algorithm that enables the use of constraint-violating initial guesses while guaranteeing satisfactory convergence. The effectiveness of the proposed method is demonstrated through comparative evaluations.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_09">
             09:30-09:55, Paper WeLB1R.9
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod939" name="modify5242" onclick="modify(5242,939)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5242'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Heuristic Graphs for Path Planning in Obstacle Fields
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457451" title="Click to go to the Author Index">
             Levin, Winston
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5242" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#nonholonomic_motion_planning" title="Click to go to the Keyword Index">
               Nonholonomic Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A kinematic (turn-radius-constrained) vehicle captures the relevant dynamics for global path planning around obstacle fields for many applications. More advanced trajectory optimizers can also use these paths as their initial guess. However, state-of-the-art heuristic graph planners ignore U-turn arcs which may result from the turn radius constraint of the vehicle and sampling-based graphs optimize the path very slowly. These heuristic graphs rapidly find the globally optimal path in cases where the vehicle’s turn radius is large compared to its environment.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_10">
             09:30-09:55, Paper WeLB1R.10
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod940" name="modify5243" onclick="modify(5243,940)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5243'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Torque-Dense Low-Impedance Powered Knee Exoskeleton with Torque-Sensitive Actuation and Direct Ball-Screw Drive
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#314045" title="Click to go to the Author Index">
             Ortolano, Brendon
            </a>
           </td>
           <td class="r">
            University of Utah
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#387493" title="Click to go to the Author Index">
             Pruyn, Kai
            </a>
           </td>
           <td class="r">
            University of Utah
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#234080" title="Click to go to the Author Index">
             Gabert, Lukas
            </a>
           </td>
           <td class="r">
            University of Utah
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#117932" title="Click to go to the Author Index">
             Lenzi, Tommaso
            </a>
           </td>
           <td class="r">
            University of Utah
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5243" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#wearable_robotics" title="Click to go to the Keyword Index">
               Wearable Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#prosthetics_and_exoskeletons" title="Click to go to the Keyword Index">
               Prosthetics and Exoskeletons
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Powered exoskeletons aim to improve human mobility by assisting the user’s biological limbs with robotic actuators. However, conventional robotic actuators with a fixed transmission ratio suffer from an inherent trade-off between motor size, output inertia, and output torque. Therefore, powered exoskeletons utilizing conventional actuators are typically heavy and loud with high joint impedance or lack sufficient torque and power to meaningfully assist the user in challenging activities. These drawbacks significantly diminish the net benefit of wearing powered exoskeletons, limiting their clinical success.
             <p>
              In this poster, we present a powered knee exoskeleton that combines a direct-ball screw drive with a variable transmission in a novel torque-sensitive actuator. Benchtop experiments confirm the actuator’s high torque density, low impedance, and quiet operation. Preliminary able-bodied human subject testing verifies the ability of the exoskeleton to provide a significant portion of the user’s biological torque and power in multiple activities. By enabling lightweight, quiet, and powerful exoskeletons, the proposed actuation concept has the potential to improve the clinical benefits of powered knee exoskeletons.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_11">
             09:30-09:55, Paper WeLB1R.11
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod941" name="modify5244" onclick="modify(5244,941)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5244'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Modeling Underactuated Swimmers in Granular Fluid Using Geometric Mechanics
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457329" title="Click to go to the Author Index">
             Chapnik, Zvi
            </a>
           </td>
           <td class="r">
            Technion
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102497" title="Click to go to the Author Index">
             Or, Yizhar
            </a>
           </td>
           <td class="r">
            Technion
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#145648" title="Click to go to the Author Index">
             Revzen, Shai
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5244" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#underactuated_robots" title="Click to go to the Keyword Index">
               Underactuated Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#nonholonomic_mechanisms_and_systems" title="Click to go to the Keyword Index">
               Nonholonomic Mechanisms and Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Geometric mechanics provides valuable insights into how biological and robotic systems use changes in shape to move by mechanically interacting with their environment. This perspective produced an approach for obtaining simplified data-driven models for locomotion systems directly from motion tracking data. Here we focus on the locomotion of under-actuated robotic systems with passive shape degrees of freedom (DoF), interacting with a granular fluid - a regime we intentionally selected because it is hard to model.	We compared four modeling approaches, predicting body velocity both within gait and across gaits. Switching our model from a phase dependent linear model to a manifold learning approach reduced velocity prediction error by 55% but required 6 times as much data; including the passive DoF in the models reduced prediction errors by 4%. These improvements compound, and yield overall R^2 values above 90%, demonstrating that our data-driven geometric mechanics models for locomotion systems can produce highly predictive models even where no first principles equations of motion are known.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_12">
             09:30-09:55, Paper WeLB1R.12
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod942" name="modify5245" onclick="modify(5245,942)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5245'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Towards an Understanding of Robotic Bin-Picking Throughput
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457338" title="Click to go to the Author Index">
             Krishnan Komaralingam, Anirudh
            </a>
           </td>
           <td class="r">
            National Institute of Standards and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457337" title="Click to go to the Author Index">
             Prem, Rachakonda
            </a>
           </td>
           <td class="r">
            National Institute of Standards and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#217318" title="Click to go to the Author Index">
             Saidi, Kamel
            </a>
           </td>
           <td class="r">
            National Institute of Standards and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457339" title="Click to go to the Author Index">
             Khatoonabadi, Armin
            </a>
           </td>
           <td class="r">
            Tisfoon Group‎
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5245" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#assembly" title="Click to go to the Keyword Index">
               Assembly
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             NIST leads and supports multiple efforts to develop standards for 3D imaging systems used for industrial automation through ASTM subcommittee E57.23 on Industrial 3D Machine Vision Systems. One of these standards aims to measure the performance of robotic bin-picking systems and NIST has established a testbed with six different bin-picking systems that use a variety of technologies. A working group led by industry experts, is formulating the metrics, artifacts, and test methods to evaluate bin-picking systems. NIST is supporting this effort by performing tests, analyzing data, and developing artifacts. The effort has proposed definitions for terms such as bin-picking vision system, robot cycle time, vision cycle time (VCT), total cycle time (TCT), and bin-picking throughput. NIST conducted tests to understand the effects on a bin-picking system’s throughput of task parameters such as part count, bin depth, part position in bin, part location in FoV, and part geometry/complexity, while keeping vision system parameters constant. Preliminary results based on a representative 3D imaging system show that VCT increases when part number &gt; 10, is not correlated to bin depth or part location, and has slight correlation with robot position and access within a bin. Results also showed that TCT and throughput are strongly correlated with part complexity/symmetry.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_13">
             09:30-09:55, Paper WeLB1R.13
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod943" name="modify5246" onclick="modify(5246,943)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5246'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design and Implementation of a Low-Profile Hip Exoskeleton for Ergonomics Assistance in Lifting and Ambulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457474" title="Click to go to the Author Index">
             Prime, Jesse
            </a>
           </td>
           <td class="r">
            University of Utah
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#255430" title="Click to go to the Author Index">
             Murray, Rosemarie
            </a>
           </td>
           <td class="r">
            University of Utah
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#117932" title="Click to go to the Author Index">
             Lenzi, Tommaso
            </a>
           </td>
           <td class="r">
            University of Utah
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5246" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#prosthetics_and_exoskeletons" title="Click to go to the Keyword Index">
               Prosthetics and Exoskeletons
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#wearable_robotics" title="Click to go to the Keyword Index">
               Wearable Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Workplace injuries cost the United States over 160 billion dollars annually. Of these workplace injuries, approximately 29% are musculoskeletal disorders (MSDs). Previous research has shown that both passive and active exoskeletons can reduce muscle activation for a wide variety of tasks, increase lifting endurance, and decrease the risk of MSDs. Passive exoskeletons tend to be low-profile but have less ability to adapt to multiple movements and use cases, whereas powered exoskeletons can be controlled to benefit multiple movements at the expense of larger size. Here, we propose the design of a low-profile and high torque-density, powered hip and back support exoskeleton to assist with ergonomics in a range of workplace tasks. By assisting the lower back and hips, we aim to reduce muscle effort in lifting tasks, reduce the risk of MSD, and reduce the exertion required for ambulation. According to dynamic simulations, our proposed actuator achieves torques up to 34 Nm of hip torque, representing approximately 35% of the biological torque required for squatting/lifting movement for an average US male. The actuator can also provide up to 31%, 87%, and 35% of the torque required for walking, stair ascent, and stair descent, respectively. The actuator is compatible with exoskeleton interfaces from the on-market IX Back Air (SuitX, USA), which allows for easy donning and doffing. The device adds just 2.8 cm laterally to the body and does not interfere with sitting.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_14">
             09:30-09:55, Paper WeLB1R.14
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod944" name="modify5247" onclick="modify(5247,944)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5247'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Structurally Decoupled Capacitive Sensing Unit for a Compact Six-Axis FT Sensor
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#233206" title="Click to go to the Author Index">
             Lee, Seung Yeon
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#356231" title="Click to go to the Author Index">
             Sim, Jae Yoon
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University, AIDIN ROBOTICS
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#192032" title="Click to go to the Author Index">
             Seok, Dong-Yeop
            </a>
           </td>
           <td class="r">
            AIDIN ROBOTICS Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#346197" title="Click to go to the Author Index">
             Kim, Yong Bum
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102438" title="Click to go to the Author Index">
             Choi, Hyouk Ryeol
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5247" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#compliant_joints_and_mechanisms" title="Click to go to the Keyword Index">
               Compliant Joints and Mechanisms
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A capacitive-type force/torque sensor (FTS) is particularly advantageous for compact and miniature designs. However, miniaturizing the sensor introduces several challenges, such as imbalanced sensitivity that leads to increased coupling errors and a reduced electrode area, which degrades sensing performance and measurement sensitivity. Typically, a six-axis FTS requires at least six electrode components, each dedicated to independently detecting force and torque along normal and shear directions. However, distinguishing and placing electrodes for normal and shear detection becomes spatially inefficient and impractical in miniaturized designs. To address these limitations, we propose a structurally decoupled compliant structure. This structure enables independent measurement along four axes—three for force and one for torque. Furthermore, we present a simplified capacitive sensing approach that does not require the separation of electrodes by direction. Instead, flat electrodes are attached directly to the compliant structure. By isotropically arranging these sensing components, an assembled compact sensing unit capable of six-axis force-torque measurement is realized. This paper presents the proposed capacitive sensing unit's design concept and simulation results.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_15">
             09:30-09:55, Paper WeLB1R.15
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod945" name="modify5248" onclick="modify(5248,945)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             Toward Reliable Bin-Picking: Collision-Aware Robotic Design and Control Strategy for Heavily Cluttered Environment
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#355920" title="Click to go to the Author Index">
             Um, Seunghwan
            </a>
           </td>
           <td class="r">
            SungKyunKwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#344462" title="Click to go to the Author Index">
             Son, Yeong Gwang
            </a>
           </td>
           <td class="r">
            SungKyunKwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#385339" title="Click to go to the Author Index">
             Shim, Jaeyoon
            </a>
           </td>
           <td class="r">
            sungkyunkwan university
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102438" title="Click to go to the Author Index">
             Choi, Hyouk Ryeol
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_16">
             09:30-09:55, Paper WeLB1R.16
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod946" name="modify5249" onclick="modify(5249,946)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5249'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Lightweight, Fully Integrated Ankle Exoskeleton with High-Torque Density Series-Elastic Actuation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#387493" title="Click to go to the Author Index">
             Pruyn, Kai
            </a>
           </td>
           <td class="r">
            University of Utah
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#242067" title="Click to go to the Author Index">
             Sarkisian, Sergei
            </a>
           </td>
           <td class="r">
            University of Utah
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#314045" title="Click to go to the Author Index">
             Ortolano, Brendon
            </a>
           </td>
           <td class="r">
            University of Utah
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#255430" title="Click to go to the Author Index">
             Murray, Rosemarie
            </a>
           </td>
           <td class="r">
            University of Utah
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#234080" title="Click to go to the Author Index">
             Gabert, Lukas
            </a>
           </td>
           <td class="r">
            University of Utah
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#117932" title="Click to go to the Author Index">
             Lenzi, Tommaso
            </a>
           </td>
           <td class="r">
            University of Utah
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5249" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#prosthetics_and_exoskeletons" title="Click to go to the Keyword Index">
               Prosthetics and Exoskeletons
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#wearable_robotics" title="Click to go to the Keyword Index">
               Wearable Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Powered ankle exoskeletons have the potential to improve mobility by assisting the ankle joint during ambulation. To achieve this goal, ankle exoskeletons must provide substantial assistive torque in a small and lightweight form. Unfortunately, most exoskeletons are too heavy and bulky for practical application. They often lack protective covers and require wearing a backpack with wires running down the user’s legs, lessening their robustness and utility in the real world. This poster presents a lightweight and compact powered ankle exoskeleton with fully integrated and enclosed actuation, batteries, and electronics. The proposed design features a linear series-elastic actuator (SEA), achieving high torque/power density while enabling high-fidelity closed-loop torque control. The proposed ankle exoskeleton was investigated using a variable stiffness impedance controller with three healthy subjects walking on a treadmill. The results of benchtop experiments show a -3 dB bandwidth exceeding 19 Hz. The results of experiments with healthy subjects show a torque density of 37 Nm/kg and a power density of 81.5 W/kg. Experiments with one stroke subject demonstrate that exoskeleton assistance results in more normative ankle and knee kinematics and increases foot clearance. This compact and lightweight ankle exoskeleton design satisfies practical requirements for real-world use while providing sufficient torque density to improve mobility.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_17">
             09:30-09:55, Paper WeLB1R.17
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod947" name="modify5250" onclick="modify(5250,947)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5250'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Data-Driven Contact-Aware Control Method for Real-Time Deformable Tool Manipulation: A Case Study in the Environmental Swabbing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457256" title="Click to go to the Author Index">
             Mahmoudi, Siavash
            </a>
           </td>
           <td class="r">
            University of Arkansas at Fayetteville
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#413738" title="Click to go to the Author Index">
             Wang, Dongyi
            </a>
           </td>
           <td class="r">
            University of Arkansas
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5250" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#force_control" title="Click to go to the Keyword Index">
               Force Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Deformable Object Manipulation (DOM) remains a critical challenge in robotics due to the complexities of developing suitable model-based control strategies. Deformable Tool Manipulation (DTM) further complicates this task by introducing additional uncertainties between the robot and its environment. While humans effortlessly manipulate deformable tools using touch and experience, robotic systems struggle to maintain stability and precision. To address these challenges, we present a novel State-Adaptive Koopman LQR (SA-KLQR) control framework for real-time deformable tool manipulation, demonstrated through a case study in environmental swab sampling for food safety. This method leverages Koopman operator-based control to linearize nonlinear dynamics while adapting to state-dependent variations in tool deformation and contact forces. A tactile-based feedback system dynamically estimates and regulates the swab tool’s angle, contact pressure, and surface coverage, ensuring compliance with food safety standards. Additionally, a sensor-embedded contact pad monitors force distribution to mitigate tool pivoting and deformation, improving stability during dynamic interactions. Experimental results validate the SA-KLQR approach, demonstrating accurate contact angle estimation, robust trajectory tracking, and reliable force regulation. The proposed framework bridging the gap between data-driven learning and optimal control in robotic interaction tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_18">
             09:30-09:55, Paper WeLB1R.18
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod948" name="modify5252" onclick="modify(5252,948)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5252'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Variable Size and Variable Stiffness Particles for Reconfigurable Granular Metamaterials
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#274991" title="Click to go to the Author Index">
             Li, Monica
            </a>
           </td>
           <td class="r">
            Yale University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#221629" title="Click to go to the Author Index">
             Do, Brian
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457479" title="Click to go to the Author Index">
             Le, Caitlin L.
            </a>
           </td>
           <td class="r">
            Yale University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457480" title="Click to go to the Author Index">
             O'Hern, Corey S.
            </a>
           </td>
           <td class="r">
            Yale University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#141983" title="Click to go to the Author Index">
             Kramer-Bottiglio, Rebecca
            </a>
           </td>
           <td class="r">
            Yale University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5252" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft robots can achieve exceptional adaptability through tunable morphological and mechanical properties. Incorporating materials with dynamically adjustable characteristics can enhance this versatility further. Granular metamaterials, consisting of discrete particles with individually variable properties, offer a promising approach to bulk property adaptation by adjusting the properties of constituent particles. This work introduces variable size and variable stiffness (VS
             <sup>
              2
             </sup>
             ) particles, in which both particle size and stiffness are independently modulated through concentric pneumatic chambers. We characterize the achievable workspace, mapping particle responses to independent chamber inflation. To demonstrate their use in a granular assembly, we arrange an array of VS
             <sup>
              2
             </sup>
             particles in a 2D hexagonal packing and validate that behavior in packed configurations aligns with free-space characterizations. This study establishes a foundation for adaptive granular materials and provides a platform for further computational and experimental exploration of granular metamaterials with tunable properties.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_19">
             09:30-09:55, Paper WeLB1R.19
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod949" name="modify5253" onclick="modify(5253,949)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5253'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LatentBKI: Open-Dictionary Continuous Mapping in Visual-Language Latent Spaces with Quantifiable Uncertainty
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#314334" title="Click to go to the Author Index">
             Wilson, Joseph
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#381664" title="Click to go to the Author Index">
             Xu, Ruihan
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#428804" title="Click to go to the Author Index">
             Sun, Yile
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#283514" title="Click to go to the Author Index">
             Ewen, Parker
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#250121" title="Click to go to the Author Index">
             Zhu, Minghan
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#151696" title="Click to go to the Author Index">
             Barton, Kira
            </a>
           </td>
           <td class="r">
            University of Michigan at Ann Arbor
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#131371" title="Click to go to the Author Index">
             Ghaffari, Maani
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5253" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#probabilistic_inference" title="Click to go to the Keyword Index">
               Probabilistic Inference
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a novel probabilistic mapping algorithm, LatentBKI, which enables open-vocabulary mapping with quantifiable uncertainty. Traditionally, semantic mapping algorithms focus on a fixed set of semantic categories which limits their applicability for complex robotic tasks. Vision-Language (VL) models have recently emerged as a technique to jointly model language and visual features in a latent space, enabling semantic recognition beyond a predefined, fixed set of semantic classes. LatentBKI recurrently incorporates neural embeddings from VL models into a voxel map with quantifiable uncertainty, leveraging the spatial correlations of nearby observations through Bayesian Kernel Inference (BKI). LatentBKI is evaluated against similar explicit semantic mapping and VL mapping frameworks on the popular Matterport3D and Semantic KITTI datasets, demonstrating that LatentBKI maintains the probabilistic benefits of continuous mapping with the additional benefit of open-dictionary queries. Real-world experiments demonstrate applicability to challenging indoor environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_20">
             09:30-09:55, Paper WeLB1R.20
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod950" name="modify5254" onclick="modify(5254,950)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5254'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Dynamic Parabolic CBF: Collision Avoidance in Multiple Dynamic Obstacle Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457399" title="Click to go to the Author Index">
             Park, Hun Kuk
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#295276" title="Click to go to the Author Index">
             Kim, Taekyung
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103171" title="Click to go to the Author Index">
             Panagou, Dimitra
            </a>
           </td>
           <td class="r">
            University of Michigan, Ann Arbor
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5254" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#nonholonomic_motion_planning" title="Click to go to the Keyword Index">
               Nonholonomic Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The safe navigation of nonholonomic robots in environments filled with dynamic obstacles requires control strategies that not only guarantee collision-free trajectories but also adapt to real-time changes. In this work, we introduce a novel Control Barrier Function candidate-the Dynamic Parabolic Control Barrier Function (DPCBF)-designed for the kinematic bicycle model. Unlike traditional approaches such as the collision cone-based CBF (C3BF), which relies on a fixed geometric safety boundary and can become overly conservative under high obstacle density, the DPCBF dynamically adjusts the safe set. By redefining safety in a rotated coordinate frame where the x-axis aligns with the relative position vector between the robot and an obstacle, the DPCBF employs a parabolic function whose curvature and translation are tuned according to the current relative distance and velocity. Extensive simulation studies demonstrate that the DPCBF outperforms the conventional C3BF by maintaining feasibility within the quadratic programming (QP) formulation under scenarios with both static and multiple moving obstacles. The adaptive nature of the parabolic safe set allows the robot to respond effectively to varying collision risks, ensuring fewer QP infeasibilities and more reliable navigation towards the goal.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_21">
             09:30-09:55, Paper WeLB1R.21
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod951" name="modify5256" onclick="modify(5256,951)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5256'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Automatic Cognitive Fatigue Assessment Using Wearable Physiological Sensors During Human-Robot Interaction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#428899" title="Click to go to the Author Index">
             Zand, Manizheh
            </a>
           </td>
           <td class="r">
            Santa Clara University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#195306" title="Click to go to the Author Index">
             Kyrarini, Maria
            </a>
           </td>
           <td class="r">
            Santa Clara University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5256" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_factors_and_human_in_the_loop" title="Click to go to the Keyword Index">
               Human Factors and Human-in-the-Loop
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#design_and_human_factors" title="Click to go to the Keyword Index">
               Design and Human Factors
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             As assistive robots increasingly support Activities of Daily Living (ADLs), real-time Cognitive Fatigue (CF) assessment is crucial for safety and performance in Human-Robot Interaction (HRI). Existing approaches often lack multimodal sensing, continuous estimation, or adaptive mechanisms. This study presents a novel framework for automatic CF assessment using data from wearable physiological sensors, such as Electrocardiography (ECG) and Electrodermal Activity (EDA), collected from 16 participants while performing collaborative ADL tasks with a mobile manipulator. CF was induced via N-back tasks and validated using the Visual Analogue Scale for Fatigue (VAS-F). Machine learning models, including Random Forest Regressor (RFR), Support Vector Regression (SVR), and Gradient Boosting Machine (GBM) were applied using the epoch-based pipeline. RFR achieved the highest accuracy in predicting the VAS-F score using only ECG data (R² = 0.89, RMSE = 4.13) and by combining ECG and EDA data (R² = 0.89, RMSE = 4.85). These findings demonstrate the feasibility of continuous CF estimation with wearable sensors. This offline modeling serves as a foundation for integrating real-time adaptation in assistive robotics, enabling personalized and safer HRI.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_22">
             09:30-09:55, Paper WeLB1R.22
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod952" name="modify5257" onclick="modify(5257,952)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5257'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Using VR As an Evaluation Tool for Robot-To-Human Communication in Underwater Tasks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#445123" title="Click to go to the Author Index">
             Major, Rachel Alejandra
            </a>
           </td>
           <td class="r">
            University of Massachusetts Lowell
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#127496" title="Click to go to the Author Index">
             Cabrera, Maria Eugenia
            </a>
           </td>
           <td class="r">
            University of Massachusetts Lowell
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5257" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#virtual_reality_and_interfaces" title="Click to go to the Keyword Index">
               Virtual Reality and Interfaces
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Working underwater presents many challenges for human divers; however, the assistance of an underwater robot has the potential to reduce risks by collaborating with a diver and reducing the workload. This work presents a virtual reality (VR) application that simulates a BlueROV2, an underwater robot, to implement and evaluate an underwater robot-to-human interaction scenario, with the aim of improving the effectiveness of communication underwater while collaborating on an inspection and manipulation task. The use of VR allows for more repeatable assessments of robotic performance, with lower risks associated to human users, while providing a level of immersion in the task that compares to humans being underwater wearing goggles. By developing an immersive VR game, combined with Wizard-of-Oz techniques which allow for structured scenarios where the robot can be triggered to interrupt at varying points in the collaboration task, the effects of attention-grabbing strategies and the choices of signal set on human performance can be assessed, as well as the robot’s ability to redirect a human collaborator in underwater tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_23">
             09:30-09:55, Paper WeLB1R.23
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod953" name="modify5258" onclick="modify(5258,953)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5258'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Integrated Aerial Manipulation: A Dual-Shovel Drone System for Object Detection and Retrieval
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#344308" title="Click to go to the Author Index">
             Senevirathna, Nilupul Nuwan
            </a>
           </td>
           <td class="r">
            Shibaura Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#430663" title="Click to go to the Author Index">
             Sarathchandra, H.A.H.Y.
            </a>
           </td>
           <td class="r">
            Shibaura Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#178324" title="Click to go to the Author Index">
             Premachandra, Chinthaka
            </a>
           </td>
           <td class="r">
            Shibaura Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5258" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dual_arm_manipulation" title="Click to go to the Keyword Index">
               Dual Arm Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study presents a drone-mounted dual-arm shovel system designed for efficient object retrieval in complex and remote environments. Addressing key challenges—such as object detection, spatial localization, precision landing, adaptive gripping, and stable airborne transport—the system integrates a rotating camera, servo-driven shovels, and an onboard computer running a deep learning-based detection model. Through synchronized motion and iterative multi-angle analysis, the system accurately identifies, assesses, and retrieves target objects. Experimental validation demonstrates reliable performance in detecting, grasping, weighing, and transporting various items. This work lays the foundation for advanced aerial manipulation, expanding the potential of drones in remote search, recovery, and logistics applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_24">
             09:30-09:55, Paper WeLB1R.24
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod954" name="modify5259" onclick="modify(5259,954)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5259'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Quantitative Evaluation Method of the Performance of a Robotic Hand with Reduced Degrees of Freedom
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#355924" title="Click to go to the Author Index">
             Kim, ChunSoo
            </a>
           </td>
           <td class="r">
            SKKU
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#179692" title="Click to go to the Author Index">
             Jung, Hosang
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102438" title="Click to go to the Author Index">
             Choi, Hyouk Ryeol
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5259" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#humanoid_robot_systems" title="Click to go to the Keyword Index">
               Humanoid Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic hands inspired by human anatomy are being developed in various forms to perform diverse manipulation tasks. However, faithfully replicating the human hand—comprising complex structures and numerous degrees of freedom (DoFs)—leads to increased manufacturing cost and complexity. In practice, not all DoFs are necessary for every task, and simplified designs often omit or couple certain joints to enhance efficiency. Designing such hands requires a careful balance between task capability and mechanical simplicity, which in turn calls for a quantitative framework to guide DoF configuration based on task requirements.
             <p>
              In this study, we propose a method for quantitatively analyzing the task performance of robotic hands with reduced DoFs. By introducing a joint-task matrix that captures the contribution of individual joints to specific tasks, and deriving a joint coupling matrix to reveal dependencies between joints, we provide a systematic approach to evaluate hand configurations. This enables decision-making based on quantitative evaluation when designing simplified robotic hands tailored to specific functional needs.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_25">
             09:30-09:55, Paper WeLB1R.25
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod955" name="modify5260" onclick="modify(5260,955)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5260'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Preliminary Results for the Estimation of Minimum Stride Frequency for Frontal Plane Stability
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#223319" title="Click to go to the Author Index">
             Karunanayaka, Harsha
            </a>
           </td>
           <td class="r">
            University of Denver
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#140408" title="Click to go to the Author Index">
             Rezazadeh, Siavash
            </a>
           </td>
           <td class="r">
            University of Denver
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5260" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#passive_walking" title="Click to go to the Keyword Index">
               Passive Walking
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The stability of bipedal system during walking or running depends on both the sagittal and frontal plane dynamics. In the frontal plane, the stability is affected by the hip offset, to the extent that adjusting stride time can lead to stable oscillations without active control, which can reduce the control effort and energy expenditure. However, there is limited understanding of how key parameters—such as mass, stiffness, leg length, and hip width—affect stability and the minimum stride frequency needed to maintain it. This study aims to address these gaps through analying how individual model parameters and the system's natural frequency influence the minimum stride frequency required for stable locomotion. Stability is evaluated through eigenvalue analysis of the linearized Poincaré map. We propose a method to predict the minimum stride frequency for various models, and compare predicted stride frequencies with actual values for randomly generated models, showing a maximum error of approximately 1%.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_26">
             09:30-09:55, Paper WeLB1R.26
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod956" name="modify5261" onclick="modify(5261,956)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5261'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Lazy-DaSH: Lazy Approach for Hypergraph-Based Multi-Robot Task and Motion Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#410604" title="Click to go to the Author Index">
             Seongwon, Lee
            </a>
           </td>
           <td class="r">
            University of Illinois, Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#237863" title="Click to go to the Author Index">
             Motes, James
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#331230" title="Click to go to the Author Index">
             Ngui, Isaac
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105498" title="Click to go to the Author Index">
             Morales, Marco
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign &amp; Instituto Tecnológico
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102662" title="Click to go to the Author Index">
             Amato, Nancy
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5261" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce Lazy-DaSH, an improvement over the recent state of the art multi-robot task and motion planning method DaSH, which scales to more than twice the number of robots and objects while achieving an order of magnitude faster planning when applied to a multi-manipulator object rearrangement problem. We achieve this improvement through a hierarchical approach, where a high-level task planning layer identifies planning spaces required for task completion, and motion feasibility is validated lazily only within these spaces. In contrast, DaSH precomputes the motion feasibility of all possible actions, resulting in higher costs for constructing state space representations. Lazy-DaSH ensures efficient query performance by utilizing a hierarchical constraint feedback mechanism, effectively conveying motion feasibility to the query process. By maintaining smaller state space representations, our method significantly reduces both representation construction time and query time. We evaluate Lazy-DaSH in two scenarios, demonstrating its scalability with increasing numbers of robots and objects, as well as its adaptability in resolving conflicts through the constraint feedback.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_27">
             09:30-09:55, Paper WeLB1R.27
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod957" name="modify5262" onclick="modify(5262,957)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5262'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Physically-Feasible Reactive Synthesis for Terrain-Adaptive Locomotion Via Trajectory Optimization and Symbolic Repair
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#269819" title="Click to go to the Author Index">
             Zhou, Ziyi
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#369833" title="Click to go to the Author Index">
             Meng, Qian
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103643" title="Click to go to the Author Index">
             Kress-Gazit, Hadas
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#158317" title="Click to go to the Author Index">
             Zhao, Ye
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5262" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#formal_methods_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Formal Methods in Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose an integrated planning framework for quadrupedal locomotion over dynamically changing, unforeseen terrains. Existing approaches either rely on heuristics for instantaneous foothold selection--compromising safety and versatility--or solve expensive trajectory optimization problems with complex terrain features and long time horizons. In contrast, our framework leverages reactive synthesis to generate correct-by-construction controllers at the symbolic level, and mixed-integer convex programming (MICP) for dynamic and physically feasible footstep planning for each symbolic transition. We use a high-level manager to reduce the large state space in synthesis by incorporating local environment information, improving synthesis scalability. To handle specifications that cannot be met due to dynamic infeasibility, and to minimize costly MICP solves, we leverage a symbolic repair process to generate only necessary symbolic transitions. During online execution, re-running the MICP with real-world terrain data, along with runtime symbolic repair, bridges the gap between offline synthesis and online execution. We demonstrate, in simulation, our framework's capabilities to discover missing locomotion skills and react promptly in safety-critical environments, such as scattered stepping stones and rebars.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_28">
             09:30-09:55, Paper WeLB1R.28
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod958" name="modify5263" onclick="modify(5263,958)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5263'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              FALA: Formally Augmented Language Agent
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422028" title="Click to go to the Author Index">
             Byrd, Grayson
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#266873" title="Click to go to the Author Index">
             Rivera, Corban
            </a>
           </td>
           <td class="r">
            Johns Hopkins University Applied Physics Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#342283" title="Click to go to the Author Index">
             Booker, Meghan
            </a>
           </td>
           <td class="r">
            Princeton University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424648" title="Click to go to the Author Index">
             Schmidt, Aurora
            </a>
           </td>
           <td class="r">
            Johns Hopkins University Applied Physic Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422684" title="Click to go to the Author Index">
             Kemp, Bethany
            </a>
           </td>
           <td class="r">
            Johns Hopkins Applied Physics Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#279734" title="Click to go to the Author Index">
             Seenivasan, Lalithkumar
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#219453" title="Click to go to the Author Index">
             Unberath, Mathias
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5263" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#agent_based_systems" title="Click to go to the Keyword Index">
               Agent-Based Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent progress in using Large Language Models (LLMs) for embodied task planning has yielded impressive results in unconstrained environments. However, their inherent unreliability—particularly due to hallucinated or inconsistent action predictions—remains a significant challenge. In contrast, formal planning methods offer strong reliability guarantees through explicit logical representations of the environment, but struggle to scale to the complexity and ambiguity of open-world tasks. This work explores the complementary strengths of these paradigms. We introduce the Formally Augmented Language Agent (FALA), a hybrid task planning framework that defers to formal methods when possible for robust decision-making, and invokes LLM reasoning only when symbolic representations fall short. This principled integration yields both high reliability and flexibility. We evaluate FALA extensively on the ALFRED benchmark for embodied task planning, achieving a 99% task completion rate using GPT-4o—substantially outperforming prior methods in both accuracy and robustness. Through ablation studies, we demonstrate that the addition of FALA's Precondition Verification and Domain Independent Planner to a zero-shot LLM agent significantly improves overall planning performance by an average of ~40% and ~60%, respectively, across 7 different LLM backbones on the ALFRED benchmark. We believe this work represents a major step towards more efficient and reliable LLM planning
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_29">
             09:30-09:55, Paper WeLB1R.29
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod959" name="modify5264" onclick="modify(5264,959)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5264'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Solving for Constraint Manifolds Using Neural Networks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#359292" title="Click to go to the Author Index">
             Clark, Landon
            </a>
           </td>
           <td class="r">
            University of Kentucky
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#140882" title="Click to go to the Author Index">
             Xie, Biyun
            </a>
           </td>
           <td class="r">
            University of Kentucky
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5264" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#constrained_motion_planning" title="Click to go to the Keyword Index">
               Constrained Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Constrained motion planning requires robots to satisfy certain conditions, such as keeping a cup upright, while completing a task. Solving for connected regions in the configuration space that satisfy these constraints can be very difficult as the functions used to model these constraints can be highly nonlinear and computationally expensive. Current state-of-the-art methods build piecewise-linear approximations of constraint manifolds to model valid configurations, and additional steps are taken to ensure connectivity between neighboring linear approximations. However, these numerical continuation methods have several drawbacks: they are numerically sensitive, they are incapable of handling inequality constraints, and they have several parameters that are difficult to properly tune. To solve these problems, the proposed method uses a neural network-based approach to learn constraint functions and compute continuous representations of constraint manifolds. The neural network is first decomposed into many different linear output regions. Then, each of these regions is checked to determine whether the constraint function can be satisfied within the given region. The proposed method finally produces a set of polytopes that represent valid configurations for the given constraint.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb1r_30">
             09:30-09:55, Paper WeLB1R.30
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod960" name="modify5265" onclick="modify(5265,960)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5265'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Recent Field Test Results of MoonBots for Moon Base Construction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103649" title="Click to go to the Author Index">
             Yoshida, Kazuya
            </a>
           </td>
           <td class="r">
            Tohoku University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5265" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#cellular_and_modular_robots" title="Click to go to the Keyword Index">
               Cellular and Modular Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robotics_and_automation_in_construction" title="Click to go to the Keyword Index">
               Robotics and Automation in Construction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The author’s research group has been conducting an advanced project under Japan's Moonshot R&amp;D Program, aiming to develop a heterogeneous, collaborative multi-robot system for lunar resource exploration and outpost construction. The system features modular robots with reconfigurable mechanical components, enabling adaptive functions and efficient reuse. Plug-and-play AI controllers are being developed to allow each robot to autonomously recognize its configuration and coordinate tasks based on situational context. To validate the concept, field tests using “MoonBots” were conducted at a lunar analog site on JAXA’s Sagamihara campus. Although composed of relatively simple modules—namely “Wheel” and “Arm” units—MoonBots demonstrated diverse capabilities such as self-assembly, rough terrain traversal, material transport, and structural deployment, through modular reconfiguration. Development of the AI system is ongoing, with a focus on achieving real-time coordination, fault tolerance, and dynamic task allocation. Pre-deployment simulations and sim-to-real transfer techniques have accelerated progress and improved reliability. Results confirm the feasibility and scalability of modular, intelligent robot teams for future lunar base construction. The up-to-date results are presented in the late breaking poster session.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt1">
             <b>
              WeBT1
             </b>
             Regular Session, 302
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod961" name="modifyWeBT1" onclick="modsession(651,961)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt1" title="Click to go to the Program at a Glance">
             <b>
              Award Finalists 6
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#102638" title="Click to go to the Author Index">
             Fanti, Maria Pia
            </a>
           </td>
           <td class="r">
            Politecnico Di Bari
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#179886" title="Click to go to the Author Index">
             Han, Amy Kyungwon
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt1_01">
             09:55-10:00, Paper WeBT1.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod962" name="modify2648" onclick="modify(2648,962)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2648'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              In-Plane Manipulation of Soft Micro-Fiber with Ultrasonic Transducer Array and Microscope
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423778" title="Click to go to the Author Index">
             Zou, Jieyun
            </a>
           </td>
           <td class="r">
            Shanghaitech University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#385274" title="Click to go to the Author Index">
             An, Siyuan
            </a>
           </td>
           <td class="r">
            Shanghaitech University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335221" title="Click to go to the Author Index">
             Wang, Mingyue
            </a>
           </td>
           <td class="r">
            Shanghaitech Univerisity
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335232" title="Click to go to the Author Index">
             Li, Jiaqi
            </a>
           </td>
           <td class="r">
            ShanghaiTech University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#447563" title="Click to go to the Author Index">
             Shi, Yalin
            </a>
           </td>
           <td class="r">
            The School of Control Science and Engineering (CSE) of Shandong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#169150" title="Click to go to the Author Index">
             Li, You-Fu
            </a>
           </td>
           <td class="r">
            City University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#285160" title="Click to go to the Author Index">
             Liu, Song
            </a>
           </td>
           <td class="r">
            ShanghaiTech University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2648" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#automation_at_micro_nano_scales" title="Click to go to the Keyword Index">
               Automation at Micro-Nano Scales
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#nanomanufacturing" title="Click to go to the Keyword Index">
               Nanomanufacturing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Noncontact manipulation of soft micro-fibers has great potential in advanced manufacturing, materials science, and biomedical engineering. However, current noncontact manipulation techniques primarily focus on objects with regular shapes, e.g., solid particles, cells, or droplets, with fewer solutions available for manipulating flexible and elongated structures. In this paper, an automated ultrasonic manipulation system is introduced for in-plane soft micro-fiber manipulation, which mainly consists of an ultrasonic transducer array and a microscope. A real-time trap generation algorithm is designed to manipulate the micro-fibers by the visual feedback from microscope. An adequate theoretical analysis is also provided for explanation of the deformation behavior of micro-fiber under external forces. The system is capable of precise in-plane positioning and motion trajectory planning to micro-fiber end, and in-plane morphological reshaping to the micro-fiber. Experiments validated the effectiveness of the proposed system for the in-plane manipulation of soft micro-fibers. Finally, the system was showcased by the practical application of material property characterization.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt1_02">
             10:00-10:05, Paper WeBT1.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod963" name="modify2173" onclick="modify(2173,963)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2173'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Complete and Bounded-Suboptimal Algorithm for a Moving Target Traveling Salesman Problem with Obstacles in 3D
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354798" title="Click to go to the Author Index">
             Bhat, Anoop
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256318" title="Click to go to the Author Index">
             Gutow, Geordan
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#239286" title="Click to go to the Author Index">
             Vundurthy, Bhaskar
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#211685" title="Click to go to the Author Index">
             Ren, Zhongqiang
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#130289" title="Click to go to the Author Index">
             Rathinam, Sivakumar
            </a>
           </td>
           <td class="r">
            TAMU
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104011" title="Click to go to the Author Index">
             Choset, Howie
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2173" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#constrained_motion_planning" title="Click to go to the Keyword Index">
               Constrained Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The moving target traveling salesman problem with obstacles (MT-TSP-O) seeks an obstacle-free trajectory for an agent that intercepts a given set of moving targets, each within a specified time windows, and returns to the agent's starting position. Each target moves with a constant velocity within its time windows, and the agent has a speed limit no smaller than any target's speed. We present FMC*-TSP, the first complete and bounded-suboptimal algorithm for the MT-TSP-O, and results for an agent whose configuration space is in R^3. Our algorithm interleaves a high-level search and a low-level search where the high-level search solves a generalized traveling salesman problem with time windows (GTSP-TW) to find a sequence of targets and corresponding time windows for the agent to visit. Given such a sequence, the low-level search then finds an associated agent trajectory. To solve the low-level planning problem, we develop a new algorithm called FMC*, which finds a shortest path on a graph of convex sets (GCS) via implicit graph search and pruning techniques specialized for problems with moving targets. We test FMC*-TSP on 280 problem instances with up to 40 targets and demonstrate its smaller median runtime than a baseline based on prior work.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt1_03">
             10:05-10:10, Paper WeBT1.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod964" name="modify4273" onclick="modify(4273,964)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4273'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Physics-Aware Robotic Palletization with Online Masking Inference
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426403" title="Click to go to the Author Index">
             Zhang, Tianqi
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#274823" title="Click to go to the Author Index">
             Wu, Zheng
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#266418" title="Click to go to the Author Index">
             Chen, Yuxin
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#358483" title="Click to go to the Author Index">
             Wang, Yixiao
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309175" title="Click to go to the Author Index">
             Liang, Boyuan
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426469" title="Click to go to the Author Index">
             Moura, Scott
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100071" title="Click to go to the Author Index">
             Tomizuka, Masayoshi
            </a>
           </td>
           <td class="r">
            University of California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#266445" title="Click to go to the Author Index">
             Ding, Mingyu
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#170266" title="Click to go to the Author Index">
             Zhan, Wei
            </a>
           </td>
           <td class="r">
            Univeristy of California, Berkeley
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4273" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The efficient planning of stacking boxes, especially in the online setting where the sequence of item arrivals is unpredictable, remains a critical challenge in modern warehouse and logistics management. Existing solutions often address box size variations, but overlook their intrinsic and physical properties, such as density and rigidity, which are crucial for real-world applications. We use reinforcement learning (RL) to solve this problem by employing action space masking to direct the RL policy towards valid actions. Unlike previous methods that rely on heuristic stability assessments which are difficult to assess in physical scenarios, our framework utilizes online learning to dynamically train the action space mask, eliminating the need for manual heuristic design. Extensive experiments demonstrate that our proposed method outperforms existing state-of-the-arts. Furthermore, we deploy our learned task planner in a real-world robotic palletizer, validating its practical applicability in operational settings.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt1_04">
             10:10-10:15, Paper WeBT1.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod965" name="modify3100" onclick="modify(3100,965)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3100'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Image-Based Compliance Control for Robotic Steering of a Ferromagnetic Guidewire
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#363182" title="Click to go to the Author Index">
             Hu, An
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#328080" title="Click to go to the Author Index">
             Sun, Chen
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424036" title="Click to go to the Author Index">
             Dmytriw, Adam
            </a>
           </td>
           <td class="r">
            Neurovascular Centre, Divisions of Therapeutic Neuroradiology An
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#183539" title="Click to go to the Author Index">
             Xiao, Nan
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101247" title="Click to go to the Author Index">
             Sun, Yu
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3100" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_servoing" title="Click to go to the Keyword Index">
               Visual Servoing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#compliance_and_impedance_control" title="Click to go to the Keyword Index">
               Compliance and Impedance Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic steering of magnetic guidewires has shown great potential in accelerating endovascular interventions, enhancing the success rate of time-sensitive surgeries such as stroke treatment. Incomplete state feedback of the guidewire from 2D perspective images and unknown interactions with the surrounding vessel wall raise challenges in modeling and steering control. These two factors, however, are commonly overlooked by existing works. In this paper, 2D perspective images of the guidewire, which comply with prevalent medical imaging modalities, are used as the only feedback. A model-based external force observer is proposed that allows the guidewire to perceive the unknown interactions, and a compliance controller is subsequently designed to handle the external force while steering the guidewire. Experiments conducted in a human-sized phantom demonstrate how the compliance controller preserves stability and safety by adapting to the estimated external force.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt1_05">
             10:15-10:20, Paper WeBT1.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod966" name="modify3058" onclick="modify(3058,966)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3058'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              AutoPeel: Adhesion-Aware Safe Peeling Trajectory Optimization for Robotic Wound Care
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#376194" title="Click to go to the Author Index">
             Liang, Xiao
            </a>
           </td>
           <td class="r">
            University of California San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424802" title="Click to go to the Author Index">
             Zhang, Youcheng
            </a>
           </td>
           <td class="r">
            University of California San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#179568" title="Click to go to the Author Index">
             Liu, Fei
            </a>
           </td>
           <td class="r">
            University of Tennessee Knoxville
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#234261" title="Click to go to the Author Index">
             Richter, Florian
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#137547" title="Click to go to the Author Index">
             Yip, Michael C.
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3058" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_centered_automation" title="Click to go to the Keyword Index">
               Human-Centered Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__planning" title="Click to go to the Keyword Index">
               Surgical Robotics: Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Chronic wounds, including diabetic ulcers, pressure ulcers, and ulcers secondary to venous hypertension, affects more than 6.5 million patients and a yearly cost of more than 25 billion in the United States alone.Chronic wound treatment is currently a manual process, and we envision a future where robotics and automation will aid in this treatment to reduce cost and improve patient care. In this work, we present the development of the first robotic system for wound dressing removal which is reported to be the worst aspect of living with chronic wounds. Our method leverages differentiable physics-based simulation to perform gradient-based Model Predictive Control (MPC) for optimized trajectory planning. By integrating fracture mechanics of adhesion, we are able to model the peeling effect inherent to dressing adhesion. The system is further guided by carefully designed objective functions that promote both efficient and safe control, reducing the risk of tissue damage. We validated the efficacy of our approach through a series of experiments conducted on both synthetic skin phantoms and real human subjects. Our results demonstrate the system's ability to achieve precise and safe dressing removal trajectories, offering a promising solution for automating this essential healthcare procedure.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt1_06">
             10:20-10:25, Paper WeBT1.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod967" name="modify4175" onclick="modify(4175,967)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4175'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              In-Vivo Tendon-Driven Rodent Ankle Exoskeleton System for Sensorimotor Rehabilitation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423107" title="Click to go to the Author Index">
             Han, Juwan
            </a>
           </td>
           <td class="r">
            POSTECH, Pohang University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423121" title="Click to go to the Author Index">
             Park, Seunghyeon
            </a>
           </td>
           <td class="r">
            POSTECH, Pohang University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103228" title="Click to go to the Author Index">
             Kim, Keehoon
            </a>
           </td>
           <td class="r">
            POSTECH, Pohang University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4175" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#prosthetics_and_exoskeletons" title="Click to go to the Keyword Index">
               Prosthetics and Exoskeletons
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#neurorobotics" title="Click to go to the Keyword Index">
               Neurorobotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#wearable_robotics" title="Click to go to the Keyword Index">
               Wearable Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a novel cable-driven rodent ankle exoskeleton system designed for in-vivo research on the restoration and enhancement of sensorimotor abilities. The system features a lightweight, actuator-decoupled exoskeleton for shaping motion and providing kinesthetic feedback, along with a vision system and feedback-controlled treadmill for gait analysis. Experiments conducted under anesthesia and in awake conditions demonstrated effective control with minimal interference to natural gait. Dynamic time warping distance and Pearson correlation coefficients were calculated between joint angles from natural gait and those from rats wearing both passive and active exoskeleton component. The knee joint showed a low DTW distance and high correlation regardless of conditions, while all three joint displayed a greater maximum value from natural gait when the active component was engaged. These results provide valuable insights into the physiological impacts of wearable robotics in animal models, advancing sensorimotor rehabilitation technologies.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt1_07">
             10:25-10:30, Paper WeBT1.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod968" name="modify1312" onclick="modify(1312,968)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1312'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Stable Tracking of Eye Gaze Direction During Ophthalmic Surgery
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309354" title="Click to go to the Author Index">
             Hong, Tinghe
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420307" title="Click to go to the Author Index">
             Cai, Shenlin
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#257199" title="Click to go to the Author Index">
             Li, Boyang
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#193739" title="Click to go to the Author Index">
             Huang, Kai
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1312" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__planning" title="Click to go to the Keyword Index">
               Surgical Robotics: Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Ophthalmic surgical robots offer superior stability and precision by reducing the natural hand tremors of human surgeons, enabling delicate operations in confined surgical spaces, such as retinal surgery. Despite significant advancements in developing vision- and force-based control methods for these robots, preoperative navigation remains heavily reliant on manual operation, limiting consistency and increasing uncertainty. Existing eye gaze estimation techniques, whether traditional or deep learning-based, face challenges such as dependence on additional sensor devices, occlusion issues in surgical environments, and the requirement for facial detection. To address these limitations, this study proposes an innovative eye localization and tracking method that combines machine learning with traditional algorithms, eliminating the need for landmarks and maintaining stable iris detection and gaze estimation under varying lighting and shadow conditions. The proposed method achieves an average error of 0.58 degrees in estimating eye orientation and an average error of 2.08 degrees in controlling the robotic arm's movement based on the calculated orientation.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt2">
             <b>
              WeBT2
             </b>
             Regular Session, 301
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod969" name="modifyWeBT2" onclick="modsession(519,969)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt2" title="Click to go to the Program at a Glance">
             <b>
              SLAM 4
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#150161" title="Click to go to the Author Index">
             Rosen, David
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#169795" title="Click to go to the Author Index">
             De Cristóforis, Pablo
            </a>
           </td>
           <td class="r">
            University of Buenos Aires
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt2_01">
             09:55-10:00, Paper WeBT2.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod970" name="modify2479" onclick="modify(2479,970)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2479'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Introspective Loop Closure for SLAM with 4D Imaging Radar
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#368127" title="Click to go to the Author Index">
             Hilger, Maximilian
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#149723" title="Click to go to the Author Index">
             Kubelka, Vladimir
            </a>
           </td>
           <td class="r">
            Örebro University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#215735" title="Click to go to the Author Index">
             Adolfsson, Daniel
            </a>
           </td>
           <td class="r">
            Örebro University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#437132" title="Click to go to the Author Index">
             Becker, Ralf
            </a>
           </td>
           <td class="r">
            Company Bosch Rexroth
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104082" title="Click to go to the Author Index">
             Andreasson, Henrik
            </a>
           </td>
           <td class="r">
            Örebro University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104036" title="Click to go to the Author Index">
             Lilienthal, Achim J.
            </a>
           </td>
           <td class="r">
            Orebro University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2479" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Simultaneous Localization and Mapping (SLAM) allows mobile robots to navigate without external positioning systems or pre-existing maps. Radar is emerging as a valuable sensing tool, especially in vision-obstructed environments, as it is less affected by particles than lidars or cameras. Modern 4D imaging radars provide three-dimensional geometric information and relative velocity measurements, but they bring challenges such as a small field of view and sparse, noisy point clouds. Detecting loop closures in SLAM is critical for reducing trajectory drift and maintaining map accuracy. However, the directional nature of 4D radar data makes identifying loop closures, especially from reverse viewpoints, difficult due to limited scan overlap. This article explores using 4D radar for loop closure in SLAM, focusing on similar and opposing viewpoints. We generate submaps for a denser environment representation and use introspective measures to reject false detections in feature-degenerate environments. Our experiments show accurate loop closure detection in geometrically diverse settings for both similar and opposing viewpoints, improving trajectory estimation with up to 82 % improvement in ATE and rejecting false positives in self-similar environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt2_02">
             10:00-10:05, Paper WeBT2.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod971" name="modify3473" onclick="modify(3473,971)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3473'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Range-Based 6-DoF Monte Carlo SLAM with Gradient-Guided Particle Filter on GPU
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#396647" title="Click to go to the Author Index">
             Nakao, Takumi
            </a>
           </td>
           <td class="r">
            Nagoya University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#168862" title="Click to go to the Author Index">
             Koide, Kenji
            </a>
           </td>
           <td class="r">
            National Institute of Advanced Industrial Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#255576" title="Click to go to the Author Index">
             Takanose, Aoki
            </a>
           </td>
           <td class="r">
            National Institute of Advanced Industrial Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#140884" title="Click to go to the Author Index">
             Oishi, Shuji
            </a>
           </td>
           <td class="r">
            National Institute of Advanced Industrial Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#152745" title="Click to go to the Author Index">
             Yokozuka, Masashi
            </a>
           </td>
           <td class="r">
            Nat. Inst. of Advanced Industrial Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#110100" title="Click to go to the Author Index">
             Date, Hisashi
            </a>
           </td>
           <td class="r">
            University of Tsukuba
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3473" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents range-based 6-DoF Monte Carlo SLAM with a gradient-guided particle update strategy. While non-parametric state estimation methods, such as particle filters, are robust in situations with high ambiguity, they are known to be unsuitable for high-dimensional problems due to the curse of dimensionality. To address this issue, we propose a particle update strategy that improves the sampling efficiency by using the gradient information of the likelihood function to guide particles toward its local maxima. Additionally, we introduce a keyframe-based map representation that represents the global map as a set of past frames (i.e., keyframes) to mitigate memory consumption. The keyframe poses for each particle are corrected using a simple loop closure method to maintain trajectory consistency. The combination of gradient information and keyframe-based map representation significantly enhances sampling efficiency and reduces memory usage compared to traditional RBPF approaches. To process a large number of particles (e.g., 100,000 particles) in real-time, the proposed framework is designed to fully exploit GPU parallel processing. Experimental results demonstrate that the proposed method exhibits extreme robustness to state ambiguity and can even deal with kidnapping situations, such as when the sensor moves to different floors via an elevator, with minimal heuristics.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt2_03">
             10:05-10:10, Paper WeBT2.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod972" name="modify3573" onclick="modify(3573,972)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3573'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Distributed Certifiably Correct Range-Aided SLAM
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398643" title="Click to go to the Author Index">
             Thoms, Alexander
            </a>
           </td>
           <td class="r">
            University of California Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#303569" title="Click to go to the Author Index">
             Papalia, Alan
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425582" title="Click to go to the Author Index">
             Velasquez, Jared
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#150161" title="Click to go to the Author Index">
             Rosen, David
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#298570" title="Click to go to the Author Index">
             Narasimhan, Sriram
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3573" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_slam" title="Click to go to the Keyword Index">
               Multi-Robot SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Reliable simultaneous localization and mapping (SLAM) algorithms are necessary for safety-critical autonomous navigation. In the communication-constrained multi-agent setting, navigation systems increasingly use point-to-point range sensors as they afford measurements with low bandwidth requirements and known data association. The state estimation problem for these systems takes the form of range-aided (RA) SLAM. However, distributed algorithms for solving the RA-SLAM problem lack formal guarantees on the quality of the returned estimate. To this end, we present the first distributed algorithm for RA-SLAM that can efficiently recover certifiably globally optimal solutions. Our algorithm, distributed certifiably correct RA-SLAM (DCORA), achieves this via the Riemannian Staircase method, where computational procedures developed for distributed certifiably correct pose graph optimization are generalized to the RA-SLAM problem. We demonstrate DCORA's efficacy on real-world multi-agent datasets by achieving absolute trajectory errors comparable to those of a state-of-the-art centralized certifiably correct RA-SLAM algorithm. Additionally, we perform a parametric study on the structure of the RA-SLAM problem using synthetic data, revealing how common parameters affect DCORA's performance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt2_04">
             10:10-10:15, Paper WeBT2.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod973" name="modify3888" onclick="modify(3888,973)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3888'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CoVoxSLAM: GPU Accelerated Globally Consistent Dense SLAM
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379039" title="Click to go to the Author Index">
             Hoss, Emiliano
            </a>
           </td>
           <td class="r">
            University of Buenos Aires
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#169795" title="Click to go to the Author Index">
             De Cristóforis, Pablo
            </a>
           </td>
           <td class="r">
            University of Buenos Aires
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3888" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#embedded_systems_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Embedded Systems for Robotic and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A dense SLAM system is essential for mobile robots, as it provides localization and allows navigation, path planning, obstacle avoidance, and decision making in unstructured environments. Due to increasing computational demands, the use of GPUs in dense SLAM is expanding. In this work, we present coVoxSLAM, a novel GPU-accelerated volumetric SLAM system that takes full advantage of the parallel processing power of the GPU to build globally consistent maps even in large-scale environments. It was deployed on different platforms (discrete and embedded GPUs) and compared with the state-of-the-art. The results obtained using public datasets show that coVoxSLAM delivers a significant performance improvement considering execution times while maintaining accurate localization. The presented system is available as an open-source system on GitHub: https://github.com/lrse-uba/coVoxSLAM.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt2_05">
             10:15-10:20, Paper WeBT2.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod974" name="modify3971" onclick="modify(3971,974)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3971'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Radar4VoxMap: Accurate Odometry from Blurred Radar Observations
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426134" title="Click to go to the Author Index">
             Seok, Jiwon
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#336743" title="Click to go to the Author Index">
             Kim, Soyeong
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#314792" title="Click to go to the Author Index">
             Jo, Jaeyoung
            </a>
           </td>
           <td class="r">
            Konkuk University, Smart Vehicle Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379150" title="Click to go to the Author Index">
             Lee, Jaehwan
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426214" title="Click to go to the Author Index">
             Minseo, Jung
            </a>
           </td>
           <td class="r">
            Hanyang
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#220505" title="Click to go to the Author Index">
             Jo, Kichun
            </a>
           </td>
           <td class="r">
            Hanyang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3971" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Compared to conventional 3D radar, the 4D imaging radar provides additional height data and finer resolution measurements. Moreover, compared to LiDAR sensors, 4D imaging radar is more cost-effective and offers enhanced durability against challenging weather conditions. Despite these advantages, radar-based localization systems face several challenges, including limited resolution, leading to scattered object recognition and less precise localization. Additionally, existing methods that form submaps from filtered results can accumulate errors, leading to blurred submaps and reducing the accuracy of the SLAM and odometry. To address these challenges, this paper introduces Radar4VoxMap, a novel approach designed to enhance radar-only odometry. The method includes an RCS-weighted voxel distribution map that improves registration accuracy. Furthermore, fixed-lag optimization with the graph is used to optimize both the submap and pose, effectively reducing cumulative errors. The proposed method has shown strong performance on open datasets. The code is available at: url{https://github.com/ailab-hanyang/Radar4VoxMap
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt2_06">
             10:20-10:25, Paper WeBT2.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod975" name="modify4946" onclick="modify(4946,975)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4946'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GenZ-ICP: Generalizable and Degeneracy-Robust LiDAR Odometry Using an Adaptive Weighting
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#412037" title="Click to go to the Author Index">
             Lee, Daehan
            </a>
           </td>
           <td class="r">
            Pohang University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#227869" title="Click to go to the Author Index">
             Lim, Hyungtae
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#139894" title="Click to go to the Author Index">
             Han, Soohee
            </a>
           </td>
           <td class="r">
            Pohang University of Science and Technology ( POSTECH )
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4946" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Light detection and ranging (LiDAR)-based odometry has been widely utilized for pose estimation due to its use of high-accuracy range measurements and immunity to ambient light conditions. However, the performance of LiDAR odometry varies depending on the environment and deteriorates in degenerative environments such as long corridors. This issue stems from the dependence on a single error metric, which has different strengths and weaknesses depending on the geometrical characteristics of the surroundings. To address these problems, this study proposes a novel iterative closest point (ICP) method called GenZ-ICP. We revisited both point-to-plane and point-topoint error metrics and propose a method that leverages their strengths in a complementary manner. Moreover, adaptability to diverse environments was enhanced by utilizing an adaptive weight that is adjusted based on the geometrical characteristics of the surroundings. As demonstrated in our experimental evaluation, the proposed GenZ-ICP exhibits high adaptability to various environments and resilience to optimization degradation in corridor-like degenerative scenarios by preventing ill-posed problems during the optimization process. Our code is available at https://github.com/cocel-postech/genz-icp.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt2_07">
             10:25-10:30, Paper WeBT2.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod976" name="modify4998" onclick="modify(4998,976)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4998'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Free-Init: Scan-Free, Motion-Free, and Correspondence-Free Initialization for Doppler LiDAR-Inertial Systems
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#376539" title="Click to go to the Author Index">
             Zhao, Mingle
            </a>
           </td>
           <td class="r">
            University of Macau
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339476" title="Click to go to the Author Index">
             Wang, Jiahao
            </a>
           </td>
           <td class="r">
            University of Macau
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#373326" title="Click to go to the Author Index">
             Gao, Tianxiao
            </a>
           </td>
           <td class="r">
            University of Macao
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#259738" title="Click to go to the Author Index">
             Xu, Chengzhong
            </a>
           </td>
           <td class="r">
            University of Macau
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#204275" title="Click to go to the Author Index">
             Kong, Hui
            </a>
           </td>
           <td class="r">
            University of Macau
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4998" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robust initialization is crucial for online systems. In the letter, a high-frequency and resilient initialization framework is designed for LiDAR-inertial systems, leveraging both inertial sensors and Doppler LiDAR. The innovative FMCW Doppler LiDAR opens up a novel avenue for robotic sensing by capturing not only point range but also Doppler velocity via the intrinsic Doppler effect. By fusing point-wise Doppler velocity with inertial measurements under non-inertial kinematics, the proposed framework, Free-Init, eliminates reliance on motion undistortion of LiDAR scans, excitation motions, and map correspondences during the initialization phase. Free-Init is also plug-and-play compatible with typical LiDAR-inertial systems and is versatile to handle a wide range of initial motions when the system starts, including stationary, dynamic, and even violent motions. The embedded Doppler-inertial velocimeter ensures fast convergence and high-frequency performance, delivering outputs exceeding 10 kHz. Comprehensive experiments on diverse platforms and across myriad motion scenes validate the framework's effectiveness. The results demonstrate the superior performance of Free-Init, highlighting the necessity of fast, resilient, and dynamic initialization for online systems.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt3">
             <b>
              WeBT3
             </b>
             Regular Session, 303
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod977" name="modifyWeBT3" onclick="modsession(305,977)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt3" title="Click to go to the Program at a Glance">
             <b>
              Mechanism Design 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#195833" title="Click to go to the Author Index">
             Yim, Justin K.
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#418551" title="Click to go to the Author Index">
             Santin, Marco
            </a>
           </td>
           <td class="r">
            Aalen University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt3_01">
             09:55-10:00, Paper WeBT3.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod978" name="modify28" onclick="modify(28,978)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('28'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Development of a 2-DOF Singularity-Free Spherical Parallel Remote Center of Motion Mechanism with Extensive Range of Motion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#384891" title="Click to go to the Author Index">
             Liu, Chun
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#123193" title="Click to go to the Author Index">
             Lin, Pei-Chun
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab28" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we report the development of an innovative two-degrees-of-freedom (2-DOF) spherical parallel remote center of motion mechanism (SPRCMM), which can offer a wide range of movement in both DOFs without encountering singularities. To facilitate the design process, the paper briefly reviews the existing spherical joints, including serial and parallel structures with and without the remote center of motion (RCM). Aiming at combining the advantages of these existing spherical joints, this paper proposes a novel design that utilizes the parallelogram mechanism to form a parallel RCM mechanism without using universal or spherical joints. Forward and inverse kinematics were constructed using the product of the exponentials. Moreover, space and closed Jacobians were derived, accompanied by manipulability in the available workspace for the mechanism. The prototype of the 2-DOF SPRCMM was built and experimentally evaluated. The experimental results confirm that the singularity-free motion of the two DOFs of the mechanism in a wide range is feasible, and the root mean squared errors in the trajectory tracking of the mechanism in most states were less than 10% of the motion range.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt3_02">
             10:00-10:05, Paper WeBT3.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod979" name="modify1322" onclick="modify(1322,979)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1322'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Highly Dynamic Physical Interaction for Robotics: Design and Control of an Active Remote Center of Compliance
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#181498" title="Click to go to the Author Index">
             Friedrich, Christian
            </a>
           </td>
           <td class="r">
            Karlsruhe University of Applied Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418184" title="Click to go to the Author Index">
             Frank, Patrick
            </a>
           </td>
           <td class="r">
            Hochschule Karlsruhe - University of Applied Sciences (HKA)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418551" title="Click to go to the Author Index">
             Santin, Marco
            </a>
           </td>
           <td class="r">
            Aalen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418300" title="Click to go to the Author Index">
             Haag, Carl Matthias
            </a>
           </td>
           <td class="r">
            Hochschule Aalen
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1322" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#force_control" title="Click to go to the Keyword Index">
               Force Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robot interaction control is often limited to low dynamics or low flexibility, depending on whether an active or passive approach is chosen. In this work, we introduce a hybrid control scheme that combines the advantages of active and passive interaction control. To accomplish this, we propose the design of a novel Active Remote Center of Compliance (ARCC), which is based on a passive and active element which can be used to directly control the interaction forces. We introduce surrogate models for a dynamic comparison against purely robot-based interaction schemes. In a comparative validation, ARCC drastically improves the interaction dynamics, leading to an increase in the motion bandwidth of up to 31 times. We introduce further our control approach as well as the integration in the robot controller. Finally, we analyze ARCC on different industrial benchmarks like peg-in-hole, top-hat rail assembly and contour following problems and compare it against the state of the art, to highlight the dynamic and flexibility. The proposed system is especially suited if the application requires a low cycle time combined with a sensitive manipulation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt3_03">
             10:05-10:10, Paper WeBT3.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod980" name="modify1364" onclick="modify(1364,980)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1364'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Pinto: A Latched Spring Actuated Robot for Jumping and Perching
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#365599" title="Click to go to the Author Index">
             Xu, Christopher
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#412099" title="Click to go to the Author Index">
             Yan, Huihan
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#195833" title="Click to go to the Author Index">
             Yim, Justin K.
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1364" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#compliant_joints_and_mechanisms" title="Click to go to the Keyword Index">
               Compliant Joints and Mechanisms
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Arboreal environments challenge current robots but are deftly traversed by many familiar animals such as squirrels. We present a small, 450 g robot "Pinto" developed for tree-jumping, a behavior seen in squirrels but rarely in legged robots: jumping from the ground onto a vertical tree trunk. We develop a powerful and lightweight latched series-elastic actuator using a twisted string and carbon fiber springs. We consider the effects of scaling down conventional quadrupeds and experimentally show how storing energy in a parallel-elastic fashion using a latch increases jump energy compared to series-elastic or springless strategies. By switching between series and parallel-elastic modes with our latched 5-bar leg mechanism, Pinto executes energetic jumps as well as maintains continuous control during shorter bounding motions. We also develop sprung 2-DoF arms equipped with spined grippers to grasp tree bark for high-speed perching following a jump.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt3_04">
             10:10-10:15, Paper WeBT3.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod981" name="modify1872" onclick="modify(1872,981)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1872'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              D3-ARM: High-Dynamic, Dexterous and Fully Decoupled Cable-Driven Robotic Arm
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421807" title="Click to go to the Author Index">
             Luo, Hong
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421778" title="Click to go to the Author Index">
             Xu, Jianle
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#308276" title="Click to go to the Author Index">
             Li, Shoujie
            </a>
           </td>
           <td class="r">
            Tsinghua Shenzhen International Graduate School
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422332" title="Click to go to the Author Index">
             Liang, Huayue
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#323430" title="Click to go to the Author Index">
             Chen, Yanbo
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#210797" title="Click to go to the Author Index">
             Xia, Chongkun
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#241746" title="Click to go to the Author Index">
             Wang, Xueqian
            </a>
           </td>
           <td class="r">
            Center for Artificial Intelligence and Robotics, Graduate School
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1872" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#tendon_wire_mechanism" title="Click to go to the Keyword Index">
               Tendon/Wire Mechanism
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Cable transmission enables motors of robotic arm to operate lightweight and low-inertia joints remotely in various environments, but it also creates issues with motion coupling and cable routing that can reduce arm's control precision and performance. In this paper, we present a novel motion decoupling mechanism with low-friction to align the cables and efficiently transmit the motor's power. By arranging these mechanisms at the joints, we fabricate a fully decoupled and lightweight cable-driven robotic arm called D3-Arm with all the electrical components be placed at the base. Its 776 mm length moving part boasts six degrees of freedom (DOF) and only 1.6 kg weights. To address the issue of cable slack, a cable-pretension mechanism is integrated to enhance the stability of long-distance cable transmission. Through a series of comprehensive tests, D3-Arm demonstrated 1.29 mm average positioning error and 2 kg payload capacity, proving the practicality of the proposed decoupling mechanisms in cable-driven robotic arm.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt3_05">
             10:15-10:20, Paper WeBT3.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod982" name="modify3150" onclick="modify(3150,982)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3150'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design of an Articulated Modular Caterpillar Using Spherical Linkages
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425124" title="Click to go to the Author Index">
             O'Connor, Sam
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#192394" title="Click to go to the Author Index">
             Plecnik, Mark
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3150" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Articulation between body segments of small insects and animals is a three degree-of-freedom (DOF) motion. Implementing this kind of motion in a compact robot is usually not tractable due to limitations in small actuator technologies. In this work, we concede full 3-DOF control and instead select a one degree-of-freedom curve in SO(3) to articulate segments of a caterpillar robot. The curve is approximated with a spherical four-bar, which is synthesized through optimal rigid body guidance. We specify the desired SO(3) motion using discrete task positions, then solve for candidate mechanisms by computing all roots of the stationary conditions using numerical homotopy continuation. A caterpillar robot prototype demonstrates the utility of this approach. This synthesis procedure is also used to design prolegs for the caterpillar robot. Each segment contains two DC motors and a shape memory alloy, which is used for latching and unlatching between segments. The caterpillar robot is capable of walking, steering, object manipulation, body articulation, and climbing.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt3_06">
             10:20-10:25, Paper WeBT3.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod983" name="modify3619" onclick="modify(3619,983)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3619'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Generative-AI-Driven Jumping Robot Design Using Diffusion Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#229363" title="Click to go to the Author Index">
             Kim, Byungchul
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#220292" title="Click to go to the Author Index">
             Wang, Tsun-Hsuan
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101388" title="Click to go to the Author Index">
             Rus, Daniela
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3619" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#methods_and_tools_for_robot_system_design" title="Click to go to the Keyword Index">
               Methods and Tools for Robot System Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent advances in foundation models are significantly expanding the capabilities of AI models. As part of this progress, this paper introduces a robot design framework that uses a diffusion model approach for generating 3D mesh structures. Specifically, we focus on generating directly fabricable robot structures that require no post-processing guided by human-imposed design constraints. Our approach can find the optimal design of the robot by optimizing or composing embedding vectors of the model. The efficacy of the framework is validated through an application to design, fabricate, and evaluate a jumping robot. Our solution is an optimized jumping robot with a 41% increase in jump height compared to the state-of-the-art design. Additionally, when the robot is augmented with an optimized foot, it can land reliably with a success ratio of 88% in contrast to the 4% success ratio of the base robot.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt4">
             <b>
              WeBT4
             </b>
             Regular Session, 304
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod984" name="modifyWeBT4" onclick="modsession(539,984)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt4" title="Click to go to the Program at a Glance">
             <b>
              Sensor Fusion 1
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#185927" title="Click to go to the Author Index">
             Yuan, Shenghai
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#140525" title="Click to go to the Author Index">
             Forbes, James Richard
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt4_01">
             09:55-10:00, Paper WeBT4.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod985" name="modify106" onclick="modify(106,985)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('106'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Hessian for Gaussian Mixture Likelihoods in Nonlinear Least Squares
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#310514" title="Click to go to the Author Index">
             Korotkine, Vassili
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#237066" title="Click to go to the Author Index">
             Cohen, Mitchell
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#140525" title="Click to go to the Author Index">
             Forbes, James Richard
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab106" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#probabilistic_inference" title="Click to go to the Keyword Index">
               Probabilistic Inference
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes a novel Hessian approximation for Maximum a Posteriori estimation problems in robotics involving Gaussian mixture likelihoods. Previous approaches manipulate the Gaussian mixture likelihood into a form that allows the problem to be represented as a nonlinear least squares (NLS) problem. The resulting Hessian approximation used within NLS solvers from these approaches neglects certain nonlinearities. The proposed Hessian approximation is derived by setting the Hessians of the Gaussian mixture component errors to zero, which is the same starting point as for the Gauss-Newton Hessian approximation for NLS, and using the chain rule to account for additional nonlinearities. The proposed Hessian approximation results in improved convergence speed and uncertainty characterization for simulated experiments, and similar performance to the state of the art on real-world experiments. A method to maintain compatibility with existing solvers, such as ceres, is also presented. Accompanying software and supplementary material can be found at https://github.com/decargroup/hessian_sum_mixtures.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt4_02">
             10:00-10:05, Paper WeBT4.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod986" name="modify396" onclick="modify(396,986)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('396'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Unveiling the Depths: A Multi-Modal Fusion Framework for Challenging Scenarios
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#391636" title="Click to go to the Author Index">
             Xu, Jialei
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416321" title="Click to go to the Author Index">
             Li, Rui
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416779" title="Click to go to the Author Index">
             Cheng, Kai
            </a>
           </td>
           <td class="r">
            USTC
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#217355" title="Click to go to the Author Index">
             Jiang, Junjun
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#365568" title="Click to go to the Author Index">
             Liu, Xianming
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab396" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Monocular depth estimation from RGB images plays a pivotal role in 3D vision. However, its accuracy can deteriorate in challenging environments such as nighttime or adverse weather conditions. While long-wave infrared cameras offer stable imaging in such challenging conditions, they are inherently low-resolution, lacking rich texture and semantics as delivered by the RGB image. Current methods focus solely on a single modality due to the difficulties to identify and integrate faithful depth cues from both sources. To address these issues, this paper presents a novel approach that identifies and integrates dominant cross-modality depth features with a learning-based framework. Concretely, we independently compute the coarse depth maps with separate networks by fully utilizing the individual depth cues from each modality. As the advantageous depth spreads across both modalities, we propose a novel confidence loss steering a confidence predictor network to yield a confidence map specifying latent potential depth areas. With the resulting confidence map, we propose a multi-modal fusion network that fuses the final depth in an end-to-end manner. Harnessing the proposed pipeline, our method demonstrates the ability of robust depth estimation in a variety of difficult scenarios. Experimental results on the challenging MS^2 and ViViD++ datasets demonstrate the effectiveness and robustness of our method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt4_03">
             10:05-10:10, Paper WeBT4.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod987" name="modify1221" onclick="modify(1221,987)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1221'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Explore the LiDAR-Camera Dynamic Adjustment Fusion for 3D Object Detection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#412225" title="Click to go to the Author Index">
             Yang, Yiran
            </a>
           </td>
           <td class="r">
            University of Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#337921" title="Click to go to the Author Index">
             Gao, Xu
            </a>
           </td>
           <td class="r">
            Baidu
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416850" title="Click to go to the Author Index">
             Wang, Tong
            </a>
           </td>
           <td class="r">
            Baidu
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417501" title="Click to go to the Author Index">
             Hao, Xin
            </a>
           </td>
           <td class="r">
            Baidu
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#336995" title="Click to go to the Author Index">
             Shi, Yifeng
            </a>
           </td>
           <td class="r">
            BAIDU.INC
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#318861" title="Click to go to the Author Index">
             Tan, Xiao
            </a>
           </td>
           <td class="r">
            Baidu
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#277127" title="Click to go to the Author Index">
             Ye, Xiaoqing
            </a>
           </td>
           <td class="r">
            Baidu Inc
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1221" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Camera and LiDAR serve as informative sensors for accurate and robust autonomous driving systems. However, these sensors often exhibit heterogeneous natures, resulting in distributional modality gaps that present significant challenges for fusion. To address this, a robust fusion technique is crucial, particularly for enhancing 3D object detection. In this paper, we introduce a dynamic adjustment technology aimed at aligning modal distributions and learning effective modality representations to enhance the fusion process. Specifically, we propose a triphase domain aligning module. This module adjusts the feature distributions from both the camera and LiDAR, bringing them closer to the ground truth domain and minimizing differences. Additionally, we explore improved representation acquisition methods for dynamic fusion, which includes modal interaction and specialty enhancement. Finally, an adaptive learning technique that merges the semantics and geometry information for dynamical instance optimization. Extensive experiments in the nuScenes dataset present competitive performance with state-of-the-art approaches. Our code will be released in the future.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt4_04">
             10:10-10:15, Paper WeBT4.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod988" name="modify1484" onclick="modify(1484,988)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1484'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Bridging Spectral-Wise and Multi-Spectral Depth Estimation Via Geometry-Guided Contrastive Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#241049" title="Click to go to the Author Index">
             Shin, Ukcheol
            </a>
           </td>
           <td class="r">
            CMU(Carnegie Mellon University)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#268069" title="Click to go to the Author Index">
             Lee, Kyunghyun
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#179403" title="Click to go to the Author Index">
             Oh, Jean
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1484" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Deploying depth estimation networks in the real world requires high-level robustness against various adverse conditions to ensure safe and reliable autonomy. For this purpose, many autonomous vehicles employ multi-modal sensor systems, including an RGB camera, NIR camera, thermal camera, LiDAR, or Radar. They mainly adopt two strategies to use multiple sensors: modality-wise and multi-modal fused inference. The former method is flexible but memory-inefficient, unreliable, and vulnerable. Multi-modal fusion can provide high-level reliability, yet it needs a specialized architecture. In this paper, we propose an effective solution, named align-and-fuse strategy, for the depth estimation from multi-spectral images. In the align stage, we align embedding spaces between multiple spectrum bands to learn shareable representation across multi-spectral images by minimizing contrastive loss of global and spatially aligned local features with geometry cues. After that, in the fuse stage, we train an attachable feature fusion module that can selectively aggregate the multi-spectral features for reliable and robust prediction results. Based on the proposed method, a single-depth network can achieve both spectral-invariant and multi-spectral fused depth estimation while preserving reliability, memory efficiency, and flexibility.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt4_05">
             10:15-10:20, Paper WeBT4.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod989" name="modify1775" onclick="modify(1775,989)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1775'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              VAIR: Visuo-Acoustic Implicit Representations for Low-Cost, Multi-Modal Transparent Surface Reconstruction in Indoor Scenes
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335203" title="Click to go to the Author Index">
             Venkatramanan Sethuraman, Advaith
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#343378" title="Click to go to the Author Index">
             Bagoren, Onur
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#409368" title="Click to go to the Author Index">
             Seetharaman, Harikrishnan
            </a>
           </td>
           <td class="r">
            University of Michigan - Ann Arbor
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#409382" title="Click to go to the Author Index">
             Richardson, Dalton
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#409340" title="Click to go to the Author Index">
             Taylor, Joseph
            </a>
           </td>
           <td class="r">
            University of Michigan, Ann Arbor
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#180427" title="Click to go to the Author Index">
             Skinner, Katherine
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1775" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Mobile robots operating indoors must be prepared to navigate challenging scenes that contain transparent surfaces. This paper proposes a novel method for the fusion of acoustic and visual sensing modalities through implicit neural represen- tations to enable dense reconstruction of transparent surfaces in indoor scenes. We propose a novel model that leverages generative latent optimization to learn an implicit representation of indoor scenes consisting of transparent surfaces. We demonstrate that we can query the implicit representation to enable volumetric rendering in image space or 3D geometry reconstruction (point clouds or mesh) with transparent surface prediction. We evaluate our method’s effectiveness qualitatively and quantitatively on a new dataset collected using a custom, low-cost sensing platform featuring RGB-D cameras and ultrasonic sensors. Our method exhibits significant improvement over state-of-the-art for transparent surface reconstruction.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt4_06">
             10:20-10:25, Paper WeBT4.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod990" name="modify4174" onclick="modify(4174,990)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4174'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CDMFusion: RGB-T Image Fusion Based on Conditional Diffusion Models Via Few Denoising Steps in Open Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423314" title="Click to go to the Author Index">
             Yang, Luojie
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#412875" title="Click to go to the Author Index">
             Yu, Meng
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426360" title="Click to go to the Author Index">
             Fang, Lijin
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#128868" title="Click to go to the Author Index">
             Yang, Yi
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#205136" title="Click to go to the Author Index">
             Yue, Yufeng
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4174" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-modal fusion can improve perceptual robustness and accuracy by fully utilizing multi-source sensor data. Current RGB-T fusion methods still falter with adverse illumination and weather. Recent advances in generative methods have shown the ability to enhance and restore visible images in adverse conditions. However, the fusion of RGB-T based on generative methods has not been studied in depth, due to limited attention given to the degradation of multi-modal features under challenging circumstances. Motivated by this observation, we propose CDMFusion, a three-branch conditional diffusion model that achieves fusion with dynamically enhancing multi-modal features and suppressing high-frequency interference. Specifically, we achieve feature-preserving fusion through three branches and establish a dynamic gating prediction module to adjust the enhancement of multi-modal features adaptively. In addition, considering the high time cost of existing diffusion models for generating fused images, we propose a skip patrol mechanism to achieve accelerated high-quality generation with no need for additional training. Experiments demonstrate our method achieves excellent performance in multiple datasets. The code and datasets are available at https://github.com/yangluojie/CDMFusion.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt4_07">
             10:25-10:30, Paper WeBT4.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod991" name="modify4227" onclick="modify(4227,991)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4227'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              UniBEVFusion: Unified Radar-Vision BEVFusion for 3D Object Detection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411638" title="Click to go to the Author Index">
             Zhao, Haocheng
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong-Liverpool University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#389634" title="Click to go to the Author Index">
             Guan, Runwei
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397402" title="Click to go to the Author Index">
             Wu, Taoyu
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong-Liverpool University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#389739" title="Click to go to the Author Index">
             Man, Ka Lok
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong-Liverpool University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397393" title="Click to go to the Author Index">
             Yu, Limin
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong-Liverpool University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#389831" title="Click to go to the Author Index">
             Yue, Yutao
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4227" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             4D millimeter-wave (MMW) radar, which provides both height information and dense point cloud data over 3D MMW radar, has become increasingly popular in 3D object detection. In recent years, radar-vision fusion models have demonstrated performance close to that of LiDAR-based models, offering advantages in terms of lower hardware costs and better resilience in extreme conditions. However, many radar-vision fusion models treat radar as a sparse LiDAR, underutilizing radar-specific information. Additionally, these multi-modal networks are often sensitive to the failure of a single modality, particularly vision. To address these challenges, we propose the Radar Depth Lift-Splat-Shoot (RDL) module, which integrates radar-specific data into the depth prediction process, enhancing the quality of visual Bird’s-Eye View (BEV) features. We further introduce a Unified Feature Fusion (UFF) approach that extracts BEV features across different modalities using shared module. To assess the robustness of multi-modal models, we develop a novel Failure Test (FT) ablation experiment, which simulates vision modality failure by injecting Gaussian noise. We conduct extensive experiments on the View-of-Delft (VoD) and TJ4D datasets. The results demonstrated that our proposed Unified BEVFusion (UniBEVFusion) network significantly outperforms state-of-the-art models on the TJ4D dataset, with improvements of 3.96% in 3D and 4.17% in BEV object detection accuracy.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt5">
             <b>
              WeBT5
             </b>
             Regular Session, 305
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod992" name="modifyWeBT5" onclick="modsession(31,992)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt5" title="Click to go to the Program at a Glance">
             <b>
              Aerial Robots: Mechanics and Control 1
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#117307" title="Click to go to the Author Index">
             Yamamoto, Ko
            </a>
           </td>
           <td class="r">
            University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#171052" title="Click to go to the Author Index">
             Saldaña, David
            </a>
           </td>
           <td class="r">
            Lehigh University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt5_01">
             09:55-10:00, Paper WeBT5.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod993" name="modify93" onclick="modify(93,993)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('93'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Generalized Thrust Estimation and Control Approach for Multirotors Micro Aerial Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#402834" title="Click to go to the Author Index">
             Santos, Davi Henrique dos
            </a>
           </td>
           <td class="r">
            Universidade Federal Da Paraíba
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#113384" title="Click to go to the Author Index">
             Saska, Martin
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#140840" title="Click to go to the Author Index">
             Nascimento, Tiago
            </a>
           </td>
           <td class="r">
            Universidade Federal Da Paraiba
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab93" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper addresses the problem of thrust estimation and control for the rotors of small-sized multirotors Uncrewed Aerial Vehicles (UAVs). Accurate control of the thrust generated by each rotor during flight is one of the main challenges for robust control of quadrotors. The most common approach is to approximate the mapping of rotor speed to thrust with a simple quadratic model. This model is known to fail under non-hovering flight conditions, introducing errors into the control pipeline. One of the approaches to modeling the aerodynamics around the propellers is the Blade Element Momentum Theory (BEMT). Here, we propose a novel BEMT-based closed-loop thrust estimator and control to eliminate the laborious calibration step of finding several aerodynamic coefficients. We aim to reuse known values as a baseline and fit the thrust estimate to values closest to the real ones with a simple test bench experiment, resulting in a single scaling value. A feedforward PID thrust control was implemented for each rotor, and the methods were validated by outdoor experiments with two multirotor UAV platforms: 250mm and 500mm. A statistical analysis of the results showed that the thrust estimation and control provided better robustness under aerodynamically varying flight conditions compared to the quadratic model.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt5_02">
             10:00-10:05, Paper WeBT5.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod994" name="modify3057" onclick="modify(3057,994)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3057'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Trajectory Planning and Control for Differentially Flat Fixed-Wing Aerial Systems
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#281846" title="Click to go to the Author Index">
             Morando, Luca
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#250700" title="Click to go to the Author Index">
             Salunkhe, Sanket Ankush
            </a>
           </td>
           <td class="r">
            Colorado School of Mines
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#373771" title="Click to go to the Author Index">
             Bobbili, Nishanth
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#297802" title="Click to go to the Author Index">
             Mao, Jeffrey
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424654" title="Click to go to the Author Index">
             Masci, Luca
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#366405" title="Click to go to the Author Index">
             Hung, Nguyen
            </a>
           </td>
           <td class="r">
            Instituto Superior Técnico
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#278294" title="Click to go to the Author Index">
             De Souza Jr., Cristino
            </a>
           </td>
           <td class="r">
            Technology Innovation Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#142369" title="Click to go to the Author Index">
             Loianno, Giuseppe
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3057" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Efficient real-time trajectory planning and control for fixed-wing unmanned aerial vehicles is challenging due to their non-holonomic nature, complex dynamics, and the additional uncertainties introduced by unknown aerodynamic effects. In this paper, we present a fast and efficient real-time trajectory planning and control approach for fixed-wing unmanned aerial vehicles, leveraging the differential flatness property of fixed-wing aircraft in coordinated flight conditions to generate dynamically feasible trajectories. The approach provides the ability to continuously replan trajectories, which we show is useful to dynamically account for the curvature constraint as the aircraft advances along its path. Extensive simulations and real-world experiments validate our approach, showcasing its effectiveness in generating trajectories across various flight conditions, including wind disturbances.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt5_03">
             10:05-10:10, Paper WeBT5.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod995" name="modify3272" onclick="modify(3272,995)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3272'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safe Quadrotor Navigation Using Composite Control Barrier Functions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398043" title="Click to go to the Author Index">
             Harms, Marvin Chayton
            </a>
           </td>
           <td class="r">
            NTNU
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#250696" title="Click to go to the Author Index">
             Jacquet, Martin
            </a>
           </td>
           <td class="r">
            NTNU
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#132933" title="Click to go to the Author Index">
             Alexis, Kostas
            </a>
           </td>
           <td class="r">
            NTNU - Norwegian University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3272" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a safety filter to ensure collision avoidance for multirotor aerial robots. The proposed formalism leverages a single Composite Control Barrier Function from all position constraints acting on a third-order nonlinear representation of the robot's dynamics. We analyze the recursive feasibility of the safety filter under the composite constraint and demonstrate that the infeasible set is negligible. The proposed method allows computational scalability against thousands of constraints and, thus, complex scenes with numerous obstacles. We experimentally demonstrate its ability to guarantee the safety of a quadrotor with an onboard LiDAR, operating in both indoor and outdoor cluttered environments against both naive and adversarial nominal policies.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt5_04">
             10:10-10:15, Paper WeBT5.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod996" name="modify3343" onclick="modify(3343,996)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3343'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              The Spinning Blimp: Design and Control of a Novel Minimalist Aerial Vehicle Leveraging Rotational Dynamics and Locomotion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#373290" title="Click to go to the Author Index">
             Santens, Leonardo
            </a>
           </td>
           <td class="r">
            Lehigh University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#286799" title="Click to go to the Author Index">
             S. D'Antonio, Diego
            </a>
           </td>
           <td class="r">
            Lehigh University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#373307" title="Click to go to the Author Index">
             Hou, Shuhang
            </a>
           </td>
           <td class="r">
            Lehigh University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#171052" title="Click to go to the Author Index">
             Saldaña, David
            </a>
           </td>
           <td class="r">
            Lehigh University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3343" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents the Spinning Blimp, a novel lighter-than-air (LTA) aerial vehicle designed for low-energy stable flight. Using an oblate spheroid helium balloon for buoyancy, the vehicle achieves minimal energy consumption while maintaining prolonged airborne states. The unique and low-cost design employs a passively arranged wing coupled with a propeller to induce a spinning behavior, providing inherent pendulum-like stabilization. We propose a control strategy that takes advantage of the continuous revolving nature of the spinning blimp to control translational motion. The cost-effectiveness of the vehicle makes it highly suitable for a variety of applications, such as patrolling, localization, air and turbulence monitoring, and domestic surveillance. Experimental evaluations affirm the design's efficacy and underscore its potential as a versatile and economically viable solution for aerial applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt5_05">
             10:15-10:20, Paper WeBT5.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod997" name="modify3434" onclick="modify(3434,997)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3434'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              One Net to Rule Them All: Domain Randomization in Quadcopter Racing across Different Platforms
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#344523" title="Click to go to the Author Index">
             Ferede, Robin
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#396790" title="Click to go to the Author Index">
             Blaha, Till Martin
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425529" title="Click to go to the Author Index">
             Lucassen, Erin
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#131961" title="Click to go to the Author Index">
             De Wagter, Christophe
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#131959" title="Click to go to the Author Index">
             de Croon, Guido
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3434" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In high-speed quadcopter racing, finding a single controller that works well across different platforms remains challenging. This work presents the first neural network controller for drone racing that generalizes across physically distinct quadcopters. We demonstrate that a single network, trained with domain randomization, can robustly control various types of quadcopters. The network relies solely on the current state to directly compute motor commands. The effectiveness of this generalized controller is validated through real-world tests on two substantially different crafts (3-inch and 5-inch race quadcopters). We further compare the performance of this generalized controller with controllers specifically trained for the 3-inch and 5-inch drone, using their identified model parameters with varying levels of domain randomization (0%, 10%, 20%, 30%). While the generalized controller shows slightly slower speeds compared to the fine-tuned models, it excels in adaptability across different platforms. Our results show that no randomization fails sim-to-real transfer while increasing randomization improves robustness but reduces speed. Despite this trade-off, our findings highlight the potential of domain randomization for generalizing controllers, paving the way for universal AI controllers that can adapt to any platform.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt5_06">
             10:20-10:25, Paper WeBT5.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod998" name="modify4063" onclick="modify(4063,998)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4063'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Modeling and Control of Aerial Robot SERPENT: A Soft Structure Incorporated Multirotor Aerial Robot Capable of In-Flight Flexible Deformation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#389402" title="Click to go to the Author Index">
             Itahara, Shotaro
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#266569" title="Click to go to the Author Index">
             Nishio, Takuzumi
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#273063" title="Click to go to the Author Index">
             Ishigaki, Taiki
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#358537" title="Click to go to the Author Index">
             Sugihara, Junichiro
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#164284" title="Click to go to the Author Index">
             Zhao, Moju
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#117307" title="Click to go to the Author Index">
             Yamamoto, Ko
            </a>
           </td>
           <td class="r">
            University of Tokyo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4063" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a novel method for controlling multirotor aerial robots connected by passive flexible elements. Despite the growing popularity of multirotor aerial robots, their real-world applications remain limited due to difficulties adapting to complex environments. Soft robotics, due to their inherent flexibility, offer a potential solution, though research on integrating flexible elements into aerial robots is still in the early stages. In this study, we propose control methods for a system where multiple aerial robots are interconnected with passive flexible elements. These robotic systems enhance adaptability, enabling tasks like object manipulation. We model the flexible parts using the piecewise constant strain (PCS) model, which allows for model-based closed-loop control and stabilizes various configurations of the system. Through simulations and experiments, we validated that the proposed method achieves both stable flight and flexible deformation. Notably, we succeeded in maintaining stable flight, which was not possible with traditional methods, and demonstrated both positional controllability and the ability of the flexible parts to bend dynamically during flight.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt5_07">
             10:25-10:30, Paper WeBT5.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod999" name="modify5155" onclick="modify(5155,999)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5155'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Embodying Compliant Touch on Drones for Aerial Tactile Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#283082" title="Click to go to the Author Index">
             Bredenbeck, Anton
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#179240" title="Click to go to the Author Index">
             Della Santina, Cosimo
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#190182" title="Click to go to the Author Index">
             Hamaza, Salua
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5155" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#compliant_joints_and_mechanisms" title="Click to go to the Keyword Index">
               Compliant Joints and Mechanisms
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Aerial robots are a well-established solution for environmental surveying, exploration, and inspection, thanks to their superior maneuverability and agility. Nowadays, the algorithms that provide these capabilities rely on GNSS and Vision, which are obstructed in some environments of interest, e.g., indoors and underground or in smoke and dust. In similar conditions, animals rely on the sense of touch and compliant responses to interactions embodied in the body morphology. This way, they can navigate safely using tactile cues by feeling the environment surrounding them. In this work, we take inspiration from the natural example and propose an approach that allows a quadrotor to navigate using tactile information from the environment. We propose to endow a conventional quadrotor with a novel robotic finger that embodies compliance and sensing capabilities. We complete this design with a navigation approach that generates new waypoints based on the robotic finger's contact information to follow the unknown environment. The overall system's evaluation shows successful, repeatable results in 36 flight experiments with various relative angles between the drone and a planar surface.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt6">
             <b>
              WeBT6
             </b>
             Regular Session, 307
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1000" name="modifyWeBT6" onclick="modsession(625,1000)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt6" title="Click to go to the Program at a Glance">
             <b>
              Vision-Based Navigation 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#180541" title="Click to go to the Author Index">
             Boukas, Evangelos
            </a>
           </td>
           <td class="r">
            Technical University of Denmark
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#130410" title="Click to go to the Author Index">
             Kottege, Navinda
            </a>
           </td>
           <td class="r">
            CSIRO
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt6_01">
             09:55-10:00, Paper WeBT6.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1001" name="modify131" onclick="modify(131,1001)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('131'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Adaptive Learning for Hybrid Visual Odometry
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#312285" title="Click to go to the Author Index">
             Liu, Ziming
            </a>
           </td>
           <td class="r">
            INRIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106118" title="Click to go to the Author Index">
             Malis, Ezio
            </a>
           </td>
           <td class="r">
            Inria
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101740" title="Click to go to the Author Index">
             Martinet, Philippe
            </a>
           </td>
           <td class="r">
            INRIA
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab131" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Hybrid visual odometry methods achieve state-of-the-art performance by fusing both data-based deep learning networks and rule-based localization approaches. However, these methods also suffer from deep learning domain gap problems, which leads to an accuracy drop of the hybrid visual odometry approach when new type of data is considered. This paper is the first to explore a practical solution to this problem. Indeed, the deep learning network in the hybrid visual odometry predicts the stereo disparity with fixed searching space. However, the disparity distribution is unbalanced in stereo images acquired in different environments. We propose an adaptive network structure to overcome this problem. Secondly, the rule-based localization module has a robust performance by online optimizing the camera pose in test data, which motivates us to introduce test-time training machine learning method for improving the data-based part of the hybrid visual odometry.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt6_02">
             10:00-10:05, Paper WeBT6.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1002" name="modify613" onclick="modify(613,1002)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('613'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SOLVR: Submap Oriented LiDAR-Visual Re-Localisation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#321756" title="Click to go to the Author Index">
             Knights, Joshua Barton
            </a>
           </td>
           <td class="r">
            Queensland University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#313096" title="Click to go to the Author Index">
             Barbas Laina, Sebastián
            </a>
           </td>
           <td class="r">
            TU Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#118755" title="Click to go to the Author Index">
             Moghadam, Peyman
            </a>
           </td>
           <td class="r">
            CSIRO
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#151104" title="Click to go to the Author Index">
             Leutenegger, Stefan
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab613" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes SOLVR, a unified pipeline for learning based LiDAR-Visual re-localisation which performs place recognition and 6-DoF registration across sensor modalities. We propose a strategy to align the input sensor modalities by leveraging stereo image streams to produce metric depth predictions with pose information, followed by fusing multiple scene views from a local window using a probabilistic occupancy framework to expand the limited field-of-view of the camera. Additionally, SOLVR adopts a flexible definition of what constitutes positive examples for different training losses, allowing us to simultaneously optimise place recognition and registration performance. Furthermore, we replace RANSAC with a registration function that weights a simple least-squares fitting with the estimated inlier likelihood of sparse keypoint correspondences, improving performance in scenarios with a low inlier ratio between the query and retrieved place.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt6_03">
             10:05-10:10, Paper WeBT6.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1003" name="modify816" onclick="modify(816,1003)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('816'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SSF: Sparse Long-Range Scene Flow for Autonomous Driving
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#374970" title="Click to go to the Author Index">
             Khoche, Ajinkya
            </a>
           </td>
           <td class="r">
            KTH Royal Institute of Technology Stockholm, SCANIA CV AB
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#293956" title="Click to go to the Author Index">
             Zhang, Qingwen
            </a>
           </td>
           <td class="r">
            KTH Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#374989" title="Click to go to the Author Index">
             Pereira Sanchez, Laura
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419107" title="Click to go to the Author Index">
             Asefaw, Aron
            </a>
           </td>
           <td class="r">
            Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#193328" title="Click to go to the Author Index">
             Sharif Mansouri, Sina
            </a>
           </td>
           <td class="r">
            Scania
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101846" title="Click to go to the Author Index">
             Jensfelt, Patric
            </a>
           </td>
           <td class="r">
            KTH - Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab816" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Scene flow enables an understanding of the motion characteristics of the environment in the 3D world. It gains particular significance in the long-range, where object-based perception methods might fail due to sparse observations far away. Although significant advancements have been made in scene flow pipelines to handle large-scale point clouds, a gap remains in scalability with respect to long-range. We attribute this limitation to the common design choice of using dense feature grids, which scale quadratically with range. In this paper, we propose Sparse Scene Flow (SSF), a general pipeline for long-range scene flow, adopting a sparse convolution based backbone for feature extraction. This approach introduces a new challenge: a mismatch in size and ordering of sparse feature maps between time-sequential point scans. To address this, we propose a sparse feature fusion scheme, that augments the feature maps with virtual voxels at missing locations. Additionally, we propose a range-wise metric that implicitly gives greater importance to faraway points. Our method, SSF, achieves state-of-the-art results on the Argoverse2 dataset, demonstrating strong performance in long-range scene flow estimation. Our source code is open-sourced at https://github.com/KTH-RPL/SSF.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt6_04">
             10:10-10:15, Paper WeBT6.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1004" name="modify3216" onclick="modify(3216,1004)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3216'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              BoxMap: Efficient Structural Mapping and Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#331794" title="Click to go to the Author Index">
             Wang, Zili
            </a>
           </td>
           <td class="r">
            Boston University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420703" title="Click to go to the Author Index">
             Allum, Christopher
            </a>
           </td>
           <td class="r">
            Boston University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101718" title="Click to go to the Author Index">
             Andersson, Sean
            </a>
           </td>
           <td class="r">
            Boston University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#169800" title="Click to go to the Author Index">
             Tron, Roberto
            </a>
           </td>
           <td class="r">
            Boston University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3216" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             While humans can successfully navigate using abstractions, ignoring details that are irrelevant to the task at hand, most of the existing approaches in robotics require detailed environment representations which consume a significant amount of sensing, computing, and storage; these issues become particularly important in resource-constrained settings with limited power budgets. Deep learning methods can learn from prior experience to abstract knowledge from novel environments, and use it to more efficiently execute tasks such as frontier exploration, object search, or scene understanding. We propose BoxMap, a Detection-Transformer-based architecture that takes advantage of the structure of the sensed partial environment to update a topological graph of the environment as a set of semantic entities (rooms and doors) and their relations (connectivity). The predictions from low-level measurements can be leveraged to achieve high-level goals with lower computational costs than methods based on detailed representations. As an example application, we consider a robot equipped with a 2-D laser scanner tasked with exploring a residential building. Our BoxMap representation scales quadratically with the number of rooms (with a small constant), resulting in significant savings over a full geometric map. Moreover, our high-level topological representation results in 30.9% shorter trajectories in the exploration task with respect to a standard method. Code is available at: bit.ly/3F6w2Yl.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt6_05">
             10:15-10:20, Paper WeBT6.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1005" name="modify4102" onclick="modify(4102,1005)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4102'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              UncAD: Towards Safe End-To-End Autonomous Driving Via Online Map Uncertainty
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426250" title="Click to go to the Author Index">
             Yang, Pengxuan
            </a>
           </td>
           <td class="r">
            University of Chinese Academy of Sciences (UCAS)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#341305" title="Click to go to the Author Index">
             Zheng, Yupeng
            </a>
           </td>
           <td class="r">
            School of Artificial Intelligence, University of Chinese Academy
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#257441" title="Click to go to the Author Index">
             Zhang, Qichao
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425854" title="Click to go to the Author Index">
             Zhu, Kefei
            </a>
           </td>
           <td class="r">
            UCAS
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417996" title="Click to go to the Author Index">
             Xing, Zebin
            </a>
           </td>
           <td class="r">
            UCAS
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#450938" title="Click to go to the Author Index">
             Lin, Qiao
            </a>
           </td>
           <td class="r">
            EACON Technology Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#413096" title="Click to go to the Author Index">
             Liu, Yun-Fu
            </a>
           </td>
           <td class="r">
            Eacon
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#450935" title="Click to go to the Author Index">
             Su, Zhiguo
            </a>
           </td>
           <td class="r">
            EACON Technology Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103042" title="Click to go to the Author Index">
             Zhao, Dongbin
            </a>
           </td>
           <td class="r">
            Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4102" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             End-to-end autonomous driving aims to produce planning trajectories from raw sensors directly. Currently, most approaches integrate perception, prediction, and planning modules into a fully differentiable network, promising great scalability. However, these methods typically rely on deterministic modeling of online maps in the perception module for guiding or constraining vehicle planning, which may incorporate erroneous perception information and further compromise planning safety. To address this issue, we delve into the importance of online map uncertainty for enhancing autonomous driving safety and propose a novel paradigm named UncAD. Specifically, UncAD first estimates the uncertainty of the online map in the perception module. It then leverages the uncertainty to guide motion prediction and planning modules to produce multi-modal trajectories. Finally, to achieve safer autonomous driving, UncAD proposes an uncertainty-collision-aware planning selection strategy according to the online map uncertainty to evaluate and select the best trajectory. In this study, we incorporate UncAD into various state-of-the-art (SOTA) end-to-end methods. Experiments on the nuScenes dataset show that integrating UncAD, with only a 1.9% increase in parameters, can reduce collision rates by up to 26% and drivable area conflict rate by up to 42%. Codes, pre-trained models, and demo videos can be accessed at https://github.com/pengxuanyang/UncAD.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt6_06">
             10:20-10:25, Paper WeBT6.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1006" name="modify4187" onclick="modify(4187,1006)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4187'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Floor Zero-Shot Object Navigation Policy
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#394915" title="Click to go to the Author Index">
             Zhang, Lingfeng
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#394926" title="Click to go to the Author Index">
             Wang, Hao
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology(Guang Zhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395018" title="Click to go to the Author Index">
             Xiao, Erjia
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426156" title="Click to go to the Author Index">
             Zhang, Xinyao
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology (GUANGZHOU)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372752" title="Click to go to the Author Index">
             Zhang, Qiang
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397168" title="Click to go to the Author Index">
             Jiang, Zixuan
            </a>
           </td>
           <td class="r">
            HKUST(GZ)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354054" title="Click to go to the Author Index">
             Xu, Renjing
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4187" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#embodied_cognitive_science" title="Click to go to the Keyword Index">
               Embodied Cognitive Science
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Object navigation in multi-floor environments presents a formidable challenge in robotics, requiring sophisticated spatial reasoning and adaptive exploration strategies. Traditional approaches have primarily focused on single-floor scenarios, overlooking the complexities introduced by multi-floor structures. To address these challenges, we first propose a Multi-floor Navigation Policy (MFNP) and implement it in Zero-Shot object navigation tasks. Our framework comprises three key components: (i) Multi-floor Navigation Policy, which enables an agent to explore across multiple floors; (ii) Multi-modal Large Language Models (MLLMs) for reasoning in the navigation process; and (iii) Inter-Floor Navigation, ensuring efficient floor transitions. We evaluate MFNP on the Habitat-Matterport 3D (HM3D) and Matterport 3D (MP3D) datasets, both include multi-floor scenes. Our experiment results demonstrate that MFNP significantly outperforms all the existing methods in Zero-Shot object navigation, achieving higher success rates and improved exploration efficiency. Ablation studies further highlight the effectiveness of each component in addressing the unique challenges of multi-floor navigation. Meanwhile, we conducted real-world experiments to evaluate the feasibility of our policy. Upon deployment of MFNP, the Unitree quadruped robot demonstrated successful multi-floor navigation and found the target object in a completely unseen environment. By introducing MFNP, we offer a new paradigm for tackling complex, multi-floor environments in object navigation tasks, opening avenues for future research in visual-based navigation in realistic, multi-floor settings.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt6_07">
             10:25-10:30, Paper WeBT6.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1007" name="modify4968" onclick="modify(4968,1007)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4968'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Fed-EC: Bandwidth-Efficient Clustering-Based Federated Learning for Autonomous Visual Robot Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#410607" title="Click to go to the Author Index">
             Gummadi, Shreya
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#253889" title="Click to go to the Author Index">
             Valverde Gasparino, Mateus
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#313916" title="Click to go to the Author Index">
             Vasisht, Deepak
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#133090" title="Click to go to the Author Index">
             Chowdhary, Girish
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana Champaign
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4968" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Centralized learning requires data to be aggregated at a central server, which poses significant challenges in terms of data privacy and bandwidth consumption. Federated learning presents a compelling alternative, however, vanilla Federated Learning methods deployed in robotics aim to learn a single global model across robots that works ideally for all. But in practice one model may not be well suited for robots deployed in various environments. This paper proposes Federated-EmbedCluster (Fed-EC), a clustering-based federated learning framework that is deployed with vision based autonomous robot navigation in diverse outdoor environments. The framework addresses the key federated learning challenge of deteriorating model performance of a single global model due to the presence of non-IID data across real-world robots. Extensive real-world experiments validate that Fed-EC reduces the communication size by 23x for each robot while matching the performance of centralized learning for goal-oriented navigation and outperforms local learning. Fed-EC can transfer previously learnt models to new robots that join the cluster.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt7">
             <b>
              WeBT7
             </b>
             Regular Session, 309
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1008" name="modifyWeBT7" onclick="modsession(397,1008)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt7" title="Click to go to the Program at a Glance">
             <b>
              Perception 1
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#103148" title="Click to go to the Author Index">
             Stasse, Olivier
            </a>
           </td>
           <td class="r">
            LAAS, CNRS
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#203908" title="Click to go to the Author Index">
             Cho, Younggun
            </a>
           </td>
           <td class="r">
            Inha University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt7_01">
             09:55-10:00, Paper WeBT7.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1009" name="modify197" onclick="modify(197,1009)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('197'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Using a Distance Sensor to Detect Deviations in a Planar Surface
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309696" title="Click to go to the Author Index">
             Sifferman, Carter
            </a>
           </td>
           <td class="r">
            University of Wisconsin-Madison
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405973" title="Click to go to the Author Index">
             Sun, William
            </a>
           </td>
           <td class="r">
            UW-Madison
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#152043" title="Click to go to the Author Index">
             Gupta, Mohit
            </a>
           </td>
           <td class="r">
            University of Wisconsin-Madison
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#178409" title="Click to go to the Author Index">
             Gleicher, Michael
            </a>
           </td>
           <td class="r">
            University of Wisconsin - Madison
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab197" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We investigate methods for determining if a planar surface contains geometric deviations (e.g. protrusions, objects, divots, or cliffs) using only an instantaneous measurement from a miniature optical time-of-flight sensor. The key to our method is to utilize the entirety of information encoded in raw time-of-flight data captured by off-the-shelf distance sensors. We provide an analysis of the problem in which we identify the key ambiguity between geometry and surface photometrics. To overcome this challenging ambiguity, we fit a Gaussian mixture model to a small dataset of planar surface measurements. This model implicitly captures the expected geometry and distribution of photometrics of the planar surface and is used to identify measurements that are likely to contain deviations. We characterize our method on a variety of surfaces and planar deviations across a range of scenarios. We find that our method utilizing raw time-of-flight data outperforms baselines which use only derived distance estimates. We build an example application in which our method enables mobile robot obstacle and cliff avoidance over a wide field-of-view.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt7_02">
             10:00-10:05, Paper WeBT7.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1010" name="modify273" onclick="modify(273,1010)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('273'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Narrowing Your FOV with SOLiD: Spatially Organized and Lightweight Global Descriptor for FOV-Constrained LiDAR Place Recognition
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#334472" title="Click to go to the Author Index">
             Kim, Hogyun
            </a>
           </td>
           <td class="r">
            Inha University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#393761" title="Click to go to the Author Index">
             Choi, Jiwon
            </a>
           </td>
           <td class="r">
            Inha University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#393776" title="Click to go to the Author Index">
             Sim, Taehu
            </a>
           </td>
           <td class="r">
            Inha Uiversity
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#212571" title="Click to go to the Author Index">
             Kim, Giseop
            </a>
           </td>
           <td class="r">
            DGIST (Daegu Gyeongbuk Institute of Science and Technology)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203908" title="Click to go to the Author Index">
             Cho, Younggun
            </a>
           </td>
           <td class="r">
            Inha University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab273" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We often encounter limited FOV situations due to various factors such as sensor fusion or sensor mount in real-world robot navigation. However, the limited FOV interrupts the generation of descriptions and impacts place recognition adversely. Therefore, we suffer from correcting accumulated drift errors in a consistent map using LiDAR-based place recognition with limited FOV. Thus, in this paper, we propose a robust LiDAR-based place recognition method for handling narrow FOV scenarios. The proposed method establishes spatial organization based on the range-elevation bin and azimuth-elevation bin to represent places. In addition, we achieve a robust place description through reweighting based on vertical direction information. Based on these representations, our method enables addressing rotational changes and determining the initial heading. Additionally, we designed a lightweight and fast approach for the robot's onboard autonomy. For rigorous validation, the proposed method was tested across various LiDAR place recognition scenarios (i.e., single-session, multi-session, and multi-robot scenarios). To the best of our knowledge, we report the first method to cope with the restricted FOV. Our place description and SLAM codes will be released. Also, the supplementary materials of our descriptor are available at https://sites.google.com/view/lidar-solid.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt7_03">
             10:05-10:10, Paper WeBT7.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1011" name="modify810" onclick="modify(810,1011)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('810'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Towards Survivability in Complex Motion Scenarios: RGB-Event Object Tracking Via Historical Trajectory Prompting
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#414471" title="Click to go to the Author Index">
             Xia, Wenhao
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#374747" title="Click to go to the Author Index">
             Zhu, Jiawen
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416665" title="Click to go to the Author Index">
             He, You
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419748" title="Click to go to the Author Index">
             Qi, Jinqing
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419582" title="Click to go to the Author Index">
             Huang, Zihao
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#285627" title="Click to go to the Author Index">
             Jia, Xu
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab810" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             事件数据最近成为 object 的有价值的辅助对象 跟踪，提供具有密集时间分辨率的提示，以及 高动态范围。现有的 RGB 事件跟踪器通常 在使用 仅靠 RGB 功能无法实现的复杂运动轨迹 提供足够的鉴别力。为了解决这个问题，我们 提出了一个创新的 RGB 事件跟踪框架，称为 EventTPT，通过触发 嵌入在历史 轨迹。具体来说，EventTPT 集成了 多个相邻帧的轨迹转换为单个 事件图像使用时间加权聚合和 随后将其作为视觉提示输入到 跟踪器进行当前帧定位。跨模态自适应 融合模块进一步设计用于 光度不一致的情况。此外，我们 提出了一种新颖的具有挑战性的 RGB 事件跟踪基准， EventUAV，包含具有高运动复杂&amp;#
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt7_04">
             10:10-10:15, Paper WeBT7.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1012" name="modify1033" onclick="modify(1033,1012)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1033'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Spatially Constrained and Deeply Learned Bilateral Structural Intensity-Depth Registration Autonomously Navigates a Flexible Endoscope
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415130" title="Click to go to the Author Index">
             Fang, Hao
            </a>
           </td>
           <td class="r">
            Xiamen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#367263" title="Click to go to the Author Index">
             Wu, Ming
            </a>
           </td>
           <td class="r">
            Xiamen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#285783" title="Click to go to the Author Index">
             Fan, Wenkang
            </a>
           </td>
           <td class="r">
            Xiamen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420728" title="Click to go to the Author Index">
             Luo, Guangcheng
            </a>
           </td>
           <td class="r">
            Zhongshan Hospital Xiamen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#179016" title="Click to go to the Author Index">
             Luo, Xiongbiao
            </a>
           </td>
           <td class="r">
            Xiamen University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1033" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Endoscope tracking is commonly utilized to provide surgeons with in-body camera poses and visual fields during invasive procedures. The fundamental aspect of endoscopic navigation lies in precisely and continuously tracing the position and orientation of the endoscope within monocular endoscopic video sequences in a preoperative data space. This work proposes a new spatially constrained and deeply learned bilateral structural intensity-depth 2D-3D registration framework for autonomously navigating a flexible endoscope. Concretely, a novel bilateral structural intensity-depth similarity function is defined to tackle the deficiency of using image intensity, while a cross-domain monocular depth estimation model trained on virtual image data is used to accurately predict real image dense depth. Additionally, a spatial constraint is introduced to precisely reinitialize an optimizer to reduce accumulative tracking errors. We validate our method on clinical data, with the experimental results showing that our method significantly outperforms current vision-based navigation methods. Particularly, the average of position and orientation errors were reduced from (4.59mm, 9.22degree) to (1.65mm, 4.67degree).
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt7_05">
             10:15-10:20, Paper WeBT7.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1013" name="modify1961" onclick="modify(1961,1013)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1961'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              E2B: A Single Modality Point-Based Tracker with Event Cameras
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#285304" title="Click to go to the Author Index">
             Ren, Hongwei
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411296" title="Click to go to the Author Index">
             Li, Zhuo
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411289" title="Click to go to the Author Index">
             Tuerhong, Aiersi
            </a>
           </td>
           <td class="r">
            Chongqing University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411291" title="Click to go to the Author Index">
             Liu, Haobo
            </a>
           </td>
           <td class="r">
            The University of Electronic Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411292" title="Click to go to the Author Index">
             Liang, Fei
            </a>
           </td>
           <td class="r">
            Huawei Technologies Company Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411293" title="Click to go to the Author Index">
             Feng, Yongxiang
            </a>
           </td>
           <td class="r">
            Huawei Technologies Company Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#111642" title="Click to go to the Author Index">
             Wang, Wenhui
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#320595" title="Click to go to the Author Index">
             Wang, Yaoyuan
            </a>
           </td>
           <td class="r">
            Huawei
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#320899" title="Click to go to the Author Index">
             Zhang, Ziyang
            </a>
           </td>
           <td class="r">
            Huawei, China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411290" title="Click to go to the Author Index">
             He, Weihua
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411295" title="Click to go to the Author Index">
             Cheng, Bojun
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1961" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             High-speed object tracking holds significant relevance across robotic domains, such as drones and autonomous driving. Compared to conventional cameras, event cameras are equipped with the ability to capture object motion information at exceptionally high temporal resolution with relatively low power consumption and remain immune from motion-blurring effects. Regrettably, many existing methods adopt a frame-based approach by stacking events into Event Frame, which overlooks the sparsity and high temporal resolution of events. This approach is reliant on the pre-training backbone and reaches a performance plateau but demands unrealistically large networks and high power consumption, rendering it impractical for real-time applications in battery-constrained scenarios. In this paper, we propose an efficient and effective single-modality tracker using Point Cloud representation named E2B (Event to Box). By directly handling the raw output of event cameras without dataformat transformation, E2B leverages events' coordinate guidance to accurately map Event Cloud features to 2D bounding boxes. Moreover, E2B incorporates the pyramid structure into the multi-stage feature extraction architecture to effectively track objects across diverse scales. In the experiments, E2B performs outstandingly on two large-scale and one synthetic event-based tracking datasets, covering both indoor and outdoor environments, as well as rigid and non-rigid objects.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt7_06">
             10:20-10:25, Paper WeBT7.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1014" name="modify4038" onclick="modify(4038,1014)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4038'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              F²R²: Frequency Filtering-Based Rectification Robustness Method for Stereo Matching
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424781" title="Click to go to the Author Index">
             Zhou, Haolong
            </a>
           </td>
           <td class="r">
            Shanghai Institute of Microsystem and Information Technology, Ch
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#255818" title="Click to go to the Author Index">
             Zhu, Dongchen
            </a>
           </td>
           <td class="r">
            Shanghai Institute of Microsystem and Information Technology, Chi
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#255810" title="Click to go to the Author Index">
             Zhang, Guanghui
            </a>
           </td>
           <td class="r">
            Shanghai Institute of Microsystem and Information Technology, Ch
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338555" title="Click to go to the Author Index">
             Wang, Lei
            </a>
           </td>
           <td class="r">
            Shanghai Institute of Microsystem and Information Technology, Ch
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#224350" title="Click to go to the Author Index">
             Li, Jiamao
            </a>
           </td>
           <td class="r">
            Shanghai Institute of Microsystem and Information Technology, Chi
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4038" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Most stereo matching networks assume that the stereo images are perfectly rectified, ignoring the perturbation of extrinsic parameters due to collisions, mechanical vibrations, and thermal expansion. This leads to poor rectification robustness in real-world stereo systems. That is, even minor rectification errors can lead to failure, making stereo systems unreliable for long-term autonomous operation in complex environments. In this paper, we are the first to propose a frequency filtering-based rectification robustness (F²R²) method for stereo matching, which aims to enhance the robustness of existing stereo networks to rectification errors. Specifically, we propose a sensitive frequency filter (SFF) to remove components susceptible to rectification errors within the frequency domain. SFF achieves the filtering through the learning-based adaptive filtering mask (AFM) guided by the spatial-frequency mapping modulation mask (SFM). Moreover, we build the matching feature reconstruction module (MFRM) to recover the features lost during filtering to benefit cost aggregation. Comprehensive experiments on simulated datasets and self-collected data validate that our method can significantly enhance the rectification robustness of stereo matching networks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt7_07">
             10:25-10:30, Paper WeBT7.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1015" name="modify5011" onclick="modify(5011,1015)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5011'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              VisTune: Auto-Tuner for UAVs Using Vision-Based Localization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#334644" title="Click to go to the Author Index">
             Humais, Muhammad Ahmed
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#250547" title="Click to go to the Author Index">
             Chehadeh, Mohamad
            </a>
           </td>
           <td class="r">
            Khalifa University for Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#246702" title="Click to go to the Author Index">
             Azzam, Rana
            </a>
           </td>
           <td class="r">
            Khalifa University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#318868" title="Click to go to the Author Index">
             Boiko, Igor
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#328150" title="Click to go to the Author Index">
             Zweiri, Yahya
            </a>
           </td>
           <td class="r">
            Khalifa University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5011" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents VisTune, a method for automatic controller tuning, specifically designed for UAVs using vision-based localization for position control. In contrast to existing methods that involve flying the UAV manually to collect the data for system identification and tuning, our approach leverages relay-based system identification and tuning that autonomously generates stable oscillations, without the need for stabilizing controller. The whole process concludes within few seconds. Prior work in vision-based position control of the UAVs often ignores the delay from the perception pipeline, which is quite significant and results in suboptimal tuning and poor control performance. Our approach accounts for perception delay and addresses practical issues, such as varying delays due to varying computation requirements and inevitable estimation errors, which pose challenges in applying relay-based identification and tuning. Typically, VBL system introduces over 100 ms delay, compared to less than 20 ms delay when motion capture system is used. Moreover, we show that the perception delay identified by VisTune can be effectively used to temporally advance the feedforward acceleration signal to achieve better tracking performance. Finally, we demonstrate the robustness of the tuned controllers on a trajectory tracking task, reaching speed up to 2.1 m/s with RMS control error of only 0.054 m while under wind disturbance of 5 m/s we report RMSE of 0.116 m. A video of experiments is available at https://youtu.be/hJoT8bn0K0o
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt8">
             <b>
              WeBT8
             </b>
             Regular Session, 311
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1016" name="modifyWeBT8" onclick="modsession(481,1016)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt8" title="Click to go to the Program at a Glance">
             <b>
              Representation Learning 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#150386" title="Click to go to the Author Index">
             Held, David
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#241049" title="Click to go to the Author Index">
             Shin, Ukcheol
            </a>
           </td>
           <td class="r">
            CMU(Carnegie Mellon University)
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt8_01">
             09:55-10:00, Paper WeBT8.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1017" name="modify31" onclick="modify(31,1017)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('31'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GeMuCo: Generalized Multisensory Correlational Model for Body Schema Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#206398" title="Click to go to the Author Index">
             Kawaharazuka, Kento
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106350" title="Click to go to the Author Index">
             Okada, Kei
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106348" title="Click to go to the Author Index">
             Inaba, Masayuki
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab31" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_experience" title="Click to go to the Keyword Index">
               Learning from Experience
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#software_architecture_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Software Architecture for Robotic and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#cognitive_control_architectures" title="Click to go to the Keyword Index">
               Cognitive Control Architectures
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Humans can autonomously learn the relationship between sensation and motion in their own bodies, estimate and control their own body states, and move while continuously adapting to the current environment. On the other hand, current robots control their bodies by learning the network structure described by humans from their experiences, making certain assumptions on the relationship between sensors and actuators. In addition, the network model does not adapt to changes in the robot's body, the tools that are grasped, or the environment, and there is no unified theory, not only for control but also for state estimation, anomaly detection, simulation, and so on. In this study, we propose a Generalized Multisensory Correlational Model (GeMuCo), in which the robot itself acquires a body schema describing the correlation between sensors and actuators from its own experience, including model structures such as network input/output. The robot adapts to the current environment by updating this body schema model online, estimates and controls its body state, and even performs anomaly detection and simulation. We demonstrate the effectiveness of this method by applying it to tool-use co
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt8_02">
             10:00-10:05, Paper WeBT8.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1018" name="modify1640" onclick="modify(1640,1018)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1640'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SplatSim: Zero-Shot Sim2Real Transfer of RGB Manipulation Policies Using Gaussian Splatting
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#290805" title="Click to go to the Author Index">
             Qureshi, Mohammad Nomaan
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420837" title="Click to go to the Author Index">
             Garg, Sparsh
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#281406" title="Click to go to the Author Index">
             Yandun, Francisco
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#150386" title="Click to go to the Author Index">
             Held, David
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101976" title="Click to go to the Author Index">
             Kantor, George
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#195210" title="Click to go to the Author Index">
             Silwal, Abhisesh
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1640" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#sensorimotor_learning" title="Click to go to the Keyword Index">
               Sensorimotor Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Sim2Real transfer, particularly for manipulation policies relying on RGB images, remains a critical challenge in robotics due to the significant domain shift between synthetic and real-world visual data. In this paper, we propose SplatSim, a novel framework that leverages Gaussian Splatting as the primary rendering primitive to reduce the Sim2Real gap for RGB-based manipulation policies. By replacing traditional mesh representations with Gaussian Splats in simulators, SplatSim produces highly photorealistic synthetic data while maintaining the scalability and cost-efficiency of simulation. We demonstrate the effectiveness of our framework by training manipulation policies within SplatSim and deploying them in the real world in a zero-shot manner, achieving an average success rate of 86.25%, compared to 97.5% for policies trained on real-world data.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt8_03">
             10:05-10:10, Paper WeBT8.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1019" name="modify1642" onclick="modify(1642,1019)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1642'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SR-AIF: Solving Sparse-Reward Robotic Tasks from Pixels with Active Inference and World Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417242" title="Click to go to the Author Index">
             Nguyen, Viet Dung
            </a>
           </td>
           <td class="r">
            Rochester Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417250" title="Click to go to the Author Index">
             Yang, Zhizhuo
            </a>
           </td>
           <td class="r">
            Rochester Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420512" title="Click to go to the Author Index">
             Buckley, Christopher
            </a>
           </td>
           <td class="r">
            Verses AI
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#324104" title="Click to go to the Author Index">
             Ororbia, Alexander
            </a>
           </td>
           <td class="r">
            Rochester Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1642" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#bioinspired_robot_learning" title="Click to go to the Keyword Index">
               Bioinspired Robot Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Although research has produced promising results demonstrating the utility of active inference (AIF) in Markov decision processes (MDPs), there is relatively less work that builds AIF models in the context of environments and problems that take the form of partially observable Markov decision processes (POMDPs). In POMDP scenarios, the agent must infer the unobserved environmental state from raw sensory observations, e.g., pixels in an image. Additionally, less work exists in examining the most difficult form of POMDP-centered control: continuous action space POMDPs under sparse reward signals. In this work, we address issues facing the AIF modeling paradigm by introducing novel prior preference learning techniques and self-revision schedules to help the agent excel in sparse-reward, continuous action, goal-based robotic control POMDP environments. Empirically, we show that our agents offer improved performance over state-of-the-art models in terms of cumulative rewards, relative stability, and success rate.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt8_04">
             10:10-10:15, Paper WeBT8.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1020" name="modify2009" onclick="modify(2009,1020)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2009'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Neuro-Symbolic Imitation Learning: Discovering Symbolic Abstractions for Skill Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#276697" title="Click to go to the Author Index">
             Keller, Leon
            </a>
           </td>
           <td class="r">
            TU Darmstadt
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#202185" title="Click to go to the Author Index">
             Tanneberg, Daniel
            </a>
           </td>
           <td class="r">
            Honda Research Institute Europe
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104326" title="Click to go to the Author Index">
             Peters, Jan
            </a>
           </td>
           <td class="r">
            Technische Universität Darmstadt
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2009" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Imitation learning is a popular method for teaching robots new behaviors. However, most existing methods focus on teaching short, isolated skills rather than long, multi-step tasks. To bridge this gap, imitation learning algorithms must not only learn individual skills but also an abstract understanding of how to sequence these skills to perform extended tasks effectively. This paper addresses this challenge by proposing a neuro-symbolic imitation learning framework. Using task demonstrations, the system first learns a symbolic representation that abstracts the low-level state-action space. The learned representation decomposes a task into easier subtasks and allows the system to leverage symbolic planning to generate abstract plans. Subsequently, the system utilizes this task decomposition to learn a set of neural skills capable of refining abstract plans into actionable robot commands. Experimental results in three simulated robotic environments demonstrate that, compared to baselines, our neuro-symbolic approach increases data efficiency, improves generalization capabilities, and facilitates interpretability.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt8_05">
             10:15-10:20, Paper WeBT8.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1021" name="modify2097" onclick="modify(2097,1021)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2097'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Chain-Of-Modality: Learning Manipulation Programs from Multimodal Human Videos with Vision-Language-Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#222003" title="Click to go to the Author Index">
             Wang, Chen
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#235958" title="Click to go to the Author Index">
             Xia, Fei
            </a>
           </td>
           <td class="r">
            Google Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#198071" title="Click to go to the Author Index">
             Yu, Wenhao
            </a>
           </td>
           <td class="r">
            Google
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#173944" title="Click to go to the Author Index">
             Zhang, Tingnan
            </a>
           </td>
           <td class="r">
            Google
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#315192" title="Click to go to the Author Index">
             Zhang, Ruohan
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#132937" title="Click to go to the Author Index">
             Liu, Karen
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#142990" title="Click to go to the Author Index">
             Fei-Fei, Li
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#219934" title="Click to go to the Author Index">
             Tan, Jie
            </a>
           </td>
           <td class="r">
            Google
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#213370" title="Click to go to the Author Index">
             Liang, Jacky
            </a>
           </td>
           <td class="r">
            Google
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2097" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#embodied_cognitive_science" title="Click to go to the Keyword Index">
               Embodied Cognitive Science
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Learning to perform manipulation tasks from human videos is a promising approach for teaching robots. However, many manipulation tasks require changing control parameters during task execution, such as force, which visual data alone cannot capture. In this work, we leverage sensing devices such as armbands that measure human muscle activities and microphones that record sound, to capture the details in the human manipulation process, and enable robots to extract task plans and control parameters to perform the same task. To achieve this, we introduce Chain-of-Modality (CoM), a prompting strategy that enables Vision Language Models to reason about multimodal human demonstration data --- videos coupled with muscle or audio signals. By progressively integrating information from each modality, CoM refines a task plan and generates detailed control parameters, enabling robots to perform manipulation tasks based on a single multimodal human video prompt. Our experiments show that CoM delivers a threefold improvement in accuracy for extracting task plans and control parameters compared to baselines, with strong generalization to new task setups and objects in real-world robot experiments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt8_06">
             10:20-10:25, Paper WeBT8.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1022" name="modify2840" onclick="modify(2840,1022)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2840'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              VertiCoder: Self-Supervised Kinodynamic Representation Learning on Vertically Challenging Terrain
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#349198" title="Click to go to the Author Index">
             Nazeri, Mohammad
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354757" title="Click to go to the Author Index">
             Datar, Aniket
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#399211" title="Click to go to the Author Index">
             Pokhrel, Anuj
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#349237" title="Click to go to the Author Index">
             Pan, Chenhui
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#183979" title="Click to go to the Author Index">
             Warnell, Garrett
            </a>
           </td>
           <td class="r">
            U.S. Army Research Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#177144" title="Click to go to the Author Index">
             Xiao, Xuesu
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2840" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_experience" title="Click to go to the Keyword Index">
               Learning from Experience
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present VertiCoder, a self-supervised representation learning approach for robot mobility on vertically challenging terrain. Using the same pre-training process, VertiCoder can handle four different downstream tasks, including forward kinodynamics learning, inverse kinodynamics learning, behavior cloning, and patch reconstruction with a single representation. VertiCoder uses a TransformerEncoder to learn the local context of its surroundings by random masking and next patch reconstruction. We show that VertiCoder achieves better performance across all four different tasks compared to specialized End-to-End models with 77% fewer parameters. We also show VertiCoder's comparable performance against state-of-the-art kinodynamic modeling and planning approaches in real-world robot deployment. These results underscore the efficacy of VertiCoder in mitigating overfitting and fostering more robust generalization across diverse environmental contexts and downstream vehicle kinodynamic tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt8_07">
             10:25-10:30, Paper WeBT8.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1023" name="modify4915" onclick="modify(4915,1023)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4915'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Correspondence Learning between Morphologically Different Robots Via Task Demonstrations
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#367836" title="Click to go to the Author Index">
             Aktas, Hakan
            </a>
           </td>
           <td class="r">
            The University of Cambridge
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#109813" title="Click to go to the Author Index">
             Nagai, Yukie
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101711" title="Click to go to the Author Index">
             Asada, Minoru
            </a>
           </td>
           <td class="r">
            Open and Transdisciplinary Research Initiatives, Osaka Universit
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104664" title="Click to go to the Author Index">
             Oztop, Erhan
            </a>
           </td>
           <td class="r">
            Osaka University / Ozyegin University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106000" title="Click to go to the Author Index">
             Ugur, Emre
            </a>
           </td>
           <td class="r">
            Bogazici University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4915" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#developmental_robotics" title="Click to go to the Keyword Index">
               Developmental Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We observe a large variety of robots in terms of their bodies, sensors, and actuators. Given the commonalities in the skill sets, teaching each skill to each different robot independently is inefficient and not scalable when the large variety in the robotic landscape is considered. If we can learn the correspondences between the sensorimotor spaces of different robots, we can expect a skill that is learned in one robot can be more directly and easily transferred to other robots. In this paper, we propose a method to learn correspondences hakan{among two or more robots that may have different morphologies. To be specific, besides robots with similar morphologies with different degrees of freedom, we show that a fixed-based manipulator robot with joint control and a differential drive mobile robot can be addressed within the proposed framework. To set up the correspondence among the robots considered, an initial base task is demonstrated to the robots to achieve the same goal. Then, a common latent representation is learned along with the individual robot policies for achieving the goal.} After the initial learning stage, the observation of a new task execution by one robot becomes sufficient to generate a latent space representation pertaining to the other robots to achieve the same task. We verified our system in a set of experiments where the correspondence between robots is learned (1) when the robots need to follow the same paths to achieve the same task, (2) when the robots need to follow different trajectories to achieve the same task, and (3) when complexities of the required sensorimotor trajectories are different for the robots. We also provide a proof-of-the-concept realization of correspondence learning between a real manipulator robot and a simulated mobile robot.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt9">
             <b>
              WeBT9
             </b>
             Regular Session, 312
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1024" name="modifyWeBT9" onclick="modsession(345,1024)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt9" title="Click to go to the Program at a Glance">
             <b>
              Multi-Robot Exploration
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#240067" title="Click to go to the Author Index">
             Solis Vidana, Juan Irving
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#274740" title="Click to go to the Author Index">
             Pedram, Ali Reza
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt9_01">
             09:55-10:00, Paper WeBT9.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1025" name="modify286" onclick="modify(286,1025)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('286'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Planning-Oriented Cooperative Perception among Heterogeneous Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415339" title="Click to go to the Author Index">
             Zheng, Han
            </a>
           </td>
           <td class="r">
            Stony Brook University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415266" title="Click to go to the Author Index">
             Ye, Fan
            </a>
           </td>
           <td class="r">
            Stony Brook University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415262" title="Click to go to the Author Index">
             Yang, Yuanyuan
            </a>
           </td>
           <td class="r">
            Stony Brook University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab286" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Vehicle-to-vehicle (V2V) based cooperative perception enhances autonomous driving by overcoming single-agent perception limitations such as occlusions, without relying on extensive infrastructure. However, most existing methods have two key limitations. They treat cooperative perception in isolation, with little consideration for downstream tasks such as planning, leading to poor coordination and inefficient planning decisions. They also assume perception model homogeneity across all vehicles, which can be impractical among vehicles from different manufacturers. To bridge such gaps, we propose Scout, an early-fusion framework for planning-oriented cooperative perception among vehicles of heterogeneous models. Specifically, we formalize a notion of emph{Deltatheta-Risk Increment Distribution (RID)} to capture the distribution of the risk increment by incomplete perception to the current trajectory plan, and define a Priority Index (PI) metric for prioritizing cooperative perception on riskier regions. We develop algorithms to estimate emph{Delta theta-RID} and PI at run-time with theoretical bounds. Empirical results demonstrate that Scout surpasses state-of-the-art methods and strong baselines on challenging benchmarks, achieving higher success rates with only 3-10% of their communication volume.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt9_02">
             10:00-10:05, Paper WeBT9.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1026" name="modify1559" onclick="modify(1559,1026)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1559'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              TaskExp: Enhancing Generalization of Multi-Robot Exploration with Multi-Task Pre-Training
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#336335" title="Click to go to the Author Index">
             Zhu, Shaohao
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#355436" title="Click to go to the Author Index">
             Zhao, Yixian
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#294245" title="Click to go to the Author Index">
             Xu, Yang
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#336308" title="Click to go to the Author Index">
             Chen, Anjun
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#163844" title="Click to go to the Author Index">
             Chen, Jiming
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#141995" title="Click to go to the Author Index">
             Xu, Jinming
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1559" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We aim to develop a general multi-agent reinforcement learning (MARL) policy that enables a group of robots to efficiently explore large-scale, unknown environments with random pose initialization. Existing MARL-based multi-robot exploration methods face challenges in reliably mapping observations to actions in large-scale scenarios and lack of zero-shot generalization to unknown environments. To this end, we propose a generic multi-task pre-training algorithm (termed TaskExp) to enhance the generalization of learning-based policies. In particular, we design a decision-related task to guide the policy to focus on valuable subspaces of the action space, improving the reliability of policy mapping. Moreover, two perception-related tasks--Location Estimation and Map Prediction--are designed to enhance the zero-shot capability of the policy by guiding it to extract general invariant features from unknown environments. With TaskExp pre-training, our policy significantly outperforms state-of-the-art planning-based methods in large-scale scenarios and demonstrates strong zero-shot performance in unseen environments. Furthermore, TaskExp can also be easily integrated to improve the existing learning-based multi-robot exploration methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt9_03">
             10:05-10:10, Paper WeBT9.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1027" name="modify1900" onclick="modify(1900,1027)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1900'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              WcDT: World-Centric Diffusion Transformer for Traffic Scene Generation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422493" title="Click to go to the Author Index">
             Yang, Chen
            </a>
           </td>
           <td class="r">
            Cardiff University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422600" title="Click to go to the Author Index">
             He, Yangfan
            </a>
           </td>
           <td class="r">
            University of Minnesota - Twin Cities
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422612" title="Click to go to the Author Index">
             Tian, Aaron Xuxiang
            </a>
           </td>
           <td class="r">
            Independent Researcher
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#330220" title="Click to go to the Author Index">
             Chen, Dong
            </a>
           </td>
           <td class="r">
            Mississippi State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424626" title="Click to go to the Author Index">
             Wang, Jianhui
            </a>
           </td>
           <td class="r">
            University of Electronic Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#353493" title="Click to go to the Author Index">
             Shi, Tianyu
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422625" title="Click to go to the Author Index">
             Heydarian, Arsalan
            </a>
           </td>
           <td class="r">
            University of Virginia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423123" title="Click to go to the Author Index">
             Liu, Pei
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology(GuangZhou)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1900" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning_under_uncertainty" title="Click to go to the Keyword Index">
               Planning under Uncertainty
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we introduce a novel approach for autonomous driving trajectory generation by harnessing the complementary strengths of diffusion probabilistic models (a.k.a., diffusion models) and transformers. Our proposed framework, termed the "World-centric Diffusion Transformer"(WcDT), optimizes the entire trajectory generation process, from feature extraction to model inference. To enhance the scene diversity and stochasticity, the historical trajectory data is first preprocessed into "Agent Move Statement" and encoded into latent space using Denoising Diffusion Probabilistic Models (DDPM) enhanced with Diffusion with Transformer (DiT) blocks. Then, the latent features, historical trajectories, HD map features, and historical traffic signal information are fused with various transformer-based encoders that is used to enhance the interaction of agents with other elements in the traffic scene. The encoded traffic scenes are then decoded by a trajectory decoder to generate multimodal future trajectories. Comprehensive experimental results show that the proposed approach exhibits superior performance in generating both realistic and diverse trajectories, showing its potential for integration into automatic driving simulation systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt9_04">
             10:10-10:15, Paper WeBT9.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1028" name="modify2427" onclick="modify(2427,1028)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2427'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hybrid Decentralization for Multi-Robot Orienteering with Mothership-Passenger Systems
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424204" title="Click to go to the Author Index">
             Butler, Nathan
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103610" title="Click to go to the Author Index">
             Hollinger, Geoffrey
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2427" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a hybrid centralized-decentralized planning algorithm for a multi-robot system made up of a single Mothership robot and multiple Passenger robots. In this system, the Passenger robots execute tasks while the Mothership provides support. This paper addresses the challenge of planning Passenger robot movements, framing it as a Stochastic Multi-Agent Orienteering Problem (SMOP) complicated by factors like stochastic operational efforts and disruptive events. We optimize the task completion efficiency of the system by combining centralized solutions from the Mothership with local plans from Passengers to enhance system resilience. Our contributions include defining the SMOP, developing a distributed solution using decentralized Monte Carlo tree search, presenting a hybrid algorithm that integrates centralized plans into the distributed framework, and evaluating the algorithm’s performance in simulation using real-world data. Our results show that our hybrid approaches outperform fully centralized and fully distributed algorithms in dynamic and disruptive scenarios with up to 26.6% increase in task completion efficiency over baseline methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt9_05">
             10:15-10:20, Paper WeBT9.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1029" name="modify2803" onclick="modify(2803,1029)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2803'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Communication-Aware Iterative Map Compression for Online Path-Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378087" title="Click to go to the Author Index">
             Psomiadis, Evangelos
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#274740" title="Click to go to the Author Index">
             Pedram, Ali Reza
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256863" title="Click to go to the Author Index">
             Maity, Dipankar
            </a>
           </td>
           <td class="r">
            University of North Carolina at Charlotte
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101179" title="Click to go to the Author Index">
             Tsiotras, Panagiotis
            </a>
           </td>
           <td class="r">
            Georgia Tech
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2803" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper addresses the problem of optimizing communicated information among heterogeneous, resource-aware robot teams to facilitate their navigation. In such operations, a mobile robot compresses its local map to assist another robot in reaching a target within an uncharted environment. The primary challenge lies in ensuring that the map compression step balances network load while transmitting only the most essential information for effective navigation. We propose a communication framework that sequentially selects the optimal map compression in a task-driven, communication-aware manner. It introduces a decoder capable of iterative map estimation, handling noise through Kalman filter techniques. The computational speed of our decoder allows for a larger compression template set compared to previous methods, and enables applications in more challenging environments. Specifically, our simulations demonstrate a remarkable 98% reduction in communicated information, compared to a framework that transmits the raw data, on a large Mars inclination map and an Earth map, all while maintaining similar planning costs. Furthermore, our method significantly reduces computational time compared to the state-of-the-art approach.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt9_06">
             10:20-10:25, Paper WeBT9.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1030" name="modify2993" onclick="modify(2993,1030)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2993'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DiffCP: Ultra-Low Bit Collaborative Perception Via Diffusion Model
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416553" title="Click to go to the Author Index">
             Mao, Ruiqing
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424066" title="Click to go to the Author Index">
             Wu, Haotian
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420158" title="Click to go to the Author Index">
             Jia, Yukuan
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421171" title="Click to go to the Author Index">
             Nan, Zhaojun
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420333" title="Click to go to the Author Index">
             Sun, Yuxuan
            </a>
           </td>
           <td class="r">
            Beijing Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#399169" title="Click to go to the Author Index">
             Zhou, Sheng
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420843" title="Click to go to the Author Index">
             Gunduz, Deniz
            </a>
           </td>
           <td class="r">
            İmperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424726" title="Click to go to the Author Index">
             Niu, Zhisheng
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2993" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Collaborative perception (CP) is emerging as a promising solution to the inherent limitations of stand-alone intelligence. However, current wireless communication systems are unable to support feature-level and raw-level collaborative algorithms due to their enormous bandwidth demands. In this paper, we propose DiffCP, a novel CP paradigm that utilizes a diffusion model to efficiently compress the sensing information of collaborators. By incorporating both geometric and semantic conditions into the generative model, DiffCP enables feature-level collaboration with an ultra-low communication cost, advancing the practical implementation of CP systems. This paradigm can be seamlessly integrated into existing CP algorithms to enhance a wide range of downstream tasks. Through extensive experimentation, we investigate the trade-offs between communication, computation, and performance. Numerical results demonstrate that DiffCP can significantly reduce communication costs by 14.5-fold while maintaining the same performance as the state-of-the-art algorithm.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt10">
             <b>
              WeBT10
             </b>
             Regular Session, 313
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1031" name="modifyWeBT10" onclick="modsession(351,1031)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt10" title="Click to go to the Program at a Glance">
             <b>
              Multi-Robot Path Planning 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#167155" title="Click to go to the Author Index">
             Pierson, Alyssa
            </a>
           </td>
           <td class="r">
            Boston University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#127543" title="Click to go to the Author Index">
             Nam, Changjoo
            </a>
           </td>
           <td class="r">
            Sogang University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt10_01">
             09:55-10:00, Paper WeBT10.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1032" name="modify97" onclick="modify(97,1032)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('97'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              APF-CPP: An Artificial Potential Field Based Multi-Robot Online Coverage Path Planning Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#363964" title="Click to go to the Author Index">
             Wang, Zikai
            </a>
           </td>
           <td class="r">
            Hongkong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#370578" title="Click to go to the Author Index">
             Zhao, Xiaoqi
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#383660" title="Click to go to the Author Index">
             Zhang, Jiekai
            </a>
           </td>
           <td class="r">
            Hong Kong Applied Science and Technology Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#297185" title="Click to go to the Author Index">
             Yang, Nachuan
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#368572" title="Click to go to the Author Index">
             Wang, Pengyu
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#297049" title="Click to go to the Author Index">
             Tang, Jiawei
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#384448" title="Click to go to the Author Index">
             Zhang, Jiuzhou
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#146878" title="Click to go to the Author Index">
             Shi, Ling
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab97" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-robot coverage planning has gained significant attention in recent years. In this paper, we introduce a novel approach called APF-CPP (Artificial Potential Field Based Multi-Robot Online Coverage Path Planning) to enhance the collaboration of multi-robot systems to accomplish coverage tasks in unknown dynamic environments. Our approach presents a unique coverage policy that leverages the concept of artificial potential field (APF). In contrast to the conventional APF-based path planning methods that directly generate paths based on the field gradient, we utilize the APF to derive coverage policies for individual robots within a multi-robot system to achieve efficient task allocation and maintain regular coverage patterns. We have developed a policy update mechanism that allows the system to adapt its task allocation policy based on real-time conditions while minimizing the impact caused by policy changes. To better handle dead-end conditions, we use the APF concept to allocate tasks better during the dead-end recovery process. We also show that our algorithm has a low computational complexity and guarantees complete coverage in a finite time. We conduct extensive comparisons with other state-of-the-art (SOTA) approaches and validate our method through simulations and real-world experiments. The experimental results demonstrate the advantages of our proposed method over existing approaches and confirm the effectiveness and robustness of real-world implementation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt10_02">
             10:00-10:05, Paper WeBT10.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1033" name="modify328" onclick="modify(328,1033)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('328'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Exact Wavefront Propagation for Globally Optimal One-To-All Path Planning on 2D Cartesian Grids
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#312653" title="Click to go to the Author Index">
             Ibrahim, Ibrahim
            </a>
           </td>
           <td class="r">
            KU Leuven
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#286163" title="Click to go to the Author Index">
             Gillis, Joris
            </a>
           </td>
           <td class="r">
            KU Leuven
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104910" title="Click to go to the Author Index">
             Decré, Wilm
            </a>
           </td>
           <td class="r">
            Katholieke Universiteit Leuven
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#114656" title="Click to go to the Author Index">
             Swevers, Jan
            </a>
           </td>
           <td class="r">
            KU Leuven
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab328" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computational_geometry" title="Click to go to the Keyword Index">
               Computational Geometry
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces an efficient mathcal{O}(n) compute and memory complexity algorithm for globally optimal path planning on 2D Cartesian grids. Unlike existing marching methods that rely on approximate discretized solutions to the Eikonal equation, our approach achieves exact wavefront propagation by pivoting the analytic distance function based on visibility. The algorithm leverages a dynamic-programming subroutine to efficiently evaluate visibility queries. Through benchmarking against state-of-the-art any-angle path planners, we demonstrate that our method outperforms existing approaches in both speed and accuracy, particularly in cluttered environments. Notably, our method inherently provides globally optimal paths to all grid points, eliminating the need for additional gradient descent steps per path query. The same capability extends to multiple starting positions. We also provide a greedy version of our algorithm as well as open-source C++ implementation of our solver.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt10_03">
             10:05-10:10, Paper WeBT10.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1034" name="modify1585" onclick="modify(1585,1034)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1585'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ICBSS: An Improved Algorithm for Multi-Agent Combinatorial Path Finding
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#375432" title="Click to go to the Author Index">
             Chen, Zheng
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421951" title="Click to go to the Author Index">
             Chen, Changlin
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422214" title="Click to go to the Author Index">
             Yiran, Ni
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1585" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The Multi-Agent Combinatorial Path Finding (MCPF) problem is a generalized version of the Multi-Agent Path Finding (MAPF) problem, in which each agent must collectively visit multiple intermediate target locations on the way to their final destinations. The state-of-the-art approach for addressing MCPF, known as Conflict-Based Steiner Search (CBSS) cite{DBLP:journals/trob/RenRC23}, leverages K-best joint sequences to create multiple search trees, and employs CBS-like search to resolve collisions for each tree. Despite its optimality guarantee, CBSS is computationally burdensome due to the duplicated collision resolutions across multiple trees and the computation of the K-best joint sequences. To address these challenges, we propose a novel algorithm called Improved Conflict-Based Steiner Search (ICBSS), aiming at expediting CBSS by replacing the multi trees with a single conflict tree (CT), which can be implemented by interleaving the time-dependent traveling salesman algorithm to compute the optimal joint path for agents under the newly generated constraints in each CT vertex. Additionally, we introduce a sub-optimal variant of ICBSS, which improves computational efficiency at the expense of solution optimality. Empirical results show that ICBSS outperforms state-of-the-art MCPF algorithms on a variety of MAPF instances.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt10_04">
             10:10-10:15, Paper WeBT10.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1035" name="modify2518" onclick="modify(2518,1035)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2518'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Escaping Local Minima: Hybrid Artificial Potential Field with Wall-Follower for Decentralized Multi-Robot Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#349876" title="Click to go to the Author Index">
             Kim, Joonkyung
            </a>
           </td>
           <td class="r">
            Sogang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424362" title="Click to go to the Author Index">
             Park, Sangjin
            </a>
           </td>
           <td class="r">
            Sogang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424369" title="Click to go to the Author Index">
             Lee, Wonjong
            </a>
           </td>
           <td class="r">
            Sogang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398302" title="Click to go to the Author Index">
             Kim, Woojun
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#146209" title="Click to go to the Author Index">
             Choi, Hyunga
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#117481" title="Click to go to the Author Index">
             Doh, Nakju
            </a>
           </td>
           <td class="r">
            Korea University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#127543" title="Click to go to the Author Index">
             Nam, Changjoo
            </a>
           </td>
           <td class="r">
            Sogang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2518" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reactive_and_sensor_based_planning" title="Click to go to the Keyword Index">
               Reactive and Sensor-Based Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We tackle the challenge of decentralized multi-robot navigation in environments with nonconvex obstacles, where complete environmental knowledge is unavailable. While reactive methods like Artificial Potential Field (APF) offer simplicity and efficiency, they suffer from local minima, causing robots to become trapped due to their lack of global environmental awareness. Other existing solutions either rely on inter-robot communication, are limited to single-robot scenarios, or struggle to navigate nonconvex obstacles effectively.
             <p>
              Our proposed method enables collision-free navigation using only local sensor and state information without a map. By incorporating a wall-following (WF) behavior into the APF approach, our method allows robots to escape local minima, even in the presence of nonconvex and dynamic obstacles including other robots. We introduce two algorithms for switching between APF and WF: a rule-based system and an encoder network trained on expert demonstrations. Experimental results show that our approach achieves substantially higher success rates compared to state-of-the-art methods, highlighting its ability to overcome the limitations of local minima in complex environments.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt10_05">
             10:15-10:20, Paper WeBT10.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1036" name="modify2925" onclick="modify(2925,1036)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2925'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Heterogeneous Exploration and Monitoring with Online Free-Space Ellipsoid Graphs
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#342003" title="Click to go to the Author Index">
             Brodt, Brennan
            </a>
           </td>
           <td class="r">
            Boston University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#167155" title="Click to go to the Author Index">
             Pierson, Alyssa
            </a>
           </td>
           <td class="r">
            Boston University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2925" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes a heterogeneous teaming solution to the problem of target discovery and monitoring in unknown, non-convex environments. The team consists of two types of agents: agile agents with sensors capable of mapping their surroundings and slower agents that are capable of monitoring or servicing discovered targets. We propose an exploration algorithm that utilizes the IRIS algorithm to generate a graph decomposition from collision free ellipses contained within the environment. This graph is passed to the monitoring agents who execute polynomial complexity assignment and touring algorithms to generate high quality path plans which service all discovered targets. Our algorithmic structure allows the team to solve the problems of exploration, target discovery, assignment, and monitoring within unknown, non-convex environments efficiently using limited information. The performance of our proposed method is verified through batch simulations and complexity analysis.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt10_06">
             10:20-10:25, Paper WeBT10.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1037" name="modify2975" onclick="modify(2975,1037)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2975'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Wavelet-Based Distributed Coverage for Heterogeneous Agents
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335001" title="Click to go to the Author Index">
             Rao, Ananya
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104011" title="Click to go to the Author Index">
             Choset, Howie
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107777" title="Click to go to the Author Index">
             Wettergreen, David
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2975" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We develop a coverage approach for heterogeneous agents that leverages the different sensing and motion capabilities of a team. Coverage performance is measured using ergodicity, which when optimized balances exploitation versus exploration, where areas of interest are indicated with an information metric. Prior work uses spectral decomposition of a spatial map of information to guide a set of heterogeneous agents, each with different sensor and motion models, to optimize coverage. This work leverages wavelet transforms to decompose the information map rather than the Fourier transform typically applied to ergodic search and demonstrates the importance of selecting a suitable wavelet family to use, based on the information map being explored. Further a sequence of wavelets is used for decomposition to overcome dependency on selecting one suitable wavelet family. Our experimental results show that using wavelet families well-suited to the specific information map for information map decomposition leads to, on average, 43% improvement over a baseline method in terms of a standard coverage metric (ergodicity), while using a well-sequenced set of wavelets for decomposition leads to a 65% improvement in coverage performance across multiple types of information maps.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt10_07">
             10:25-10:30, Paper WeBT10.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1038" name="modify3014" onclick="modify(3014,1038)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3014'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Agent Obstacle Avoidance Using Velocity Obstacles and Control Barrier Functions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424886" title="Click to go to the Author Index">
             Sánchez Roncero, Alejandro
            </a>
           </td>
           <td class="r">
            KTH Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#326274" title="Click to go to the Author Index">
             Cabral Muchacho, Rafael Ignacio
            </a>
           </td>
           <td class="r">
            KTH Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104031" title="Click to go to the Author Index">
             Ogren, Petter
            </a>
           </td>
           <td class="r">
            Royal Institute of Technology (KTH)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3014" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#formal_methods_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Formal Methods in Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Velocity Obstacles (VO) methods form a paradigm for collision avoidance strategies among moving obstacles and agents. While VO methods perform well in simple multi-agent environments, they do not guarantee safety and can show overly conservative behavior in common situations. In this paper, we propose to combine a VO strategy for guidance with a Control Barrier Function approach for safety, which overcomes the overly conservative behavior of VOs and formally guarantees safety. We validate our method in a baseline comparison study, using second-order integrator and car-like dynamics. Results support that our method outperforms the baselines with respect to path smoothness, collision avoidance, and success rates.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt11">
             <b>
              WeBT11
             </b>
             Regular Session, 314
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1039" name="modifyWeBT11" onclick="modsession(317,1039)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt11" title="Click to go to the Program at a Glance">
             <b>
              Micro/Nano Robots
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#238795" title="Click to go to the Author Index">
             Alapan, Yunus
            </a>
           </td>
           <td class="r">
            University of Wisconsin-Madison
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#106386" title="Click to go to the Author Index">
             Yoon, Jungwon
            </a>
           </td>
           <td class="r">
            Gwangju Institutue of Science and Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt11_01">
             09:55-10:00, Paper WeBT11.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1040" name="modify126" onclick="modify(126,1040)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('126'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              VALG: Vision-Based Adaptive Laser Gripper for Model-Free Pose Control of Floating Objects at Air-Liquid Interface
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335610" title="Click to go to the Author Index">
             Hui, Xusheng
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#140225" title="Click to go to the Author Index">
             Luo, Jianjun
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University(P.R.China)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#408030" title="Click to go to the Author Index">
             You, Haonan
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab126" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Non-contact manipulation at the air-liquid interface holds significant potential for applications in microrobotics, non-invasive assembly, and biochemistry analysis. However, achieving simultaneous position and orientation (pose) control of floating objects remains a considerable challenge, particularly for adaptive control without prior modeling of the objects. Here, we introduce the Vision-based Adaptive Laser Gripper (VALG) system addressing these challenges. By leveraging the distributed thermocapillary flow induced by patterned laser scanning, a pose control strategy based on the equidistant contour scanning laser is proposed and validated. The proposed system relies solely on visual recognition to generate adaptive laser grippers, which achieve static equilibrium to simultaneously constrain the position and orientation of the floating objects. Experimental validation demonstrates the effectiveness of the VALG system in independent position and orientation control, coupled pose control, and path following. The VALG system facilitates smooth, precise, fast, and adaptive pose control of generalized floating objects, establishing it as a universal and versatile platform for non-contact manipulation at the air-liquid interface.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt11_02">
             10:00-10:05, Paper WeBT11.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1041" name="modify3117" onclick="modify(3117,1041)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3117'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Interactive OT Gym: A Reinforcement Learning-Based Interactive Optical Tweezer (OT)-Driven Microrobotics Simulation Platform
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424581" title="Click to go to the Author Index">
             Zongcai, Tan
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#191798" title="Click to go to the Author Index">
             Zhang, Dandan
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3117" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#automation_at_micro_nano_scales" title="Click to go to the Keyword Index">
               Automation at Micro-Nano Scales
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Optical tweezers (OT) offer unparalleled capabilities for micromanipulation with submicron precision in biomedical applications. However, controlling conventional multi-trap OT to achieve cooperative manipulation of multiple complex-shaped microrobots in dynamic environments poses a significant challenge. To address this, we introduce Interactive OT Gym, a reinforcement learning (RL)-based simulation platform designed for OT-driven microrobotics. Our platform supports complex physical field simulations and integrates haptic feedback interfaces, RL modules, and context-aware shared control strategies tailored for OT-driven microrobot in cooperative biological object manipulation tasks. This integration allows for an adaptive blend of manual and autonomous control, enabling seamless transitions between human input and autonomous operation. We evaluated the effectiveness of our platform using a cell manipulation task. Experimental results show that our shared control system significantly improves micromanipulation performance, reducing task completion time by approximately 67% compared to using pure human or RL control alone and achieving a 100% success rate. With its high fidelity, interactivity, low cost, and high-speed simulation capabilities, Interactive OT Gym serves as a user-friendly training and testing environment for the development of advanced interactive OT-driven micromanipulation systems and control algorithms.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt11_03">
             10:05-10:10, Paper WeBT11.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1042" name="modify3671" onclick="modify(3671,1042)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3671'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Model-Based Robotic Cell Aspiration: Tackling the Impact of Air Segment
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#373560" title="Click to go to the Author Index">
             Zheng, Jiachun
            </a>
           </td>
           <td class="r">
            Chinese University of HongKong, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#181349" title="Click to go to the Author Index">
             Zhang, Zhuoran
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong, Shenzhen
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3671" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#automation_at_micro_nano_scales" title="Click to go to the Keyword Index">
               Automation at Micro-Nano Scales
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#biological_cell_manipulation" title="Click to go to the Keyword Index">
               Biological Cell Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Cell aspiration is a common micro-manipulation technique for cell transfer, particularly in textit{in vitro} fertilization (IVF) procedures. The minuscule volume of a cell (pL) and limited damping provided by the medium make it challenging to accurately and quickly aspirate a cell to the desired position inside the micropipette. Experienced clinicians intentionally insert an air segment inside the micropipette in advance to make the aspiration easier. Nevertheless, the unclear damping effects and the varying initial length of the air segment in each aspiration pose difficulties for most operators. Inadequate judgment and response may lead to overshoot or even loss of the cell. This paper constructs a nonlinear dynamics model to elucidate the cell motion inside a micropipette containing an inserted air segment. The model reveals the impact of the air segment. A model-based controller is designed to facilitate the accurate aspiration of human sperm to a desired position, incorporating an estimated initial length of the air segment. Experiments were conducted to quantitatively evaluate the performance of both the model and the controller involving various initial air segment lengths. The results demonstrated a 100% success rate in 50 sperm aspiration experiments, achieving an average positional accuracy within pm2 pixels and an average settling time of 5.89 seconds.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt11_04">
             10:10-10:15, Paper WeBT11.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1043" name="modify3780" onclick="modify(3780,1043)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3780'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Efficient Optimization of a Permanent Magnet Array for a Stable 2D Trap
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423377" title="Click to go to the Author Index">
             Müller, Ann-Sophia
            </a>
           </td>
           <td class="r">
            German Cancer Research Center (DKFZ)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#268721" title="Click to go to the Author Index">
             Jeong, Moonkwang
            </a>
           </td>
           <td class="r">
            Deutsches Krebsforschungszentrum (DKFZ)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#311387" title="Click to go to the Author Index">
             Tian, Jiyuan
            </a>
           </td>
           <td class="r">
            German Cancer Research Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423385" title="Click to go to the Author Index">
             Zhang, Meng
            </a>
           </td>
           <td class="r">
            German Cancer Research Center (DKFZ)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#168443" title="Click to go to the Author Index">
             Qiu, Tian
            </a>
           </td>
           <td class="r">
            German Cancer Research Center (DKFZ)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3780" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#automation_at_micro_nano_scales" title="Click to go to the Keyword Index">
               Automation at Micro-Nano Scales
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Untethered magnetic manipulation of biomedical millirobots has a high potential for minimally invasive surgical applications. However, it is still challenging to exert high actuation forces on the small robots over a large distance. Permanent magnets offer stronger magnetic torques and forces than electromagnetic coils, however, feedback control is more difficult. As proven by Earnshaw's theorem, it is not possible to achieve a stable magnetic trap in 3D by static permanent magnets. Here, we report a stable 2D magnetic force trap by an array of permanent magnets to control a millirobot. The trap is located in an open space with a tunable distance to the magnet array in the range of 20 - 120mm, which is relevant to human anatomical scales. The design is achieved by a novel GPU-accelerated optimization algorithm that uses mean squared error (MSE) and Adam optimizer to efficiently compute the optimal angles for any number of magnets in the array. The algorithm is verified using numerical simulation and physical experiments with an array of two magnets. A millirobot is successfully trapped and controlled to follow a complex trajectory. The algorithm demonstrates high scalability by optimizing the angles for 100 magnets in under three seconds. Moreover, the optimization workflow can be adapted to optimize a permanent magnet array to achieve the desired force vector fields.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt11_05">
             10:15-10:20, Paper WeBT11.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1044" name="modify4790" onclick="modify(4790,1044)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4790'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Real-Time 3D MPI-Based Navigation Scheme for Microrobots with Flexible Field Free Point Trajectories and Virtual FFP Intuitive Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#266041" title="Click to go to the Author Index">
             Bui, Minh Phu
            </a>
           </td>
           <td class="r">
            Gwangju Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#266031" title="Click to go to the Author Index">
             Park, Myungjin
            </a>
           </td>
           <td class="r">
            Gwangju Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#343707" title="Click to go to the Author Index">
             Le, Tuan Anh
            </a>
           </td>
           <td class="r">
            Gwangju Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106386" title="Click to go to the Author Index">
             Yoon, Jungwon
            </a>
           </td>
           <td class="r">
            Gwangju Institutue of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4790" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Magnetic Particle Imaging (MPI)-based navigation shows significant potential for accurately guiding microrobots to desired target locations. Existing MPI-based navigation systems have been limited to two-dimensional planar movements due to increased computational load and a lack of efficient 3D actuator schemes. So we introduce a real-time 3D MPI-based navigation scheme for microrobot, utilizing a flexible field-free point (FFP) trajectory scanning scheme and 3D virtual FFP (vFFP) intuitive manipulation. The FFP trajectory is chosen flexibly to enhance temporal resolution. A virtual FFP force model for actuator function, with high potential for interactive manipulation, is used to linearize the magnetic force concerning the relative positions of microrobot and the actual FFP. The proposed concept has been validated using the available 3D amplitude modulation MPI system with a 90 mm bore size and a 4 T/m/µ0 gradient. By employing a flexible FFP trajectory, the MPI system can achieve an image sampling rate of up to 4 Hz for a 3D Field of View of 60  40  60 mm³, enabling real-time MPI-based navigation. Furthermore, the proposed navigation control strategy can reach any target outlet within the 3D blood model with a low mean error in vFFP linearization of less than 5%.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt11_06">
             10:20-10:25, Paper WeBT11.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1045" name="modify4999" onclick="modify(4999,1045)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4999'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              3D Noncontact Micro-Particle Manipulation with Acoustic Robot End-Effector under Microscope
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335221" title="Click to go to the Author Index">
             Wang, Mingyue
            </a>
           </td>
           <td class="r">
            Shanghaitech Univerisity
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335232" title="Click to go to the Author Index">
             Li, Jiaqi
            </a>
           </td>
           <td class="r">
            ShanghaiTech University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#285192" title="Click to go to the Author Index">
             Jia, Yuyu
            </a>
           </td>
           <td class="r">
            ShanghaiTech University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#320242" title="Click to go to the Author Index">
             Sun, Zhenhuan
            </a>
           </td>
           <td class="r">
            Shanghaitech University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#189350" title="Click to go to the Author Index">
             Su, Hu
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Science
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#285160" title="Click to go to the Author Index">
             Liu, Song
            </a>
           </td>
           <td class="r">
            ShanghaiTech University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4999" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#automation_at_micro_nano_scales" title="Click to go to the Keyword Index">
               Automation at Micro-Nano Scales
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_servoing" title="Click to go to the Keyword Index">
               Visual Servoing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             As an essential component of noncontact manipulation, acoustic manipulation has achieved great success in multidisciplinary research and applications. Although acoustic tweezers have made advancements in manipulating particles in air, handling individual particles with high precision in water remains challenging and inadequately addressed due to the difficulty in precisely characterizing and calibrating acoustic robot end-effectors from a robotic perspective. In this paper, we present a vision-based automated noncontact particle manipulation approach using an acoustic robot end-effector, which achieves precise and reliable particle manipulation in 3D space. Specifically, visual feedback is incorporated for microparticle localization, and a dynamic acoustic field modulation method is proposed for controlling the end-effector. The invisible robot end-effector is localized and characterized through hydrophone scanning. The proposed vision solution is capable of automated trapping and precise translation of micro-particles suspended in a water-based environment and is applicable to particles with both negative and positive impedance contrast against the medium. Experimental results demonstrate the effectiveness of this approach towards automated noncontact particle manipulation with an acoustic robot end-effector
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt12">
             <b>
              WeBT12
             </b>
             Regular Session, 315
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1046" name="modifyWeBT12" onclick="modsession(165,1046)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt12" title="Click to go to the Program at a Glance">
             <b>
              Human-Robot Collaboration 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#135389" title="Click to go to the Author Index">
             Jain, Siddarth
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Research Laboratories (MERL)
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#238485" title="Click to go to the Author Index">
             Zhi, Jixuan
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt12_01">
             09:55-10:00, Paper WeBT12.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1047" name="modify230" onclick="modify(230,1047)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('230'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Dynamic Collaborative Workspace Based on Human Interference Estimation for Safe and Productive Human-Robot Collaboration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#114910" title="Click to go to the Author Index">
             Kamezaki, Mitsuhiro
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#385315" title="Click to go to the Author Index">
             Wada, Tomohiro
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100151" title="Click to go to the Author Index">
             Sugano, Shigeki
            </a>
           </td>
           <td class="r">
            Waseda University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab230" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_centered_automation" title="Click to go to the Keyword Index">
               Human-Centered Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Collaborative robots that operate safely close to workers without fences have attracted attention, but few examples of such human-robot collaboration (HRC) have been seen in factories. The main reason is the difficulty in balancing safety and productivity. Current fenceless HRC systems stop the robot when a human enters the collaborative workspace (C) where both human and robot can work to ensure safety, which ISO/TS15066 regulates. The robot stops even when the human is far enough away, so productivity is drastically decreased (FCW, Fixed C). If a system could identify the human-work area, designate it as a no-entry space in C for the robot (C^P), and dynamically set the closed C (C^C) with shrinking C by C^P, productivity would improve thanks to enabling the robot to work in C^C and safety would be ensured thanks to allowing the human to continue working in C^P. In this study, we propose a new concept of a dynamic collaborative workspace (DCW) that dynamically sets C^C and C^P based on the human’s predicted trajectory. It also provides visual and auditory prompts to enable the human to understand DCW states, i.e., when a human enters C, C is changed, and the robot is in emergency mode. We compared four HRC systems using a real robot arm: two conventional FCW ones with and without fences and two proposed DCW ones with and without a state indicator and found that the proposed system with a state indicator has the best productivity and ensures the same level of safety as the conventional system with fences.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt12_02">
             10:00-10:05, Paper WeBT12.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1048" name="modify1016" onclick="modify(1016,1048)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1016'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Next-Best-Trajectory Planning of Robot Manipulators for Effective Observation and Exploration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#364214" title="Click to go to the Author Index">
             Renz, Heiko
            </a>
           </td>
           <td class="r">
            TU Dortmund University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#228639" title="Click to go to the Author Index">
             Krämer, Maximilian
            </a>
           </td>
           <td class="r">
            TU Dortmund University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105830" title="Click to go to the Author Index">
             Hoffmann, Frank
            </a>
           </td>
           <td class="r">
            Technische Universität Dortmund
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#136913" title="Click to go to the Author Index">
             Bertram, Torsten
            </a>
           </td>
           <td class="r">
            Technische Universität Dortmund
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1016" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reactive_and_sensor_based_planning" title="Click to go to the Keyword Index">
               Reactive and Sensor-Based Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visual observation of objects is essential for many robotic applications, such as object reconstruction and manipulation, navigation, and scene understanding. Machine learning algorithms constitute the state-of-the-art in many fields but require vast data sets, which are costly and time-intensive to collect. Automated strategies for observation and exploration are crucial to enhance the efficiency of data gathering. Therefore, a novel strategy utilizing the Next-Best-Trajectory principle is developed for a robot manipulator operating in dynamic environments. Local trajectories are generated to maximize the information gained from observations along the path while avoiding collisions. We employ a voxel map for environment modeling and utilize raycasting from perspectives around a point of interest to estimate the information gain. A global ergodic trajectory planner provides an optional reference trajectory to the local planner, improving exploration and helping to avoid local minima. To enhance computational efficiency, raycasting for estimating the information gain in the environment is executed in parallel on the graphics processing unit. Benchmark results confirm the efficiency of the parallelization, while real-world experiments demonstrate the strategy’s effectiveness.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt12_03">
             10:05-10:10, Paper WeBT12.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1049" name="modify1634" onclick="modify(1634,1049)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1634'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              TriHRCBot: A Robotic Architecture for Triadic Human-Robot Collaboration through Mediated Object Alignment
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#231446" title="Click to go to the Author Index">
             Semeraro, Francesco
            </a>
           </td>
           <td class="r">
            The University of Manchester
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397436" title="Click to go to the Author Index">
             Leadbetter, James Hugo
            </a>
           </td>
           <td class="r">
            BAE Systems Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#240194" title="Click to go to the Author Index">
             Cangelosi, Angelo
            </a>
           </td>
           <td class="r">
            University of Manchester
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1634" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#cognitive_control_architectures" title="Click to go to the Keyword Index">
               Cognitive Control Architectures
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Human-robot collaboration has great potential in enhancing robot deployment at close proximity with people, especially in non-dyadic collaborations with multiple users. However, autonomous systems that are capable of handling such interactions in a physical domain are rare. This work proposes TriHRCBot, a robotic architecture designed to handle a collaborative task that involves two concurrent users. The architecture is sensitive to position, orientation, body lengths and state of the users in the interaction, and uses this information to adjust the pose of a target object to enable both users to act on it at the same time. A robotic system equipped with the TriHRCBot architecture was deployed in a user study in which 30 participants from the BAE Systems Academy for Skills and Knowledge Centre interacted with it during such multi-user collaborative task. The study shows that the participants considered TriHRCBot acceptable for the task at hand.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt12_04">
             10:10-10:15, Paper WeBT12.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1050" name="modify2741" onclick="modify(2741,1050)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2741'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Open-Nav: Exploring Zero-Shot Vision-And-Language Navigation in Continuous Environment with Open-Source LLMs
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#370117" title="Click to go to the Author Index">
             Qiao, Yanyuan
            </a>
           </td>
           <td class="r">
            The University of Adelaide
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417582" title="Click to go to the Author Index">
             Lyu, Wenqi
            </a>
           </td>
           <td class="r">
            The University of Adelaide
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418119" title="Click to go to the Author Index">
             Wang, Hui
            </a>
           </td>
           <td class="r">
            The University of Adelaide, AIML
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405032" title="Click to go to the Author Index">
             Wang, Zixu
            </a>
           </td>
           <td class="r">
            South China University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418797" title="Click to go to the Author Index">
             Li, Zerui
            </a>
           </td>
           <td class="r">
            Adelaide University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418016" title="Click to go to the Author Index">
             Zhang, Yuan
            </a>
           </td>
           <td class="r">
            The University of Adelaide
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#350379" title="Click to go to the Author Index">
             Tan, Mingkui
            </a>
           </td>
           <td class="r">
            South China University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#314849" title="Click to go to the Author Index">
             Wu, Qi
            </a>
           </td>
           <td class="r">
            University of Adelaide
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2741" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Vision-and-Language Navigation (VLN) tasks require an agent to follow textual instructions to navigate through 3D environments. Traditional approaches use supervised learning methods, relying heavily on domain-specific datasets to train VLN models. Recent methods try to utilize closed-source large language models (LLMs) like GPT-4 to solve VLN tasks in zero-shot manners, but face challenges related to expensive token costs and potential data breaches in real-world applications. In this work, we introduce Open-Nav, a novel study that explores open-source LLMs for zero-shot VLN in the continuous environment. Open-Nav employs a spatial-temporal chain-of-thought (CoT) reasoning approach to break down tasks into instruction comprehension, progress estimation, and decision-making. It enhances scene perceptions with fine-grained object and spatial knowledge to improve LLM's reasoning in navigation. Our extensive experiments in both simulated and real-world environments demonstrate that Open-Nav achieves competitive performance compared to using closed-source LLMs.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt12_05">
             10:15-10:20, Paper WeBT12.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1051" name="modify4412" onclick="modify(4412,1051)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4412'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Integrating Field of View in Human-Aware Collaborative Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#246873" title="Click to go to the Author Index">
             Hsu, Ya-Chuan
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426688" title="Click to go to the Author Index">
             Michael, Defranco
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#391996" title="Click to go to the Author Index">
             Patel, Rutvik Rakeshbhai
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#117265" title="Click to go to the Author Index">
             Nikolaidis, Stefanos
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4412" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning_under_uncertainty" title="Click to go to the Keyword Index">
               Planning under Uncertainty
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In human-robot collaboration (HRC), it is crucial for robot agents to consider humans' knowledge of their surroundings. In reality, humans possess a narrow field of view (FOV), limiting their perception. However, research on HRC often overlooks this aspect and presumes an omniscient human collaborator. Our study addresses the challenge of adapting to the evolving subtask intent of humans while accounting for their limited FOV. We integrate FOV within the human-aware probabilistic planning framework. To account for large state spaces due to considering FOV, we propose a hierarchical online planner that efficiently finds approximate solutions while enabling the robot to explore low-level action trajectories that enter the human FOV, influencing their intended subtask. Through user study with our adapted cooking domain, we demonstrate our FOV-aware planner reduces human's interruptions and redundant actions during collaboration by adapting to human perception limitations. We extend these findings to a virtual reality kitchen environment, where we observe similar collaborative behaviors.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt12_06">
             10:20-10:25, Paper WeBT12.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1052" name="modify4546" onclick="modify(4546,1052)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4546'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              PACE: Proactive Assistance in Human-Robot Collaboration through Action-Completion Estimation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424087" title="Click to go to the Author Index">
             De Lazzari, Davide
            </a>
           </td>
           <td class="r">
            University of Padua
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#224747" title="Click to go to the Author Index">
             Terreran, Matteo
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#356043" title="Click to go to the Author Index">
             Giacomuzzo, Giulio
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#135389" title="Click to go to the Author Index">
             Jain, Siddarth
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Research Laboratories (MERL)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#134969" title="Click to go to the Author Index">
             Falco, Pietro
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#143494" title="Click to go to the Author Index">
             Carli, Ruggero
            </a>
           </td>
           <td class="r">
            University of Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#188794" title="Click to go to the Author Index">
             Romeres, Diego
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Research Laboratories
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4546" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#assembly" title="Click to go to the Keyword Index">
               Assembly
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces the Proactive Assistance through action-Completion Estimation (PACE) framework, designed to enhance human-robot collaboration through real-time monitoring of human progress. PACE incorporates a novel method that combines Dynamic Time Warping (DTW) with correlation analysis to track human task progression from hand movements. PACE trains a reinforcement learning policy from limited demonstrations to generate a proactive assistance policy that synchronizes robotic actions with human activities, minimizing idle time and enhancing collaboration efficiency. We validate the framework through user studies involving 12 participants, showing significant improvements in interaction fluency, reduced waiting times, and positive user feedback compared to traditional methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt12_07">
             10:25-10:30, Paper WeBT12.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1053" name="modify5057" onclick="modify(5057,1053)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5057'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Improving Human-Robot Collaboration Via Computational Design
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#238485" title="Click to go to the Author Index">
             Zhi, Jixuan
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104438" title="Click to go to the Author Index">
             Lien, Jyh-Ming
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5057" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#service_robotics" title="Click to go to the Keyword Index">
               Service Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             When robots enter our day-to-day lives, the shared space surrounding humans and robots is critical for facilitating Human-Robot collaboration. The design of shared space should satisfy humans' preferences and robots' efficiency. This work uses the kitchen as an example to illustrate the importance of good space designs in enhancing
             <p>
              collaboration. Given the kitchen boundary, food stations, counters, and
              <p>
               recipes, the proposed method determines the optimal placement of stations and counters that meet the requirements of kitchen design rules and improve performance. The key technical challenge is that the optimization method usually evaluates thousands of designs, and each evaluation analyzes the traffic flow of the space, which must solve many motion planning problems. To address this technical challenge, we use a decentralized motion planner that can solve multi-agent motion planning efficiently. Our results indicate that optimized kitchen designs can provide noticeable performance improvement to Human-Robot collaboration.
              </p>
             </p>
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt13">
             <b>
              WeBT13
             </b>
             Regular Session, 316
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1054" name="modifyWeBT13" onclick="modsession(379,1054)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt13" title="Click to go to the Program at a Glance">
             <b>
              Multifingered Hands
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#107917" title="Click to go to the Author Index">
             Schimmels, Joseph
            </a>
           </td>
           <td class="r">
            Marquette University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#400747" title="Click to go to the Author Index">
             Allen-Blanchette, Christine
            </a>
           </td>
           <td class="r">
            Princeton University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt13_01">
             09:55-10:00, Paper WeBT13.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1055" name="modify60" onclick="modify(60,1055)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('60'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Vision-Based Force/Position Fusion Actuation-Sensing Scheme for Tendon-Driven Mechanism
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#364430" title="Click to go to the Author Index">
             Chen, Shiwei
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#365072" title="Click to go to the Author Index">
             Deng, Zhiming
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#365101" title="Click to go to the Author Index">
             Gu, Haiyu
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#280385" title="Click to go to the Author Index">
             Wei, Cheng
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab60" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#tendon_wire_mechanism" title="Click to go to the Keyword Index">
               Tendon/Wire Mechanism
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Current robotic sensing systems typically employ multiple sensors to obtain position and force information. This usually leads to many challenges, such as high costs and complex wiring. In this paper,a vision-based force/position fusion actuation-sensing scheme is proposed. The scheme can measure the angles and torques of all joints with only one low-cost camera. Through careful design of the actuation-sensing mechanism, the camera can achieve high resolution and high bandwidth processing. The proposed angle measurement model and external torque measurement model are evaluated by rigorous experiments. The experimental results indicate that the designed mechanism shows excellent repeatability and accuracy. The average error for all angles is less than 1 degree, and the average maximum relative error for torque is 4.43%.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt13_02">
             10:00-10:05, Paper WeBT13.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1056" name="modify779" onclick="modify(779,1056)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('779'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              BODex: Scalable and Efficient Robotic Dexterous Grasp Synthesis Using Bilevel Optimization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338572" title="Click to go to the Author Index">
             Chen, Jiayi
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418999" title="Click to go to the Author Index">
             Ke, Yubin
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#155911" title="Click to go to the Author Index">
             Wang, He
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab779" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#big_data_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Big Data in Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic dexterous grasping is important for interacting with the environment. To unleash the potential of data-driven models for dexterous grasping, a large-scale, high-quality dataset is essential. While gradient-based optimization offers a promising way for constructing such datasets, previous works suffer from limitations, such as inefficiency, strong assumptions in the grasp quality energy, or limited object sets for experiments. Moreover, the lack of a standard benchmark for comparing different methods and datasets hinders progress in this field. To address these challenges, we develop a highly efficient synthesis system and a comprehensive benchmark with MuJoCo for dexterous grasping. We formulate grasp synthesis as a bilevel optimization problem, combining a novel lower-level quadratic programming (QP) with an upper-level gradient descent process. By leveraging recent advances in CUDA-accelerated robotic libraries and GPU-based QP solvers, our system can parallelize thousands of grasps and synthesize over 49 grasps per second on a single 3090 GPU. Our synthesized grasps for Shadow, Allegro, and Leap hands all achieve a success rate above 75% in simulation, with a penetration depth under 1 mm, outperforming existing baselines on nearly all metrics. Compared to the previous large-scale dataset, DexGraspNet, our dataset significantly improves the performance of learning models, with a success rate from around 40% to 80% in simulation. Real-world testing of the trained model on the Shadow Hand achieves an 81% success rate across 20 diverse objects. The codes and datasets are released on our project page: https://pku-epic.github.io/BODex.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt13_03">
             10:05-10:10, Paper WeBT13.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1057" name="modify1107" onclick="modify(1107,1057)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1107'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DemoStart: Demonstration-Led Auto-Curriculum Applied to Sim-To-Real with Multi-Fingered Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#196487" title="Click to go to the Author Index">
             Bauza Villalonga, Maria
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#204263" title="Click to go to the Author Index">
             Chen, Jose Enrique
            </a>
           </td>
           <td class="r">
            DeepMind
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420514" title="Click to go to the Author Index">
             Dalibard, Valentin
            </a>
           </td>
           <td class="r">
            Google DeepMind
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420538" title="Click to go to the Author Index">
             Gileadi, Nimrod
            </a>
           </td>
           <td class="r">
            Google
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#108351" title="Click to go to the Author Index">
             Hafner, Roland
            </a>
           </td>
           <td class="r">
            Google DeepMind
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#241226" title="Click to go to the Author Index">
             Martins, Murilo
            </a>
           </td>
           <td class="r">
            DeepMind
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420518" title="Click to go to the Author Index">
             Moore, Joss
            </a>
           </td>
           <td class="r">
            Google DeepMind
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#313949" title="Click to go to the Author Index">
             Pevceviciute, Rugile
            </a>
           </td>
           <td class="r">
            Deepmind
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#224326" title="Click to go to the Author Index">
             Laurens, Antoine, Marin, Alix
            </a>
           </td>
           <td class="r">
            EPFL
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#151123" title="Click to go to the Author Index">
             Rao, Dushyant
            </a>
           </td>
           <td class="r">
            Google DeepMind
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#176937" title="Click to go to the Author Index">
             Zambelli, Martina
            </a>
           </td>
           <td class="r">
            Google DeepMind
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106156" title="Click to go to the Author Index">
             Riedmiller, Martin
            </a>
           </td>
           <td class="r">
            DeepMind
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#137719" title="Click to go to the Author Index">
             Scholz, Jonathan
            </a>
           </td>
           <td class="r">
            Google Deepmind
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#218832" title="Click to go to the Author Index">
             Bousmalis, Konstantinos
            </a>
           </td>
           <td class="r">
            DeepMind
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#111052" title="Click to go to the Author Index">
             Nori, Francesco
            </a>
           </td>
           <td class="r">
            Google DeepMind
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#239449" title="Click to go to the Author Index">
             Heess, Nicolas
            </a>
           </td>
           <td class="r">
            Google Deepmind
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1107" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present DemoStart, a novel auto-curriculum reinforcement learning method capable of learning complex manipulation behaviors on an arm equipped with a three-fingered robotic hand, from only a sparse reward and a handful of demonstrations in simulation.
             <p>
              Learning from simulation drastically reduces the development cycle of behavior generation, and domain randomization techniques are leveraged to achieve successful zero-shot sim-to-real transfer. Transferred policies are learned directly from raw pixels from multiple cameras and robot proprioception.
              <p>
               Our approach outperforms policies learned from demonstrations on the real robot and requires 100 times fewer demonstrations, collected in simulation.
               <p>
                More details and videos in https://sites.google.com/view/demostart.
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt13_04">
             10:10-10:15, Paper WeBT13.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1058" name="modify1184" onclick="modify(1184,1058)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1184'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Dexterous Assembly Using a Planar Hand Having Programmable Passive Compliance
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420598" title="Click to go to the Author Index">
             Frye, Jacob
            </a>
           </td>
           <td class="r">
            Marquette University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107917" title="Click to go to the Author Index">
             Schimmels, Joseph
            </a>
           </td>
           <td class="r">
            Marquette University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1184" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#compliance_and_impedance_control" title="Click to go to the Keyword Index">
               Compliance and Impedance Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Special purpose compliant end-effectors are effective in realizing task-appropriate passive compliance. This paper presents a programmable, 3-fingered, antagonistic, compliant hand (P3ACH) capable of realizing a desired compliant behavior within a large space of multidirectional compliant behaviors. Manipulation dexterity is demonstrated by performing different assembly tasks faster, more robustly, and with lower contact forces than an active system realizing the same compliant behavior.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt13_05">
             10:15-10:20, Paper WeBT13.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1059" name="modify1521" onclick="modify(1521,1059)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1521'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GAGrasp: Geometric Algebra Diffusion for Dexterous Grasping
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#342055" title="Click to go to the Author Index">
             Zhong, Tao
            </a>
           </td>
           <td class="r">
            Princeton University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#400747" title="Click to go to the Author Index">
             Allen-Blanchette, Christine
            </a>
           </td>
           <td class="r">
            Princeton University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1521" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose GAGrasp, a novel framework for dexterous grasp generation that leverages geometric algebra representations to enforce equivariance to SE(3) transformations. By encoding the SE(3) symmetry constraint directly into the architecture, our method improves data and parameter efficiency while enabling robust grasp generation across diverse object poses. Additionally, we incorporate a differentiable physics-informed refinement layer, which ensures that generated grasps are physically plausible and stable. Extensive experiments demonstrate the model's superior performance in generalization, stability, and adaptability compared to existing methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt13_06">
             10:20-10:25, Paper WeBT13.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1060" name="modify2890" onclick="modify(2890,1060)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2890'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Model Q-II: An Underactuated Hand with Enhanced Grasping Modes and Primitives for Dexterous Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#249062" title="Click to go to the Author Index">
             Dong, Yinkai
            </a>
           </td>
           <td class="r">
            Harvard University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#194772" title="Click to go to the Author Index">
             Kim, Jehyeok
            </a>
           </td>
           <td class="r">
            Yale University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#213341" title="Click to go to the Author Index">
             Patel, Vatsal
            </a>
           </td>
           <td class="r">
            Yale University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#240350" title="Click to go to the Author Index">
             Feng, Huijuan
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103607" title="Click to go to the Author Index">
             Dollar, Aaron
            </a>
           </td>
           <td class="r">
            Yale University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2890" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces Model Q-II, an enhanced underactuated robotic hand designed to improve dexterous manipulation through expanded grasping modes and manipulation primitives. The Model Q-II incorporates tripod and enhanced power grasping modes, achieving increased versatility without adding additional actuators. The design employs passive mechanisms, such as lateral contact walls and a finger-locking system, to facilitate seamless transitions between modes, enabling precise pinch-to-tripod and pinch-to-power gating. These enhancements allow the hand to perform complex in-hand manipulations, including multi-directional object positioning. Theoretical analysis, simulations, and experimental evaluations validate the hand’s performance, demonstrating improved grasping force, range, and manipulation capabilities. The results highlight Model Q-II’s ability to handle various tasks, offering a robust, cost-effective solution for applications requiring both precise and powerful grasping.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt13_07">
             10:25-10:30, Paper WeBT13.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1061" name="modify3543" onclick="modify(3543,1061)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3543'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Canonical Representation and Force-Based Pretraining of 3D Tactile for Dexterous Visuo-Tactile Policy Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309444" title="Click to go to the Author Index">
             Wu, Tianhao
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#367878" title="Click to go to the Author Index">
             Li, Jinzhou
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#371662" title="Click to go to the Author Index">
             Zhang, Jiyao
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#299205" title="Click to go to the Author Index">
             Mingdong Wu, Aaron
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#280114" title="Click to go to the Author Index">
             Dong, Hao
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3543" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Tactile sensing plays a vital role in enabling robots to perform fine-grained, contact-rich tasks. However, the high dimensionality of tactile data, due to the large coverage on dexterous hands, poses significant challenges for effective tactile feature learning, especially for 3D tactile data, as there are no large standardized datasets and no strong pretrained backbones. To address these challenges, we propose a novel canonical representation that reduces the difficulty of 3D tactile feature learning and further introduces a force-based self-supervised pretraining task to capture both local and net force features, which are crucial for dexterous manipulation. Our method achieves an average success rate of 78% across four fine-grained, contact-rich dexterous manipulation tasks in real-world experiments, demonstrating effectiveness and robustness compared to other methods. Further analysis shows that our method fully utilizes both spatial and force information from 3D tactile data to accomplish the tasks. The videos can be viewed at https://3dtacdex.github.io.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt14">
             <b>
              WeBT14
             </b>
             Regular Session, 402
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1062" name="modifyWeBT14" onclick="modsession(611,1062)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt14" title="Click to go to the Program at a Glance">
             <b>
              Tracking and Prediction 3
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#162768" title="Click to go to the Author Index">
             Usher, Colin
            </a>
           </td>
           <td class="r">
            Georgia Tech Research Institute
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#113633" title="Click to go to the Author Index">
             Vitzilaios, Nikolaos
            </a>
           </td>
           <td class="r">
            University of South Carolina
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt14_01">
             09:55-10:00, Paper WeBT14.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1063" name="modify2384" onclick="modify(2384,1063)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2384'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Dynamic Compact Consensus Tracking for Aerial Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#353465" title="Click to go to the Author Index">
             Sun, XiaoLou
            </a>
           </td>
           <td class="r">
            Southeast University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#352188" title="Click to go to the Author Index">
             Quan, Zhibin
            </a>
           </td>
           <td class="r">
            Southeast University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415924" title="Click to go to the Author Index">
             Zhang, Feng
            </a>
           </td>
           <td class="r">
            Nanjing University of Posts and Telecommunications
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395133" title="Click to go to the Author Index">
             Li, Yuntian
            </a>
           </td>
           <td class="r">
            PML
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395135" title="Click to go to the Author Index">
             Wang, Chunyan
            </a>
           </td>
           <td class="r">
            Purple Mountain Laboratories
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#390683" title="Click to go to the Author Index">
             Si, Wufei
            </a>
           </td>
           <td class="r">
            Purple Mountain Laboratories
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418138" title="Click to go to the Author Index">
             Ni, Wenhui
            </a>
           </td>
           <td class="r">
            Purple Mountain Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#389634" title="Click to go to the Author Index">
             Guan, Runwei
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#390678" title="Click to go to the Author Index">
             Wu, Yuan
            </a>
           </td>
           <td class="r">
            Purple Mountain Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#380038" title="Click to go to the Author Index">
             Meng, Shen
            </a>
           </td>
           <td class="r">
            Purple Mountain Laboratories
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#444005" title="Click to go to the Author Index">
             Huang, YongMing
            </a>
           </td>
           <td class="r">
            PML
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2384" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Existing one-stream trackers have attracted widespread attention. However, they are not applicable in realtime UAV tracking systems due to substantial computational overhead, especially when dynamic templates are introduced. To address this issue, we propose a novel Dynamic Compact Consensus Tracker (DC2T), constructed by stacking modules that each consists of a Compact Token Encoder (CTE) and Dynamic Consensus Attention (DCA). Unlike traditional methods that convert images into a large number of tokens, the CTE, inspired by ”superpixel”, extracts a compact set of representative tokens from both initial and dynamic templates, eliminating the need for a large token set. This strategic reduction in the number of compact tokens markedly decreases the computational load of CTE, enhancing the efficiency of subsequent attention operations. To achieve near-linear complexity of the DCA, compact dynamic template tokens (as keys) are re-queried by search tokens (as queries) to perform dynamic consensus on the aggregated tokens (as values). This arrangement seamlessly incorporates dynamic spatio-temporal features into the DCA while avoiding the computational burden typically associated with dynamic templates. With the aim of further enhancing the system’s responsiveness and accuracy, a direct control network is crafted to seamlessly incorporate the prediction of high-level control values into the tracking network, ensuring a cohesive and efficient interaction with the controller. Comprehensive experiments and real-world evaluations have proven DC2T’s superior performance, accompanied by a significant reduction in FLOPs. Furthermore, we have conducted experiments that demonstrate the tracker’s ability to integrate seamlessly with other technologies such as SLAM and detection, enabling precise tracking of arbitrary objects. The tracker code will be released in https://github.com/xiaolousun/refine-pytracking.git.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt14_02">
             10:00-10:05, Paper WeBT14.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1064" name="modify2447" onclick="modify(2447,1064)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2447'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CGTrack: Cascade Gating Network with Hierarchical Feature Aggregation for UAV Tracking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#413418" title="Click to go to the Author Index">
             Li, Weihong
            </a>
           </td>
           <td class="r">
            University of Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335602" title="Click to go to the Author Index">
             Liu, Xiaoqiong
            </a>
           </td>
           <td class="r">
            University of North Texas
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#204190" title="Click to go to the Author Index">
             Fan, Heng
            </a>
           </td>
           <td class="r">
            University of North Texas
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424283" title="Click to go to the Author Index">
             Zhang, Libo
            </a>
           </td>
           <td class="r">
            Iscas
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2447" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent advancements in visual object tracking have markedly improved the capabilities of unmanned aerial vehicle (UAV) tracking, which is a critical component in real-world robotics applications. While the integration of hierarchical lightweight networks has become a prevalent strategy for enhancing efficiency in UAV tracking, it often results in a significant drop in network capacity, which further exacerbates challenges in UAV scenarios, such as frequent occlusions and extreme changes in viewing angles. To address these issues, we in this paper introduce a novel family of UAV trackers, termed CGTrack, which combines both explicit and implicit techniques to expand network capacity within a coarse-to-fine framework. Specifically, we first introduce a Hierarchical Feature Cascade (HFC) module that leverages the spirit of feature reuse to increase network capacity by integrating the deep semantic cues with the rich spatial information, incurring minimal computational costs while enhancing feature representation. Based on this, we design a novel Lightweight Gated Center Head (LGCH) that utilizes gating mechanisms to decouple target-oriented coordinates from previously expanded features, which contain dense local discriminative information. Extensive experiments on three challenging UAV tracking benchmarks demonstrate that CGTrack achieves state-of-the-art performance while running fast. Code will be available at https://github.com/NightwatchFox11/CGTrack
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt14_03">
             10:05-10:10, Paper WeBT14.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1065" name="modify2461" onclick="modify(2461,1065)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2461'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Tracking Everything in Robotic-Assisted Surgery
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424281" title="Click to go to the Author Index">
             Zhan, Bohan
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#266571" title="Click to go to the Author Index">
             Zhao, Wang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#200546" title="Click to go to the Author Index">
             Fang, Yi
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#340543" title="Click to go to the Author Index">
             Du, Bo
            </a>
           </td>
           <td class="r">
            Wuhan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#139057" title="Click to go to the Author Index">
             Vasconcelos, Francisco
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#128031" title="Click to go to the Author Index">
             Stoyanov, Danail
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#123487" title="Click to go to the Author Index">
             Elson, Daniel
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#234039" title="Click to go to the Author Index">
             Huang, Baoru
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2461" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurate tracking of tissues and instruments in videos is crucial for Robotic-Assisted Minimally Invasive Surgery (RAMIS), as it enables the robot to comprehend the surgical scene with precise locations and interactions of tissues and tools. Traditional keypoint-based sparse tracking is limited by featured points, while flow-based dense two-view matching suffers from long-term drifts. Recently, the Tracking Any Point (TAP) algorithm was proposed to overcome these limitations and achieve dense accurate long-term tracking. However, its efficacy in surgical scenarios remains untested, largely due to the lack of a comprehensive surgical tracking dataset for evaluation. To address this gap, we introduce a new annotated surgical tracking dataset for benchmarking tracking methods for surgical scenarios, comprising real-world surgical videos with complex tissue and instrument motions. We extensively evaluate state-of-the-art (SOTA) TAP-based algorithms on this dataset and reveal their limitations in challenging surgical scenarios, including fast instrument motion, severe occlusions, and motion blur, etc. Furthermore, we propose a new tracking method, namely SurgMotion, to solve the challenges and further improve the tracking performance. Our proposed method outperforms most TAP-based algorithms in surgical instruments tracking, and especially demonstrates significant improvements over baselines in challenging medical videos.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt14_04">
             10:10-10:15, Paper WeBT14.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1066" name="modify2494" onclick="modify(2494,1066)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2494'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LaMOT: Language-Guided Multi-Object Tracking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422783" title="Click to go to the Author Index">
             Li, Yunhao
            </a>
           </td>
           <td class="r">
            University of Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335602" title="Click to go to the Author Index">
             Liu, Xiaoqiong
            </a>
           </td>
           <td class="r">
            University of North Texas
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418794" title="Click to go to the Author Index">
             Liu, Luke
            </a>
           </td>
           <td class="r">
            Centennial High School
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#204190" title="Click to go to the Author Index">
             Fan, Heng
            </a>
           </td>
           <td class="r">
            University of North Texas
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424283" title="Click to go to the Author Index">
             Zhang, Libo
            </a>
           </td>
           <td class="r">
            Iscas
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2494" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Vision-Language MOT is a critical tracking problem that has recently garnered increasing attention. It aims to track objects based on human language commands, displacing the traditional use of templates or pre-set information from training sets in conventional tracking tasks. However, a key challenge remains in understanding why language is used for tracking, hindering further development. In this paper, we introduce Language-Guided MOT, a unified task framework, and LaMOT, a corresponding large-scale benchmark, which encompasses diverse scenarios and language descriptions and comprises 1,660 sequences from 4 different datasets. The purpose of LaMOT is to unify various Vision-Language MOT tasks while providing a standardized evaluation platform. To ensure high-quality annotations, we manually assign appropriate descriptive texts to each target in every video and conduct careful inspection and correction. To our knowledge, LaMOT is the first benchmark dedicated to Language-Guided MOT. Additionally, we propose a simple yet effective tracker, termed LaMOTer. By establishing a unified task framework, providing challenging benchmarks, and offering insights for future algorithm design and evaluation, we expect to contribute to the advancement of research in Vision-Language MOT. We will release the data at https://github.com/Nathan-Li123/LaMOT.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt14_05">
             10:15-10:20, Paper WeBT14.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1067" name="modify3645" onclick="modify(3645,1067)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3645'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Real-Time UAV Tracking: A Comparative Study of YOLOv8 with Object Tracking Algorithms
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423763" title="Click to go to the Author Index">
             Russo, Tyler
            </a>
           </td>
           <td class="r">
            University of South Carolina
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#113633" title="Click to go to the Author Index">
             Vitzilaios, Nikolaos
            </a>
           </td>
           <td class="r">
            University of South Carolina
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3645" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Unmanned Aerial Vehicle (UAV) usage has rapidly increased leading to an effort to accurately and efficiently track UAVs. Many existing approaches utilize YOLO, a state-of-the art object detection model, in conjunction with object tracking algorithms to detect and follow UAVs in real-time. However, these systems typically focus on a single method, without considering alternative tracking methods. In this paper, we present an experimental comparison of multiple object tracking algorithms integrated with YOLOv8, offering a comprehensive evaluation of their performance in UAV tracking scenarios. First, the model size was optimized to determine the best balance between speed and accuracy. Then, various tracking methods are tested to determine the most effective combination. The YOLOv8 model combined with a Kernelized Correlation Filter outperformed various other trackers in varying environmental scenarios, with a combined success rate and tracking accuracy of 0.8041. This approach was further implemented in real-time on a Jetson Orion Nano GPU, utilizing a pan-tilt gimbal and an Intel RealSense D435i camera. Running at 20 FPS, the system demonstrated robustness and stability during motion and various environmental scenarios, highlighting its potential for integration into applications such as ground-based UAV surveillance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt14_06">
             10:20-10:25, Paper WeBT14.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1068" name="modify4883" onclick="modify(4883,1068)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4883'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MoD-SLAM: Monocular Dense Mapping for Unbounded 3D Scene Reconstruction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#409230" title="Click to go to the Author Index">
             Zhou, Heng
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#409760" title="Click to go to the Author Index">
             Guo, Zhetao
            </a>
           </td>
           <td class="r">
            Cloudspace Technology Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#409761" title="Click to go to the Author Index">
             Yuxiang, Ren
            </a>
           </td>
           <td class="r">
            Beijing Dianjing Ciyuan Culture Communication Co. ,  Ltd.,
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#409752" title="Click to go to the Author Index">
             Liu, Shuhong
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#409702" title="Click to go to the Author Index">
             Zhang, Lechen
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#409712" title="Click to go to the Author Index">
             Zhang, Kaidi
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#346050" title="Click to go to the Author Index">
             Li, Mingrui
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4883" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Monocular SLAM has received a lot of attention due to its simple RGB inputs and the lifting of complex sensor constraints. However, existing
             <p>
              monocular SLAM systems lack accurate depth estimation, which limits the
              <p>
               accuracy of tracking and mapping performance. To address this limitation, we propose MoD-SLAM, the first monocular NeRF-based dense mapping method that allows 3D reconstruction in real-time in unbounded scenes. Specifically, we introduce a depth estimation module in the front-end to extract accurate priori depth values to supervise mapping and tracking processes. This strategy is essential to improve the SLAM performance. Moreover, a Gaussian-based unbounded scene representation approach is designed to solve the challenge of mapping scenes without boundaries. By introducing a robust depth loss term into the tracking process, our SLAM system achieves more precise pose estimation in large-scale scenes. Our experiments on two standard datasets show that MoD-SLAM achieves competitive performance, improving the accuracy of the 3D reconstruction and localization by up to 30% and 15% respectively compared with existing monocular SLAM systems.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt14_07">
             10:25-10:30, Paper WeBT14.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1069" name="modify4939" onclick="modify(4939,1069)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4939'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Certifiable Algorithm for Simultaneous Shape Estimation and Object Tracking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#341199" title="Click to go to the Author Index">
             Shaikewitz, Lorenzo
            </a>
           </td>
           <td class="r">
            Massachusettes Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#299521" title="Click to go to the Author Index">
             Ubellacker, Samuel
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#119426" title="Click to go to the Author Index">
             Carlone, Luca
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4939" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Applications from manipulation to autonomous vehicles rely on robust and general object tracking to safely perform tasks in dynamic environments. We propose the first certifiably optimal category-level approach for simultaneous shape estimation and pose tracking of an object of known category (e.g. a car). Our approach uses 3D semantic keypoint measurements extracted from an RGB-D image sequence, and phrases the estimation as a fixed-lag smoothing problem. Temporal constraints enforce the object's rigidity (fixed shape) and smooth motion according to a constant-twist motion model. The solutions to this problem are the estimates of the object's state (poses, velocities) and shape (paramaterized according to the active shape model) over the smoothing horizon. Our key contribution is to show that despite the non-convexity of the fixed-lag smoothing problem, we can solve it to certifiable optimality using a small-size semidefinite relaxation. We also present a fast outlier rejection scheme that filters out incorrect keypoint detections with shape and time compatibility tests, and wrap our certifiable solver in a graduated non-convexity scheme. We evaluate the proposed approach on synthetic and real data, showcasing its performance in a table-top manipulation scenario and a drone-based vehicle tracking application.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt15">
             <b>
              WeBT15
             </b>
             Regular Session, 403
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1070" name="modifyWeBT15" onclick="modsession(573,1070)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt15" title="Click to go to the Program at a Glance">
             <b>
              Surgical Robotics: Laparoscopy
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#131482" title="Click to go to the Author Index">
             De Momi, Elena
            </a>
           </td>
           <td class="r">
            Politecnico Di Milano
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#192568" title="Click to go to the Author Index">
             Dagnino, Giulio
            </a>
           </td>
           <td class="r">
            University of Twente
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt15_01">
             09:55-10:00, Paper WeBT15.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1071" name="modify1795" onclick="modify(1795,1071)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1795'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hypergraph-Transformer (HGT) for Interaction Event Prediction in Laparoscopic and Robotic Surgery
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#325132" title="Click to go to the Author Index">
             Yin, Lianhao
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#209985" title="Click to go to the Author Index">
             Ban, Yutong
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#310657" title="Click to go to the Author Index">
             Eckhoff, Jennifer A
            </a>
           </td>
           <td class="r">
            MGH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#206064" title="Click to go to the Author Index">
             Meireles, Ozanan
            </a>
           </td>
           <td class="r">
            MGH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101388" title="Click to go to the Author Index">
             Rus, Daniela
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#173551" title="Click to go to the Author Index">
             Rosman, Guy
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1795" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Understanding and anticipating events and actions is critical for intraoperative assistance and decision-making during minimally invasive surgery. We propose a predictive neural network that is capable of understanding and predicting critical interaction aspects of surgical workflow based on endoscopic, intracorporeal video data, while flexibly leveraging surgical knowledge graphs. The approach incorporates a hypergraph-transformer (HGT) structure that encodes expert knowledge into the network design and predicts the hidden embedding of the graph. We verify our approach on established surgical datasets and applications, including the prediction of action-triplets, and the achievement of the Critical View of Safety (CVS), which is a critical safety measure. Moreover, we address specific, safety-related forecasts of surgical processes, such as predicting the clipping of the cystic duct or artery without prior achievement of the CVS. Our results demonstrate improvement in prediction of interactive event when incorporating with our approach compared to unstructured alternatives.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt15_02">
             10:00-10:05, Paper WeBT15.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1072" name="modify1877" onclick="modify(1877,1072)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1877'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robotic Flexible Magnetic Retractor for Dynamic Tissue Manipulation in Endoscopic Submucosal Dissection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379323" title="Click to go to the Author Index">
             Chan, Wai Shing
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#340836" title="Click to go to the Author Index">
             Sun, Yichong
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#265996" title="Click to go to the Author Index">
             Li, Yehui
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#286470" title="Click to go to the Author Index">
             Li, Jixiu
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#393037" title="Click to go to the Author Index">
             Yip, Hon Chi
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#176430" title="Click to go to the Author Index">
             Chiu, Philip, Wai-yan
            </a>
           </td>
           <td class="r">
            Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#152176" title="Click to go to the Author Index">
             Li, Zheng
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1877" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Endoscopic submucosal dissection (ESD) is a procedure targeted for early gastrointestinal cancer. Traction plays a crucial role in enhancing the efficiency of cutting lesions, thereby reducing procedural complexity and duration. From the perspective of traction devices, current non-magnetic ones hold shortcomings in complicating the workspace in directional tissue manipulation; Current magnetic traction devices cannot be prepared before the procedure, and require the withdrawal of endoscope in the midway to re-introduce the magnetic retractor to the lesion site. Towards these plights, this paper introduces a robotic flexible magnetic retractor designed for tissue manipulation during ESD. Precisely, the flexible prototype can be seamlessly inserted through the instrument channel of an endoscope to the lesion site without the need for endoscope withdrawal. Moreover, the introduction of robotic magnetic actuation enhances the agile control of magnetic retractors while alleviating the surgeon’s workload in magnetic-retractorassisted ESD. The experimental results validate the functionality and efficacy of the prototype magnetic retractor in magnetic traction-assisted ESD procedures. The retractor demonstrated its ability to provide adequate traction and accomplish clinical tasks. This innovative approach holds promise for enhancing the efficiency and outcomes of ESD procedures, offering a compelling alternative to traditional traction methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt15_03">
             10:05-10:10, Paper WeBT15.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1073" name="modify2119" onclick="modify(2119,1073)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2119'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Leveraging Surgical Activity Grammar for Primary Intention Prediction in Laparoscopy Procedures
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#322021" title="Click to go to the Author Index">
             Zhang, Jie
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#403129" title="Click to go to the Author Index">
             Zhou, Song
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#199701" title="Click to go to the Author Index">
             Wang, Yiwei
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#322019" title="Click to go to the Author Index">
             Wan, Chidan
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#140969" title="Click to go to the Author Index">
             Zhao, Huan
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#322022" title="Click to go to the Author Index">
             Cai, Xiong
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#195115" title="Click to go to the Author Index">
             Ding, Han
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2119" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__planning" title="Click to go to the Keyword Index">
               Surgical Robotics: Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Surgical procedures are inherently complex and dynamic, with intricate dependencies and various execution paths. Accurate identification of the intentions behind critical actions, referred to as Primary Intentions (PIs), is crucial to understanding and planning the procedure. This paper presents a novel framework that advances PI recognition in instructional videos by combining top-down grammatical structure with bottom-up visual cues. The grammatical structure is based on a rich corpus of surgical procedures, offering a hierarchical perspective on surgical activities. A grammar parser, utilizing the surgical activity grammar, processes visual data obtained from laparoscopic images through surgical action detectors, ensuring a more precise interpretation of the visual information. Experimental results on the benchmark dataset demonstrate that our method outperforms existing surgical activity detectors that rely solely on visual features. Our research provides a promising foundation for developing advanced robotic surgical systems with enhanced planning and automation capabilities.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt15_04">
             10:10-10:15, Paper WeBT15.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1074" name="modify2292" onclick="modify(2292,1074)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2292'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SLAM Assisted 3D Tracking System for Laparoscopic Surgery
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#293703" title="Click to go to the Author Index">
             Song, Jingwei
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#240845" title="Click to go to the Author Index">
             Zhang, Ray
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421285" title="Click to go to the Author Index">
             Zhang, Wenwei
            </a>
           </td>
           <td class="r">
            Wuhan United Imaging Surgical Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421057" title="Click to go to the Author Index">
             Zhou, Hao
            </a>
           </td>
           <td class="r">
            Shanghai United Imaging Healthcare Advanced Technology Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#131371" title="Click to go to the Author Index">
             Ghaffari, Maani
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2292" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A major limitation of minimally invasive surgery is the difficulty in accurately locating the internal anatomical structures of the target organ due to the lack of tactile feedback and transparency. Augmented reality (AR) offers a promising solution to overcome this challenge. Numerous studies have shown that combining learning-based and geometric methods can achieve accurate preoperative and intraoperative data registration. This work proposes a real-time monocular 3D tracking algorithm for post-registration tasks. The ORB-SLAM2 framework is adopted and modified for prior-based 3D tracking. The primitive 3D shape is used for fast initialization of the ORB-SLAM2 monocular mode. A pseudo-segmentation strategy is employed to separate the target organ from the background for tracking, and the 3D shape is incorporated as a geometric prior in its pose graph optimization. Experiments from in-vivo and ex-vivo tests demonstrate that the proposed 3D tracking system provides robust 3D tracking and effectively handles typical challenges such as fast motion, out-of-field-of-view scenarios, partial visibility, and ''organ-background'' relative motion.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt15_05">
             10:15-10:20, Paper WeBT15.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1075" name="modify2831" onclick="modify(2831,1075)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2831'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SurgPose: Generalisable Surgical Instrument Pose Estimation Using Zero-Shot Learning and Stereo Vision
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#290909" title="Click to go to the Author Index">
             Rai, Utsav
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#340701" title="Click to go to the Author Index">
             Xu, Haozheng
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#155082" title="Click to go to the Author Index">
             Giannarou, Stamatia
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2831" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurate pose estimation of surgical tools in Robot-assisted Minimally Invasive Surgery (RMIS) is essential for surgical navigation and robot control. While traditional marker-based methods offer accuracy, they face challenges with occlusions, reflections, and tool-specific designs. Similarly, supervised learning methods require extensive training on annotated datasets, limiting their adaptability to new tools. Despite their success in other domains, zero-shot pose estimation models remain unexplored in RMIS for pose estimation of surgical instruments, creating a gap in generalising to unseen surgical tools. This paper presents a novel 6 Degrees of Freedom (DoF) pose estimation pipeline for surgical instruments, leveraging state-of-the-art zero-shot RGB-D models like the FoundationPose and SAM-6D. We advanced these models by incorporating vision-based depth estimation using the RAFT-Stereo method, for robust depth estimation in reflective and textureless environments. Additionally, we enhanced SAM-6D by replacing its instance segmentation module, Segment Anything Model (SAM), with a fine-tuned Mask R-CNN, significantly boosting segmentation accuracy in occluded and complex conditions. Extensive validation reveals that our enhanced SAM-6D surpasses FoundationPose in zero-shot pose estimation of unseen surgical instruments, setting a new benchmark for zero-shot RGB-D pose estimation in RMIS. This work enhances the generalisability of pose estimation for unseen objects and pioneers the application of RGB-D zero-shot methods in RMIS.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt15_06">
             10:20-10:25, Paper WeBT15.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1076" name="modify3106" onclick="modify(3106,1076)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3106'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design and Effectiveness of Virtual Monitors and AR-Based Endoscope Control for Robotically Assisted Laparoscopic Surgery
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#329058" title="Click to go to the Author Index">
             Budjakoski, Nikola
            </a>
           </td>
           <td class="r">
            ImFusion GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#399074" title="Click to go to the Author Index">
             Schneider, Dominik
            </a>
           </td>
           <td class="r">
            German Aerospace Center (DLR)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256324" title="Click to go to the Author Index">
             Song, Tianyu
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309994" title="Click to go to the Author Index">
             Sommersperger, Michael
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#139881" title="Click to go to the Author Index">
             Weber, Bernhard
            </a>
           </td>
           <td class="r">
            German Aerospace Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107647" title="Click to go to the Author Index">
             Navab, Nassir
            </a>
           </td>
           <td class="r">
            TU Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#147336" title="Click to go to the Author Index">
             Klodmann, Julian
            </a>
           </td>
           <td class="r">
            German Aerospace Center
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3106" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#virtual_reality_and_interfaces" title="Click to go to the Keyword Index">
               Virtual Reality and Interfaces
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Managing indirect access in laparoscopy as a minimally invasive procedure poses challenges to physicians. In particular, an endoscope must be navigated to achieve adequate visualization of the surgical anatomy, while coping with unergonomic poses, tremor, and fatigue. Furthermore, the alignment of visual perception and physical movement, dictated by the endoscope's position relative to the monitor, can lead to hand-eye coordination challenges. We propose unified deployment of a robotic endoscope holder together with an augmented reality display to counteract the aforementioned challenges in laparoscopy. Our augmented reality system provides an interactive, stereoscopic, virtual monitor displaying an endoscopic stream. In addition, our method design enables direct control of the robotic endoscope holder. Our user study demonstrates the potential of the proposed method to significantly improve hand-eye coordination, while insights from our usability study for robotic control indicate promising trends, including high usability and low cognitive demand.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt15_07">
             10:25-10:30, Paper WeBT15.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1077" name="modify3611" onclick="modify(3611,1077)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3611'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MEDiC: Autonomous Surgical Robotic Assistance to Maximizing Exposure for Dissection and Cautery
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#376194" title="Click to go to the Author Index">
             Liang, Xiao
            </a>
           </td>
           <td class="r">
            University of California San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425775" title="Click to go to the Author Index">
             Wang, Chung-Pang
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#355515" title="Click to go to the Author Index">
             Shinde, Nikhil
            </a>
           </td>
           <td class="r">
            University of California San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#179568" title="Click to go to the Author Index">
             Liu, Fei
            </a>
           </td>
           <td class="r">
            University of Tennessee Knoxville
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#234261" title="Click to go to the Author Index">
             Richter, Florian
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#137547" title="Click to go to the Author Index">
             Yip, Michael C.
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3611" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__planning" title="Click to go to the Keyword Index">
               Surgical Robotics: Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Surgical automation has the capability to improve the consistency of patient outcomes and broaden access to advanced surgical care in underprivileged communities. Shared autonomy, where the robot automates routine subtasks while the surgeon retains partial teleoperative control, offers great potential to make an impact. In this paper we focus on one important skill within surgical shared autonomy: Automating robotic assistance to maximize visual exposure and apply tissue tension for dissection and cautery. Ensuring consistent exposure to visualize the surgical site is crucial for both efficiency and patient safety. However, achieving this is highly challenging due to the complexities of manipulating deformable volumetric tissues that are prevalent in surgery. To address these challenges we propose MEDiC, a framework for autonomous surgical robotic assistance to maximizing exposure for dissection and cautery. We integrate a differentiable physics model with perceptual feedback to achieve our two key objectives: 1) Maximizing tissue exposure and applying tension for a specified dissection site through visual-servoing conrol and 2) Selecting optimal control positions for a dissection target based on deformable Jacobian analysis. We quantitatively assess our method through repeated real robot experiments on a tissue phantom, and showcase its capabilities through dissection experiments using shared autonomy on real animal tissue.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt16">
             <b>
              WeBT16
             </b>
             Regular Session, 404
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1078" name="modifyWeBT16" onclick="modsession(119,1078)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt16" title="Click to go to the Program at a Glance">
             <b>
              Deformable Object Manipulation
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#114104" title="Click to go to the Author Index">
             Hoffmann, Matej
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague, Faculty of Electrical Engineering
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#211507" title="Click to go to the Author Index">
             Sakcak, Basak
            </a>
           </td>
           <td class="r">
            Maastricht University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt16_01">
             09:55-10:00, Paper WeBT16.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1079" name="modify2407" onclick="modify(2407,1079)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2407'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DeformPAM: Data-Efficient Learning for Long-Horizon Deformable Object Manipulation Via Preference-Based Action Alignment
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#381065" title="Click to go to the Author Index">
             Chen, Wendi
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#311240" title="Click to go to the Author Index">
             Xue, Han
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423092" title="Click to go to the Author Index">
             Zhou, Fangyuan
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423091" title="Click to go to the Author Index">
             Fang, Yuan
            </a>
           </td>
           <td class="r">
            Shanghai Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#224610" title="Click to go to the Author Index">
             Lu, Cewu
            </a>
           </td>
           <td class="r">
            ShangHai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2407" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#bimanual_manipulation" title="Click to go to the Keyword Index">
               Bimanual Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In recent years, imitation learning has made progress in the field of robotic manipulation. However, it still faces challenges when dealing with complex long-horizon deformable object tasks, such as high-dimensional state spaces, complex dynamics, and multimodal action distributions. Traditional imitation learning methods often require a large amount of data and encounter distributional shifts and accumulative errors in these tasks. To address these issues, we propose a data-efficient general learning framework (DeformPAM) based on preference learning and reward-guided action selection. DeformPAM decomposes long-horizon tasks into multiple action primitives, utilizes 3D point cloud inputs and diffusion models to model action distributions, and trains an implicit reward model using human preference data. During the inference phase, the reward model scores multiple candidate actions, selecting the optimal action for execution, thereby reducing the occurrence of anomalous actions and improving task completion quality. Experiments conducted on three challenging real-world long-horizon deformable object manipulation tasks demonstrate the effectiveness of this method. Results show that DeformPAM improves both task completion quality and efficiency compared to baseline methods even with limited data. Code and data will be available at deform-pam.robotflow.ai.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt16_02">
             10:00-10:05, Paper WeBT16.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1080" name="modify2678" onclick="modify(2678,1080)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2678'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Autonomous Bimanual Manipulation of Deformable Objects Using Deep Reinforcement Learning Guided Adaptive Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417020" title="Click to go to the Author Index">
             Liu, Jiayi
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#321455" title="Click to go to the Author Index">
             Yang, Sihang
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#199701" title="Click to go to the Author Index">
             Wang, Yiwei
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#140969" title="Click to go to the Author Index">
             Zhao, Huan
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#195115" title="Click to go to the Author Index">
             Ding, Han
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2678" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Deformable object manipulation (DOM) which is a common subtask in various surgical procedures represents an inevitable challenge in robot-assisted surgery (RAS) due to complex nonlinear deformation. This paper proposes a deep reinforcement learning guided adaptive control (RLAC) model-free framework, which combines learning-based and Jacobian-based methods. To complement each other for optimized performance, we harness the sampling of deep reinforcement learning (DRL) policy explored in simulations to solve a reasonable estimation of the initial deformation Jacobian. In early control iterations, the actions suggested by the DRL agent are adopted until the estimated real-time Jacobian approximates the actual deformation model. Subsequently, the independent Jacobian-based adaptive control (AC) with sufficient initial deformation awareness begins execution to achieve precise internal feature manipulation on deformable objects. Experimental results demonstrate that our method enables more efficient positioning and exhibits near-optimal positioning paths. RLAC with robust sim-to-real performance provides a feasible approach for the complex autonomous DOM in the real world.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt16_03">
             10:05-10:10, Paper WeBT16.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1081" name="modify3960" onclick="modify(3960,1081)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3960'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Embedded IPC: Fast and Intersection-Free Simulation in Reduced Subspace for Robot Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#373176" title="Click to go to the Author Index">
             Du, Wenxin
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422181" title="Click to go to the Author Index">
             Yu, Chang
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422098" title="Click to go to the Author Index">
             Ma, Siyu
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422198" title="Click to go to the Author Index">
             Jiang, Ying
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#392427" title="Click to go to the Author Index">
             Zong, Zeshun
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422736" title="Click to go to the Author Index">
             Yang, Yin
            </a>
           </td>
           <td class="r">
            University of Utah
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#308160" title="Click to go to the Author Index">
             Masterjohn, Joseph
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#206962" title="Click to go to the Author Index">
             Castro, Alejandro
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#315849" title="Click to go to the Author Index">
             Han, Xuchen
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#217457" title="Click to go to the Author Index">
             Jiang, Chenfanfu
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3960" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#contact_modeling" title="Click to go to the Keyword Index">
               Contact Modeling
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Physics-based simulation is essential for developing and evaluating robot manipulation policies, particularly in scenarios involving deformable objects and complex contact interactions. However, existing simulators often struggle to balance computational efficiency with numerical accuracy, especially when modeling deformable materials with frictional contact constraints. We introduce an efficient subspace representation for the Incremental Potential Contact (IPC) method, leveraging model reduction to decrease the number of degrees of freedom. Our approach decouples simulation complexity from the resolution of the input model by representing elasticity in a low-resolution subspace while maintaining collision constraints on an embedded high-resolution surface. Our barrier formulation ensures intersection-free trajectories and configurations regardless of material stiffness, time step size, or contact severity. We validate our simulator through quantitative experiments with a soft bubble gripper grasping and qualitative demonstrations of placing a plate on a dish rack. The results demonstrate our simulator's efficiency, physical accuracy, computational stability, and robust handling of frictional contact, making it well-suited for generating demonstration data and evaluating downstream robot training applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt16_04">
             10:10-10:15, Paper WeBT16.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1082" name="modify3993" onclick="modify(3993,1082)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3993'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Highly Robust Contact Sensor for Precise Contact Detection of Fabric
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#387894" title="Click to go to the Author Index">
             Ling, Zhengrong
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426148" title="Click to go to the Author Index">
             Hong, Lanxuan
            </a>
           </td>
           <td class="r">
            Hkust
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#229913" title="Click to go to the Author Index">
             Yang, Xiong
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397195" title="Click to go to the Author Index">
             Tang, Yifeng
            </a>
           </td>
           <td class="r">
            City University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#363902" title="Click to go to the Author Index">
             Guo, Dong
            </a>
           </td>
           <td class="r">
            City University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#133349" title="Click to go to the Author Index">
             Shen, Yajing
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3993" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#contact_modeling" title="Click to go to the Keyword Index">
               Contact Modeling
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Automation in the apparel and textile industry has long been a pursuit. However, accurately locating the surface of a fabric remains a challenge, limiting the automation in sorting, packaging, and other processes. When humans locate clothing, they rely on contact feedback for the exact position of the clothing surface. As existing contact detection solutions are significantly affected by environmental factors, it is essential to develop a sensor with robust contact detection capabilities. In this work, we introduce a contact sensor with high robustness and high force resolution. This contact sensor detects contact by measuring the deformation of an elastomer using a distance-measuring module. Based on the deformation characteristics of the elastomer, we designed a detection algorithm that not only reduces the noise of data but also extracts features such as trends and elastomer states, enabling reliable contact detection. Through experiments, we validated that this contact sensor can detect contact forces as low as 0.017 N and is robust to external interference or sensor movement. We also verified that the sensor can process data within 7.5 ms and return contact detection with 95% accuracy. Additionally, we assessed its effectiveness in real fabric contact scenarios.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt16_05">
             10:15-10:20, Paper WeBT16.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1083" name="modify4817" onclick="modify(4817,1083)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4817'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design, Modelling, and Experimental Verification of Passively Adaptable Roller Gripper for Separating Stacked Fabric
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#236167" title="Click to go to the Author Index">
             Unde, Jayant
            </a>
           </td>
           <td class="r">
            Nagoya University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#254280" title="Click to go to the Author Index">
             Colan, Jacinto
            </a>
           </td>
           <td class="r">
            Nagoya University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101240" title="Click to go to the Author Index">
             Hasegawa, Yasuhisa
            </a>
           </td>
           <td class="r">
            Nagoya University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4817" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#contact_modeling" title="Click to go to the Keyword Index">
               Contact Modeling
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study presents a novel approach to fabric manipulation through the development and optimization of a single-actuator-driven roller gripper. Focused on addressing the challenges inherent in handling fabrics with diverse thicknesses and materials, our gripper employs a passive adaptable mechanism driven by springs, enabling effective manipulation of fabrics ranging from 0.1mm to 2.25mm in thickness. We analyze gripper-fabric interaction forces to identify the parameters that influence successful grasping. We then optimize the gripper’s normal forces and the roller’s tangential force using the proposed model. Systematic evaluations demonstrated the gripper’s capability to separate individual layers from fabric stacks, achieving a 94.9% success rate across multiple fabric types. Overall, this research offers a compact, cost-effective solution with broad applicability in diverse industrial automation contexts, providing valuable insights for advancing robotic fabric handling systems. The gripper’s design is open-access and available for rapid development and customization at https://github.com/JayantUnde/Gripper.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt16_06">
             10:20-10:25, Paper WeBT16.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1084" name="modify4827" onclick="modify(4827,1084)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4827'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Closed-Loop Shape Control of Deformable Linear Objects Based on Cosserat Model
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#345362" title="Click to go to the Author Index">
             Artinian, Azad
            </a>
           </td>
           <td class="r">
            ISIR - Sorbonne Université
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102570" title="Click to go to the Author Index">
             Ben Amar, Faiz
            </a>
           </td>
           <td class="r">
            Université Pierre Et Marie Curie, Paris 6
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103589" title="Click to go to the Author Index">
             Perdereau, Véronique
            </a>
           </td>
           <td class="r">
            Sorbonne University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4827" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#dual_arm_manipulation" title="Click to go to the Keyword Index">
               Dual Arm Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_servoing" title="Click to go to the Keyword Index">
               Visual Servoing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The robotic shape control of deformable linear objects has garnered increasing interest within the robotics community. Despite recent progress, the majority of shape control approaches can be classified into two main groups: open-loop control, which relies on physically realistic models to represent the object, and closed-loop control, which employs less precise models alongside visual data to compute commands. In this work, we present a novel 3D shape control approach that includes the physically realistic Cosserat model into a closedloop control framework, using vision feedback to rectify errors in real-time. This approach capitalizes on the advantages of both groups: the realism and precision provided by physics-based models, and the rapid computation, therefore enabling real-time correction of model errors, and robustness to elastic parameter estimation inherent in vision-based approaches. This is achieved by computing a deformation Jacobian derived from both the Cosserat model and visual data. To demonstrate the effectiveness of the method, we conduct a series of shape control experiments where robots are tasked with deforming linear objects towards a desired shape.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt16_07">
             10:25-10:30, Paper WeBT16.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1085" name="modify5041" onclick="modify(5041,1085)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5041'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Single-Grasp Deformable Object Discrimination: The Effect of Gripper Morphology, Sensing Modalities, and Action Parameters
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#321087" title="Click to go to the Author Index">
             Pliska, Michal
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague, Faculty of Electrical Engi
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#296661" title="Click to go to the Author Index">
             Patni, Shubhan
            </a>
           </td>
           <td class="r">
            Ceske Vysoke Uceni Technicke V Praze, FEL
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#286425" title="Click to go to the Author Index">
             Mareš, Michal
            </a>
           </td>
           <td class="r">
            Faculty of Electrical Engineering, Czech Technical University In
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#286449" title="Click to go to the Author Index">
             Stoudek, Pavel
            </a>
           </td>
           <td class="r">
            Technology Innovation Institute (TII), Abu Dhabi
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#226430" title="Click to go to the Author Index">
             Straka, Zdenek
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague, Faculty of Electrical Engi
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#165953" title="Click to go to the Author Index">
             Stepanova, Karla
            </a>
           </td>
           <td class="r">
            Czech Technical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#114104" title="Click to go to the Author Index">
             Hoffmann, Matej
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague, Faculty of Electrical Engi
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5041" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In haptic object discrimination, the effect of gripper embodiment, action parameters, and sensory channels has not been systematically studied. We used two anthropomorphic hands and two 2-finger grippers to grasp two sets of deformable objects. On the object classification task, we found: (i) among classifiers, SVM on sensory features and LSTM on raw time series performed best across all grippers; (ii) faster compression speeds degraded performance; (iii) generalization to different grasping configurations was limited; transfer to different compression speeds worked well for the Barrett Hand only. Visualization of the feature spaces using PCA showed that the gripper morphology and the action parameters were the main source of variance, rendering generalization across embodiment or grasp configurations very hard. On the highly challenging dataset consisting of polyurethane foams alone, only the Barrett Hand achieved excellent performance. Tactile sensors can thus provide a key advantage even if recognition is based on stiffness rather than shape. The dataset with 24000 measurements is publicly available.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt17">
             <b>
              WeBT17
             </b>
             Regular Session, 405
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1086" name="modifyWeBT17" onclick="modsession(547,1086)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt17" title="Click to go to the Program at a Glance">
             <b>
              Soft Actuators 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#217972" title="Click to go to the Author Index">
             Markvicka, Eric
            </a>
           </td>
           <td class="r">
            University of Nebraska-Lincoln
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#101814" title="Click to go to the Author Index">
             Papadopoulos, Evangelos
            </a>
           </td>
           <td class="r">
            National Technical University of Athens
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt17_01">
             09:55-10:00, Paper WeBT17.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1087" name="modify460" onclick="modify(460,1087)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('460'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Introducing Mag-Nets: Rapidly Bending Electromagnetic Actuators for Self-Contained Soft Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#289756" title="Click to go to the Author Index">
             Bolanakis, Georgios
            </a>
           </td>
           <td class="r">
            National Technical University of Athens
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101814" title="Click to go to the Author Index">
             Papadopoulos, Evangelos
            </a>
           </td>
           <td class="r">
            National Technical University of Athens
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab460" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Present electromagnetic soft actuators rely on external magnetic fields or power supplies, while the very few that operate autonomously produce weak actuating forces, limiting their practicality. This work introduces a novel current-controlled electromagnetic actuator that employs copper coils and permanent magnets to produce substantial driving forces. The actuator can serve as a building block for independently controlled actuating networks to develop sophisticated self-contained soft robots and grippers. The design, inspired by fast pneu-net (fPN) actuators, ensures minimal bending resistance from the silicone body and, thus, allows high-speed bending motions. Two applications of the prototype actuator are studied; a two-fingered soft gripper realizing bending speeds of up to 1491°/s and maximum grasping force of 1.19 N, and an entirely self-contained crawling soft robot utilizing friction anisotropy to generate forward locomotion. A lumped-element model is developed and validated experimentally to describe the dynamics of the gripper’s soft finger. Pick-and-place tasks on various targets, and tests on the crawling robot demonstrate, overall, the effectiveness of the developed actuator. The uniqueness of Mag-Nets, lying in their control simplicity, enhanced capability and cost-effectiveness, sets the foundations for a new design approach for soft robots and grippers.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt17_02">
             10:00-10:05, Paper WeBT17.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1088" name="modify555" onclick="modify(555,1088)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('555'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Miniature Dielectric Elastomer Actuator Probe Inspecting Confined Spaces Embedding a CMOS Sensor
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417920" title="Click to go to the Author Index">
             Sandhu, Sahib
            </a>
           </td>
           <td class="r">
            University of Connecticut
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#337690" title="Click to go to the Author Index">
             Li, Ang (Leo)
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#383637" title="Click to go to the Author Index">
             Tugui, Codrin
            </a>
           </td>
           <td class="r">
            University of Connecticut
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#204660" title="Click to go to the Author Index">
             Duduta, Mihai
            </a>
           </td>
           <td class="r">
            University of Connecticut
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab555" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Navigating and inspecting confined space is crucial for the aerospace and healthcare industries. Exploring smaller and narrower spaces allows for problems to be identified earlier, preventing negative outcomes for patients and equipment. The challenge is to scale down the navigation probe while preserving degrees of freedom (DOF) and functionality. Dielectric elastomer actuators (DEAs) are promising probe candidates because they are solid-state, electrical-driven, and can be scaled down favorably. This work demonstrates a modular 2-DOF DEA miniature probe with an embedded CMOS sensor for visual data acquisition. The modularity achieved by a novel hinge system enables switching between single and dual DEA probes based on 2D or 3D pathway structures. The probes can be controlled using a pocket-sized circuit with two knobs to turn. We present the operating mechanism, device assembly, fabrication, and characterization of DEA bending actuators with widths below 2mm. In the end, we demonstrate the ability of devices to navigate through various complex and confined pathways.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt17_03">
             10:05-10:10, Paper WeBT17.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1089" name="modify566" onclick="modify(566,1089)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('566'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Portable, High-Frequency, and High-Voltage Control Circuits for Untethered Miniature Robots Driven by Dielectric Elastomer Actuators
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#287659" title="Click to go to the Author Index">
             Shao, Qi
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#121288" title="Click to go to the Author Index">
             Liu, Xin-Jun
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#192649" title="Click to go to the Author Index">
             Zhao, Huichan
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab566" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we propose a high-voltage, high-frequency control circuit for the untethered applications of dielectric elastomer actuators (DEAs). The circuit board leverages low-voltage resistive components connected in series to control voltages of up to 1.8 kV within a compact size, suitable for frequencies ranging from 0 to 1 kHz. A single-channel control board weighs only 2.5 g. We tested the performance of the control circuit under different load conditions and power supplies. Based on this control circuit, along with a commercial miniature high-voltage power converter, we construct an untethered crawling robot driven by a cylindrical DEA. The 42-g untethered robots successfully obtained crawling locomotion on a bench and within a pipeline at a driving frequency of 15 Hz, while simultaneously transmitting real-time video data via an onboard camera and antenna. Our work provides a practical way to use low-voltage control electronics to achieve the untethered driving of DEAs, and therefore portable and wearable devices.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt17_04">
             10:10-10:15, Paper WeBT17.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1090" name="modify1549" onclick="modify(1549,1090)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1549'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Stretchable Electrohydraulic Artificial Muscle for Full Motion Ranges in Musculoskeletal Antagonistic Joints
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#310038" title="Click to go to the Author Index">
             Kazemipour, Amirhossein
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#329053" title="Click to go to the Author Index">
             Hinchet, Ronan
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#164300" title="Click to go to the Author Index">
             Katzschmann, Robert Kevin
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1549" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#compliant_joints_and_mechanisms" title="Click to go to the Keyword Index">
               Compliant Joints and Mechanisms
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Artificial muscles play a crucial role in musculoskeletal robotics and prosthetics to approximate the force-generating functionality of biological muscle. However, current artificial muscle systems are typically limited to either contraction or extension, not both. This limitation hinders the development of fully functional artificial musculoskeletal systems. We address this challenge by introducing an artificial antagonistic muscle system capable of both contraction and extension. Our design integrates non-stretchable electrohydraulic soft actuators (HASELs) with electrostatic clutches within an antagonistic musculoskeletal framework. This configuration enables an antagonistic joint to achieve a full range of motion without displacement loss due to tendon slack. We implement a synchronization method to coordinate muscle and clutch units, ensuring smooth motion profiles and speeds. This approach facilitates seamless transitions between antagonistic muscles at operational frequencies of up to 3.2 Hz. While our prototype utilizes electrohydraulic actuators, this muscle-clutch concept is adaptable to other non-stretchable artificial muscles, such as McKibben actuators, expanding their capability for extension and full range of motion in antagonistic setups. Our design represents a significant advancement in the development of fundamental components for more functional and efficient artificial musculoskeletal systems, bringing their capabilities closer to those of their biological counterparts.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt17_05">
             10:15-10:20, Paper WeBT17.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1091" name="modify2138" onclick="modify(2138,1091)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2138'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Beyond Traversing in a Thin Pipe: Self-Sensing Odometry of a Pipeline Robot Driven by High-Frequency Dielectric Elastomer Actuators
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418540" title="Click to go to the Author Index">
             Cheng, Ran
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#287659" title="Click to go to the Author Index">
             Shao, Qi
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#121288" title="Click to go to the Author Index">
             Liu, Xin-Jun
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#192649" title="Click to go to the Author Index">
             Zhao, Huichan
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2138" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we propose an earthworm-inspired miniature pipeline robot capable of self-sensing odometry. The robot features a dielectric elastomer actuator as its elongation body and two specially designed passive anchors to achieve unidirectional motion without slipping. The odometry was achieved through the self-sensing scheme of DEAs and the summation of all step sizes over a period. The careful implementation of the self-sensing method resulted in a small sensing resolution of 0.05 mm at a high actuation frequency of 20 Hz for a cylindrical DEA. Finally, the robot obtained a self-sensing odometry in a pipe, showing good consistency with the ground truth. This work paves a new way for a miniature in-pipe robot to sense its own state without additional sensors to save space and power.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt17_06">
             10:20-10:25, Paper WeBT17.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1092" name="modify4226" onclick="modify(4226,1092)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4226'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              High-Force Electroadhesion Based on Unique Liquid-Solid Dielectrics for UAV Perching
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426192" title="Click to go to the Author Index">
             Luo, Junjie
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#253047" title="Click to go to the Author Index">
             Li, Jisen
            </a>
           </td>
           <td class="r">
            Shenzhen Institute of Artificial Intelligence and Robotics for S
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#152964" title="Click to go to the Author Index">
             Wang, Hongqiang
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#176251" title="Click to go to the Author Index">
             Zhu, Jian
            </a>
           </td>
           <td class="r">
            Chinese University of Hong Kong, Shenzhen
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4226" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Electroadhesion (EA), as an electrostatically driven, controllable adhesion technology, has unique attributes such as low noise, robust adaptability, and energy efficiency. However, its adhesion pressure is still low (0.1~10kPa) which may significantly limit its applications. This paper presents an innovative electroadhesion pad embedded with liquid and solid dielectrics. The experiments demonstrate that this liquid-solid electroadhesion pad (LSEAP) is capable of much larger adhesion pressure, compared to the traditional solid electroadhesion pad (SEAP). On one hand, the LSEAP can increase the dielectric contact with the substrate. On the other hand, the actuator can increase its dielectric strength. We also explore application of this actuator to perching of a commercial Unmanned Aerial Vehicle (UAV), in order to promote the UAV’s sustainable flight. Notably, the untethered LSEAP system, with an adhesion area as small as 4 cm² and a self-weight as light as 8.7 g, can support a UAV of 249.7 g for stable adhesion on various surfaces. The adhesion pressure generated by our LSEAD can be 32.2kPa, significantly larger than those reported in the literature. The weight ratio of the UAV to the LSEAP system is 14.6, more than double those in the previous studies. The integration of this EA system markedly prolongs the operational duration of UAVs, rendering them suitable for sustainable surveillance and reconnaissance missions. This LSEAP also marks a pivotal advancement towards adhesion-based applications such as grippers and wall-climbing robots.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt18">
             <b>
              WeBT18
             </b>
             Regular Session, 406
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1093" name="modifyWeBT18" onclick="modsession(207,1093)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt18" title="Click to go to the Program at a Glance">
             <b>
              Intelligent Transportation Systems and AI-Based Methods
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#330220" title="Click to go to the Author Index">
             Chen, Dong
            </a>
           </td>
           <td class="r">
            Mississippi State University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#173551" title="Click to go to the Author Index">
             Rosman, Guy
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt18_01">
             09:55-10:00, Paper WeBT18.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1094" name="modify676" onclick="modify(676,1094)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('676'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Scale Convolutional Networks with Class-Normalized Logit Clipping for Robust Sea State Estimation from Noisy Ship Motion Data
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418497" title="Click to go to the Author Index">
             Qin, Xin
            </a>
           </td>
           <td class="r">
            Tianjin University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418552" title="Click to go to the Author Index">
             Liu, Mengna
            </a>
           </td>
           <td class="r">
            Tianjin University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#237918" title="Click to go to the Author Index">
             Cheng, Xu
            </a>
           </td>
           <td class="r">
            Smart Innovation Norway
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418685" title="Click to go to the Author Index">
             Liu, Xiufeng
            </a>
           </td>
           <td class="r">
            Technical University of Denmark
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#316203" title="Click to go to the Author Index">
             Shi, Fan
            </a>
           </td>
           <td class="r">
            Tianjin University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#121984" title="Click to go to the Author Index">
             Zhang, Jianhua
            </a>
           </td>
           <td class="r">
            Tianjin University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103342" title="Click to go to the Author Index">
             Chen, Shengyong
            </a>
           </td>
           <td class="r">
            Tianjin University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab676" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#big_data_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Big Data in Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous ships utilize automation systems to achieve unmanned navigation, driving innovation in maritime transportation. However, sea conditions, inffuenced by dynamic factors such as wave height, wind speed, and ocean currents, present a challenge in accurately assessing these conditions. Traditional classification models often assume accurate labels, but noisy labels are prevalent in real-world applications. Existing methods, such as noise sample filtering or loss function adjustment, have limited applicability and poor generalization when dealing with complex sea condition data. To address this issue, this study proposes an end-to-end neural network model. The model’s feature extraction module uses deep representation learning to capture latent patterns in the data, and a loss function is designed to mitigate the impact of outliers. The integration of these components allows the model to perform accurate classification even in the presence of noisy labels. Extensive experiments on public and sea condition datasets validate the effectiveness of this approach, demonstrating that the model exhibits strong generalization capabilities and holds great promise for practical applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt18_02">
             10:00-10:05, Paper WeBT18.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1095" name="modify1002" onclick="modify(1002,1095)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1002'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Directed-CP: Directed Collaborative Perception for Connected and Autonomous Vehicles Via Proactive Attention
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416035" title="Click to go to the Author Index">
             Tao, Yihang
            </a>
           </td>
           <td class="r">
            City University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#373668" title="Click to go to the Author Index">
             Hu, Senkang
            </a>
           </td>
           <td class="r">
            City University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#373641" title="Click to go to the Author Index">
             Fang, Zhengru
            </a>
           </td>
           <td class="r">
            City University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#373742" title="Click to go to the Author Index">
             Fang, Yuguang
            </a>
           </td>
           <td class="r">
            City Universty of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1002" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Collaborative perception (CP) leverages visual data from connected and autonomous vehicles (CAV) to expand an ego vehicle’s field of view (FoV). Despite recent progress, current CP methods do expand the ego vehicle’s 360-degree perceptual range almost equally, but faces two key challenges. Firstly, in areas with uneven traffic distribution, focusing on directions with little traffic offers limited benefits. Secondly, under limited communication budgets, allocating excessive bandwidth to less critical directions lowers the perception accuracy in more vital areas. To address these issues, we propose Directed-CP, a proactive and direction-aware CP system aiming at improving CP in specific directions. Our key idea is to enable an ego vehicle to proactively signal its interested directions and readjust its attention to enhance local directional CP performance. To achieve this, we first propose an RSU-aided direction masking mechanism that assists an ego vehicle in identifying vital directions. Additionally, we design a direction-aware selective attention module to wisely aggregate pertinent features based on ego vehicle’s directional priorities, communication budget, and the positional data of CAVs. Moreover, we introduce a direction-weighted detection loss (DWLoss) to capture the divergence between directional CP outcomes and the ground truth, facilitating effective model training. Extensive experiments on the V2X-Sim 2.0 dataset demonstrate that our approach achieves 19.8% higher local perception accuracy in interested directions and 2.5% higher overall perception accuracy than the state-of-the-art methods in collaborative 3D object detection tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt18_03">
             10:05-10:10, Paper WeBT18.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1096" name="modify1169" onclick="modify(1169,1096)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1169'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Motion Forecasting Via Model-Based Risk Minimization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419439" title="Click to go to the Author Index">
             Distelzweig, Aron
            </a>
           </td>
           <td class="r">
            Albert-Ludwigs-Universität Freiburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420467" title="Click to go to the Author Index">
             Kosman, Eitan
            </a>
           </td>
           <td class="r">
            Bosch
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420530" title="Click to go to the Author Index">
             Andreas, Look
            </a>
           </td>
           <td class="r">
            Bosch
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#211043" title="Click to go to the Author Index">
             Janjoš, Faris
            </a>
           </td>
           <td class="r">
            Robert Bosch GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#355423" title="Click to go to the Author Index">
             Manivannan, Denesh Kumar
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#160427" title="Click to go to the Author Index">
             Valada, Abhinav
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1169" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#behavior_based_systems" title="Click to go to the Keyword Index">
               Behavior-Based Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Forecasting the future trajectories of surrounding agents is crucial for autonomous vehicles to ensure safe, efficient, and comfortable route planning. While model en- sembling has improved prediction accuracy in various fields, its application in trajectory prediction is limited due to the multi-modal nature of predictions. In this paper, we propose a novel sampling method applicable to trajectory prediction based on the predictions of multiple models. We first show that conventional sampling based on predicted probabilities can degrade performance due to missing alignment between models. To address this problem, we introduce a new method that generates optimal trajectories from a set of neural networks, framing it as a risk minimization problem with a variable loss function. By using state-of-the-art models as base learners, our approach constructs diverse and effective ensembles for optimal trajectory sampling. Extensive experiments on the nuScenes prediction dataset demonstrate that our method surpasses current state-of-the-art techniques, achieving top ranks on the leaderboard. We also provide a comprehensive empirical study on ensembling strategies, offering insights into their effectiveness. Our findings highlight the potential of advanced ensembling techniques in trajectory prediction, significantly improving predictive performance and paving the way for more reliable predicted trajectories.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt18_04">
             10:10-10:15, Paper WeBT18.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1097" name="modify1199" onclick="modify(1199,1097)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1199'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Computational Teaching for Driving Via Multi-Task Imitation Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#191756" title="Click to go to the Author Index">
             Edakkattil Gopinath, Deepak
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#191375" title="Click to go to the Author Index">
             Cui, Xiongyi
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#159948" title="Click to go to the Author Index">
             DeCastro, Jonathan
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#325807" title="Click to go to the Author Index">
             Sumner, Emily
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420659" title="Click to go to the Author Index">
             Costa, Jean
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420651" title="Click to go to the Author Index">
             Yasuda, Hiroshi
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#350510" title="Click to go to the Author Index">
             Morgan, Allison
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420660" title="Click to go to the Author Index">
             Dees, Laporsha
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#211380" title="Click to go to the Author Index">
             Chau, Sheryl
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107631" title="Click to go to the Author Index">
             Leonard, John
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#126623" title="Click to go to the Author Index">
             Chen, Tiffany
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#173551" title="Click to go to the Author Index">
             Rosman, Guy
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#250030" title="Click to go to the Author Index">
             Balachandran, Avinash
            </a>
           </td>
           <td class="r">
            Toyota Research Institue
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1199" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_performance_augmentation" title="Click to go to the Keyword Index">
               Human Performance Augmentation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Learning motor skills for sports or performance driving is often done with professional instruction from expert human teachers, whose availability is limited. Our goal is to enable automated teaching via a learned model that interacts with the student similar to a human teacher. However, training such automated teaching systems is limited by the availability of high-quality annotated datasets of expert teacher and student interactions as they are difficult to collect at scale. To address this data scarcity problem, we propose an approach for training a coaching system for complex motor tasks such as high performance driving via a Multi-Task Imitation Learning (MTIL) paradigm. MTIL allows our model to learn robust representations by utilizing self supervised training signals from more readily available non- interactive datasets of humans performing the task of interest.
             <p>
              We validate our approach with (1) a semi-synthetic dataset created from real human driving trajectories, (2) a professional track driving instruction dataset, (3) a track racing driving simulator human-subject study, and (4) a system demonstration on an instrumented car at a race track.
              <p>
               Our experiments show that the right set of auxiliary machine learning tasks improves prediction of teaching instructions. Moreover, in the human subjects study, students exposed to the instructions from our teaching system improve their ability to stay within track limits, and show favorable perception of the model’s interaction with them, in terms of usefulness and satisfaction.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt18_05">
             10:15-10:20, Paper WeBT18.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1098" name="modify2248" onclick="modify(2248,1098)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2248'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Comprehensive LLM-Powered Framework for Driving Intelligence Evaluation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419539" title="Click to go to the Author Index">
             You, Shanhe
            </a>
           </td>
           <td class="r">
            Institute for AI Industry Research, Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#392263" title="Click to go to the Author Index">
             Luo, Xuewen
            </a>
           </td>
           <td class="r">
            Monash University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419742" title="Click to go to the Author Index">
             Liang, Xinhe
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419575" title="Click to go to the Author Index">
             Yu, Jiashu
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#336733" title="Click to go to the Author Index">
             Zheng, Chen
            </a>
           </td>
           <td class="r">
            Institute for AI Industry Research, Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#311413" title="Click to go to the Author Index">
             Gong, Jiangtao
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2248" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_centered_automation" title="Click to go to the Keyword Index">
               Human-Centered Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#performance_evaluation_and_benchmarking" title="Click to go to the Keyword Index">
               Performance Evaluation and Benchmarking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Evaluation methods for autonomous driving are crucial for algorithm optimization. However, due to the complexity of driving intelligence, there is currently no comprehensive evaluation method for the level of autonomous driving intelligence. In this paper, we propose an evaluation framework for driving behavior intelligence in complex traffic environments, aiming to fill this gap. We constructed a natural language evaluation dataset of human professional drivers and passengers through naturalistic driving experiments and post-driving behavior evaluation interviews. Based on this dataset, we developed an LLM-powered driving evaluation framework. The effectiveness of this framework was validated through simulated experiments in the CARLA urban traffic simulator and further corroborated by human assessment. Our research provides valuable insights for evaluating and designing more intelligent, human-like autonomous driving agents. The implementation details of the framework and detailed information about the dataset can be found at the Github.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt18_06">
             10:20-10:25, Paper WeBT18.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1099" name="modify2574" onclick="modify(2574,1099)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2574'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LoRD: Adapting Differentiable Driving Policies to Distribution Shifts
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#317032" title="Click to go to the Author Index">
             Diehl, Christopher
            </a>
           </td>
           <td class="r">
            TU Dortmund University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#188039" title="Click to go to the Author Index">
             Karkus, Peter
            </a>
           </td>
           <td class="r">
            NVIDIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#180771" title="Click to go to the Author Index">
             Veer, Sushant
            </a>
           </td>
           <td class="r">
            NVIDIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#123466" title="Click to go to the Author Index">
             Pavone, Marco
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#136913" title="Click to go to the Author Index">
             Bertram, Torsten
            </a>
           </td>
           <td class="r">
            Technische Universität Dortmund
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2574" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#transfer_learning" title="Click to go to the Keyword Index">
               Transfer Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Distribution shifts between operational domains can severely affect the performance of learned models in self-driving vehicles (SDVs). While this is a well-established problem, prior work has mostly explored naive solutions such as fine-tuning, focusing on the motion prediction task. In this work, we explore novel adaptation strategies for differentiable autonomy stacks (structured policy) consisting of prediction, planning, and control, perform evaluation in closed-loop, and investigate the often-overlooked issue of catastrophic forgetting. Specifically, we introduce two simple yet effective techniques: a low-rank residual decoder (LoRD) and multi-task fine-tuning. Through experiments across three models conducted on two real-world autonomous driving datasets (nuPlan, exiD), we demonstrate the effectiveness of our methods and highlight a significant performance gap between open-loop and closed-loop evaluation in prior approaches. Our approach improves forgetting by up to 23.33% and the closed-loop OOD driving score by 9.93% in comparison to standard fine-tuning.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt18_07">
             10:25-10:30, Paper WeBT18.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1100" name="modify4049" onclick="modify(4049,1100)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4049'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              BehAV: Behavioral Rule Guided Autonomy Using VLMs for Robot Navigation in Outdoor Scenes
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#308861" title="Click to go to the Author Index">
             Kulathun Mudiyanselage, Kasun Weerakoon
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#367201" title="Click to go to the Author Index">
             Elnoor, Mohamed
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#414034" title="Click to go to the Author Index">
             Seneviratne, Gershom Devake
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#396015" title="Click to go to the Author Index">
             Rajagopal, Vignesh
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#243362" title="Click to go to the Author Index">
             Arul, Senthil Hariharan
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#269549" title="Click to go to the Author Index">
             Liang, Jing
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#239160" title="Click to go to the Author Index">
             M Jaffar, Mohamed Khalid
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106235" title="Click to go to the Author Index">
             Manocha, Dinesh
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4049" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#perception_action_coupling" title="Click to go to the Keyword Index">
               Perception-Action Coupling
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present BehAV, a novel approach for autonomous robot navigation in outdoor scenes guided by human instructions and leveraging Vision Language Models (VLMs). Our method interprets human commands using a Large Language Model (LLM) and categorizes the instructions into navigation and behavioral guidelines. Navigation guidelines consist of directional commands (e.g., "move forward until") and associated landmarks (e.g., "the building with blue windows"), while behavioral guidelines encompass regulatory actions (e.g., "stay on") and their corresponding objects (e.g., "pavements"). We use VLMs for their zero-shot scene understanding capabilities to estimate landmark locations from RGB images for robot navigation. Further, we introduce a novel scene representation that utilizes VLMs to ground behavioral rules into a behavioral cost map. This cost map encodes the presence of behavioral objects within the scene and assigns costs based on their regulatory actions. The behavioral cost map is integrated with a LiDAR-based occupancy map for navigation. To navigate outdoor scenes while adhering to the instructed behaviors, we present an unconstrained Model Predictive Control (MPC)-based planner that prioritizes both reaching landmarks and following behavioral guidelines. We evaluate the performance of BehAV on a quadruped robot across diverse real-world scenarios, demonstrating a 22.49% improvement in alignment with human-teleoperated actions, as measured by Fréchet distance, and achieving a 40% higher navigation success rate compared to state-of-the-art methods.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt19">
             <b>
              WeBT19
             </b>
             Regular Session, 407
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1101" name="modifyWeBT19" onclick="modsession(569,1101)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt19" title="Click to go to the Program at a Glance">
             <b>
              State Estimation
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#417137" title="Click to go to the Author Index">
             Kargar Tasooji, Tohid
            </a>
           </td>
           <td class="r">
            University of Georgia
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#178177" title="Click to go to the Author Index">
             Xiong, Xiaobin
            </a>
           </td>
           <td class="r">
            University of Wisconsin Madison
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt19_01">
             09:55-10:00, Paper WeBT19.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1102" name="modify101" onclick="modify(101,1102)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('101'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Adaptive Graduated Nonconvexity Loss Function for Robust Nonlinear Least Squares Solutions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335405" title="Click to go to the Author Index">
             Jung, Kyungmin
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#275560" title="Click to go to the Author Index">
             Hitchcox, Thomas
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#140525" title="Click to go to the Author Index">
             Forbes, James Richard
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab101" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#graduated_nonconvexity" title="Click to go to the Keyword Index">
               Graduated nonconvexity
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robust_adaptive_control_of_robotic_systems" title="Click to go to the Keyword Index">
               Robust/Adaptive Control of Robotic Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_and_adaptive_systems" title="Click to go to the Keyword Index">
               Learning and Adaptive Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Many problems in robotics, such as estimating the state from noisy sensor data or aligning two point clouds, can be posed and solved as least-squares problems. Unfortunately, vanilla nonminimal solvers for least-squares problems are notoriously sensitive to outliers and initialization errors. The conventional approach to outlier rejection is to use a robust loss function, which is typically selected and tuned
             <p>
              a priori. A newly developed approach to handle large initialization errors is graduated nonconvexity (GNC), which is defined for a particular choice of a robust loss function. The main contribution of this paper is to combine these two approaches by using an adaptive kernel within a GNC optimization scheme. This produces least-squares problems that are robust to both outliers and initialization errors, without the need for model selection and tuning. Simulations and experiments demonstrate that the proposed method is more robust compared to non-GNC counterparts and performs on par with other GNC-tailored loss functions. An Example code can be found at https://github.com/decargroup/gnc-adapt.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt19_02">
             10:00-10:05, Paper WeBT19.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1103" name="modify1209" onclick="modify(1209,1103)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1209'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Direct Solutions in Moving Horizon Estimation with Deep Learning Methods
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#363186" title="Click to go to the Author Index">
             Lionti, Fabien
            </a>
           </td>
           <td class="r">
            INRIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415252" title="Click to go to the Author Index">
             Gutowski, Nicolas
            </a>
           </td>
           <td class="r">
            University of Angers, LERIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#393235" title="Click to go to the Author Index">
             Aubin, Sébastien
            </a>
           </td>
           <td class="r">
            DGA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101740" title="Click to go to the Author Index">
             Martinet, Philippe
            </a>
           </td>
           <td class="r">
            INRIA
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1209" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             State estimation in the context of dynamical systems is crucial for various applications, including control and monitoring. Moving Horizon Estimation (MHE) is an optimization-based state estimation algorithm that leverages a known dynamical model integrated over a moving horizon. The MHE optimization criterion corresponds to identify the initial state that best aligns the integrated trajectory with the system observation. In MHE setting, the state estimation performance increases with the considered length of the moving horizon but it can become computationally intensive which is a limiting factor for its applicability to fast-varying dynamical systems or on hardware with restricted computational power. Deep Learning (DL) methods can learn solutions to complex optimization problems without incurring any additional online computational cost beyond the inference of the considered architecture. In the context of state estimation we propose to study different type of DL architecture in order to provide full state estimation from partial and noisy system observations. The novel proposed method is based on an end-to-end differentiable formulation of the MHE optimization problem, enabling the offline training of a DL model to provide a state estimation that minimizes the MHE optimization criterion. Once training is completed, state estimations are generated through an explicit relationship learned by the DL model. The proposed method is compared to the online MHE formulation in various case studies, including scenarios with partially observed state and model discrepancies in the context of lateral vehicle dynamics. The results highlight improved state estimation performance both in terms of reduced computational time and accuracy with respect to the online MHE algorithm.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt19_03">
             10:05-10:10, Paper WeBT19.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1104" name="modify3788" onclick="modify(3788,1104)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3788'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Data-Driven Contact Estimation Method for Wheeled-Biped Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421281" title="Click to go to the Author Index">
             Gökbakan, Umit Bora
            </a>
           </td>
           <td class="r">
            Inria
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256420" title="Click to go to the Author Index">
             Dümbgen, Frederike
            </a>
           </td>
           <td class="r">
            ENS, PSL University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#169843" title="Click to go to the Author Index">
             Caron, Stephane
            </a>
           </td>
           <td class="r">
            Inria
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3788" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#contact_modeling" title="Click to go to the Keyword Index">
               Contact Modeling
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#probabilistic_inference" title="Click to go to the Keyword Index">
               Probabilistic Inference
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Contact estimation is a key ability for limbed robots, where making and breaking contacts has a direct impact on state estimation and balance control. Existing approaches typically rely on gate-cycle priors or designated contact sensors. We design a contact estimator that is suitable for the emerging wheeled-biped robot types that do not have these features. To this end, we propose a Bayes filter in which update steps are learned from real-robot torque measurements while prediction steps rely on inertial measurements. We evaluate this approach in extensive real-robot and simulation experiments. Our method achieves better performance while being considerably more sample efficient than a comparable deep-learning baseline.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt19_04">
             10:10-10:15, Paper WeBT19.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1105" name="modify4031" onclick="modify(4031,1105)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4031'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Simultaneous Ground Reaction Force and State Estimation Via Constrained Moving Horizon Estimation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379359" title="Click to go to the Author Index">
             Kang, Jiarong
            </a>
           </td>
           <td class="r">
            University of Wisconsin Madison
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#178177" title="Click to go to the Author Index">
             Xiong, Xiaobin
            </a>
           </td>
           <td class="r">
            University of Wisconsin Madison
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4031" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurate ground reaction force (GRF) estimation can significantly improve the adaptability of legged robots in various real-world applications. For instance, with estimated GRF and contact kinematics, the locomotion control and planning assist the robot in overcoming uncertain terrains. The canonical momentum-based methods, formulated as nonlinear observers, do not fully address the noisy measurements and the dependence between floating-base states and the generalized momentum dynamics. In this paper, we present a simultaneous ground reaction force and state estimation framework for legged robots, which systematically addresses the sensor noise and the coupling between states and dynamics. With the floating base orientation estimated separately, a decentralized Moving Horizon Estimation (MHE) method is implemented to fuse the robot dynamics, proprioceptive sensors, exteroceptive sensors, and deterministic contact complementarity constraints in a convex windowed optimization. The proposed method is shown to be capable of providing accurate GRF and state estimation on several legged robots, including the custom-designed humanoid robot Bucky, the open-source educational planar bipedal robot STRIDE, and the quadrupedal robot Unitree Go1, with a frequency of 200Hz and a past time window of 0.04s.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt19_05">
             10:15-10:20, Paper WeBT19.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1106" name="modify4887" onclick="modify(4887,1106)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4887'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              FracGM: A Fast Fractional Programming Technique for Geman-McClure Robust Estimator
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#410013" title="Click to go to the Author Index">
             Chen, Bang-Shien
            </a>
           </td>
           <td class="r">
            National Taiwan Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#306849" title="Click to go to the Author Index">
             Lin, Yu-Kai
            </a>
           </td>
           <td class="r">
            MediaTek Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#410083" title="Click to go to the Author Index">
             Chen, Jian-Yu
            </a>
           </td>
           <td class="r">
            National Central University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#410962" title="Click to go to the Author Index">
             Huang, Chih-Wei
            </a>
           </td>
           <td class="r">
            National Central University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#410016" title="Click to go to the Author Index">
             Chern, Jann-Long
            </a>
           </td>
           <td class="r">
            National Taiwan Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411130" title="Click to go to the Author Index">
             Sun, Ching-Cherng
            </a>
           </td>
           <td class="r">
            National Central University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4887" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robust estimation is essential in computer vision, robotics, and navigation, aiming to minimize the impact of outlier measurements for improved accuracy. We present a fast algorithm for Geman-McClure robust estimation, FracGM, leveraging fractional programming techniques. This solver reformulates the original non-convex fractional problem to a convex dual problem and a linear equation system, iteratively solving them in an alternating optimization pattern. Compared to graduated non-convexity approaches, this strategy exhibits a faster convergence rate and better outlier rejection capability. In addition, the global optimality of the proposed solver can be guaranteed under given conditions. We demonstrate the proposed FracGM solver with Wahba's rotation problem and 3-D point-cloud registration along with relaxation pre-processing and projection post-processing. Compared to state-of-the-art algorithms, when the outlier rates increase from 20% to 80%, FracGM shows 53% and 88% lower rotation and translation increases. In real-world scenarios, FracGM achieves better results in 13 out of 18 outcomes, while having a 19.43% improvement in the computation time.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt19_06">
             10:20-10:25, Paper WeBT19.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1107" name="modify4919" onclick="modify(4919,1107)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4919'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Equivariant IMU Preintegration with Biases: A Galilean Group Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354421" title="Click to go to the Author Index">
             Delama, Giulio
            </a>
           </td>
           <td class="r">
            University of Klagenfurt
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#274032" title="Click to go to the Author Index">
             Fornasier, Alessandro
            </a>
           </td>
           <td class="r">
            University of Klagenfurt
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105364" title="Click to go to the Author Index">
             Mahony, Robert
            </a>
           </td>
           <td class="r">
            Australian National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#132320" title="Click to go to the Author Index">
             Weiss, Stephan
            </a>
           </td>
           <td class="r">
            Universität Klagenfurt
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4919" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_inertial_slam" title="Click to go to the Keyword Index">
               Visual-Inertial SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This letter proposes a new approach for Inertial Measurement Unit (IMU) preintegration, a fundamental building block that can be leveraged in different optimization-based Inertial Navigation System (INS) localization solutions. Inspired by recent advances in equivariant theory applied to biased INSs, we derive a discrete-time formulation of the IMU preintegration on Gal(3) ⋉ gal(3), the left-trivialization of the tangent group of the Galilean group Gal(3). We define a novel preintegration error that geometrically couples the navigation states and the bias leading to lower linearization error. Our method improves in consistency compared to existing preintegration approaches which treat IMU biases as a separate state-space. Extensive validation against state-of-the-art methods, both in simulation and with real-world IMU data, implementation in the Lie++ library, and open-source code are provided.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt19_07">
             10:25-10:30, Paper WeBT19.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1108" name="modify5030" onclick="modify(5030,1108)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5030'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              State Estimation for Continuum Multi-Robot Systems on SE(3)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#225265" title="Click to go to the Author Index">
             Lilge, Sven
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#115139" title="Click to go to the Author Index">
             Barfoot, Timothy
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#113447" title="Click to go to the Author Index">
             Burgner-Kahrs, Jessica
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5030" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#flexible_robots" title="Click to go to the Keyword Index">
               Flexible Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#state_estimation" title="Click to go to the Keyword Index">
               State Estimation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#parallel_robots" title="Click to go to the Keyword Index">
               Parallel Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In contrast to conventional robots, accurately modeling the kinematics and statics of continuum robots is challenging due to partially unknown material properties, parasitic effects, or unknown forces acting on the continuous body. Consequentially, state estimation approaches that utilize additional sensor information to predict the shape of continuum robots have garnered significant interest. This paper presents a novel approach to state estimation for systems with multiple coupled continuum robots, which allows estimating the shape and strain variables of multiple continuum robots in an arbitrary coupled topology. Simulations and experiments demonstrate the capabilities and versatility of the proposed method, while achieving accurate and continuous estimates for the state of such systems, resulting in average end-effector errors of 3.3 mm and 5.02° depending on the sensor setup. It is further shown, that the approach offers fast computation times of below 10 ms, enabling its utilization in quasi-static real-time scenarios with average update rates of 100-200 Hz. An open-source C++ implementation of the proposed state estimation method is made publicly available to the community.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt20">
             <b>
              WeBT20
             </b>
             Regular Session, 408
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1109" name="modifyWeBT20" onclick="modsession(41,1109)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt20" title="Click to go to the Program at a Glance">
             <b>
              Agricultural Automation 1
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#322878" title="Click to go to the Author Index">
             Jiang, Yu
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#101923" title="Click to go to the Author Index">
             Carpin, Stefano
            </a>
           </td>
           <td class="r">
            University of California, Merced
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt20_01">
             09:55-10:00, Paper WeBT20.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1110" name="modify113" onclick="modify(113,1110)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('113'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              IMU Augment Tightly Coupled Lidar-Visual-Inertial Odometry for Agricultural Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#403327" title="Click to go to the Author Index">
             Hoang, Quoc Hung
            </a>
           </td>
           <td class="r">
            Chungbuk National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104634" title="Click to go to the Author Index">
             Kim, Gon-Woo
            </a>
           </td>
           <td class="r">
            Chungbuk National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab113" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#agricultural_automation" title="Click to go to the Keyword Index">
               Agricultural Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robotics_and_automation_in_agriculture_and_forestry" title="Click to go to the Keyword Index">
               Robotics and Automation in Agriculture and Forestry
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a new tightly coupled LiDAR visual-odometry scheme for agricultural autonomous machinery under a structureless environment and the presence of fluctuation uncertainties. By proposing the robust adaptive filter, the effects of unknown disturbances and noises are significantly addressed. In the meantime, the IMU orientation is effectively estimated by the great capability of an error state Kalman filter (ESKF). The IMU attitude estimation is integrated to significantly improve the accuracy of both LiDAR and visual odometry. Hence, the suggested approach obtains the perfect output performance, smooth trajectory, and robustness against uncertainties. Finally, the effectiveness of the proposed LiDAR visual-odometry is confirmed with the real-time experiment of different scenarios.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt20_02">
             10:00-10:05, Paper WeBT20.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1111" name="modify1700" onclick="modify(1700,1111)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1700'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Joint 3D Point Cloud Segmentation Using Real-Sim Loop: From Panels to Trees and Branches
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#393220" title="Click to go to the Author Index">
             Qiu, Tian
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422139" title="Click to go to the Author Index">
             Du, Ruiming
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397699" title="Click to go to the Author Index">
             Spine, Nikolai
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397706" title="Click to go to the Author Index">
             Cheng, Lailiang
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#322878" title="Click to go to the Author Index">
             Jiang, Yu
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1700" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robotics_and_automation_in_agriculture_and_forestry" title="Click to go to the Keyword Index">
               Robotics and Automation in Agriculture and Forestry
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Modern orchards are planted in structured rows with distinct
             <i>
              panel
             </i>
             divisions to improve management. Accurate and efficient joint segmentation of point cloud from
             <i>
              P
             </i>
             anel to
             <i>
              T
             </i>
             ree and
             <i>
              B
             </i>
             ranch (P2TB) is essential for robotic operations. However, most current segmentation methods focus on single-instance segmentation and depend on a sequence of deep networks to perform joint tasks. This strategy hinders the use of hierarchical information embedded in the data, leading to both error accumulation and increased costs for annotation and computation, which limits its scalability for real-world applications. In this study, we proposed a novel approach that incorporated a Real2Sim L-TreeGen for training data generation and a joint model (J-P2TB) designed for the P2TB task. The J-P2TB model, trained on the generated simulation dataset, was used for joint segmentation of real-world panel point clouds via zero-shot learning. Compared to representative methods, our model outperformed them in most segmentation metrics while using 40% fewer learnable parameters. This Sim2Real result highlighted the efficacy of L-TreeGen in model training and the performance of J-P2TB for joint segmentation, demonstrating its strong accuracy, efficiency, and generalizability for real-world applications. These improvements would not only greatly benefit the development of robots for automated orchard operations but also advance digital twin technology, enabling the facilitation of field robotics across various domains.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt20_03">
             10:05-10:10, Paper WeBT20.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1112" name="modify2472" onclick="modify(2472,1112)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2472'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Energy Efficient Planning for Repetitive Heterogeneous Tasks in Precision Agriculture
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#292959" title="Click to go to the Author Index">
             Xie, Shuangyu
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107102" title="Click to go to the Author Index">
             Goldberg, Ken
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101712" title="Click to go to the Author Index">
             Song, Dezhen
            </a>
           </td>
           <td class="r">
            Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2472" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#agricultural_automation" title="Click to go to the Keyword Index">
               Agricultural Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robotics_and_automation_in_agriculture_and_forestry" title="Click to go to the Keyword Index">
               Robotics and Automation in Agriculture and Forestry
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic weed removal in precision agriculture introduces a repetitive heterogeneous task planning (RHTP) challenge for a mobile manipulator. RHTP has two unique characteristics: 1) an observe-first-and-manipulate-later (OFML) temporal constraint that forces a unique ordering of two different tasks for each target and 2) energy savings from efficient task collocation to minimize unnecessary movements. RHTP can be framed as a stochastic renewal process. According to the Renewal Reward Theorem, the expected energy usage per task cycle is the long-run average. Traditional task and motion planning focuses on feasibility rather than optimality due to the unknown object and obstacle position prior to execution. However, the known target/obstacle distribution in precision agriculture allows minimizing the expected energy usage. For each instance in this renewal process, we first compute task space partition, a novel data structure that computes all possibilities of task multiplexing and its probabilities with robot reachability. Then we propose a region-based set-coverage problem to formulate the RHTP as a mixed-integer nonlinear programming. We have implemented and solved RHTP using Branch-and-Bound solver. Compared to a baseline in simulations based on real field data, the results suggest a significant improvement in path length, number of robot stops, overall energy usage, and number of replans.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt20_04">
             10:10-10:15, Paper WeBT20.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1113" name="modify3044" onclick="modify(3044,1113)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3044'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Leveraging LLMs for Mission Planning in Precision Agriculture
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425024" title="Click to go to the Author Index">
             Zuzuarregui, Marcos
            </a>
           </td>
           <td class="r">
            University of California, Merced
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101923" title="Click to go to the Author Index">
             Carpin, Stefano
            </a>
           </td>
           <td class="r">
            University of California, Merced
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3044" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#software_tools_for_robot_programming" title="Click to go to the Keyword Index">
               Software Tools for Robot Programming
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robotics_and_automation_in_agriculture_and_forestry" title="Click to go to the Keyword Index">
               Robotics and Automation in Agriculture and Forestry
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#agricultural_automation" title="Click to go to the Keyword Index">
               Agricultural Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotics and artificial intelligence hold significant potential for advancing precision agriculture. While robotic systems have been successfully deployed for various tasks, adapting them to perform diverse missions remains challenging, particularly because end users often lack technical expertise. In this paper, we present an end-to-end system that	leverages large language models (LLMs), specifically ChatGPT, to enable users to assign complex data collection tasks to autonomous robots using natural language instructions. To enhance reusability, mission plans are encoded using an existing IEEE task specification standard, and are executed on robots via ROS2 nodes that bridge high-level mission descriptions with existing ROS libraries. Through extensive experiments, we highlight the strengths and limitations of LLMs in this context, particularly regarding spatial reasoning and solving complex routing challenges, and show how our proposed implementation overcomes them.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt20_05">
             10:15-10:20, Paper WeBT20.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1114" name="modify4318" onclick="modify(4318,1114)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4318'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hierarchical Tri-Manual Planning for Vision-Assisted Fruit Harvesting with Quadrupedal Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#266895" title="Click to go to the Author Index">
             Liu, Zhichao
            </a>
           </td>
           <td class="r">
            University of California, Riverside
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#389235" title="Click to go to the Author Index">
             Zhou, Jingzong
            </a>
           </td>
           <td class="r">
            University of California, Riverside
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#151110" title="Click to go to the Author Index">
             Karydis, Konstantinos
            </a>
           </td>
           <td class="r">
            University of California, Riverside
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4318" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robotics_and_automation_in_agriculture_and_forestry" title="Click to go to the Keyword Index">
               Robotics and Automation in Agriculture and Forestry
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#bimanual_manipulation" title="Click to go to the Keyword Index">
               Bimanual Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper addresses the challenge of developing a multi-arm quadrupedal robot capable of efficiently harvesting fruit in complex, natural environments. To overcome the inherent limitations of traditional bimanual manipulation, we introduce the first three-arm quadrupedal robot LocoHarv-3, that builds on top of the Spot quadruped, and propose a novel hierarchical tri-manual planning approach for automated fruit harvesting with collision-free trajectories between the built-in end-effector of Spot and our custom-made bimanual manipulator. Our comprehensive semi-autonomous framework integrates teleoperation, supported by LiDAR-based odometry and mapping, with learning-based visual perception for accurate fruit detection and pose estimation. Validation is conducted through a series of controlled indoor experiments using motion capture and extensive field tests in natural settings. Results demonstrate a 90% success rate in in-lab settings with a single attempt, and field trials further verify the system's robustness and efficiency in more challenging real-world environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt20_06">
             10:20-10:25, Paper WeBT20.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1115" name="modify4347" onclick="modify(4347,1115)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4347'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Capacitated Agriculture Fleet Vehicle Routing with Implements and Limited Autonomy: A Model and a Two-Phase Solution Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426624" title="Click to go to the Author Index">
             Lopez-Sanchez, Aitor
            </a>
           </td>
           <td class="r">
            Universidad Rey Juan Carlos
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#166263" title="Click to go to the Author Index">
             Lujak, Marin
            </a>
           </td>
           <td class="r">
            University Rey Juan Carlos
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426623" title="Click to go to the Author Index">
             Semet, Frederic
            </a>
           </td>
           <td class="r">
            Centrale Lille
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426622" title="Click to go to the Author Index">
             Billhardt, Holger
            </a>
           </td>
           <td class="r">
            Universidad Rey Juan Carlos
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4347" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#agent_based_systems" title="Click to go to the Keyword Index">
               Agent-Based Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robotics_and_automation_in_agriculture_and_forestry" title="Click to go to the Keyword Index">
               Robotics and Automation in Agriculture and Forestry
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we study the vehicle routing problem (VRP) for a fleet of cooperative autonomous agricultural robots (agribots) equipped with detachable implements, with the goal of efficiently and sustainably completing agricultural tasks in precision crop farming. State of the art in the area of agribot fleet routing with detachable implements is lacking. Consequently, we propose the Capacitated Agriculture Fleet Vehicle Routing Problem with Implements and Limited Autonomy (CAFVRPILA), designed to optimize the agribot fleet's routes across a set of given agricultural tasks while considering implement capacities, agribot-implement compatibilities, and agribots' limited battery autonomies. A heuristic two-phase decomposition approach is proposed for this problem. Simulation experiments show that minimizing travel distances and costs with CAFVRPILA enhances sustainable farming while maximizing productivity and resource use. The results also demonstrate that synchronizing multiple operations improves efficiency, particularly in larger fleets.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt20_07">
             10:25-10:30, Paper WeBT20.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1116" name="modify4452" onclick="modify(4452,1116)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4452'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Towards Closing the Loop in Robotic Pollination for Indoor Farming Via Autonomous Microscopic Inspection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426449" title="Click to go to the Author Index">
             Kong, Chuizheng
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338268" title="Click to go to the Author Index">
             Qiu, Alex
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426606" title="Click to go to the Author Index">
             Wibowo, Idris
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426743" title="Click to go to the Author Index">
             Ren, Marvin
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426695" title="Click to go to the Author Index">
             Dhori, Aishik
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426779" title="Click to go to the Author Index">
             Ling, Kai-Shu
            </a>
           </td>
           <td class="r">
            United States Department of Agriculture - Agricultural Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#139609" title="Click to go to the Author Index">
             Hu, Ai-Ping
            </a>
           </td>
           <td class="r">
            Georgia Tech Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#206254" title="Click to go to the Author Index">
             Kousik, Shreyas
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4452" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robotics_and_automation_in_agriculture_and_forestry" title="Click to go to the Keyword Index">
               Robotics and Automation in Agriculture and Forestry
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#agricultural_automation" title="Click to go to the Keyword Index">
               Agricultural Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#automation_at_micro_nano_scales" title="Click to go to the Keyword Index">
               Automation at Micro-Nano Scales
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Effective pollination is a key challenge for indoor farming, since bees struggle to navigate without the sun. While a variety of robotic system solutions have been proposed, it remains difficult to autonomously check that a flower has been sufficiently pollinated to produce high-quality fruit, which is especially critical for self-pollinating crops such as strawberries. To this end, this work proposes a novel robotic system for indoor farming. The proposed hardware combines a 7-degree-of-freedom (DOF) manipulator arm with a custom end-effector, comprised of an endoscope camera, a 2-DOF microscope subsystem, and a custom vibrating pollination tool; this is paired with algorithms to detect and estimate the pose of strawberry flowers, navigate to each flower, pollinate using the tool, and inspect with the microscope. The key novelty is vibrating the flower from below while simultaneously inspecting with a microscope from above. Each subsystem is validated via extensive experiments.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt21">
             <b>
              WeBT21
             </b>
             Regular Session, 410
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1117" name="modifyWeBT21" onclick="modsession(393,1117)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt21" title="Click to go to the Program at a Glance">
             <b>
              Optimization and Optimal Control
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#312226" title="Click to go to the Author Index">
             Belvedere, Tommaso
            </a>
           </td>
           <td class="r">
            CNRS
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#172485" title="Click to go to the Author Index">
             Mastalli, Carlos
            </a>
           </td>
           <td class="r">
            Heriot-Watt University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt21_01">
             09:55-10:00, Paper WeBT21.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1118" name="modify588" onclick="modify(588,1118)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('588'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Embedded Robust Model Predictive Path Integral Control Using Sensitivity Tubes and GPU Acceleration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#327941" title="Click to go to the Author Index">
             Falk Nyboe, Frederik
            </a>
           </td>
           <td class="r">
            University of Southern Denmark
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#313030" title="Click to go to the Author Index">
             Afifi, Amr
            </a>
           </td>
           <td class="r">
            University of Twente
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103169" title="Click to go to the Author Index">
             Robuffo Giordano, Paolo
            </a>
           </td>
           <td class="r">
            Irisa Cnrs Umr6074
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#268678" title="Click to go to the Author Index">
             Ebeid, Emad
            </a>
           </td>
           <td class="r">
            University of Southern Denmark
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104988" title="Click to go to the Author Index">
             Franchi, Antonio
            </a>
           </td>
           <td class="r">
            University of Twente / Sapienza University of Rome
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab588" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#embedded_systems_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Embedded Systems for Robotic and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes a method to robustify model predictive path integral (MPPI) control by directly taking into account the effects of parameter uncertainty into the controller formulation. Leveraging the recent notion of closed-loop state sensitivity, the proposed MPPI can consider the state sensitivity against parameter mismatch as a part of the system state, and consequently exploit this additional information to address the challenge of model mismatch in sampling-based model predictive control. Using an obstacle avoidance scenario, we demonstrate the use of our approach to control an aerial robot. We present an embedded implementation of our method, utilizing parallelization of computations on a GPU. Finally, we show the increased robustness of our approach over a standard MPPI controller through hardware-in-the-loop simulations and validate its embedded real-time properties.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt21_02">
             10:00-10:05, Paper WeBT21.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1119" name="modify624" onclick="modify(624,1119)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('624'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Guided Bayesian Optimization: Data-Efficient Controller Tuning with Digital Twin (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#284042" title="Click to go to the Author Index">
             Nobar, Mahdi
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418360" title="Click to go to the Author Index">
             Keller, Jürg
            </a>
           </td>
           <td class="r">
            FHNW
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#278013" title="Click to go to the Author Index">
             Rupenyan, Alisa
            </a>
           </td>
           <td class="r">
            Zurich University of Applied Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418362" title="Click to go to the Author Index">
             Khosravi, Mohammad
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#116976" title="Click to go to the Author Index">
             Lygeros, John
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab624" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#calibration_and_identification" title="Click to go to the Keyword Index">
               Calibration and Identification
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#incremental_learning" title="Click to go to the Keyword Index">
               Incremental Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This article presents the guided Bayesian optimization (BO) algorithm as an efficient data-driven method for iteratively tuning closed-loop controller parameters using a digital twin of the system. The digital twin is built using closed-loop data acquired during standard BO iterations, and activated when the uncertainty in the Gaussian Process model of the optimization objective on the real system is high. We define a controller tuning framework independent of the controller or the plant structure. Our proposed methodology is model-free, making it suitable for nonlinear and unmodelled plants with measurement noise. The objective function consists of performance metrics modeled by Gaussian processes. We utilize the available information in the closed-loop system to progressively maintain a digital twin that guides the optimizer, improving the data efficiency of our method. Switching the digital twin on and off is triggered by our data-driven criteria related to the digital twin's uncertainty estimations in the BO tuning framework. Effectively, it replaces much of the exploration of the real system with exploration performed on the digital twin. We analyze the properties of our method in simulation and demonstrate its performance on two real closed-loop systems with different plant and controller structures. The experimental results show that our method requires fewer experiments on the physical plant than Bayesian optimization to find the optimal controller parameters.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt21_03">
             10:05-10:10, Paper WeBT21.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1120" name="modify2642" onclick="modify(2642,1120)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2642'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhancing Robotic System Robustness Via Lyapunov Exponent-Based Optimization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#290633" title="Click to go to the Author Index">
             Fadini, Gabriele
            </a>
           </td>
           <td class="r">
            ETHZ
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#147028" title="Click to go to the Author Index">
             Coros, Stelian
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2642" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a novel differentiable approach to quantifying and optimizing stability in robotic systems addressing an open challenge in the field of robot analysis, control,design, and optimization. Our method leverages differentiable simulation over extended time horizons to estimate a robustness metric based on the Lyapunov exponents. The proposed metric offers several properties, including a natural extension to limit cycles (commonly encountered in robotics tasks and locomotion)and independence from the trajectory path for states converging to the attractor. We showcase, with an textit{ad-hoc} JAX gradient-based optimization framework, remarkable flexibility in tackling the robustness challenge. Our approach is tested through diverse scenarios of varying complexity, encompassing high-degree-of-freedom systems and contact-rich environments. The positive outcomes across these cases highlight the potential of our method in quantifying and possibly enhancing system robustness.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt21_04">
             10:10-10:15, Paper WeBT21.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1121" name="modify3029" onclick="modify(3029,1121)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3029'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Endpoint-Explicit Differential Dynamic Programming Via Exact Resolution
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424722" title="Click to go to the Author Index">
             Parilli, Maria
            </a>
           </td>
           <td class="r">
            Universidad Simón Bolívar
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#360298" title="Click to go to the Author Index">
             Martinez, Sergi
            </a>
           </td>
           <td class="r">
            Heriot-Watt
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#172485" title="Click to go to the Author Index">
             Mastalli, Carlos
            </a>
           </td>
           <td class="r">
            Heriot-Watt University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3029" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_contact_whole_body_motion_planning_and_control" title="Click to go to the Keyword Index">
               Multi-Contact Whole-Body Motion Planning and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#formal_methods_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Formal Methods in Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce a novel method for handling endpoint constraints in constrained differential dynamic programming (DDP). Unlike existing approaches, our method guarantees quadratic convergence and is exact, effectively managing rank deficiencies in both endpoint and stagewise equality constraints. It is applicable to both forward and inverse dynamics formulations, making it particularly well-suited for model predictive control (MPC) applications and for accelerating optimal control (OC) solvers. We demonstrate the efficacy of our approach across a broad range of robotics problems and provide a user-friendly open-source implementation within CROCODDYL.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt21_05">
             10:15-10:20, Paper WeBT21.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1122" name="modify3913" onclick="modify(3913,1122)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3913'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Second-Order Stein Variational Dynamic Optimization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#291747" title="Click to go to the Author Index">
             Aoyama, Yuichiro
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425891" title="Click to go to the Author Index">
             Lehmann, Peter
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#110087" title="Click to go to the Author Index">
             Theodorou, Evangelos
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3913" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#constrained_motion_planning" title="Click to go to the Keyword Index">
               Constrained Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a novel second-order trajectory optimization algorithm based on Stein Variational Newton's Method and Maximum Entropy Differential Dynamic Programming. The proposed algorithm, called Stein Variational Differential Dynamic Programming, is a kernel-based extension of Maximum Entropy Differential Dynamic Programming that combines the best of the two worlds of sampling-based and gradient-based optimization. The resulting algorithm avoids known drawbacks of gradient-based dynamic optimization in terms of getting stuck at local minima, while it overcomes limitations of sampling-based stochastic optimization in terms of introducing undesirable stochasticity when applied in online fashion. To test the efficacy of the proposed algorithm, experiments are conducted in Model Predictive Control mode. The experiments include comparisons with unimodal and multimodal Maximum Entropy Differential Dynamic Programming as well as Model Predictive Path Integral Control and its multimodal and Stein Variational extensions. The results demonstrate the superior performance of the proposed algorithms and confirm the hypothesis that there is a middle ground between sampling- and gradient-based optimization that is indeed beneficial for dynamic optimization.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt21_06">
             10:20-10:25, Paper WeBT21.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1123" name="modify4181" onclick="modify(4181,1123)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4181'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Application of Koopman Direct Encoding-Based Model Predictive Control to Nonlinear Electromechanical Systems
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256233" title="Click to go to the Author Index">
             Park, Sungbin
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#227249" title="Click to go to the Author Index">
             Kim, Won Dong
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science &amp; Technology (KAIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#389384" title="Click to go to the Author Index">
             Jeon, Sangha
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology(KAIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#115549" title="Click to go to the Author Index">
             Kim, Jung
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4181" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#contact_modeling" title="Click to go to the Keyword Index">
               Contact Modeling
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The Koopman operator framework has shown promising results in enabling the analysis of nonlinear dynamics into an infinite-dimensional linear representation. Koopman direct encoding (KDE) is a model-based approach that utilizes inner products and compositions in a Hilbert space to compute the Koopman operator. However, it has primarily been applied to autonomous systems and simulation environments. Here, we extend the application of KDE to nonautonomous systems and real-world environments by introducing Koopman direct encoding-based model predictive control (KDE-MPC). It was validated on nonlinear electromechanical systems with segmented dynamic conditions, such as contact-noncontact transitions, which pose challenges for modeling and control. Simulation results demonstrate a more stable and smoother position profile compared to proportional-integral-derivative control, particularly at discontinuous boundaries. KDE-MPC was also applied to real-world systems, achieving similar position tracking performance to simulation results. We anticipate that KDE-MPC will offer a viable solution for complex robotic control challenges.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt21_07">
             10:25-10:30, Paper WeBT21.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1124" name="modify5058" onclick="modify(5058,1124)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5058'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Effective Search for Control Hierarchies within the Policy Decomposition Framework
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#214806" title="Click to go to the Author Index">
             Khadke, Ashwin
            </a>
           </td>
           <td class="r">
            The AI Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#140177" title="Click to go to the Author Index">
             Geyer, Hartmut
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5058" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#evolutionary_robotics" title="Click to go to the Keyword Index">
               Evolutionary Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Policy decomposition is a novel framework for approximating optimal control policies of complex dynamical systems with a hierarchy of policies derived from smaller but tractable subsystems. It stands out amongst the class of hierarchical control methods by estimating a priori how well the closed-loop behavior of different control hierarchies matches the optimal policy. However, the number of possible
             <p>
              hierarchies grows prohibitively with the number of inputs and the dimension of the state-space of the system making it unrealistic to estimate the closed-loop performance for all hierarchies. Here, we present the development of two search methods based on Genetic Algorithm and Monte-Carlo Tree Search to tackle this combinatorial challenge, and demonstrate that it is indeed surmountable. We showcase the efficacy of our search methods and the generality of the framework by applying it towards finding hierarchies for control of three distinct robotic systems: a simplified biped, a planar manipulator, and
              <p>
               a quadcopter. The discovered hierarchies, in comparison to heuristically designed ones, provide improved closed-loop performance or can be computed in minimal time with marginally worse control performance, and also exceed the control performance of policies obtained with popular deep reinforcement learning methods.
              </p>
             </p>
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt22">
             <b>
              WeBT22
             </b>
             Regular Session, 411
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1125" name="modifyWeBT22" onclick="modsession(225,1125)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt22" title="Click to go to the Program at a Glance">
             <b>
              Learning Based Planning for Manipulation 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#110852" title="Click to go to the Author Index">
             Choi, Changhyun
            </a>
           </td>
           <td class="r">
            University of Minnesota, Twin Cities
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#284885" title="Click to go to the Author Index">
             Alt, Benjamin
            </a>
           </td>
           <td class="r">
            ArtiMinds Robotics
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt22_01">
             09:55-10:00, Paper WeBT22.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1126" name="modify45" onclick="modify(45,1126)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('45'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Movement Primitive Diffusion: Learning Gentle Robotic Manipulation of Deformable Objects
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#244877" title="Click to go to the Author Index">
             Scheikl, Paul Maria
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#327889" title="Click to go to the Author Index">
             Schreiber, Nicolas
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#385107" title="Click to go to the Author Index">
             Haas, Christoph
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#315115" title="Click to go to the Author Index">
             Freymuth, Niklas
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#113579" title="Click to go to the Author Index">
             Neumann, Gerhard
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#169287" title="Click to go to the Author Index">
             Lioutikov, Rudolf
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#141354" title="Click to go to the Author Index">
             Mathis-Ullrich, Franziska
            </a>
           </td>
           <td class="r">
            Friedrich-Alexander-University Erlangen-Nurnberg (FAU)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab45" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Policy learning in robot-assisted surgery (RAS) lacks data efficient and versatile methods that exhibit the desired motion quality for delicate surgical interventions. To this end, we introduce Movement Primitive Diffusion (MPD), a novel method for imitation learning (IL) in RAS that focuses on gentle manipulation of deformable objects. The approach combines the versatility of diffusion-based imitation learning (DIL) with the high-quality motion generation capabilities of Probabilistic Dynamic Movement Primitives (ProDMPs). This combination enables MPD to achieve gentle manipulation of deformable objects, while maintaining data efficiency critical for RAS applications where demonstration data is scarce. We evaluate MPD across various simulated and real world robotic tasks on both state and image observations. MPD outperforms state-of-the-art DIL methods in success rate, motion quality, and data efficiency.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt22_02">
             10:00-10:05, Paper WeBT22.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1127" name="modify147" onclick="modify(147,1127)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('147'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Sim-Grasp: Learning 6-DOF Grasp Policies for Cluttered Environments Using a Synthetic Benchmark
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#286601" title="Click to go to the Author Index">
             Li, Juncheng
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105300" title="Click to go to the Author Index">
             Cappelleri, David
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab147" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we present Sim-Grasp, a robust 6-DOF two-finger grasping system that integrates advanced language models for enhanced object manipulation in cluttered environments. We introduce the Sim-Grasp-Dataset, which includes 1,550 objects across 500 scenarios with 7.9 million annotated labels, and develop Sim-GraspNet to generate grasp poses from point clouds. The Sim-Grasp-Polices achieve grasping success rates of 97.14% for single objects and 87.43% and 83.33% for mixed clutter scenarios of Levels 1-2 and Levels 3-4 objects, respectively. By incorporating language models for target identification through text and box prompts, Sim-Grasp enables both object-agnostic and target picking, pushing the boundaries of intelligent robotic systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt22_03">
             10:05-10:10, Paper WeBT22.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1128" name="modify3580" onclick="modify(3580,1128)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3580'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Controlled Robot Language with Frame Semantics (FrameCRL) for Autonomous Context-Aware High-Level Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#278533" title="Click to go to the Author Index">
             Tran, Dang
            </a>
           </td>
           <td class="r">
            University of Alabama
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#238337" title="Click to go to the Author Index">
             Yan, Fujian
            </a>
           </td>
           <td class="r">
            Wichita State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#196907" title="Click to go to the Author Index">
             Zhang, Qiang
            </a>
           </td>
           <td class="r">
            The University of Alabama
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#188716" title="Click to go to the Author Index">
             Zhang, Yinlong
            </a>
           </td>
           <td class="r">
            Shenyang Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#121880" title="Click to go to the Author Index">
             He, Hongsheng
            </a>
           </td>
           <td class="r">
            The University of Alabama
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3580" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dual_arm_manipulation" title="Click to go to the Keyword Index">
               Dual Arm Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes a configurable and scalable framework based on Controlled Robot Language with Frame Semantics (FrameCRL) for plan generation. Given natural language instructions, FrameCRL constructs an equivalent formal semantic formulation in the form of discourse representation structures (DRS). Imperative verbs are extracted from the semantic structures as keys to anchor relevant semantic frames from FrameNet, and the selected semantic frames are used to construct goal statements in planning language. Non-imperative statements are further analyzed to generate object specifications and the initial state of the planning problem. These generated statements are then merged into a single planning script, which can be solved directly by the integrated planner. The performance of FrameCRL was evaluated on various natural language corpora and compared with large language models (LLM) based methods in plan generation. The results demonstrated the outperformance of FrameCRL in generating high-quality plans and its capability to handle large context scenarios. The FrameCRL was also tested on pick-and-place tasks using a dual-arm robot and it showcased a robust performance in linguistic understanding.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt22_04">
             10:10-10:15, Paper WeBT22.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1129" name="modify4205" onclick="modify(4205,1129)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4205'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Effective Tuning Strategies for Generalist Robot Manipulation Policies
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417700" title="Click to go to the Author Index">
             Zhang, Wenbo
            </a>
           </td>
           <td class="r">
            University of Adelaide
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422128" title="Click to go to the Author Index">
             Li, Yang
            </a>
           </td>
           <td class="r">
            Commonwealth Scientific and Industrial Research Organisation
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#370117" title="Click to go to the Author Index">
             Qiao, Yanyuan
            </a>
           </td>
           <td class="r">
            The University of Adelaide
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#373130" title="Click to go to the Author Index">
             Huang, Siyuan
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426305" title="Click to go to the Author Index">
             Liu, Jiajun
            </a>
           </td>
           <td class="r">
            CSIRO
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#116733" title="Click to go to the Author Index">
             Dayoub, Feras
            </a>
           </td>
           <td class="r">
            The University of Adelaide
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#241180" title="Click to go to the Author Index">
             Ma, Xiao
            </a>
           </td>
           <td class="r">
            Dyson
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203829" title="Click to go to the Author Index">
             Liu, Lingqiao
            </a>
           </td>
           <td class="r">
            University of Adelaide
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4205" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#transfer_learning" title="Click to go to the Keyword Index">
               Transfer Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Generalist robot manipulation policies (GMPs) have the potential to generalize across a wide range of tasks, environments, and devices. However, existing policies continue to struggle with out-of-distribution scenarios, considering that the action data remains notoriously hard to collect. While fine-tuning offers a practical way to quickly adapt a GMP to novel domains and tasks with limited samples, we observe that the performance of the resulting GMP differs significantly with respect to the design choices of fine-tuning strategies. In this work, we first conduct an in-depth empirical study to investigate the effect of key factors in GMP fine-tuning strategies, covering the action space, policy head, and the choice of tunable parameters, where over 2,500 rollouts are evaluated for a single configuration. We systematically discuss and summarize our findings and identify the key design choices, which we believe give a practical guideline for GMP fine-tuning. We observe that in a low-data regime, with carefully chosen fine-tuning strategies, a GMP significantly outperforms the state-of-the-art imitation learning algorithms. The results presented in this work establish a new baseline for future studies on fine-tuned GMPs.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt22_05">
             10:15-10:20, Paper WeBT22.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1130" name="modify4361" onclick="modify(4361,1130)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4361'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RM-Planner: Integrating Reinforcement Learning with Whole-Body Model Predictive Control for Mobile Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379776" title="Click to go to the Author Index">
             Zhuang, Zixuan
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425150" title="Click to go to the Author Index">
             Zheng, Le
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#332277" title="Click to go to the Author Index">
             Li, Wanyue
            </a>
           </td>
           <td class="r">
            The University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423166" title="Click to go to the Author Index">
             Liu, Renming
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#183721" title="Click to go to the Author Index">
             Lu, Peng
            </a>
           </td>
           <td class="r">
            The University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#169114" title="Click to go to the Author Index">
             Cheng, Hui
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4361" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#service_robotics" title="Click to go to the Keyword Index">
               Service Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Mobile manipulation is a crucial problem in various real-world applications. However, existing methods have demonstrated unsatisfactory training efficiency and sparse rewards, requiring complex coordination strategies between the mobile base and arm. In this paper, we propose RM-Planner, a planning method for mobile manipulation tasks in unknown complex environments. By adopting a two-layer hierarchical framework, we utilize a whole-body Model Predictive Control (MPC)-based low-level planner to track subgoals and generate aggressive but safe joint commands throughout the entire manipulation process, while a Reinforcement Learning (RL)-based high-level policy directly uses 3D point cloud representations of the environment, guiding the robot to achieve optimal manipulation postures based on current observations and specific task objectives. We conduct extensive simulations and real-world experiments, where RM-planner significantly outperforms state-of-the-art methods. Our code will be released at href{https://github.com/SYSU-RoboticsLab/RM-Planner.git}{h ttps://github.com/SYSU-RoboticsLab/RM-Planner.git}.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt22_06">
             10:20-10:25, Paper WeBT22.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1131" name="modify4520" onclick="modify(4520,1131)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4520'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Routing Manipulation of Deformable Linear Object Using Reinforcement Learning and Diffusion Policy
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#315217" title="Click to go to the Author Index">
             Li, Mingen
            </a>
           </td>
           <td class="r">
            University of Minnesota Twin Cities
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335053" title="Click to go to the Author Index">
             Yu, Houjian
            </a>
           </td>
           <td class="r">
            University of Minnesota, Twin Cities
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#110852" title="Click to go to the Author Index">
             Choi, Changhyun
            </a>
           </td>
           <td class="r">
            University of Minnesota, Twin Cities
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4520" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Tasks involving deformable linear objects (DLOs) are prevalent in daily life but pose significant challenges due to their infinite degrees of freedom and underactuated nature. Frequent contact between DLOs and surrounding objects with unknown physical parameters, such as friction, further complicates their manipulation. Performing tasks like routing ropes through a hole requires gentle yet robust manipulation, making it particularly challenging. Previous research has not adequately addressed general DLO manipulation tasks that involve intensive contact, especially in environments with rough surfaces. This paper presents a robust and delicate manipulation learning approach for the DLO routing task, leveraging reinforcement learning (RL) and diffusion policy. First, reinforcement learning agents are trained separately for rope insertion and pulling. During training, the agents are encouraged to minimize rope tension throughout task execution in environments with randomized friction to achieve delicate motion. Next, the rollouts from these agents are collected as expert demonstrations to train a diffusion policy. Our approach generates delicate motions to prevent the rope from being damaged or getting stuck on rough surfaces while remaining robust against environmental disturbances. Please refer to our project page: https://lmeee.github.io/DLOPull/
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt22_07">
             10:25-10:30, Paper WeBT22.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1132" name="modify4548" onclick="modify(4548,1132)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4548'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              TransDiff: Diffusion-Based Method for Manipulating Transparent Objects Using a Single RGB-D Image
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#376399" title="Click to go to the Author Index">
             Wang, Haoxiao
            </a>
           </td>
           <td class="r">
            Tianjin University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#376394" title="Click to go to the Author Index">
             Zhou, Kaichen
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425975" title="Click to go to the Author Index">
             Gu, Binrui
            </a>
           </td>
           <td class="r">
            Peiking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425533" title="Click to go to the Author Index">
             Feng, ZhiYuan
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425746" title="Click to go to the Author Index">
             Wang, Weijie
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425566" title="Click to go to the Author Index">
             Sun, Peilin
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426891" title="Click to go to the Author Index">
             Xiao, Yicheng
            </a>
           </td>
           <td class="r">
            Southeast University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#121984" title="Click to go to the Author Index">
             Zhang, Jianhua
            </a>
           </td>
           <td class="r">
            Tianjin University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#280114" title="Click to go to the Author Index">
             Dong, Hao
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4548" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Manipulating transparent objects presents significant challenges due to the complexities introduced by their reflection and refraction properties, which considerably hinder the accurate estimation of their 3D shapes. To address these challenges, we, for the first time, propose a single-view RGB-D-based depth completion framework, TransDiff, that leverages the Denoising Diffusion Probabilistic Models(DDPM) to achieve material-agnostic object grasping in desktop. Specifically, we leverage features extracted from RGB images, including semantic segmentation, edge maps, and normal maps, to condition the depth map generation process. Our method learns an iterative denoising process that transforms a random depth distribution into a depth map, guided by initially refined depth information, ensuring more accurate depth estimation in scenarios involving transparent objects. Additionally, we propose a novel training method to better align the noisy depth and RGB image features, which are used as conditions to refine depth estimation step by step.
             <p>
              Finally, we utilized an improved inference process to accelerate the denoising procedure. Through comprehensive experimental validation, we demonstrate that our method significantly outperforms the baselines in both synthetic and real-world benchmarks with acceptable inference time. The demo of our method can be found on: url{https://transdiff.github.io/}
             </p>
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="webt23">
             <b>
              WeBT23
             </b>
             Regular Session, 412
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1133" name="modifyWeBT23" onclick="modsession(69,1133)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#webt23" title="Click to go to the Program at a Glance">
             <b>
              Autonomous Vehicle Perception 4
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#160427" title="Click to go to the Author Index">
             Valada, Abhinav
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#217534" title="Click to go to the Author Index">
             Ding, Wenchao
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt23_01">
             09:55-10:00, Paper WeBT23.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1134" name="modify2128" onclick="modify(2128,1134)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2128'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Efficient Submap-Based Autonomous MAV Exploration Using Visual-Inertial SLAM Configurable for LiDARs or Depth Cameras
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#191616" title="Click to go to the Author Index">
             Papatheodorou, Sotiris
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309262" title="Click to go to the Author Index">
             Boche, Simon
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#313096" title="Click to go to the Author Index">
             Barbas Laina, Sebastián
            </a>
           </td>
           <td class="r">
            TU Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#151104" title="Click to go to the Author Index">
             Leutenegger, Stefan
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2128" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reactive_and_sensor_based_planning" title="Click to go to the Keyword Index">
               Reactive and Sensor-Based Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous exploration of unknown space is an essential component for the deployment of mobile robots in the real world. Safe navigation is crucial for all robotics applications and requires accurate and consistent maps of the robot's surroundings. To achieve full autonomy and allow deployment in a wide variety of environments, the robot must rely on on-board state estimation which is prone to drift over time. We propose a Micro Aerial Vehicle (MAV) exploration framework based on local submaps to allow retaining global consistency by applying loop-closure corrections to the relative submap poses. To enable large-scale exploration we efficiently compute global, environment-wide frontiers from the local submap frontiers and use a sampling-based next-best-view exploration planner. Our method seamlessly supports using either a LiDAR sensor or a depth camera, making it suitable for different kinds of MAV platforms. We perform comparative evaluations in simulation against a state-of-the-art submap-based exploration framework to showcase the efficiency and reconstruction quality of our approach. Finally, we demonstrate the applicability of our method to real-world MAVs, one equipped with a LiDAR and the other with a depth camera.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt23_02">
             10:00-10:05, Paper WeBT23.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1135" name="modify2818" onclick="modify(2818,1135)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2818'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Parking-SG: Open-Vocabulary Hierarchical 3D Scene Graph Representation for Open Parking Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418322" title="Click to go to the Author Index">
             Zhang, Yaowen
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423685" title="Click to go to the Author Index">
             Ruan, Yi
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#277638" title="Click to go to the Author Index">
             Pan, Miaoxin
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#128868" title="Click to go to the Author Index">
             Yang, Yi
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#128869" title="Click to go to the Author Index">
             Fu, Mengyin
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2818" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#automation_technologies_for_smart_cities" title="Click to go to the Keyword Index">
               Automation Technologies for Smart Cities
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Automatic Valet Parking (AVP) has garnered significant attention from industry and academia due to its potential to enhance traffic efficiency, parking safety, and user experience. While AVP technologies have been successfully applied in standard parking scenarios with clear markings, real-world parking environments are far more diverse and complex, posing challenges for current systems. To address these limitations, we present Parking-SG, an open-vocabulary hierarchical 3D scene graph representation, facilitating the application of AVP in open and complex environments. Our approach builds an object-based, open-vocabulary map that integrates both ground-level and ground-above objects for comprehensive environmental understanding. Leveraging common sense reasoning and object behavior relationships, various standard or non-standard parking spaces are inferred in open environments. Additionally, we extract and analyze path topology to construct a hierarchical map representation, supporting complex AVP tasks. Parking-SG is validated in both simulated and real-world environments, demonstrating its ability to generate rich environmental representations, accurately and flexibly infer parking spaces, and effectively perform complex AVP tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt23_03">
             10:05-10:10, Paper WeBT23.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1136" name="modify3393" onclick="modify(3393,1136)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3393'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              3D Lane Detection Based on Projection-Consistent Reference Points and Intra &amp; Inter-Lane Context
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#412354" title="Click to go to the Author Index">
             Bing, Yiqiu
            </a>
           </td>
           <td class="r">
            Capital Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425166" title="Click to go to the Author Index">
             Niu, Huilin
            </a>
           </td>
           <td class="r">
            Capital Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425130" title="Click to go to the Author Index">
             Zhang, Hong
            </a>
           </td>
           <td class="r">
            Sensetime
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425285" title="Click to go to the Author Index">
             Jiang, Na
            </a>
           </td>
           <td class="r">
            Capital Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#374685" title="Click to go to the Author Index">
             Zhou, Zhong
            </a>
           </td>
           <td class="r">
            BeiHang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425044" title="Click to go to the Author Index">
             Geng, Qichuan
            </a>
           </td>
           <td class="r">
            Capital Normal University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3393" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             3D lane detection aims to identify lane categories and trends in 3D space, which is a vital and challenging task in autonomous driving. Existing methods introduce various priors to guide 3D lane prediction, which generally consist of a series of reference points for context aggregation. However, due to the misalignment between these reference points and the lanes, it is difficult to obtain complete and discriminative context for complex instances. In this paper, we are devoted to introducing 3D priors adaptive to lane appearances, which serve as references to aggregate the lane context. Specifically, we propose a projection-consistent reference generation strategy to keep the projected 3D reference points geometrically consistent with the corresponding lanes in images. In addition, a segmentation-lifting denoising strategy is designed to improve the ability of the model to map the lane segmentation into 3D space. To leverage more lane-related information, we propose a decoupled lane-context aggregation module by considering the perspectives of individual geometries and integrated layout, namely intra-lane and inter-lane context. Extensive experiments on the OpenLane dataset show that our approach outperforms previous methods and achieves the state-of-the-art performance. The code will be made publicly available.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt23_04">
             10:10-10:15, Paper WeBT23.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1137" name="modify3404" onclick="modify(3404,1137)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3404'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Unveiling the Black Box: Independent Functional Module Evaluation for Bird's-Eye-View Perception Model
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417327" title="Click to go to the Author Index">
             Zhang, Ludan
            </a>
           </td>
           <td class="r">
            Nankai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425495" title="Click to go to the Author Index">
             Ding, Xiaokang
            </a>
           </td>
           <td class="r">
            School of Electronic and Information Engineering, Beijing Univer
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425409" title="Click to go to the Author Index">
             Dai, Yuqi
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420517" title="Click to go to the Author Index">
             He, Lei
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#194499" title="Click to go to the Author Index">
             Li, Keqiang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3404" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             End-to-end models are emerging as the mainstream in autonomous driving perception. However, the inability to meticulously deconstruct their internal mechanisms results in diminished development efficacy and impedes the establishment of trust. Pioneering in the issue, we present the Independent Functional Module Evaluation for Bird’s-Eye-View Perception Model (BEV-IFME), a novel framework that juxtaposes the module's feature maps against Ground Truth within a unified semantic Representation Space to quantify their similarity, thereby assessing the training maturity of individual functional modules. The core of the framework lies in the process of feature map encoding and representation aligning, facilitated by our proposed two-stage Alignment AutoEncoder, which ensures the preservation of salient information and the consistency of feature structure. The metric for evaluating the training maturity of functional modules, Similarity Score, demonstrates a robust positive correlation with BEV metrics, with an average correlation coefficient of 0.9387, attesting to the framework's reliability for assessment purposes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt23_05">
             10:15-10:20, Paper WeBT23.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1138" name="modify3424" onclick="modify(3424,1138)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3424'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Panoptic-Depth Forecasting
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#301363" title="Click to go to the Author Index">
             Juana Valeria, Hurtado
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425510" title="Click to go to the Author Index">
             Mohan, Riya
            </a>
           </td>
           <td class="r">
            Freiburg University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#160427" title="Click to go to the Author Index">
             Valada, Abhinav
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3424" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Forecasting the semantics and 3D structure of scenes is essential for robots to navigate and plan actions safely. Recent methods have explored semantic and panoptic scene forecasting; however, they do not consider the geometry of the scene. In this work, we propose the panoptic-depth forecasting task for jointly predicting future panoptic segmentation and depth maps from monocular camera images. To facilitate this work, we extend the popular KITTI-360 and Cityscapes benchmarks by computing depth maps from LiDAR point clouds and leveraging sequential labeled data. We also introduce a suitable evaluation metric that quantifies both the panoptic quality and depth estimation accuracy of future frames in a coherent manner. Furthermore, we present two baselines and propose the novel netname architecture that learns rich spatio-temporal representations by incorporating a transformer-based encoder, a forecasting module, and task-specific decoders to predict future panoptic-depth outputs. Extensive evaluations demonstrate the effectiveness of netname across two datasets and three forecasting tasks, consistently addressing the primary challenges. We make the code publicly available at https://pdcast.cs.uni-freiburg.de
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt23_06">
             10:20-10:25, Paper WeBT23.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1139" name="modify3575" onclick="modify(3575,1139)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3575'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Coarse-To-Fine Cross-Modality Generation for Enhancing Vehicle Re-Identification with High-Fidelity Synthetic Data
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415305" title="Click to go to the Author Index">
             Jin, Leyang
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417247" title="Click to go to the Author Index">
             Ji, Wei
            </a>
           </td>
           <td class="r">
            Nanjing University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256093" title="Click to go to the Author Index">
             Chua, Tatseng
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379446" title="Click to go to the Author Index">
             Zheng, Zhedong
            </a>
           </td>
           <td class="r">
            University of Macau
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3575" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Due to the critical issues of privacy and partial occlusion, license plate information is not always available in vehicle recognition systems. Consequently, researchers have increasingly turned towards vehicle re-identification (reID) techniques to bridge the gap between cross-view camera systems. Despite the growing interest, one major challenge persists: the scarcity of authentic, large-scale training datasets. To address this challenge, this paper introduces a coarse-to-fine generation pipeline designed to synthesize high-fidelity vehicle data, thereby facilitating subsequent vehicle representation learning. Specifically, the proposed approach consists of three stages: Prompt Processing, Diffusion Fine-tuning, and Semantic Filtering. First, we collect detailed prompts from vehicle websites and companies with fine-grained vehicle prototype attributes. Next, we leverage the prior knowledge of these automotive prototypes to fine-tune diffusion models. Finally, to ensure the quality of the synthesized data, we employ pre-trained vision-language models to filter out substandard images. Building upon the high-quality data generated by this pipeline, we validate the effectiveness using vanilla models. Extensive experimental evaluations demonstrate that our approach achieves competitive accuracy on public benchmarks such as VeRi-776, VehicleID and CityFlowV2, and is compatible with various model architectures.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="webt23_07">
             10:25-10:30, Paper WeBT23.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1140" name="modify4156" onclick="modify(4156,1140)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4156'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              HGS-Mapping: Online Dense Mapping Using Hybrid Gaussian Representation in Urban Scenes
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#367344" title="Click to go to the Author Index">
             Wu, Ke
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#407883" title="Click to go to the Author Index">
             Zhang, Kaizhao
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#290428" title="Click to go to the Author Index">
             Zhang, Zhiwei
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#407873" title="Click to go to the Author Index">
             Tie, Muer
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#407871" title="Click to go to the Author Index">
             Yuan, Shanshuai
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339746" title="Click to go to the Author Index">
             Zhao, Jieru
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#322500" title="Click to go to the Author Index">
             Gan, Zhongxue
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#217534" title="Click to go to the Author Index">
             Ding, Wenchao
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4156" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Online dense mapping of urban scenes forms a fundamental cornerstone for scene understanding and naviga- tion of autonomous vehicles. Recent
             <p>
              advancements in dense mapping methods are mainly based on NeRF, whose rendering speed is too slow to meet online requirements. 3D Gaussian Splatting (3DGS), with its rendering speed hundreds of times faster than NeRF, holds greater potential in online dense mapping. However, integrating 3DGS into a street-view dense mapping framework still faces
              <p>
               two challenges, including incom- plete reconstruction due to the absence of geometric information beyond the LiDAR coverage area and extensive computation for reconstruction in large urban scenes. To this
               <p>
                end, we propose HGS-Mapping, an online dense mapping framework in unbounded large-scale scenes. To attain complete construction, our framework introduces Hybrid Gaussian Representation, which models different parts of the entire scene using Gaussians with distinct properties. Furthermore, we employ a hybrid Gaussian initialization mechanism and an adaptive update method to achieve high-fidelity and rapid reconstruction. To the best of our knowledge, we are the first to
                <p>
                 integrate Gaussian representation into online dense mapping of urban scenes. Our approach achieves SOTA reconstruction accuracy while only employing 66% number of Gaussians, leading to 20% faster reconstruction
                 <p>
                  speed.
                 </p>
                </p>
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect1">
             <b>
              WeCT1
             </b>
             Regular Session, 302
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1141" name="modifyWeCT1" onclick="modsession(653,1141)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect1" title="Click to go to the Program at a Glance">
             <b>
              Award Finalists 7
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#101856" title="Click to go to the Author Index">
             Sukhatme, Gaurav
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#101975" title="Click to go to the Author Index">
             Althoefer, Kaspar
            </a>
           </td>
           <td class="r">
            Queen Mary University of London
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect1_01">
             11:15-11:20, Paper WeCT1.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1142" name="modify757" onclick="modify(757,1142)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('757'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Distributed Multi-Robot Source Seeking in Unknown Environments with Unknown Number of Sources
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397950" title="Click to go to the Author Index">
             Chen, Lingpeng
            </a>
           </td>
           <td class="r">
            Chinese University of Hong Kong, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#332340" title="Click to go to the Author Index">
             Kailas, Siva
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#371001" title="Click to go to the Author Index">
             Deolasee, Srujan
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#185040" title="Click to go to the Author Index">
             Luo, Wenhao
            </a>
           </td>
           <td class="r">
            University of Illinois Chicago
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#117857" title="Click to go to the Author Index">
             Sycara, Katia
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398302" title="Click to go to the Author Index">
             Kim, Woojun
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab757" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce a novel distributed source seeking framework, DIAS, designed for multi-robot systems in scenarios where the number of sources is unknown and potentially exceeds the number of robots. Traditional robotic source seeking methods typically focused on directing each robot to a specific strong source and may fall short in comprehensively identifying all potential sources. DIAS addresses this gap by introducing a hybrid controller that identifies the presence of sources and then alternates between exploration for data gathering and exploitation for guiding robots to identified sources. It further enhances search efficiency by dividing the environment into Voronoi cells and approximating source density functions based on Gaussian process regression. Additionally, DIAS can be integrated with existing source seeking algorithms. We compare DIAS with existing algorithms, including DoSS and GMES in simulated gas leakage scenarios where the number of sources outnumbers or is equal to the number of robots. The numerical results show that DIAS outperforms the baseline methods in both the efficiency of source identification by the robots and the accuracy of the estimated environmental density function.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect1_02">
             11:20-11:25, Paper WeCT1.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1143" name="modify4189" onclick="modify(4189,1143)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4189'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Deploying Ten Thousand Robots: Scalable Imitation Learning for Lifelong Multi-Agent Path Finding
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416588" title="Click to go to the Author Index">
             Jiang, He
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#353594" title="Click to go to the Author Index">
             Wang, Yutong
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#343289" title="Click to go to the Author Index">
             Veerapaneni, Rishi
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378259" title="Click to go to the Author Index">
             Duhan, Tanishq Harish
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#180884" title="Click to go to the Author Index">
             Sartoretti, Guillaume Adrien
            </a>
           </td>
           <td class="r">
            National University of Singapore (NUS)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#270001" title="Click to go to the Author Index">
             Li, Jiaoyang
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4189" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Lifelong Multi-Agent Path Finding (LMAPF) repeatedly finds collision-free paths for multiple agents that are continually assigned new goals when they reach current ones. Recently, this field has embraced learning-based methods, which reactively generate single-step actions based on individual local observations. However, it is still challenging for them to match the performance of the best search-based algorithms, especially in large-scale settings. This work proposes an imitation-learning-based LMAPF solver that introduces a novel communication module as well as systematic single-step collision resolution and global guidance techniques. Our proposed solver, Scalable Imitation Learning for LMAPF (SILLM), inherits the fast reasoning speed of learning-based methods and the high solution quality of search-based methods with the help of modern GPUs. Across six large-scale maps with up to 10,000 agents and varying obstacle structures, SILLM surpasses the best learning- and search-based baselines, achieving average throughput improvements of 137.7% and 16.0%, respectively. Furthermore, SILLM also beats the winning solution of the 2023 League of Robot Runners, an international LMAPF competition. Finally, we validated SILLM with 10 real robots and 100 virtual robots in a mock warehouse environment.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect1_03">
             11:25-11:30, Paper WeCT1.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1144" name="modify1025" onclick="modify(1025,1144)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1025'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Nonholonomic Robot Object Transportation with Obstacle Crossing Using a Deformable Sheet
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#380792" title="Click to go to the Author Index">
             Zhang, Weijian
            </a>
           </td>
           <td class="r">
            University of Bimingham
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#282781" title="Click to go to the Author Index">
             Street, Charlie
            </a>
           </td>
           <td class="r">
            University of Birmingham
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#169802" title="Click to go to the Author Index">
             Mansouri, Masoumeh
            </a>
           </td>
           <td class="r">
            Birmingham University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1025" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#nonholonomic_motion_planning" title="Click to go to the Keyword Index">
               Nonholonomic Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we address multi-robot formation planning where nonholonomic robots collaboratively transport objects using a deformable sheet in unstructured, cluttered environments. The formation can expand or contract to adjust the height of the object on the sheet. However, interactions between the robots and sheet introduce complex constraints for formation planning. Complexity increases further when the only feasible solution requires crossing an obstacle, i.e. where robots navigate in different homotopy classes around an obstacle such that the object hovers above it. Most existing nonholonomic formation planners do not admit obstacle crossing, limiting performance. In this paper, we present a two-stage iterative trajectory optimization framework which explicitly considers obstacle crossing. First, we capture the set of all feasible homotopy classes for each robot using a topological probabilistic roadmap. We then iteratively apply numerical optimization techniques to find a safe and feasible solution for the formation. We demonstrate the efficacy of our framework in simulation and on real robot hardware.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect1_04">
             11:30-11:35, Paper WeCT1.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1145" name="modify2044" onclick="modify(2044,1145)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2044'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Configuration-Adaptive Visual Relative Localization for Spherical Modular Self-Reconfigurable Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#336190" title="Click to go to the Author Index">
             Liu, Yuming
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#381805" title="Click to go to the Author Index">
             Zheng, Qiu
            </a>
           </td>
           <td class="r">
            The Chinese University of HongKong, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#226856" title="Click to go to the Author Index">
             Tu, Yuxiao
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#212292" title="Click to go to the Author Index">
             Gao, Yuan
            </a>
           </td>
           <td class="r">
            Shenzhen Institute of Artificial Intelligence and Robotics for S
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267777" title="Click to go to the Author Index">
             Liang, Guanqi
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#113090" title="Click to go to the Author Index">
             Lam, Tin Lun
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong, Shenzhen
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2044" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#cellular_and_modular_robots" title="Click to go to the Keyword Index">
               Cellular and Modular Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Spherical Modular Self-reconfigurable Robots (SMSRs) have been popular in recent years. Their Self-reconfigurable nature allows them to adapt to different environments and tasks, and achieve what a single module could not achieve. To collaborate with each other, relative localization between each module and assembly is crucial. Existing relative localization methods either have low accuracy, which is unsuitable for short-distance collaborations, or are designed for fixed-shape robots, whose visual features remain static over time. This paper proposes the first visual relative localization method for SMSRs. We first detect and identify individual modules of SMSRs, and adopt visual tracking to improve the detection and identification robustness. Using an optimization-based method, tracking result is then fused with odometry to estimate the relative pose between assemblies. To deal with the non-convexity of the optimization problem, we adopt semi-definite relaxation to transform it into a convex form. The proposed method is validated and analysed in real-world experiments. The overall localization performance and the performance under time-varying configuration are evaluated. The result shows that the relative position estimation accuracy reaches 2%, and the orientation estimation accuracy reaches 6.64^circ, and that our method surpasses the state-of-the-art methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect1_05">
             11:35-11:40, Paper WeCT1.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1146" name="modify2189" onclick="modify(2189,1146)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2189'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Realm: Real-Time Line-Of-Sight Maintenance in Multi-Robot Navigation with Unknown Obstacles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#296723" title="Click to go to the Author Index">
             Bai, Ruofei
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#185927" title="Click to go to the Author Index">
             Yuan, Shenghai
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423732" title="Click to go to the Author Index">
             Li, Kun
            </a>
           </td>
           <td class="r">
            Chongqing University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#238454" title="Click to go to the Author Index">
             Guo, Hongliang
            </a>
           </td>
           <td class="r">
            Agency for Science Technology and Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#196715" title="Click to go to the Author Index">
             Yau, Wei-Yun
            </a>
           </td>
           <td class="r">
            I2R
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#115410" title="Click to go to the Author Index">
             Xie, Lihua
            </a>
           </td>
           <td class="r">
            NanyangTechnological University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2189" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#networked_robots" title="Click to go to the Keyword Index">
               Networked Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#constrained_motion_planning" title="Click to go to the Keyword Index">
               Constrained Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-robot navigation in complex environments relies on inter-robot communication and mutual observation for situational awareness. This paper studies the multi-robot navigation problem in unknown environments with line-of-sight (LoS) connectivity constraints. While previous works are limited to known environment models to derive the LoS constraints between robots, this paper eliminates such requirements by directly formulating the LoS constraints from real-time LiDAR scans, adopting techniques in point cloud visibility analysis. Based on that, we propose a novel LoS-distance metric to quantify both the urgency and sensitivity of losing LoS between robots considering their potential movements. Moreover, to address the imbalanced urgency of losing LoS between two robots, we design a fusion function to capture the overall urgency while generating gradients that facilitate robots' collaborative behavior to maintain LoS. The team connectivity is guaranteed by encoding the LoS constraints into a potential function that preserves the positivity of the Fiedler eigenvalue of robots' underlying graph. Finally, we establish a LoS-constrained exploration framework integrating the proposed connectivity controller. We showcase its applications in multi-robot exploration in complex unknown environments, where robots can always maintain the LoS connectivity through distributed sensing and communication while collaboratively exploring unknown environments. Our implementations are available at url{https://github.com/bairuofei/LoS_constrained_navigation}.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect2">
             <b>
              WeCT2
             </b>
             Regular Session, 301
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1147" name="modifyWeCT2" onclick="modsession(213,1147)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect2" title="Click to go to the Program at a Glance">
             <b>
              Interactive Robot Learning
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#187169" title="Click to go to the Author Index">
             Losey, Dylan
            </a>
           </td>
           <td class="r">
            Virginia Tech
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#211129" title="Click to go to the Author Index">
             Zhou, Bolei
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect2_01">
             11:15-11:20, Paper WeCT2.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1148" name="modify1136" onclick="modify(1136,1148)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1136'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Personalizing Interfaces to Humans with User-Friendly Priors
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338970" title="Click to go to the Author Index">
             Christie, Benjamin
            </a>
           </td>
           <td class="r">
            Virginia Tech
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#224839" title="Click to go to the Author Index">
             Nemlekar, Heramb
            </a>
           </td>
           <td class="r">
            Virginia Tech
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#187169" title="Click to go to the Author Index">
             Losey, Dylan
            </a>
           </td>
           <td class="r">
            Virginia Tech
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1136" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#probabilistic_inference" title="Click to go to the Keyword Index">
               Probabilistic Inference
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#virtual_reality_and_interfaces" title="Click to go to the Keyword Index">
               Virtual Reality and Interfaces
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robots often need to convey information to human users. For example, robots can leverage visual, auditory, and haptic interfaces to display their intent or express their internal state. In some scenarios there are socially agreed upon conventions for what these signals mean: e.g., a red light indicates an autonomous car is slowing down. But as robots develop new capabilities and seek to convey more complex data, the meaning behind their signals is not always mutually understood: one user might think a flashing light indicates the autonomous car is an aggressive driver, while another user might think the same signal means the autonomous car is defensive. In this paper we enable robots to adapt their interfaces to the current user so that the human's personalized interpretation is aligned with the robot's meaning. We start with an information theoretic end-to-end approach, which automatically tunes the interface policy to optimize the correlation between human and robot. But to ensure that this learning policy is intuitive --- and to accelerate how quickly the interface adapts to the human --- we recognize that humans have priors over how interfaces should function. For instance, humans expect interface signals to be proportional and convex. Our approach biases the robot's interface towards these priors, resulting in signals that are adapted to the current user while still following social expectations. Our simulations and user study results across 15 participants suggest that these priors improve robot-to-human communication. See videos here: https://youtu.be/Re3OLg57hp8.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect2_02">
             11:20-11:25, Paper WeCT2.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1149" name="modify1850" onclick="modify(1850,1149)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1850'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Personalization in Human-Robot Interaction through Preference-Based Action Representation Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#316417" title="Click to go to the Author Index">
             Wang, Ruiqi
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354292" title="Click to go to the Author Index">
             Zhao, Dezhong
            </a>
           </td>
           <td class="r">
            Beijing University of Chemical Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422461" title="Click to go to the Author Index">
             Suh, Dayoon
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411634" title="Click to go to the Author Index">
             Yuan, Ziqin
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#326072" title="Click to go to the Author Index">
             Chen, Guohua
            </a>
           </td>
           <td class="r">
            Beijing University of Chemical Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#164680" title="Click to go to the Author Index">
             Min, Byung-Cheol
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1850" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_factors_and_human_in_the_loop" title="Click to go to the Keyword Index">
               Human Factors and Human-in-the-Loop
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Preference-based reinforcement learning (PbRL) has shown significant promise for personalization in human-robot interaction (HRI) by explicitly integrating human preferences into the robot learning process. However, existing practices often require training a personalized robot policy from scratch, resulting in inefficient use of human feedback. In this paper, we propose preference-based action representation learning (PbARL), an efficient fine-tuning method that decouples common task structure from preference by leveraging pre-trained robot policies. Instead of directly fine-tuning the pre-trained policy with human preference, PbARL uses it as a reference for an action representation learning task that maximizes the mutual information between the pre-trained source domain and the target user preference-aligned domain. This approach allows the robot to personalize its behaviors while preserving original task performance and eliminates the need for extensive prior information from the source domain, thereby enhancing efficiency and practicality in real-world HRI scenarios. Empirical results on the Assistive Gym benchmark and a real-world user study (N=8) demonstrate the benefits of our method compared to state-of-the-art approaches. Website at https://sites.google.com/view/pbarl.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect2_03">
             11:25-11:30, Paper WeCT2.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1150" name="modify2455" onclick="modify(2455,1150)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2455'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Interface Matters: Comparing First and Third-Person Perspective Interfaces for Bi-Manual Robot Behavioural Cloning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#340556" title="Click to go to the Author Index">
             Luo, Haining
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#245778" title="Click to go to the Author Index">
             Chacon Quesada, Rodrigo
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#323258" title="Click to go to the Author Index">
             Casado, Fernando E.
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#360304" title="Click to go to the Author Index">
             Lingg, Nico
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#114394" title="Click to go to the Author Index">
             Demiris, Yiannis
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2455" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#virtual_reality_and_interfaces" title="Click to go to the Keyword Index">
               Virtual Reality and Interfaces
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#bimanual_manipulation" title="Click to go to the Keyword Index">
               Bimanual Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Despite the growing interest in Behavioural Cloning for robots, few existing research has explicitly explored the impact of user interfaces on the effectiveness of expert demonstrations. We investigate the importance of user interface design in Behavioural Cloning, highlighting the critical role that interfaces play in conveying human demonstrations and robotics capabilities. This study compares the effectiveness of first and third-person perspective interfaces for robot shoe- lacing, a highly dexterous, bi-manual manipulation task that involves deformable objects and requires high precision. Our study highlights the importance of considering the impact of interface design on expert demonstration quality in Behavioural Cloning applications. By providing a first-person perspective, we observed significant differences in demonstration execution time and consistency compared to the third-person perspective. These findings suggest that the choice of interface can influence the quality of expert demonstrations, which in turn affects the performance of learning algorithms.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect2_04">
             11:30-11:35, Paper WeCT2.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1151" name="modify2846" onclick="modify(2846,1151)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2846'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robot Policy Transfer with Online Demonstrations: An Active Reinforcement Learning Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#360072" title="Click to go to the Author Index">
             Hou, Muhan
            </a>
           </td>
           <td class="r">
            Vrije University Amsterdam
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#155588" title="Click to go to the Author Index">
             Hindriks, Koen
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Amsterdam
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#282987" title="Click to go to the Author Index">
             Eiben, A.E.
            </a>
           </td>
           <td class="r">
            VU Amsterdam
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#184682" title="Click to go to the Author Index">
             Baraka, Kim
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Amsterdam
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2846" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_factors_and_human_in_the_loop" title="Click to go to the Keyword Index">
               Human Factors and Human-in-the-Loop
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#transfer_learning" title="Click to go to the Keyword Index">
               Transfer Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Transfer Learning (TL) is a powerful tool that enables robots to transfer learned policies across different environments, tasks, or embodiments. To further facilitate this process, efforts have been made to combine it with Learning from Demonstrations (LfD) for more flexible and efficient policy transfer. However, these approaches are almost exclusively limited to offline demonstrations collected before policy transfer starts, which may suffer from the intrinsic issue of covariance shift brought by LfD and harm the performance of policy transfer. Meanwhile, extensive work in the learning-from-scratch setting has shown that online demonstrations can effectively alleviate covariance shift and lead to better policy performance with improved sample efficiency. This work combines these insights to introduce online demonstrations into a policy transfer setting. We present Policy Transfer with Online Demonstrations, an active LfD algorithm for policy transfer that can optimize the timing and content of queries for online episodic expert demonstrations under a limited demonstration budget. We evaluate our method in eight robotic scenarios, involving policy transfer across diverse environment characteristics, task objectives, and robotic embodiments, with the aim to transfer a trained policy from a source task to a related but different target task. The results show that our method significantly outperforms all baselines in terms of average success rate and sample efficiency, compared to two canonical LfD methods with offline demonstrations and one active LfD method with online demonstrations. Additionally, we conduct preliminary sim-to-real tests of the transferred policy on three transfer scenarios in the real-world environment, demonstrating the policy effectiveness on a real robot manipulator.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect2_05">
             11:35-11:40, Paper WeCT2.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1152" name="modify3475" onclick="modify(3475,1152)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3475'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              User-Aware Collaborative Learning in Human-Robot Interactions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#277282" title="Click to go to the Author Index">
             Gucsi, Bálint
            </a>
           </td>
           <td class="r">
            University of Southampton
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#215033" title="Click to go to the Author Index">
             Tuyen, Nguyen Tan Viet
            </a>
           </td>
           <td class="r">
            University of Southampton
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#207812" title="Click to go to the Author Index">
             Chu, Bing
            </a>
           </td>
           <td class="r">
            University of Southampton
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#156717" title="Click to go to the Author Index">
             Tarapore, Danesh
            </a>
           </td>
           <td class="r">
            University of Southampton
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#277281" title="Click to go to the Author Index">
             Tran-Thanh, Long
            </a>
           </td>
           <td class="r">
            University of Warwick
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3475" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_teaming" title="Click to go to the Keyword Index">
               Human-Robot Teaming
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_experience" title="Click to go to the Keyword Index">
               Learning from Experience
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Our work investigates how social robots can efficiently collaborate with human users in a user-aware manner, minimising the generated frustration in human colleagues, thus enhancing their experience. As part of this, we develop a user-aware framework for human-robot collaborative learning. We model users’ frustration during human-robot interactions based on recent interactions inspired by Psychological principles and develop different frustration-aware interactive preference learning and decision-making models using multi-armed bandit and knapsack methods. Evaluating our approach, 1) we conducted simulated experiments on realistic human-behaviour datasets and 2) a user-study in which participants worked with a TIAGo Steel humanoid robot on a collaboration task using frustration-aware and non frustration-aware (Upper Confidence Bounds and Instruction-based) models. We demonstrate that when collaborating with the frustration-aware robot, users completed the collaboration task 9.04% faster and using 20.54% less number of verbal interactions, with user questionnaire responses reporting less frustration experienced compared to the baseline approaches. Additionally, we create a multimodal dataset containing over 6 hours of human-robot interactions displaying various explicit and implicit user responses.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect2_06">
             11:40-11:45, Paper WeCT2.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1153" name="modify3476" onclick="modify(3476,1153)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3476'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Data-Efficient Learning from Human Interventions for Mobile Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#284763" title="Click to go to the Author Index">
             Peng, Zhenghao
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#287256" title="Click to go to the Author Index">
             Liu, Zhizheng
            </a>
           </td>
           <td class="r">
            SenseTime
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#211129" title="Click to go to the Author Index">
             Zhou, Bolei
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3476" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_factors_and_human_in_the_loop" title="Click to go to the Keyword Index">
               Human Factors and Human-in-the-Loop
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Mobile robots are essential in applications such as autonomous delivery and hospitality services. Applying learning-based methods to address mobile robot tasks has gained popularity due to its robustness and generalizability. Traditional methods such as Imitation Learning (IL) and Reinforcement Learning (RL) offer adaptability but require large datasets, carefully crafted reward functions, and face sim-to-real gaps, making them challenging for efficient and safe real-world deployment. We propose an online human-in-the-loop learning method PVP4Real that combines IL and RL to address these issues. PVP4Real enables efficient real-time policy learning from online human intervention and demonstration, without reward or any pretraining, significantly improving data efficiency and training safety. We validate our method by training two different robots---a legged quadruped, and a wheeled delivery robot---in two mobile robot tasks, one of which even uses raw RGBD image as observation. The training finishes {within 15 minutes}. Our experiments show the promising future of human-in-the-loop learning in addressing the data efficiency issue in real-world robotic tasks. More information is available at: https://metadriverse.github.io/pvp4real/
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect3">
             <b>
              WeCT3
             </b>
             Regular Session, 303
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1154" name="modifyWeCT3" onclick="modsession(303,1154)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect3" title="Click to go to the Program at a Glance">
             <b>
              Mechanism Design 3
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#102290" title="Click to go to the Author Index">
             Tadakuma, Kenjiro
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#226350" title="Click to go to the Author Index">
             Sibai, Hussein
            </a>
           </td>
           <td class="r">
            Washington University in St. Louis
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect3_01">
             11:15-11:20, Paper WeCT3.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1155" name="modify6" onclick="modify(6,1155)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('6'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Morphing Quadrotor-Blimp with Balloon Failure Resilience for Mobile Ecological Sensing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#296008" title="Click to go to the Author Index">
             Sharma, Suryansh
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#388912" title="Click to go to the Author Index">
             Verhoeff, Mike
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#388932" title="Click to go to the Author Index">
             Joosen, Floor Elisabeth
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#296245" title="Click to go to the Author Index">
             Venkatesha Prasad, RangaRao
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#190182" title="Click to go to the Author Index">
             Hamaza, Salua
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab6" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#failure_detection_and_recovery" title="Click to go to the Keyword Index">
               Failure Detection and Recovery
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The increasing popularity of helium-assisted blimps for extended monitoring or data collection applications is hindered by a critical limitation -- single-point failure when the balloon malfunctions or bursts. To address this, we introduce Janus, a hybrid blimp-drone platform equipped with integrated balloon failure detection and recovery capability. Janus employs a triggered mechanism that seamlessly transitions the platform from a blimp to a standard quad-rotor drone. Utilizing multiple sensors and fusing their readings, we have developed a robust balloon failure detection system. Janus demonstrates omnidirectional mobility in blimp mode and transitions promptly into quadrotor mode upon receiving the signal. Our results affirm the successful recovery of the system from balloon failure, with a rapid response time of 66ms to balloon failure detection. The drone morphs into a quadrotor and achieves recovery within 0.362 seconds in 90% of cases. By amalgamating the enduring flight capabilities of blimps with the agility of quad-rotors within a morphing platform like Janus, we cater to applications demanding both prolonged flight duration and enhanced agility.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect3_02">
             11:20-11:25, Paper WeCT3.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1156" name="modify390" onclick="modify(390,1156)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('390'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Novel Passive Parallel Elastic Actuation Principle for Load Compensation in Legged Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#296616" title="Click to go to the Author Index">
             Zhang, Yifang
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#340644" title="Click to go to the Author Index">
             Jiang, Jingcheng
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105401" title="Click to go to the Author Index">
             Tsagarakis, Nikos
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab390" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work introduces a novel parallel elastic actuation principle designed to provide torque compensation for legged robots. Unlike existing solutions, the proposed concept leverages a nitrogen N2 gas spring combined with a cam roller module to generate a highly customizable torque compensation profile for the target leg joint. An optimization-based design approach is employed to derive the specifications of the gas spring and optimize the cam module to produce a compensation torque profile closest to the desired one. The proposed load compensation concept and related mechanism are experimentally evaluated and practically integrated into the knee joint of a two-DoF monopedal robot actuated by cycloid actuators. The experimental results demonstrate that the proposed principle can effectively generate the required compensation torque profile and achieve significant benefits for the prototyped monopedal robot system by reducing 71.92% of the additional energy consumption caused by the payload. The entire system is compact, easy to integrate, and highly customizable, enabling the creation of nonlinear torque compensation profiles as needed. The work provides a promising solution to load compensation in legged robots.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect3_03">
             11:25-11:30, Paper WeCT3.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1157" name="modify935" onclick="modify(935,1157)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('935'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Mathematical Modeling and Rolling Motion Generation of Planar Seven-Link Robot That Forms Passive Closed and Active Open Chains
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103082" title="Click to go to the Author Index">
             Asano, Fumihiko
            </a>
           </td>
           <td class="r">
            Japan Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#374282" title="Click to go to the Author Index">
             Sedoguchi, Taiki
            </a>
           </td>
           <td class="r">
            Japan Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#145698" title="Click to go to the Author Index">
             Tokuda, Isao T.
            </a>
           </td>
           <td class="r">
            Ritsumeikan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab935" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#underactuated_robots" title="Click to go to the Keyword Index">
               Underactuated Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper investigates the mathematical modeling and basic motion properties of planar seven-link robots that forms passive closed and active open chains. The passive closed model is formed by connecting seven rigid frames via seven viscoelastic joints, and the active open model is formed by connecting them via actuated joints. The former is a convex heptagonal model and can exhibit passive-dynamic rolling on a gentle downhill, whereas the latter virtually forms a forward-leaning octagonal shape by controlling the six relative joint angles. In the first half of this paper, we describe the model assumptions and develop the mathematical equations of motion and collision of the passive closed model, and numerically analyze the motion characteristics by changing the slope angle while checking the conditions necessary for stable motion generation. In the second half, we outline the active open model, develop the PD control system, and numerically analyze the motion characteristics by changing the target angle parameter that controls the degree of forward lean of the virtual octagon.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect3_04">
             11:30-11:35, Paper WeCT3.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1158" name="modify3414" onclick="modify(3414,1158)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3414'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LEVA: A High-Mobility Logistic Vehicle with Legged Suspension
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421658" title="Click to go to the Author Index">
             Arnold, Marco
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421663" title="Click to go to the Author Index">
             Hildebrandt, Lukas
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421671" title="Click to go to the Author Index">
             Janssen, Kaspar
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421637" title="Click to go to the Author Index">
             Ongan, Efe
            </a>
           </td>
           <td class="r">
            Ethz - Rsl
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424366" title="Click to go to the Author Index">
             Bürge, Pascal
            </a>
           </td>
           <td class="r">
            ZHAW / Zurich University of Applied Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423278" title="Click to go to the Author Index">
             Gábriel, Ádám Gyula
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424139" title="Click to go to the Author Index">
             Kennedy, James
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422005" title="Click to go to the Author Index">
             Lolla, Rishi
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425243" title="Click to go to the Author Index">
             Oppliger, Quanisha
            </a>
           </td>
           <td class="r">
            ZHAW Zurich University of Applied Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424289" title="Click to go to the Author Index">
             Schaaf, Micha
            </a>
           </td>
           <td class="r">
            ZHAW Zurich University of Applied Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395890" title="Click to go to the Author Index">
             Church, Joseph
            </a>
           </td>
           <td class="r">
            ETH RSL
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422045" title="Click to go to the Author Index">
             Fritsche, Michael Xaver
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#236286" title="Click to go to the Author Index">
             Klemm, Victor
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#344080" title="Click to go to the Author Index">
             Tuna, Turcan
            </a>
           </td>
           <td class="r">
            ETH Zurich, Robotic Systems Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#238450" title="Click to go to the Author Index">
             Valsecchi, Giorgio
            </a>
           </td>
           <td class="r">
            Robotic System Lab, ETH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351893" title="Click to go to the Author Index">
             Weibel, Cedric
            </a>
           </td>
           <td class="r">
            ETH Zuerich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#114045" title="Click to go to the Author Index">
             Hutter, Marco
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#454157" title="Click to go to the Author Index">
             Wüthrich, Michael
            </a>
           </td>
           <td class="r">
            ZHAW Zurich University of Applied Sciences
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3414" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The autonomous transportation of materials over challenging terrain is a challenge with major economic implications and remains unsolved. This paper introduces LEVA, a high-payload, high-mobility robot designed for autonomous logistics across varied terrains, including those typical in agriculture, construction, and search and rescue operations. LEVA uniquely integrates an advanced legged suspension system using parallel kinematics. It is capable of traversing stairs using a rl controller, has steerable wheels, and includes a specialized box pickup mechanism that enables autonomous payload loading as well as precise and reliable cargo transportation of up to 85 kg across uneven surfaces, steps and inclines while maintaining a cot of as low as 0.15. Through extensive experimental validation, LEVA demonstrates its off-road capabilities and reliability regarding payload loading and transport.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect3_05">
             11:35-11:40, Paper WeCT3.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1159" name="modify3801" onclick="modify(3801,1159)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3801'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safe Decentralized Multi-Agent Control Using Black-Box Predictors, Conformal Decision Policies, and Control Barrier Functions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425965" title="Click to go to the Author Index">
             Huriot, Sacha
            </a>
           </td>
           <td class="r">
            Washington University in St. Louis
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#226350" title="Click to go to the Author Index">
             Sibai, Hussein
            </a>
           </td>
           <td class="r">
            Washington University in St. Louis
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3801" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We address the challenge of safe control in decentralized multi-agent robotic settings, where agents use uncertain black-box models to predict other agents' trajectories. We use the recently proposed conformal decision theory to adapt the restrictiveness of control barrier functions-based safety constraints based on observed prediction errors. We use these constraints to synthesize controllers that balance between the objectives of safety and task accomplishment, despite the prediction errors. We provide an upper bound on the average over time of the value of a monotonic function of the difference between the safety constraint based on the predicted trajectories and the constraint based on the ground truth ones. We validate our theory through experimental results showing the performance of our controllers when navigating a robot in the multi-agent scenes in the Stanford Drone Dataset.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect3_06">
             11:40-11:45, Paper WeCT3.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1160" name="modify5073" onclick="modify(5073,1160)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5073'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Poloidal Drive: Direct-Drive Transmission Mechanism for Active Omni-Wheels with Spoke Interference Avoidance
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#216613" title="Click to go to the Author Index">
             Sano, Shunsuke
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102290" title="Click to go to the Author Index">
             Tadakuma, Kenjiro
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#383365" title="Click to go to the Author Index">
             Kayawake, Ryotaro
            </a>
           </td>
           <td class="r">
            Tohoku University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#192974" title="Click to go to the Author Index">
             Watanabe, Masahiro
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#254295" title="Click to go to the Author Index">
             Abe, Kazuki
            </a>
           </td>
           <td class="r">
            Osaka University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#321877" title="Click to go to the Author Index">
             Kemmotsu, Yuto
            </a>
           </td>
           <td class="r">
            Tohoku University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100118" title="Click to go to the Author Index">
             Tadokoro, Satoshi
            </a>
           </td>
           <td class="r">
            Tohoku University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5073" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Wheels require extra space for steering. Omnidirectional wheels are ideal for confined spaces as they can move in all directions: forward/backward and left/right. Conventional omnidirectional wheels with passive rollers achieve this movement by combining multiple wheels. However, if even one wheel loses contact with the ground, the vehicle becomes inoperable. To overcome this limitation, omnidirectional wheels with actively driven rollers have been proposed. These designs, however, require additional components, which increase weight. This is because multi-step intermediate transmission mechanisms are needed to convert spindle rotation into roller rotation. Eliminating the intermediate transmission mechanism reduces the number of components and provides more space to enhance wheel strength. This study proposed a mechanism without intermediate transmission, clarified its design framework, and experimentally demonstrated its feasibility as an active omnidirectional wheel. The proposed design framework defines conditions to maximize both power transmission efficiency and strength. Experimental results showed that the transmission efficiency of the proposed mechanism is comparable to that of conventional mechanisms.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect4">
             <b>
              WeCT4
             </b>
             Regular Session, 304
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1161" name="modifyWeCT4" onclick="modsession(533,1161)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect4" title="Click to go to the Program at a Glance">
             <b>
              Sensor Fusion 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#204668" title="Click to go to the Author Index">
             Albini, Alessandro
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#101712" title="Click to go to the Author Index">
             Song, Dezhen
            </a>
           </td>
           <td class="r">
            Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI) and Texas A&amp;M University (TAMU)
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect4_01">
             11:15-11:20, Paper WeCT4.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1162" name="modify742" onclick="modify(742,1162)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('742'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An End-To-End Learning-Based Multi-Sensor Fusion for Autonomous Vehicle Localization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418506" title="Click to go to the Author Index">
             Lin, Changhong
            </a>
           </td>
           <td class="r">
            DiDi Autonomous Driving
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#236834" title="Click to go to the Author Index">
             Lin, Jiarong
            </a>
           </td>
           <td class="r">
            The University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#181591" title="Click to go to the Author Index">
             Sui, Zhiqiang
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#225875" title="Click to go to the Author Index">
             Qu, Xiaozhi
            </a>
           </td>
           <td class="r">
            Didichuxing
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418639" title="Click to go to the Author Index">
             Wang, Rui
            </a>
           </td>
           <td class="r">
            DiDi Autonomous Driving
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405925" title="Click to go to the Author Index">
             Sheng, Kehua
            </a>
           </td>
           <td class="r">
            DIdi Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405926" title="Click to go to the Author Index">
             Zhang, Bo
            </a>
           </td>
           <td class="r">
            DIdi Inc
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab742" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-sensor fusion is essential for autonomous vehicle localization, as it is capable of integrating data from various sources for enhanced accuracy and reliability. The accuracy of the integrated location and orientation depends on the precision of the uncertainty modeling. Traditional methods of uncertainty modeling typically assume a Gaussian distribution and involve manual heuristic parameter tuning. However, these methods struggle to scale effectively and address long-tail scenarios. To address these challenges, we propose a learning-based method that encodes sensor information using higher-order neural network features, thereby eliminating the need for uncertainty estimation. This method significantly eliminates the need for parameter fine-tuning by developing an end-to-end neural network that is specifically designed for multi-sensor fusion. In our experiments, we demonstrate the effectiveness of our approach in real-world autonomous driving scenarios. Results show that the proposed method outperforms existing multi-sensor fusion methods in terms of both accuracy and robustness. A video of the results can be viewed at https://youtu.be/q4iuobMbjME.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect4_02">
             11:20-11:25, Paper WeCT4.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1163" name="modify987" onclick="modify(987,1163)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('987'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Unleashing HyDRa: Hybrid Fusion, Depth Consistency and Radar for Unified 3D Perception
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419383" title="Click to go to the Author Index">
             Wolters, Philipp
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419385" title="Click to go to the Author Index">
             Gilg, Johannes
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#363073" title="Click to go to the Author Index">
             Teepe, Torben
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419405" title="Click to go to the Author Index">
             Herzog, Fabian
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420173" title="Click to go to the Author Index">
             Laouichi, Anouar
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419438" title="Click to go to the Author Index">
             Hofmann, Martin
            </a>
           </td>
           <td class="r">
            Fusionride Technology (Germany) GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#111879" title="Click to go to the Author Index">
             Rigoll, Gerhard
            </a>
           </td>
           <td class="r">
            Technische Universität München
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab987" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Low-cost, vision-centric 3D perception systems for autonomous driving have made significant progress in recent years, narrowing the gap to expensive LiDAR-based methods. The primary challenge in becoming a fully reliable alternative lies in robust depth prediction capabilities, as camera-based systems struggle with long detection ranges and adverse lighting and weather conditions. In this work, we introduce HyDRa, a novel camera-radar fusion architecture for diverse 3D perception tasks. Building upon the principles of dense Bird's-Eye-View (BEV)-based architectures, HyDRa introduces a hybrid fusion approach to combine the strengths of complementary camera and radar features in two distinct representation spaces. Our Height Association Transformer module leverages radar features already in the perspective view to produce more robust and accurate depth predictions. In the BEV, we refine the initial sparse representation by a adar-weighted Depth Consistency. HyDRa achieves a new state-of-the-art for camera-radar fusion of 64.2 NDS (+1.8) and 58.4 AMOTA (+1.5) on the public nuScenes dataset. Moreover, our new semantically rich and spatially accurate BEV features can be directly converted into a powerful occupancy representation, beating all previous camera-based methods on the Occ3D benchmark by an impressive 3.7 mIoU. Code and models are available at https://github.com/phi-wol/hydra.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect4_03">
             11:25-11:30, Paper WeCT4.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1164" name="modify1945" onclick="modify(1945,1164)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1945'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              VIP-Dock: Vision, Inertia, and Pressure Sensor Fusion for Underwater Docking with Optical Beacon Guidance
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417417" title="Click to go to the Author Index">
             Zhang, Suohang
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417521" title="Click to go to the Author Index">
             Qian, Shipang
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417418" title="Click to go to the Author Index">
             Wang, Lu
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420829" title="Click to go to the Author Index">
             Fei, Xinyu
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421266" title="Click to go to the Author Index">
             Chen, Yanhu
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1945" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_based_control" title="Click to go to the Keyword Index">
               Sensor-based Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Underwater docking enhances the operational capabilities of Autonomous Underwater Vehicles (AUVs) by facilitating energy and data transfer. Optical beacons serve as the primary guidance method for AUVs to localize and track docking stations. This paper presents VIP-Dock, a novel optical beacon tracking algorithm for robust underwater docking of AUVs. VIP-Dock addresses the challenge of maintaining accurate beacon tracking under visual interference by integrating visual, inertial, and pressure perception. Employing an unscented Kalman filter framework, the VIP-Dock algorithm provides continuous optimal estimation of beacon positions. Experimental results demonstrated VIP-Dock's real-time tracking performance in actual docking scenarios and its ability to maintain accuracy during visual input failure. Implementation in a digital twin system for an underwater vertical shuttle showed significant improvement, increasing docking success rates from 62% to 84% across 100 trials under simulated current disturbances.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect4_04">
             11:30-11:35, Paper WeCT4.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1165" name="modify2274" onclick="modify(2274,1165)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2274'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Heterogeneous Sensor Fusion and Active Perception for Transparent Object Reconstruction with a PDM^2 Sensor and a Camera
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#315365" title="Click to go to the Author Index">
             Guo, Fengzhi
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#292959" title="Click to go to the Author Index">
             Xie, Shuangyu
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#219779" title="Click to go to the Author Index">
             Wang, Di
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#233448" title="Click to go to the Author Index">
             Fang, Cheng
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#233384" title="Click to go to the Author Index">
             Zou, Jun
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101712" title="Click to go to the Author Index">
             Song, Dezhen
            </a>
           </td>
           <td class="r">
            Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2274" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Transparent household objects present a challenge for domestic service robots, since neither regular cameras nor RGB-D cameras can provide accurate points for shape reconstruction. The new type of pretouch dual-modality distance and material sensor (PDM^2) can provide reliable and accurate depth readings, but it is a point sensor and scanning the object exclusively with the sensor is too inefficient. Hence, we present a sensor fusion approach by combining a regular camera with the PDM^2 sensor. The approach is based on a data fusion algorithm for shape reconstruction and an active perception algorithm for scan planning for the PDM^2 sensor. The data fusion algorithm is a distributed Gaussian process (GP)-based shape reconstruction method that allows for incremental local update to reduce computational time. The active perception algorithm is an optimization-based approach by increasing the information gain (IG) and prioritizing the boundary points under a preset travel distance constraint. We have implemented and tested the algorithms with six different transparent household items. The results show satisfactory shape reconstruction results in all test cases with an average increase in intersection over union (IoU) from 0.73 to 0.96.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect4_05">
             11:35-11:40, Paper WeCT4.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1166" name="modify3254" onclick="modify(3254,1166)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3254'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DA-Fusion: Deformable Attention-Based RGB-D Fusion Transformer for Unseen Object Instance Segmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#352260" title="Click to go to the Author Index">
             Park, Yesol
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339622" title="Click to go to the Author Index">
             Yoon, Hye Jung
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#352172" title="Click to go to the Author Index">
             Kim, Juno
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#133606" title="Click to go to the Author Index">
             Zhang, Byoung-Tak
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3254" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#logistics" title="Click to go to the Keyword Index">
               Logistics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In logistics automation, accurately segmenting unseen objects is essential for tasks such as bin picking, shelf picking, and warehouse sorting, which involve complex and cluttered environments. Traditional RGB-based methods tend to over-segment objects due to their reliance on texture, while depth-based methods often under-segment by focusing primarily on geometric features. To address these limitations, we propose DA-Fusion, a deformable attention-based RGB-D fusion Transformer designed for unseen object instance segmentation. DA-Fusion effectively combines the strengths of both RGB and depth data, enhancing segmentation accuracy in cluttered and multi-layered object environments. We also introduce the Object Clutter Bin Dataset (OCBD), a benchmark dataset specifically tailored for evaluating bin-picking scenarios in top-down views. Extensive evaluations demonstrate that DA-Fusion outperforms state-of-the-art methods across diverse environments, making it particularly suited for real-world logistics tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect4_06">
             11:40-11:45, Paper WeCT4.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1167" name="modify4663" onclick="modify(4663,1167)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4663'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              PAIR360: A Paired Dataset of High-Resolution 360˚ Panoramic Images and LiDAR Scans
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#408122" title="Click to go to the Author Index">
             Kim, Geunu
            </a>
           </td>
           <td class="r">
            Kyung Hee University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#403122" title="Click to go to the Author Index">
             Kim, Daeho
            </a>
           </td>
           <td class="r">
            Kyung Hee University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#408148" title="Click to go to the Author Index">
             Jang, Jaeyun
            </a>
           </td>
           <td class="r">
            Kyung Hee University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#140342" title="Click to go to the Author Index">
             Hwang, Hyoseok
            </a>
           </td>
           <td class="r">
            Kyung Hee University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4663" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_slam" title="Click to go to the Keyword Index">
               Data Sets for SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#omnidirectional_vision" title="Click to go to the Keyword Index">
               Omnidirectional Vision
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The 360˚ camera is a compact omnidirectional perception system for capturing panoramic images with the same field of view as LiDAR. This boosts its versatility for use in autonomous driving and robotics. However, most existing datasets of 360˚ panoramic images primarily focus on indoor or virtual environments, or they offer only low-resolution outdoor images and LiDAR configurations. In this letter, we present PAIR360, a multi-modal dataset encompassing high-resolution 360˚ camera images and 3D LiDAR scans, aimed at stimulating research in computer vision. To this end, we collected a comprehensive dataset at Kyung Hee University Global Campus, capturing 52 sequences from 7 different areas under diverse atmospheric conditions, including sunny, cloudy, and sunrise. The dataset features 8K resolution panoramic imagery, six	fisheye images, point clouds, GPS, and IMU data, all synchronized using LiDAR timestamps and calibrated across visual sensors. We also provide additional data, such as depth maps, segmentation, and 3D maps, to demonstrate the feasibility of our dataset and its application to various computer vision tasks. The dataset is available for download at: https://airlabkhu.github.io/PAIR-360-Dataset/
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect5">
             <b>
              WeCT5
             </b>
             Regular Session, 305
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1168" name="modifyWeCT5" onclick="modsession(17,1168)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect5" title="Click to go to the Program at a Glance">
             <b>
              Aerial Manipulation 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#164300" title="Click to go to the Author Index">
             Katzschmann, Robert Kevin
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#311422" title="Click to go to the Author Index">
             Panetsos, Fotis
            </a>
           </td>
           <td class="r">
            New York University Abu Dhabi
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect5_01">
             11:15-11:20, Paper WeCT5.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1169" name="modify2019" onclick="modify(2019,1169)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2019'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              NDOB-Based Control of a UAV with Delta-Arm Considering Manipulator Dynamics
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#391239" title="Click to go to the Author Index">
             Chen, Hongming
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397532" title="Click to go to the Author Index">
             Ye, Biyu
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#391930" title="Click to go to the Author Index">
             Liang, Xianqi
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423062" title="Click to go to the Author Index">
             Deng, Weiliang
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#204460" title="Click to go to the Author Index">
             Lyu, Ximin
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2019" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Aerial Manipulators (AMs) provide a versatile platform for various applications, including 3D printing, architecture, and aerial grasping missions. However, their operational speed is often sacrificed to uphold precision. Existing control strategies for AMs often regard the manipulator as a disturbance and employ robust control methods to mitigate its influence. This research focuses on elevating the precision of the end effector and enhancing the agility of aerial manipulator movements. We present a composite control scheme to address these challenges. Initially, a Nonlinear Disturbance Observer (NDOB) is utilized to compensate for internal coupling effects and external disturbances. Subsequently, manipulator dynamics are processed through a high pass filter to facilitate agile movements. By integrating the proposed control method into a fully autonomous delta-arm-based AM system, we substantiate the controller's efficacy through extensive real-world experiments. The outcomes illustrate that the end-effector can achieve accuracy at the millimeter level.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect5_02">
             11:20-11:25, Paper WeCT5.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1170" name="modify2654" onclick="modify(2654,1170)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2654'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Flapping-Wing Flying Robot with Integrated Dual-Arm Scissors-Type Flora Sampling System
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424288" title="Click to go to the Author Index">
             Gordillo Durán, Rodrigo
            </a>
           </td>
           <td class="r">
            Universidad De Sevilla
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#284639" title="Click to go to the Author Index">
             Tapia, Raul
            </a>
           </td>
           <td class="r">
            University of Seville
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#271768" title="Click to go to the Author Index">
             Rafee Nekoo, Saeed
            </a>
           </td>
           <td class="r">
            GRVC Robotics Lab, Universidad De Sevilla
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#122665" title="Click to go to the Author Index">
             Martinez-de Dios, J.R.
            </a>
           </td>
           <td class="r">
            University of Seville
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104455" title="Click to go to the Author Index">
             Ollero, Anibal
            </a>
           </td>
           <td class="r">
            AICIA. G41099946
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2654" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The flapping-wing robotic birds were inspired by nature to present an alternative way of thrust and lift generation instead of conventional high-speed rotary propellers in unmanned aerial platforms. The advances in flapping technology recently led to the prototyping of leg-claw mechanisms for perching and occasionally very lightweight arms for sampling or tiny object aerial manipulation. A dual-arm manipulator on top of a robotic bird might not be bio-inspired and safe in case of a collision with the environment or human-robot interaction. Here in this work, the previously designed dual-arm scissors-type manipulator has been improved in terms of workspace, mechanism, vision system, and blade placement to present a more natural way of sampling. The new dual-arm, with 100.2(g) weight, is redesigned inside a beak to have protection against possible collisions and also secure the cutting blades within a protected shield. During the flight, the dual-arm system is inside the cover and invisible; the lower beak is opened before manipulation and sets out the arm in a proper place for sampling. This new safety cover (beak) along with the new blade mechanism enhanced the cutting power and the safety of the operation. The experimental results show the successful cutting of a series of plant samples.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect5_03">
             11:25-11:30, Paper WeCT5.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1171" name="modify2795" onclick="modify(2795,1171)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2795'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Reliable Aerial Manipulation: Combining Visual Tracking with Range Sensing for Robust Grasping
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#325364" title="Click to go to the Author Index">
             Blöchlinger, Marc
            </a>
           </td>
           <td class="r">
            ETHZ
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#240027" title="Click to go to the Author Index">
             Toshimitsu, Yasunori
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#164300" title="Click to go to the Author Index">
             Katzschmann, Robert Kevin
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2795" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Reliable object localization is a critical challenge in drone-based aerial manipulation, particularly when objects are outside the camera's field of view. This paper presents a new approach to enhance drone reliability in aerial grasping tasks by integrating a 1D time-of-flight range sensor with a vision-based localization system. The range sensor, positioned beneath the drone, generates a detailed point cloud of the ground beneath the drone, allowing for precise object localization even when the drone hovers directly above the target. By combining visual tracking with real-time distance measurements, our system achieves a 96% grasp success rate across 128 trials with diverse objects, representing a significant improvement over previous approaches. This method enables zero-shot grasping without prior knowledge of the objects, increasing versatility and robustness in complex, unstructured environments. The open-source software and hardware design of the platform provides a foundation for further research and development in the field of autonomous aerial manipulation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect5_04">
             11:30-11:35, Paper WeCT5.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1172" name="modify3823" onclick="modify(3823,1172)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3823'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safety-Critical Control for Aerial Physical Interaction in Uncertain Environment
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#298635" title="Click to go to the Author Index">
             Byun, Jeonghyun
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419840" title="Click to go to the Author Index">
             Kim, Yeonjoon
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256238" title="Click to go to the Author Index">
             Lee, Dongjae
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103663" title="Click to go to the Author Index">
             Kim, H. Jin
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3823" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Aerial manipulation for safe physical interaction with their environments is gaining significant momentum in robotics research. In this paper, we present a disturbance-observer-based safety-critical control for a fully actuated aerial manipulator interacting with both static and dynamic structures. Our approach centers on a safety filter that dynamically adjusts the desired trajectory of the vehicle's pose, accounting for the aerial manipulator's dynamics, the disturbance observer's structure, and motor thrust limits. We provide rigorous proof that the proposed safety filter ensures the forward invariance of the safety set—representing motor thrust limits—even in the presence of disturbance estimation errors. To demonstrate the superiority of our method over existing control strategies for aerial physical interaction, we perform comparative experiments involving complex tasks, such as pushing against a static structure and pulling a plug firmly attached to an electric socket. Furthermore, to highlight its repeatability in scenarios with sudden dynamic changes, we perform repeated tests of pushing a movable cart and extracting a plug from a socket. These experiments confirm that our method not only outperforms existing methods but also excels in handling tasks with rapid dynamic variations.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect5_05">
             11:35-11:40, Paper WeCT5.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1173" name="modify4060" onclick="modify(4060,1173)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4060'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SPIBOT: A Drone-Tethered Mobile Gripper for Robust Aerial Object Retrieval in Dynamic Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#381132" title="Click to go to the Author Index">
             Kang, Gyuree
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology (KAIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426195" title="Click to go to the Author Index">
             Guenes, Ozan
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426158" title="Click to go to the Author Index">
             Lee, Seungwook
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421026" title="Click to go to the Author Index">
             Azhari, Maulana Bisyir
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104593" title="Click to go to the Author Index">
             Shim, David Hyunchul
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4060" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In real-world field operations, aerial grasping systems face significant challenges in dynamic environments due to strong winds, shifting surfaces, and the need to handle heavy loads. Particularly when dealing with heavy objects, the powerful propellers of the drone can inadvertently blow the target object away as it approaches, making the task even more difficult. To address these challenges, we introduce SPIBOT, a novel drone-tethered mobile gripper system designed for robust and stable autonomous target retrieval. SPIBOT operates via a tether, much like a spider, allowing the drone to maintain a safe distance from the target. To ensure both stable mobility and secure grasping capabilities, SPIBOT is equipped with six legs and sensors to estimate the robot's and mission's states. It is designed with a reduced volume and weight compared to other hexapod robots, allowing it to be easily stowed under the drone and reeled in as needed. Designed for the 2024 MBZIRC Maritime Grand Challenge, SPIBOT is built to retrieve a 1kg target object in the highly dynamic conditions of the moving deck of a ship. This system integrates a real-time action selection algorithm that dynamically adjusts the robot's actions based on proximity to the mission goal and environmental conditions, enabling rapid and robust mission execution. Experimental results across various terrains, including a pontoon on a lake, a grass field, and rubber mats on coastal sand, demonstrate SPIBOT's ability to efficiently and reliably retrieve targets. SPIBOT swiftly converges on the target and completes its mission, even when dealing with irregular initial states and noisy information introduced by the drone.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect5_06">
             11:40-11:45, Paper WeCT5.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1174" name="modify4970" onclick="modify(4970,1174)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4970'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GP-Based NMPC for Aerial Transportation of Suspended Loads
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#311422" title="Click to go to the Author Index">
             Panetsos, Fotis
            </a>
           </td>
           <td class="r">
            New York University Abu Dhabi
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103160" title="Click to go to the Author Index">
             Karras, George
            </a>
           </td>
           <td class="r">
            University of Thessaly
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103188" title="Click to go to the Author Index">
             Kyriakopoulos, Kostas
            </a>
           </td>
           <td class="r">
            New York University - Abu Dhabi
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4970" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we leverage Gaussian Processes (GPs) and present a learning-based control scheme for the transportation of cable-suspended loads with multirotor Unmanned Aerial Vehicles (UAVs). Our ultimate goal is to approximate the model discrepancies that exist between the actual and nominal system dynamics. Towards this direction, weighted and sparse Gaussian Process (GP) regression is exploited so as to approximate online the model errors and guarantee real-time performance while also ensuring adaptability to the conditions prevailing in the outdoor environment where the UAV is deployed. The learned model errors are fed into a nonlinear Model Predictive Controller (NMPC), formulated for the corrected system dynamics, which achieves the transportation of the UAV towards reference positions with simultaneous minimization of the cable angular motion, regardless of the outdoor conditions and the existence of external disturbances, primarily stemming from the unknown wind. The proposed scheme is validated through simulations and real-world experiments with an octorotor, demonstrating an 80% reduction in the steady-state position error under 4 Beaufort wind conditions compared to the nominal NMPC.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect6">
             <b>
              WeCT6
             </b>
             Regular Session, 307
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1175" name="modifyWeCT6" onclick="modsession(623,1175)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect6" title="Click to go to the Program at a Glance">
             <b>
              Vision-Based Navigation 3
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#231211" title="Click to go to the Author Index">
             Salek Shahrezaie, Roya
            </a>
           </td>
           <td class="r">
            University of Nevada, Reno
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#294132" title="Click to go to the Author Index">
             Chang, Yan
            </a>
           </td>
           <td class="r">
            Nvidia
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect6_01">
             11:15-11:20, Paper WeCT6.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1176" name="modify534" onclick="modify(534,1176)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('534'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Knowledge-Driven Visual Target Navigation: Dual Graph Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417077" title="Click to go to the Author Index">
             Li, Shiyao
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417113" title="Click to go to the Author Index">
             Meng, Ziyang
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417146" title="Click to go to the Author Index">
             Pei, JianSong
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#295056" title="Click to go to the Author Index">
             Chen, Jiahao
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417111" title="Click to go to the Author Index">
             Dong, BingCheng
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417290" title="Click to go to the Author Index">
             Li, Guangsheng
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#207299" title="Click to go to the Author Index">
             Liu, Shenglan
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203065" title="Click to go to the Author Index">
             Wang, Feilong
            </a>
           </td>
           <td class="r">
            Dalian University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab534" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robotics_in_under_resourced_settings" title="Click to go to the Keyword Index">
               Robotics in Under-Resourced Settings
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In unknown environments, navigating a robot by a given image to a specific location or instance is critical and challenging. The existing end-to-end approaches require simultaneous implicit learning of multiple subtasks, and modular approaches depend on metric information. Both approaches face high computational demands, often leading to difficulties in real-time updates and limited generalization, making them challenging to implement on resource-constrained devices. To address these challenges, we propose Dual Graph Navigation (DGN), a knowledge-driven, lightweight image instance navigation framework. DGN builds an External Knowledge Graph (EKG) from small-scale datasets to capture prior object correlations, efficiently guiding target exploration. During exploration, DGN builds an Internal Knowledge Graph (IKG) using an instance-aware module, which records explored objects based on reachability relationships rather than precise metric information. The IKG dynamically updates the EKG, enhancing the robot's adaptability to the current environment. Together, they realize topological perception and reduce computational overhead. Furthermore, unlike approaches characterized by over-dependence between components, DGN employs a plug-and-play modular design that allows independent training and flexible replacement of functional modules, effectively enhancing generalization performance while reducing training and deployment costs. Experiments illustrate that DGN generalizes well in different simulation environments (AI2-THOR, Habitat), achieving state-of-the-art performance on the ProcTHOR-10K dataset. It is compatible with three distinct real-world robot platforms, including edge computing devices without CUDA support. It exhibits a decision-making speed of 3.8 to 5.5 times over baseline methods. Further details can be found on the project page:https://dogplanningloyo.github.io/DGN/
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect6_02">
             11:20-11:25, Paper WeCT6.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1177" name="modify1255" onclick="modify(1255,1177)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1255'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning to Predict the Future from Monocular Vision for Efficient Human-Aware Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#317965" title="Click to go to the Author Index">
             Huang, Yushuang
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#160132" title="Click to go to the Author Index">
             Jiang, Hao
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417190" title="Click to go to the Author Index">
             Liu, Zihan
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology of the Chinese Academy of Scie
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#268937" title="Click to go to the Author Index">
             Ouyang, Wanli
            </a>
           </td>
           <td class="r">
            The University of Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#149649" title="Click to go to the Author Index">
             Wang, Zhaoqi
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology, the Chinese Academy of Scienc
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1255" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Human-aware navigation (HAN) aims to build autonomous agents that robustly and naturally navigate in human-centered environments. Due to the complex and dynamic nature of this task, existing approaches typically rely on sophisticated pipelines that separately process perception and decision-making to solve it. In this work, we propose an Obstruction Distance Vector based End-to-End Model (ODVEEM), using monocular vision for navigation around humans. The Obstruction Distance Vector (ODV) is an intermediate representation in our model, leveraged to describe the Obstruction Distance to the first future collision in all possible directions in the horizontal field of view. As ODV cannot be calculated directly in the real world, we design a neural network for ODV estimation, formulating it as a classification problem with auxiliary proxy tasks, which play a key role in effectively predicting the implicit future motion of nearby humans. Taking advantage of ODV, ODVEEM supervised by human behavioral heuristics is employed to guide the agent to reach a goal efficiently and avoid potential collisions. Several challenging experiments show our method's substantial improvement over a number of baseline methods, attaining solid performance with zero-shot transfer to unseen simulated and real-world environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect6_03">
             11:25-11:30, Paper WeCT6.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1178" name="modify1343" onclick="modify(1343,1178)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1343'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DP-Habitat: Bridging the Gap between Simulation and Reality for Visual Navigation in Dynamic Pedestrian Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415059" title="Click to go to the Author Index">
             Qin, Liang
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420324" title="Click to go to the Author Index">
             Wang, Min
            </a>
           </td>
           <td class="r">
            Hefei Comprehensive National Science Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415768" title="Click to go to the Author Index">
             Wang, Haodong
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421177" title="Click to go to the Author Index">
             Zhou, Wengang
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#333551" title="Click to go to the Author Index">
             Li, Houqiang
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1343" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visual navigation in dynamic environments poses a considerable challenge, particularly in scenarios with diverse pedestrian behaviors. Traditional simulators primarily focus on static scenes, while existing dynamic pedestrian simulators often suffer limitations such as monotonous pedestrian models, lack of interaction with the environment, and constrained scenarios. These deficiencies lead to notable discrepancies from real-world dynamic pedestrian environments. To bridge this gap, we introduce DP-Habitat, a dynamic pedestrian simulator developed on the Habitat platform. DP-Habitat efficiently simulates a wide range of complex and realistic human behaviors, with flexible interactions between pedestrian models and environments. It also supports rapid deployment of pedestrian models across various scenes, thereby more accurately replicating the complexities of real-world dynamic pedestrian settings. Additionally, we present Adaptive Object Navigation with Dynamic Mapping (AON-DM), a novel baseline method specifically designed for dynamic pedestrian settings. AON-DM integrates real-time pedestrian tracking and predictive modeling with a hybrid path planning strategy, markedly improving navigation efficiency and success rates. Our experimental results reveal that dynamic pedestrians significantly affect visual navigation performance within DP-Habitat, with AON-DM achieving superior effectiveness compared to existing methods under these challenging conditions. Furthermore, our approach maintains high performance in real-world scenarios, highlighting its practical applicability and robustness. The code and data are available at url{https://github.com/qinliangql/DP-Habitat.git}.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect6_04">
             11:30-11:35, Paper WeCT6.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1179" name="modify1837" onclick="modify(1837,1179)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1837'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              X-MOBILITY: End-To-End Generalizable Navigation Via World Modeling
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#165545" title="Click to go to the Author Index">
             Liu, Wei
            </a>
           </td>
           <td class="r">
            Nvidia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#200843" title="Click to go to the Author Index">
             Zhao, Huihua
            </a>
           </td>
           <td class="r">
            Georgia Tech
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309158" title="Click to go to the Author Index">
             Li, Chenran
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#127043" title="Click to go to the Author Index">
             Biswas, Joydeep
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#171949" title="Click to go to the Author Index">
             Okal, Billy
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420859" title="Click to go to the Author Index">
             Goyal, Pulkit
            </a>
           </td>
           <td class="r">
            Nvidia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#294132" title="Click to go to the Author Index">
             Chang, Yan
            </a>
           </td>
           <td class="r">
            Nvidia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#137613" title="Click to go to the Author Index">
             Pouya, Soha
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1837" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#probabilistic_inference" title="Click to go to the Keyword Index">
               Probabilistic Inference
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             General-purpose navigation in challenging environments remains a significant problem in robotics, with current state-of-the-art approaches facing myriad limitations. Classical approaches struggle with cluttered settings and require extensive tuning, while learning-based methods face difficulties generalizing to out-of-distribution environments. This paper introduces xmobility{}, an end-to-end generalizable navigation model that overcomes existing challenges by leveraging three key ideas. First, xmobility{} employs an auto-regressive world modeling architecture with a latent state space to capture world dynamics. Second, a diverse set of multi-head decoders enables the model to learn a rich state representation that correlates strongly with effective navigation skills. Third, by decoupling world modeling from action policy, our architecture can train effectively on a variety of data sources, both with and without expert policies—off-policy data allows the model to learn world dynamics, while on-policy data with supervisory control enables optimal action policy learning. Through extensive experiments, we demonstrate that xmobility{} not only generalizes effectively but also surpasses current state-of-the-art navigation approaches. Additionally, xmobility{} also achieves zero-shot Sim2Real transferability and shows strong potential for cross-embodiment generalization.
             <p>
              Project page: https://nvlabs.github.io/X-MOBILITY
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect6_05">
             11:35-11:40, Paper WeCT6.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1180" name="modify2155" onclick="modify(2155,1180)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2155'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Map-SemNav: Advancing Zero-Shot Continuous Vision-And-Language Navigation through Visual Semantics and Map Integration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354031" title="Click to go to the Author Index">
             Wu, Shuai
            </a>
           </td>
           <td class="r">
            Tianjin University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354136" title="Click to go to the Author Index">
             Liu, Ruonan
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420870" title="Click to go to the Author Index">
             Xie, Zongxia
            </a>
           </td>
           <td class="r">
            Tianjin University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421125" title="Click to go to the Author Index">
             Pang, Zhibo
            </a>
           </td>
           <td class="r">
            KTH Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2155" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#agent_based_systems" title="Click to go to the Keyword Index">
               Agent-Based Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper explores zero-shot Vision-and-Language Navigation (VLN), enabling agents to generalize navigation to unseen data classes. Most current approaches rely on large models, but these are not specifically tailored for VLN, lacking direct learning from navigation environments and slowing down agents due to their overwhelming size. To tackle this, we propose Map-Semantic Zero-shot Navigation (Map-SemNav), which does not rely on large models for navigation planning. Map-SemNav utilizes three key cues: direction, object, and scene, to acquire relational knowledge instead of memorizing specific classes, which enables generalization to unseen data. Direction is guided by a top-down semantic map, while object and scene information is decoupled from environment knowledge. Extensive experiments demonstrate that Map-SemNav outperforms state-of-the-art large model-based methods in zero-shot VLN tasks within continuous environments, while also offering higher efficiency due to its simplified architecture.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect6_06">
             11:40-11:45, Paper WeCT6.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1181" name="modify4838" onclick="modify(4838,1181)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4838'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safer Gap: Safe Navigation of Planar Nonholonomic Robots with a Gap-Based Local Planner
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#219027" title="Click to go to the Author Index">
             Feng, Shiyu
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#355147" title="Click to go to the Author Index">
             Abuaish, Ahmad
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106981" title="Click to go to the Author Index">
             Vela, Patricio
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4838" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reactive_and_sensor_based_planning" title="Click to go to the Keyword Index">
               Reactive and Sensor-Based Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper extends the gap-based navigation technique Potential Gap with safety guarantees at the local planning level for a kinematic planar nonholonomic robot model, leading to Safer Gap. It relies on a subset of navigable free space from the robot to a gap, denoted the keyhole region. The region is defined by the union of the largest collision-free disc centered on the robot and a collision-free trapezoidal region directed through the gap. Safer Gap first generates Bezier-based collision-free paths within the keyhole regions. The keyhole region of the top scoring path is encoded by a shallow neural network-based zeroing barrier function (ZBF) synthesized in real-time. Nonlinear Model Predictive Control (NMPC) with Keyhole ZBF constraints and output tracking of the Bezier path, synthesizes a safe kinematically feasible trajectory. The Potential Gap projection operator serves as a last action to enforce safety if the NMPC optimization fails to converge to a solution within the prescribed time. Simulation and experimental validation of Safer Gap confirm its collision-free navigation properties.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect7">
             <b>
              WeCT7
             </b>
             Regular Session, 309
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1182" name="modifyWeCT7" onclick="modsession(295,1182)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect7" title="Click to go to the Program at a Glance">
             <b>
              Marine Robotics 4
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#105621" title="Click to go to the Author Index">
             Guo, Yi
            </a>
           </td>
           <td class="r">
            Stevens Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#296252" title="Click to go to the Author Index">
             Ohrem, Sveinung Johan
            </a>
           </td>
           <td class="r">
            SINTEF Ocean AS
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect7_01">
             11:15-11:20, Paper WeCT7.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1183" name="modify220" onclick="modify(220,1183)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('220'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Bathymetric Surveying with Imaging Sonar Using Neural Volume Rendering
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338009" title="Click to go to the Author Index">
             Xie, Yiping
            </a>
           </td>
           <td class="r">
            Linköping University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#123330" title="Click to go to the Author Index">
             Troni, Giancarlo
            </a>
           </td>
           <td class="r">
            Monterey Bay Aquarium Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#172217" title="Click to go to the Author Index">
             Bore, Nils
            </a>
           </td>
           <td class="r">
            KTH Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106906" title="Click to go to the Author Index">
             Folkesson, John
            </a>
           </td>
           <td class="r">
            KTH
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab220" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This research addresses the challenge of estimating bathymetry from imaging sonars where the state-of-the-art works have primarily relied on either supervised learning with ground-truth labels or surface rendering based on the Lambertian assumption. In this letter, we propose a novel, self-supervised framework based on volume rendering for reconstructing bathymetry using forward-looking sonar (FLS) data collected during standard surveys. We represent the seafloor as a neural heightmap encapsulated with a parametric multi-resolution hash encoding scheme and model the sonar measurements with a differentiable renderer using sonar volumetric rendering employed with hierarchical sampling techniques. Additionally, we model the horizontal and vertical beam patterns and estimate them jointly with the bathymetry. We evaluate the proposed method quantitatively on simulation and field data collected by remotely operated vehicles (ROVs) during low-altitude surveys. Results show that the proposed method outperforms the current state-of-the-art approaches that use imaging sonars for seabed mapping. We also demonstrate that the proposed approach can potentially be used to increase the resolution of a low-resolution prior map with FLS data from low-altitude surveys.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect7_02">
             11:20-11:25, Paper WeCT7.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1184" name="modify736" onclick="modify(736,1184)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('736'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Diver to Robot Communication Underwater
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#205665" title="Click to go to the Author Index">
             Codd-Downey, Robert
            </a>
           </td>
           <td class="r">
            York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104422" title="Click to go to the Author Index">
             Jenkin, Michael
            </a>
           </td>
           <td class="r">
            York University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab736" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#gesture__posture_and_facial_expressions" title="Click to go to the Keyword Index">
               Gesture, Posture and Facial Expressions
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Gesture-based communication is a standard underwater communication strategy that is taught to divers as part of their regular diver training and it would seem a natural mechanism to leverage for diver to robot communication underwater. Enabling an unmanned underwater vehicle (UUV) to understand such sequences would involve having the robot learn the large set of gestures that divers use and the way they are combined. As perfect transcription of gestures is unlikely, the communication process also requires an error-correcting framework to ensure that communication is clear and correct. Here we describe an interactive process that provides this infrastructure. A weakly supervised transfer learning approach is used to recognize standard SCUBA gestures in individual video frames and within a Sim2Real process to train a LSTM to recognize gesture sequences. This process is placed within a per-gesture and per-sequence interaction process to assist and confirm the recognition of individual gestures and to confirm entire gesture sequences. Individual aspects of this process and complete end-to-end operation are demonstrated using an unmanned underwater vehicle.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect7_03">
             11:25-11:30, Paper WeCT7.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1185" name="modify989" onclick="modify(989,1185)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('989'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SIMP: Energy and Time-Efficient Real-Time 3D Motion Planning for Bio-Inspired AUVs
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419985" title="Click to go to the Author Index">
             Bjørlo, August Sletnes
            </a>
           </td>
           <td class="r">
            NTNU
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#192519" title="Click to go to the Author Index">
             Xanthidis, Marios
            </a>
           </td>
           <td class="r">
            SINTEF Ocean
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379062" title="Click to go to the Author Index">
             Føre, Martin
            </a>
           </td>
           <td class="r">
            NTNU
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#138305" title="Click to go to the Author Index">
             Kelasidi, Eleni
            </a>
           </td>
           <td class="r">
            NTNU
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab989" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Underwater navigation is an area of increasing research interest due to its fundamental complexity and industrial applications. Though, due to convenience and current theoretical understanding, the vast majority of underwater platforms utilize thrusters, while other forms of propulsion, such as undulation locomotion, have been given limited exposure. This paper provides the first real-time motion planning framework that produces energy and time efficient paths with empirical local optimality for articulated swimming robots in 3D, called SIMP. SIMP utilizes learned associations between parameterized dynamically feasible undulatory gaits with their expected energy cost, velocity, and swept-out volume of the robot during execution, to formulate a simplified optimization problem that decides the path to be followed with the corresponding consecutive gaits, and navigates the robot safely in complex 3D environments. The proposed pipeline is tested in numerical experiments with realistic dynamics for a 10-link underwater snake robot (USR) with anguilliform gaits, in simulated cluttered environments of significant challenge, displaying real-time replanning performance of more than 1 Hz.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect7_04">
             11:30-11:35, Paper WeCT7.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1186" name="modify1251" onclick="modify(1251,1186)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1251'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              End-To-End Underwater Multi-View Stereo for Dense Scene Reconstruction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351220" title="Click to go to the Author Index">
             Yang, Guidong
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#319735" title="Click to go to the Author Index">
             Wen, Junjie
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351216" title="Click to go to the Author Index">
             Zhao, Benyun
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#391025" title="Click to go to the Author Index">
             Li, Qingxiang
            </a>
           </td>
           <td class="r">
            The Chineses University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#375342" title="Click to go to the Author Index">
             Huang, Yijun
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#334961" title="Click to go to the Author Index">
             Lei, Lei
            </a>
           </td>
           <td class="r">
            City University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351227" title="Click to go to the Author Index">
             Chen, Xi
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420348" title="Click to go to the Author Index">
             Lam, Alan Hiu-Fung
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong,
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#171587" title="Click to go to the Author Index">
             Chen, Ben M.
            </a>
           </td>
           <td class="r">
            Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1251" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent advancements in learning-based multi-view stereo (MVS) have demonstrated significant improvements over traditional counterpart, primarily due to the extensive availability of multi-view training images with ground-truth metric depths in the terrestrial in-air domain. However, underwater multi-view stereo (UwMVS) faces substantial challenges arising from the domain gap between in-air and underwater environments, leading to degraded performance when applying in-air MVS models to underwater scenarios. Furthermore, the progress of learning-based UwMVS methods has been hindered by the scarcity of underwater multi-view images with ground-truth depth maps and point clouds. In this paper, we address these challenges by introducing a physically-guided approach for synthesizing underwater multi-view images and present the first large-scale UwMVS dataset for end-to-end training and evaluation of learning-based UwMVS methods. Furthermore, we propose a novel UwMVS network that enhances geometric cue encoding to achieve more accurate and complete point cloud reconstruction. Extensive experiments on our dataset and real-world underwater scenes demonstrate that our dataset enables the trained models for underwater dense reconstruction and that our method achieves state-of-the-art performance in underwater reconstruction. Dataset, code and appendix are available at: https://cuhk-usr-group.github.io/UwMVS/
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect7_05">
             11:35-11:40, Paper WeCT7.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1187" name="modify2560" onclick="modify(2560,1187)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2560'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              UR-MVO: Robust Monocular Visual Odometry for Underwater Scenarios
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398311" title="Click to go to the Author Index">
             Barhoum, Zein Alabedeen
            </a>
           </td>
           <td class="r">
            ITMO University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398318" title="Click to go to the Author Index">
             Maalla, Yazan
            </a>
           </td>
           <td class="r">
            ITMO University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398449" title="Click to go to the Author Index">
             Daher, Sulieman
            </a>
           </td>
           <td class="r">
            ITMO University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398317" title="Click to go to the Author Index">
             Topolnitskii, Alexander
            </a>
           </td>
           <td class="r">
            ITMO University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#313150" title="Click to go to the Author Index">
             Mahmoud, Jaafar
            </a>
           </td>
           <td class="r">
            ITMO University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#166925" title="Click to go to the Author Index">
             Kolyubin, Sergey
            </a>
           </td>
           <td class="r">
            ITMO University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2560" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visual odometry (VO) in underwater environments presents significant challenges due to poor visibility and dynamic scene changes, which render conventional (in-air) VO solutions unsuitable for underwater applications. We propose an underwater robust monocular visual odometry (UR-MVO) pipeline tailored for underwater scenarios with feature extraction and matching based on SuperPoint and SuperGlue models, respectively. We enhance the robustness of the feature extractor through field-specific fine-tuning of the SuperPoint model using few-shot unsupervised learning. This tuning was done on real images of underwater scenes in order to enhance its performance in the harsh underwater image conditions. Moreover, we integrate semantic segmentation trained on underwater images into our pipeline to eliminate unreliable features belonging to dynamic objects and background. We evaluated the proposed solution on the Aqualoc dataset, demonstrating higher localization accuracy compared to other SOTA direct and feature-based monocular VO methods like DSO and SVO and also obtained very competitive results compared to more resource-intensive monocular VSLAM approaches with loop closure process like LDSO, UVS, and ORB-SLAM. The results show a high potential for our approach for further applications in underwater exploration and mapping using affordable sensory setups. We publish the code for the benefit of the community https://github.com/be2rlab/UR-MVO
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect7_06">
             11:40-11:45, Paper WeCT7.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1188" name="modify3334" onclick="modify(3334,1188)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3334'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SeaSplat: Representing Underwater Scenes with 3D Gaussian Splatting and a Physically Grounded Image Formation Model
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#277470" title="Click to go to the Author Index">
             Yang, Daniel
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107631" title="Click to go to the Author Index">
             Leonard, John
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#118013" title="Click to go to the Author Index">
             Girdhar, Yogesh
            </a>
           </td>
           <td class="r">
            Woods Hole Oceanographic Institution
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3334" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce SeaSplat, a method to enable real-time rendering of underwater scenes leveraging recent advances in 3D radiance fields. Underwater scenes are challenging visual environments, as rendering through a medium such as water introduces both range and color dependent effects on image capture. We constrain 3D Gaussian Splatting (3DGS), a recent advance in radiance fields enabling rapid training and real-time rendering of full 3D scenes, with a physically grounded underwater image formation model. Applying SeaSplat to the real-world scenes from SeaThru-NeRF dataset, a scene collected by an underwater vehicle in the US Virgin Islands, and simulation-degraded real-world scenes, not only do we see increased quantitative performance on rendering novel viewpoints from the scene with the medium present, but are also able to recover the underlying true color of the scene and restore renders to be without the presence of the intervening medium. We show that the underwater image formation helps learn scene structure, with better depth maps, as well as show that our improvements maintain the significant computational improvements afforded by leveraging a 3D Gaussian representation
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect8">
             <b>
              WeCT8
             </b>
             Regular Session, 311
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1189" name="modifyWeCT8" onclick="modsession(435,1189)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect8" title="Click to go to the Program at a Glance">
             <b>
              Planinng and Control for Legged Robots 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#103117" title="Click to go to the Author Index">
             Yoshida, Eiichi
            </a>
           </td>
           <td class="r">
            Faculty of Advanced Engineering, Tokyo University of Science
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#123193" title="Click to go to the Author Index">
             Lin, Pei-Chun
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect8_01">
             11:15-11:20, Paper WeCT8.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1190" name="modify65" onclick="modify(65,1190)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('65'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ProNav: Proprioceptive Traversability Estimation for Legged Robot Navigation in Outdoor Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#367201" title="Click to go to the Author Index">
             Elnoor, Mohamed
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#243363" title="Click to go to the Author Index">
             Sathyamoorthy, Adarsh Jagan
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#308861" title="Click to go to the Author Index">
             Kulathun Mudiyanselage, Kasun Weerakoon
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106235" title="Click to go to the Author Index">
             Manocha, Dinesh
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab65" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#perception_action_coupling" title="Click to go to the Keyword Index">
               Perception-Action Coupling
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose a novel method, ProNav, which uses proprioceptive signals for traversability estimation in challenging outdoor terrains for autonomous legged robot navigation. Our approach uses sensor data from a legged robot’s joint encoders, force, and current sensors to measure the joint positions, forces, and current consumption respectively to accurately assess a terrain’s stability, resistance to the robot’s motion, risk of entrapment, and crash. Based on these factors, we compute the appropriate robot gait to maximize stability, which leads to reduced energy consumption. Our approach can also be used to predict imminent crashes in challenging terrains and execute behaviors to preemptively avoid them. We integrate ProNav with an exteroceptive-based method to navigate realworld environments with dense vegetation, high granularity, negative obstacles, etc. Our method shows an improvement up to 40% in terms of success rate and up to 15.1% reduction in terms of energy consumption compared to exteroceptive-based methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect8_02">
             11:20-11:25, Paper WeCT8.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1191" name="modify549" onclick="modify(549,1191)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('549'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MOVE: Multi-Skill Omnidirectional Legged Locomotion with Limited View in 3D Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405183" title="Click to go to the Author Index">
             Li, Songbo
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#394003" title="Click to go to the Author Index">
             Luo, Shixin
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#113218" title="Click to go to the Author Index">
             Wu, Jun
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#232612" title="Click to go to the Author Index">
             Zhu, Qiuguo
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab549" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Legged robots possess inherent advantages in traversing complex 3D terrains. However, previous work on low-cost quadruped robots with egocentric vision systems has been limited by a narrow front-facing view and exteroceptive noise, restricting omnidirectional mobility in such environments. While building a voxel map through a hierarchical structure can refine exteroception processing, it introduces significant computational overhead, noise, and delays. In this paper, we present MOVE, a one-stage end-to-end learning framework capable of multi-skill omnidirectional legged locomotion with limited view in 3D environments, just like what a real animal can do. When movement aligns with the robot's line of sight, exteroceptive perception enhances locomotion, enabling extreme climbing and leaping. When vision is obstructed or the direction of movement lies outside the robot's field of view, the robot relies on proprioception for tasks like crawling and climbing stairs. We integrate all these skills into a single neural network by introducing a pseudo-siamese network structure combining supervised and contrastive learning which helps the robot infer its surroundings beyond its field of view. Experiments in both simulations and real-world scenarios demonstrate the robustness of our method, broadening the operational environments for robotics with egocentric vision.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect8_03">
             11:25-11:30, Paper WeCT8.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1192" name="modify926" onclick="modify(926,1192)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('926'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Generating Diverse Challenging Terrains for Legged Robots Using Quality-Diversity Algorithm
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#323670" title="Click to go to the Author Index">
             Esquerre-Pourtère, Arthur
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#250338" title="Click to go to the Author Index">
             Kim, Minsoo
            </a>
           </td>
           <td class="r">
            Graduate School of Convergence Science and Technology, Seoul Nat
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101200" title="Click to go to the Author Index">
             Park, Jaeheung
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab926" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#evolutionary_robotics" title="Click to go to the Keyword Index">
               Evolutionary Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#failure_detection_and_recovery" title="Click to go to the Keyword Index">
               Failure Detection and Recovery
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             While legged robots have achieved significant advancements in recent years, ensuring the robustness of their controllers on unstructured terrains remains challenging. It requires generating diverse and challenging unstructured terrains to test the robot and discover its vulnerabilities. This topic remains underexplored in the literature. This paper presents a Quality-Diversity framework to generate diverse and challenging terrains that uncover weaknesses in legged robot controllers. Our method, applied to both simulated bipedal and quadruped robots, produces an archive of terrains optimized to challenge the controller in different ways. Quantitative and qualitative analyses show that the generated archive effectively contains terrains that the robots struggled to traverse, presenting different failure modes. Interesting results were observed, including failure cases that were not necessarily expected. Experiments show that the generated terrains can also be used to improve RL-based controllers.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect8_04">
             11:30-11:35, Paper WeCT8.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1193" name="modify1163" onclick="modify(1163,1193)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1163'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Added Mass and Accuracy of the FF-SLIP Model for Legged Swimming
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#205583" title="Click to go to the Author Index">
             Austin, Max
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422851" title="Click to go to the Author Index">
             Ma, Linna
            </a>
           </td>
           <td class="r">
            Florida State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354816" title="Click to go to the Author Index">
             Vasquez, Derek A.
            </a>
           </td>
           <td class="r">
            Florida State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#325183" title="Click to go to the Author Index">
             Van Stratum, Brian
            </a>
           </td>
           <td class="r">
            Florida State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104389" title="Click to go to the Author Index">
             Clark, Jonathan
            </a>
           </td>
           <td class="r">
            Florida State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1163" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#biomimetics" title="Click to go to the Keyword Index">
               Biomimetics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents the addition of two models for added mass to the Fluid-Field Spring-Loaded Inverted Pendulum (FF-SLIP) Model for legged swimming. The relative ability of these models to capture the increased fluid forces due to virtual mass displacement is evaluated using a two-legged swimming robot, Tadpole. We show that a simple addition to our reduced-order model can predict fluid-leg interaction forces while remaining computationally efficient.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect8_05">
             11:35-11:40, Paper WeCT8.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1194" name="modify1463" onclick="modify(1463,1194)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1463'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Virtual Gravity Controller for Efficient Underactuated Biped Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411729" title="Click to go to the Author Index">
             Maligianni, Despoina
            </a>
           </td>
           <td class="r">
            National Technical University of Athens
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411730" title="Click to go to the Author Index">
             Valouxis, Fotios
            </a>
           </td>
           <td class="r">
            National Technical University of Athens
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411731" title="Click to go to the Author Index">
             Kantounias, Antonios
            </a>
           </td>
           <td class="r">
            National Technical University of Athens
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#218842" title="Click to go to the Author Index">
             Smyrli, Aikaterini
            </a>
           </td>
           <td class="r">
            National Technical University of Athens, Athena Research Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101814" title="Click to go to the Author Index">
             Papadopoulos, Evangelos
            </a>
           </td>
           <td class="r">
            National Technical University of Athens
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1463" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#passive_walking" title="Click to go to the Keyword Index">
               Passive Walking
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#underactuated_robots" title="Click to go to the Keyword Index">
               Underactuated Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a virtual gravity controller for underactuated biped robots. A bio-inspired model of passive bipedal walking is used as the basis for the controller's design. An analytical expression of the controller is obtained, allowing on-line implementations of the developed control scheme. Following a design modification tailored to the controller, the robot is able to reproduce its passive gait even on level-ground. The results are verified via independent high-fidelity physics simulations of the real robot's digital twin. The active robot demonstrates significant dynamic convergence to the passive model's dynamics, with only minor motorization efforts. The developed control scheme showcases robustness and energetic efficiency, and leads the way to a design-oriented approach in active biped locomotion.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect8_06">
             11:40-11:45, Paper WeCT8.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1195" name="modify2745" onclick="modify(2745,1195)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2745'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Stair Climbing of a Transformable Robot Using Varying Leg-Wheel Contact Points
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415763" title="Click to go to the Author Index">
             Lai, Yen-Li
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#144825" title="Click to go to the Author Index">
             Yu, Wei-Shun
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#123193" title="Click to go to the Author Index">
             Lin, Pei-Chun
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2745" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Staircases are a challenging terrain frequently encountered in urban environments. While leg-wheel robots take advantage of having both legged and wheeled modes, their ability to negotiate stairs still requires careful planning. This paper presents a novel approach to developing a stair-climbing behavior for leg-wheel transformable robots. A comprehensive stair-climbing strategy is constructed by analyzing the workspace of the leg-wheel mechanism, considering the position of the robot’s center of mass, and accounting for foothold displacement owing to the possible leg-wheel forward rolling motion. This strategy enables the robot to safely navigate stairs using its leg-wheel's appropriate parts. Stability during transitions between steps is ensured, and an optimized swing trajectory is proposed to minimize slippage and impact. The approach is validated through simulations and further tested experimentally on staircases with treads of 27 cm and risers of 12 cm, as well as staircases with treads of 24 cm and risers of 14 cm. The experimental results demonstrate the effectiveness and robustness of the proposed method.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect9">
             <b>
              WeCT9
             </b>
             Regular Session, 312
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1196" name="modifyWeCT9" onclick="modsession(143,1196)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect9" title="Click to go to the Program at a Glance">
             <b>
              Geometric Foundations
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#115139" title="Click to go to the Author Index">
             Barfoot, Timothy
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#121977" title="Click to go to the Author Index">
             Ge, Qiaode
            </a>
           </td>
           <td class="r">
            Stony Brook University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect9_01">
             11:15-11:20, Paper WeCT9.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1197" name="modify2816" onclick="modify(2816,1197)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2816'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              "Hierarchy of Needs" for Robots: Control Synthesis for Compositions of Hierarchical, Complex Objectives
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#329675" title="Click to go to the Author Index">
             Lin, Ruoyu
            </a>
           </td>
           <td class="r">
            University of California, Irvine
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101985" title="Click to go to the Author Index">
             Egerstedt, Magnus
            </a>
           </td>
           <td class="r">
            University of California, Irvine
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2816" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#hybrid_logical_dynamical_planning_and_verification" title="Click to go to the Keyword Index">
               Hybrid Logical/Dynamical Planning and Verification
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_control" title="Click to go to the Keyword Index">
               Integrated Planning and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Drawing inspiration from Maslow's "hierarchy of needs", this paper develops a real-time control synthesis framework for robots to address hierarchical, complex objectives, recognizing that their behaviors are inherently driven by underlying needs. Each need is encoded by the zero-superlevel set of a control barrier function (CBF), which can be time-varying, and all the needs at the same level in a hierarchy are composed into a single one through Boolean compositions of the corresponding CBFs. The effectiveness of the proposed framework is demonstrated through a hypothetical interstellar exploration mission using laboratory robots, and novel results on nonsmooth CBF and time-varying CBF are derived.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect9_02">
             11:20-11:25, Paper WeCT9.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1198" name="modify3152" onclick="modify(3152,1198)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3152'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RM4D: A Combined Reachability and Inverse Reachability Map for Common 6-/7-Axis Robot Arms by Dimensionality Reduction to 4D
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#294004" title="Click to go to the Author Index">
             Rudorfer, Martin
            </a>
           </td>
           <td class="r">
            Aston University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3152" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Knowledge of a manipulator’s workspace is fundamental for a variety of tasks including robot design, grasp planning and robot base placement. Consequently, workspace representations are well studied in robotics. Two important representations are reachability maps and inverse reachability maps. The former predicts whether a given end-effector pose is reachable from where the robot currently is, and the latter suggests suitable base positions for a desired end-effector pose. Typically, the reachability map is built by discretizing the 6D space containing the robot’s workspace and determining, for each cell, whether it is reachable or not. The reachability map is subsequently inverted to build the inverse map. This is a cumbersome process which restricts the applications of such maps. In this work, we exploit commonalities of existing six and seven axis robot arms to reduce the dimension of the discretization from 6D to 4D. We propose Reachability Map 4D (RM4D), a map that only requires a single 4D data structure for both forward and inverse queries. This gives a much more compact map that can be constructed by an order of magnitude faster than existing maps, with no inversion overheads and no loss in accuracy. Finally, we showcase the efficiency gains by applying RM4D for finding suitable base positions in a scenario with 800 target grasps.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect9_03">
             11:25-11:30, Paper WeCT9.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1199" name="modify3503" onclick="modify(3503,1199)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3503'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Average-Distance Minimizing Motion Sweep for Bounded Spatial Objects and Its Application in B´ezier-Like Freeform Motion Generation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425550" title="Click to go to the Author Index">
             Liu, Huan
            </a>
           </td>
           <td class="r">
            Stony Brook University, SUNY
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#121977" title="Click to go to the Author Index">
             Ge, Qiaode
            </a>
           </td>
           <td class="r">
            Stony Brook University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3503" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper uses the ellipsoidal parameters associated with volume moments of inertia of a bounded solid object to construct a motion sweep joining two poses of the solid object, in contrast to earlier works on motion interpolation in SE(3) without taking into account the shape of the moving object. The paper borrows the concept of shape-dependent object norms introduced by Kazerounian and Rastegar and refined by Chirikjian and Zhou to compute as a metric the average of the squared distances (or ASD) among all homologous points of the bounded body between two given poses and seeks to obtain an optimal interpolating motion that minimizes a combination of two ASD distances from each intermediate pose to the two given poses. It is found that the ASD minimizing motion sweep is a novel straight-line motion such that while the centroid of the object follows a straight line, the orientation of the object is constrained so that the ASD metric is minimized. Furthermore, the rotational component can be determined by polar decomposition of the linearly interpolated rotation matrices, scaled by the object's inertia parameters. As an illustration of one of its applications, this motion sweep is repeatedly applied using the de Casteljau algorithm to generate Bézier-like freeform motions, whose paths are in general dependent on the shape of the inertia ellipsoid.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect9_04">
             11:30-11:35, Paper WeCT9.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1200" name="modify4860" onclick="modify(4860,1200)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4860'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Geometric Static Modeling Framework for Piecewise-Continuous Curved-Link Multi Point-Of-Contact Tensegrity Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#383277" title="Click to go to the Author Index">
             Ervin, Lauren
            </a>
           </td>
           <td class="r">
            University of Alabama
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#140014" title="Click to go to the Author Index">
             Vikas, Vishesh
            </a>
           </td>
           <td class="r">
            University of Alabama
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4860" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Tensegrities synergistically combine tensile (cable) and rigid (link) elements to achieve structural integrity, making them lightweight, packable, and impact resistant. Consequently, they have high potential for locomotion in unstructured environments. This research presents geometric modeling of a Tensegrity eXploratory Robot (TeXploR) comprised of two semi-circular, curved links held together by 12 prestressed cables and actuated with an internal mass shifting along each link. This design allows for efficient rolling with stability (e.g., tip-over on an incline). However, the unique design poses static and dynamic modeling challenges given the discontinuous nature of the semi-circular, curved links, two changing points of contact with the surface plane, and instantaneous movement of the masses along the links. The robot is modeled using a geometric approach where the holonomic constraints confirm the experimentally observed four-state hybrid system, proving TeXploR rolls along one link while pivoting about the end of the other. It also identifies the quasi-static state transition boundaries that enable a continuous change in the robot states via internal mass shifting. This is the first time in literature a non-spherical two-point contact system is kinematically and geometrically modeled. Furthermore, the static solutions are closed-form and do not require numerical exploration of the solution. The MATLAB® simulations are experimentally validated on a tetherless prototype with mean absolute error of 4.36° for the arc angles of the points of contact.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect9_05">
             11:35-11:40, Paper WeCT9.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1201" name="modify4962" onclick="modify(4962,1201)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4962'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GISR: Geometric Initialization and Silhouette-Based Refinement for Single-View Robot Pose and Configuration Estimation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#406025" title="Click to go to the Author Index">
             Bilic, Ivan
            </a>
           </td>
           <td class="r">
            University of Zagreb
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#220559" title="Click to go to the Author Index">
             Maric, Filip
            </a>
           </td>
           <td class="r">
            University of Toronto Institute for Aerospace Studies
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106001" title="Click to go to the Author Index">
             Bonsignorio, Fabio
            </a>
           </td>
           <td class="r">
            FER, University of Zagreb
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106395" title="Click to go to the Author Index">
             Petrovic, Ivan
            </a>
           </td>
           <td class="r">
            University of Zagreb
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4962" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In autonomous robotics, measurement of the robot’s internal state and perception of its environment, including interaction with other agents such as collaborative robots, are essential. Estimating the pose of the robot arm from a single view has the potential to replace classical eye-to-hand calibration approaches and is particularly attractive for online estimation and dynamic environments. In addition to its pose, recovering the robot configuration provides a complete spatial understanding of the observed robot that can be used to anticipate the actions of other agents in advanced robotics use cases. Furthermore, this additional redundancy enables the planning and execution of recovery protocols in case of sensor failures or external disturbances. We introduce GISR - a deep configuration and robot-to-camera pose estimation method that prioritizes execution in real-time. GISR consists of two modules: (i) a geometric initialization module that efficiently computes an approximate robot pose and configuration, and (ii) a deep iterative silhouette-based refinement module that arrives at a final solution in just a few iterations. We evaluate GISR on publicly available data and show that it outperforms existing methods of the same class in terms of both speed and accuracy, and can compete with approaches that rely on ground-truth proprioception and recover only the pose. Our code will be available at https://github.com/iwhitey/GISR-robot.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect10">
             <b>
              WeCT10
             </b>
             Regular Session, 313
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1202" name="modifyWeCT10" onclick="modsession(353,1202)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect10" title="Click to go to the Program at a Glance">
             <b>
              Multi-Robot Path Planning 3
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#103610" title="Click to go to the Author Index">
             Hollinger, Geoffrey
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#114720" title="Click to go to the Author Index">
             Yu, Jingjin
            </a>
           </td>
           <td class="r">
            Rutgers University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect10_01">
             11:15-11:20, Paper WeCT10.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1203" name="modify476" onclick="modify(476,1203)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('476'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Stop-N-Go: Search-Based Conflict Resolution for Motion Planning of Multiple Robotic Manipulators
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#408469" title="Click to go to the Author Index">
             Han, Gidon
            </a>
           </td>
           <td class="r">
            Sogang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#408470" title="Click to go to the Author Index">
             Park, Jeongwoo
            </a>
           </td>
           <td class="r">
            Sogang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#127543" title="Click to go to the Author Index">
             Nam, Changjoo
            </a>
           </td>
           <td class="r">
            Sogang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab476" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We address the motion planning problem for multiple robotic manipulators in packed environments where shared workspace can result in goal positions occupied or blocked by other robots unless those other robots move away to make the goal positions free. While planning in a coupled configuration space (C-space) is straightforward, it struggles to scale with the number of robots and often fails to find solutions. Decoupled planning is faster but frequently leads to conflicts between trajectories.
             <p>
              We propose a conflict resolution approach that inserts pauses into individually planned trajectories using an A*search strategy to minimize the makespan--the total time until all robots complete their tasks. This method allows some robots to stop, enabling others to move without collisions, and maintains short distances in the C-space. It also effectively handles cases where goal positions are initially blocked by other robots. Experimental results show that our method successfully solves challenging instances where baseline methods fail to find feasible solutions.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect10_02">
             11:20-11:25, Paper WeCT10.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1204" name="modify1730" onclick="modify(1730,1204)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1730'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Constrained Nonlinear Kaczmarz Projection on Intersections of Manifolds for Coordinated Multi-Robot Mobile Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#325233" title="Click to go to the Author Index">
             Agrawal, Akshaya
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#386882" title="Click to go to the Author Index">
             Mayer, Parker
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#180041" title="Click to go to the Author Index">
             Kingston, Zachary
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103610" title="Click to go to the Author Index">
             Hollinger, Geoffrey
            </a>
           </td>
           <td class="r">
            Oregon State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1730" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#constrained_motion_planning" title="Click to go to the Keyword Index">
               Constrained Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Cooperative manipulation tasks impose various structure-, task-, and robot-specific constraints on mobile manipulators. However, current methods struggle to model and solve these myriad constraints simultaneously. We propose a twofold solution: first, we model constraints as a family of manifolds amenable to simultaneous solving. Second, we introduce the constrained nonlinear Kaczmarz (cNKZ) projection technique to produce constraint-satisfying solutions. Experiments show that cNKZ dramatically outperforms baseline approaches, which cannot find solutions at all. We integrate cNKZ with a sampling-based motion planning algorithm to generate complex, coordinated motions for 3--6 mobile manipulators (18--36 DoF), with cNKZ solving up to 80 nonlinear constraints simultaneously and achieving up to a 92% success rate in cluttered environments. We also demonstrate our approach on hardware using three Turtlebot3 Waffle Pi robots with OpenMANIPULATOR-X arms.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect10_03">
             11:25-11:30, Paper WeCT10.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1205" name="modify1861" onclick="modify(1861,1205)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1861'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Targeted Parallelization of Conflict-Based Search for Multi-Robot Path Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#283385" title="Click to go to the Author Index">
             Guo, Teng
            </a>
           </td>
           <td class="r">
            Rutgers University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#114720" title="Click to go to the Author Index">
             Yu, Jingjin
            </a>
           </td>
           <td class="r">
            Rutgers University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1861" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-Robot Path Planning (MRPP) on graphs, also known as Multi-Agent PathFinding (MAPF), is a well-established NP-hard problem with critically important applications. In (near)-optimally solving MRPP, as serial computation approaches its efficiency limits, parallelization offers a promising route to extend that limit further. As a single solution is unlikely to be successful in addressing all settings, e.g., in handling small/hard or large/sparse MRPP instances, in this study, we explore a targeted parallelization effort to boost the performance of conflict-based search for MRPP. Specifically, when instances are relatively small but robots are densely packed with strong interactions, we devise a decentralized parallel algorithm that concurrently explores multiple branches that leads to markedly enhanced solution discovery. On the other hand, for large problems with sparse robot-robot interactions, we find that prioritizing node expansion and conflict resolution more promising. Our innovative multi-threaded approach to parallelizing bounded-suboptimal conflict search-based algorithms demonstrates significant improvements over baseline serial methods in success rate or runtime. Our work furthers the understanding of MRPP and charts a promising path for elevating solution quality and computational efficiency through parallel algorithmic strategies.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect10_04">
             11:30-11:35, Paper WeCT10.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1206" name="modify2548" onclick="modify(2548,1206)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2548'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Heuristically Guided Compilation for Task Assignment and Path Finding
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#375432" title="Click to go to the Author Index">
             Chen, Zheng
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421951" title="Click to go to the Author Index">
             Chen, Changlin
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422214" title="Click to go to the Author Index">
             Yiran, Ni
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423511" title="Click to go to the Author Index">
             Wang, Junhao
            </a>
           </td>
           <td class="r">
            Hefei University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2548" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We investigate the Combined Target-Assignment and Path-Finding (TAPF) problem that computes both task assignments and collision-free paths for multiple agents, that is, each agent is required to select a target from an underlying set, reaching which leads to a payoff. There is a cost closely related to the time required for each agent to reach the goal. The objective is to maximize the minimum gain generated by the agents. We proposed a Compilation-Based Approach with Heuristics (TA-CBWH) to approximate the optimal solution, behind which are two critical ideas: (i) for a specific task assignment, we formulate an integer linear programming (ILP) and create the iteration combined with large neighborhood search (LNS) to improve the solution quality to near-optimal quickly; (ii) regarding distinct task assignments, a switching mechanism is developed to determine the most promising iteration while progressively eliminating unnecessary task assignments. Comparative experiments demonstrate that TA-CBWH outperforms a wide range of existing approaches across various maps and different numbers of agents.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect10_05">
             11:35-11:40, Paper WeCT10.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1207" name="modify5009" onclick="modify(5009,1207)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5009'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safety-Guaranteed Distributed Formation Control of Multi-Robot Systems Over Graphs with Rigid and Elastic Edges
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#389866" title="Click to go to the Author Index">
             Pham, Hoang
            </a>
           </td>
           <td class="r">
            Tampere University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405617" title="Click to go to the Author Index">
             Ranasinghe, Nadun
            </a>
           </td>
           <td class="r">
            Tampere University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405750" title="Click to go to the Author Index">
             Le, Dong
            </a>
           </td>
           <td class="r">
            Tampere University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#208106" title="Click to go to the Author Index">
             Atman, Made Widhi Surya
            </a>
           </td>
           <td class="r">
            Turku University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#127376" title="Click to go to the Author Index">
             Gusrialdi, Azwirman
            </a>
           </td>
           <td class="r">
            Tampere University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5009" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper considers the problem of formation control of multi-robot systems represented by a graph featuring both rigid and elastic edges, capturing specified range tolerance to the desired inter-robot distances. The objective is to navigate the robots safely through unknown environments with obstacles, utilizing onboard sensors like LiDAR while maintaining inter-robot distance constraints. To this end, a novel cooperative control algorithm is proposed, employing quadratic programming and leveraging control barrier functions to integrate multiple control objectives seamlessly. This approach ensures a unified strategy and provides a safety certificate. Experimental validation of the proposed cooperative control algorithm is conducted using a robotic testbed.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect11">
             <b>
              WeCT11
             </b>
             Regular Session, 314
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1208" name="modifyWeCT11" onclick="modsession(527,1208)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect11" title="Click to go to the Program at a Glance">
             <b>
              Safe Control 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#191008" title="Click to go to the Author Index">
             Bajcsy, Andrea
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#207093" title="Click to go to the Author Index">
             Hu, Bin
            </a>
           </td>
           <td class="r">
            University of Houston
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect11_01">
             11:15-11:20, Paper WeCT11.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1209" name="modify239" onclick="modify(239,1209)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('239'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safety-Critical Control with Saliency Detection for Mobile Robots in Dynamic Multi-Obstacle Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372916" title="Click to go to the Author Index">
             Zhang, Yu
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#337488" title="Click to go to the Author Index">
             Wen, Long
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#301914" title="Click to go to the Author Index">
             Hong, Lin
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#370306" title="Click to go to the Author Index">
             Zhang, Liding
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#414577" title="Click to go to the Author Index">
             Guo, Qun
            </a>
           </td>
           <td class="r">
            Technische Universität München
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#414576" title="Click to go to the Author Index">
             Li, Shixin
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#195330" title="Click to go to the Author Index">
             Bing, Zhenshan
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105608" title="Click to go to the Author Index">
             Knoll, Alois
            </a>
           </td>
           <td class="r">
            Tech. Univ. Muenchen TUM
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab239" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes a novel dual-filter architecture utilizing RGB-D camera data and dynamic control barrier functions (D-CBFs) for real-time obstacle avoidance in unstructured environments. The proposed method efficiently handles static, suddenly appearing, and dynamic obstacles, maintaining consistent computational performance across diverse scenarios. To achieve this, two key challenges must be addressed. First, the substantial volume of pixel and depth map data requires robust, real-time processing for efficient D-CBF construction. Second, constructing D-CBFs for each obstacle in multi-obstacle scenarios increases optimization solver time. To address these challenges, we adapt the concept of salient object detection (SOD), proposing an enhanced FastSOD (E-FastSOD) method for rapid risk area identification. This approach rapidly filters out low-risk areas, while high-risk regions are mathematically represented utilizing the proposed enhanced minimal bounding circle (E-MBC) technique. We differentiate static and dynamic obstacles by comparing current and previous MBC states, employing Kalman filtering for obstacle state prediction. This setup enables efficient online D-CBF construction for each MBC, balancing computational speed with accurate obstacle representation. Subsequently, the second filter establishes buffer zones around established D-CBFs, activating only those corresponding to zones the robot actually enters, rather than all D-CBFs to increase real-time performance. We prove the system's safety and asymptotic stabilization under this architecture. Simulated and real-world experiments validate our method, demonstrating an equipped mobile robot's ability to accomplish tasks while ensuring safety across diverse, unknown scenarios.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect11_02">
             11:20-11:25, Paper WeCT11.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1210" name="modify272" onclick="modify(272,1210)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('272'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safe Coverage for Heterogeneous Systems with Limited Connectivity
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#315252" title="Click to go to the Author Index">
             Taylor, Annalisa T.
            </a>
           </td>
           <td class="r">
            Northwestern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#232583" title="Click to go to the Author Index">
             Berrueta, Thomas
            </a>
           </td>
           <td class="r">
            Northwestern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#299488" title="Click to go to the Author Index">
             Pinosky, Allison
            </a>
           </td>
           <td class="r">
            Northwestern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104560" title="Click to go to the Author Index">
             Murphey, Todd
            </a>
           </td>
           <td class="r">
            Northwestern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab272" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#networked_robots" title="Click to go to the Keyword Index">
               Networked Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             An ongoing challenge for emergency deployments is operating multi-robot teams of diverse agents under communication constraints---where inter-agent connectivity is rare. Thus, heterogeneous systems must autonomously adapt to changing conditions while maintaining safety. In this work, we develop an algorithm for heterogeneous, decentralized multi-robot systems to independently manage safety constraints with provable guarantees for safety and communication for a coverage task. We demonstrate this algorithm in scenarios where up to 100 agents must navigate a simulated cluttered environment with safety constraints that change as agents observe hazards. Further, we show that the performance of a system with a largely disconnected network is equivalent to a fully connected communication network, suggesting that treating connectivity as a constraint may be unnecessary with an appropriate control strategy.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect11_03">
             11:25-11:30, Paper WeCT11.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1211" name="modify1648" onclick="modify(1648,1211)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1648'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safe Control of Quadruped in Varying Dynamics Via Safety Index Adaptation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419451" title="Click to go to the Author Index">
             Yun, SirkHoo, Kai
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#246058" title="Click to go to the Author Index">
             Chen, Rui
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University; University of Michigan;
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419616" title="Click to go to the Author Index">
             Dunaway, Chase
            </a>
           </td>
           <td class="r">
            New Mexico Institute of Mining and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104857" title="Click to go to the Author Index">
             Dolan, John M.
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#171352" title="Click to go to the Author Index">
             Liu, Changliu
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1648" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Varying dynamics pose a fundamental difficulty when deploying safe control laws in the real world. Safety Index Synthesis (SIS) deeply relies on the system dynamics and once the dynamics change, the previously synthesized safety index becomes invalid. In this work, we show the real-time efficacy of Safety Index Adaptation (SIA) in varying dynamics. SIA enables real-time adaptation to the changing dynamics so that the adapted safe control law can still guarantee 1) forward invariance within a safe region and 2) finite time convergence to that safe region. This work employs SIA on a package-carrying quadruped robot, where the payload weight changes in real-time. SIA updates the safety index when the dynamics change, e.g., a change in payload weight, so that the quadruped can avoid obstacles while achieving its performance objectives. Numerical study provides theoretical guarantees for SIA and a series of hardware experiments demonstrate the effectiveness of SIA in real-world deployment in avoiding obstacles under varying dynamics.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect11_04">
             11:30-11:35, Paper WeCT11.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1212" name="modify1654" onclick="modify(1654,1212)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1654'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Updating Robot Safety Representations Online from Natural Language Feedback
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#340105" title="Click to go to the Author Index">
             Santos, Leonardo
            </a>
           </td>
           <td class="r">
            Universidade Federal De Minas Gerais
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#382326" title="Click to go to the Author Index">
             Li, Zirui
            </a>
           </td>
           <td class="r">
            University of Rochester
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#272270" title="Click to go to the Author Index">
             Peters, Lasse
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#220606" title="Click to go to the Author Index">
             Bansal, Somil
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#191008" title="Click to go to the Author Index">
             Bajcsy, Andrea
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1654" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robots must operate safely when deployed in novel and human-centered environments, like homes. Current safe control approaches typically assume that the safety constraints are known a priori, and thus, the robot can pre-compute a corresponding safety controller. While this may make sense for some safety constraints (e.g., avoiding collision with walls by analyzing a floor plan), other constraints are more complex (e.g., spills), inherently personal, context-dependent, and can only be identified at deployment time when the robot is interacting in a specific environment and with a specific person (e.g., fragile objects, expensive rugs). Here, language provides a flexible mechanism to communicate these evolving safety constraints to the robot. In this work, we use vision language models (VLMs) to interpret language feedback and the robot’s image observations to continuously update the robot’s representation of safety constraints. With these inferred constraints, we update a Hamilton-Jacobi reachability safety controller to efficiently update the robot controller to ensure ongoing safety. Through simulation and hardware experiments, we demonstrate the robot’s ability to infer and respect language-based safety constraints with the proposed approach.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect11_05">
             11:35-11:40, Paper WeCT11.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1213" name="modify1873" onclick="modify(1873,1213)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1873'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Detecting Perception-Based Attacks Using Visual Odometry: Inconsistency Modeling and Checking on Robotic States
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#227285" title="Click to go to the Author Index">
             Xu, Yuan
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420961" title="Click to go to the Author Index">
             Deng, Gelei
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256104" title="Click to go to the Author Index">
             Zhang, Tianwei
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1873" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Perception systems in robotic vehicles are crucial for safe and efficient operation, providing key state estimates necessary for planning and control. However, these systems are increasingly vulnerable to perception-based attacks, such as odometry spoofing, position spoofing, obstacle hiding, and object misclassification, which can lead to catastrophic failures. In this paper, we propose a novel approach to detect perception-based attacks by modeling inconsistencies between the physical and estimated states of the robot. Our approach offers a unified methodology for detecting different types of attacks with high accuracy and minimal computational overhead. We validate our method through extensive simulations and real-world scenarios, achieving a 99.5% success rate in detecting attacks, while maintaining a low latency (within 100ms).
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect11_06">
             11:40-11:45, Paper WeCT11.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1214" name="modify1946" onclick="modify(1946,1214)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1946'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Distributed Perception Aware Safe Leader Follower System Via Control Barrier Methods
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420872" title="Click to go to the Author Index">
             Suganda, Richie Ryulie
            </a>
           </td>
           <td class="r">
            University of Houston
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420955" title="Click to go to the Author Index">
             Tran, Tony
            </a>
           </td>
           <td class="r">
            University of Houston
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422820" title="Click to go to the Author Index">
             Pan, Miao
            </a>
           </td>
           <td class="r">
            University of Houston
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422825" title="Click to go to the Author Index">
             Fan, Lei
            </a>
           </td>
           <td class="r">
            University of Houston
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#253405" title="Click to go to the Author Index">
             Lin, Qin
            </a>
           </td>
           <td class="r">
            University of Houston
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#207093" title="Click to go to the Author Index">
             Hu, Bin
            </a>
           </td>
           <td class="r">
            University of Houston
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1946" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper addresses a distributed leader-follower formation control problem for a group of agents, each using a body-fixed camera with a limited field of view (FOV) for state estimation. The main challenge arises from the need to coordinate the agents’ movements with their cameras’ FOV to maintain visibility of the leader for accurate and reliable state estimation. To address this challenge, we propose a novel perception-aware distributed leader-follower safe control scheme that incorporates FOV limits as state constraints. A Control Barrier Function (CBF) based quadratic program is employed to ensure the forward invariance of a safety set defined by these constraints. Furthermore, new neural network based and double bounding boxes based estimators, combined with temporal filters, are developed to estimate system states directly from real-time image data, providing consistent performance across various environments. Comparison results in the Gazebo simulator demonstrate the effectiveness and robustness of the proposed framework in two distinct environments.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect12">
             <b>
              WeCT12
             </b>
             Regular Session, 315
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1215" name="modifyWeCT12" onclick="modsession(173,1215)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect12" title="Click to go to the Program at a Glance">
             <b>
              Human-Robot Interaction 4
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#277916" title="Click to go to the Author Index">
             Turco, Enrico
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#208532" title="Click to go to the Author Index">
             Molnar, Jennifer
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect12_01">
             11:15-11:20, Paper WeCT12.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1216" name="modify1478" onclick="modify(1478,1216)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1478'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Gesturing towards Efficient Robot Control: Exploring Sensor Placement and Control Modes for Mid-Air Human-Robot Interaction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#408487" title="Click to go to the Author Index">
             Mielke, Tonia
            </a>
           </td>
           <td class="r">
            Otto-Von-Guericke University Magdeburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#408490" title="Click to go to the Author Index">
             Heinrich, Florian
            </a>
           </td>
           <td class="r">
            Otto-Von-Guericke University Magdeburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#408494" title="Click to go to the Author Index">
             Hansen, Christian
            </a>
           </td>
           <td class="r">
            Otto-Von-Guericke University Magdeburg
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1478" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#design_and_human_factors" title="Click to go to the Keyword Index">
               Design and Human Factors
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#virtual_reality_and_interfaces" title="Click to go to the Keyword Index">
               Virtual Reality and Interfaces
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_based_control" title="Click to go to the Keyword Index">
               Sensor-based Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             While collaborative robots effectively combine robotic precision with human capabilities, traditional control methods such as button presses or hand guidance can be slow and physically demanding. This has led to an increasing interest in natural user interfaces that integrate hand gesture-based interactions for more intuitive and flexible robot control. Therefore, this paper systematically explores mid-air robot control by comparing position and rate control modes with different state-of-the-art and novel sensor placements. A user study was conducted to evaluate each combination in terms of accuracy, task duration, perceived workload, and physical exertion. Our results indicate that position control is more efficient than rate control. Traditional desk-mounted sensors can provide a good balance between accuracy and comfort. However, robot-mounted sensors are a viable alternative for short-term, accurate control with less spatial requirements. Leg-mounted sensors, while comfortable, pose challenges to hand-eye coordination. Based on these findings, we provide design implications for improving the usability and comfort of mid-air human-robot interaction. Future research should extend this evaluation to a wider range of tasks and environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect12_02">
             11:20-11:25, Paper WeCT12.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1217" name="modify1890" onclick="modify(1890,1217)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1890'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Understanding Dynamic Human-Robot Proxemics in the Case of Four-Legged Canine-Inspired Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#393181" title="Click to go to the Author Index">
             Xu, Xiangmin
            </a>
           </td>
           <td class="r">
            University of Glasgow
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#324299" title="Click to go to the Author Index">
             Meng, Zhen
            </a>
           </td>
           <td class="r">
            University of Glasgow
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#324367" title="Click to go to the Author Index">
             Li, Liying Emma
            </a>
           </td>
           <td class="r">
            University of Glasgow
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#312215" title="Click to go to the Author Index">
             Khamis, Mohamed
            </a>
           </td>
           <td class="r">
            University of Glasgow
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#312420" title="Click to go to the Author Index">
             Zhao, Philip Guodong
            </a>
           </td>
           <td class="r">
            University of Manchester, UK
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421989" title="Click to go to the Author Index">
             Robin, Bretin
            </a>
           </td>
           <td class="r">
            University of Glasgow
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1890" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#safety_in_hri" title="Click to go to the Keyword Index">
               Safety in HRI
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The integration of humanoid and animal-shaped robots into specialized domains, such as healthcare, multi-terrain operations, and psychotherapy, necessitates a deep understanding of proxemics—the study of spatial behavior that governs effective human-robot interactions. Unlike traditional robots in manufacturing or logistics, these robots must navigate complex human environments where maintaining appropriate physical and psychological distances is crucial for seamless interaction. This study explores the application of proxemics in human-robot interactions, focusing specifically on quadruped robots, which present unique challenges and opportunities due to their lifelike movement and form. Utilizing a motion capture system, we examine how different interaction postures of a canine robot influence human participants' proxemic behavior in dynamic scenarios. By capturing and analyzing position and orientation data, this research aims to identify key factors that affect proxemic distances and inform the design of socially acceptable robots. The findings underscore the importance of adhering to human psychological and physical distancing norms in robot design, ensuring that autonomous systems can coexist harmoniously with humans.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect12_03">
             11:25-11:30, Paper WeCT12.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1218" name="modify2733" onclick="modify(2733,1218)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2733'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Autonomous Navigation in Crowded Space Using Multi-Sensory Data Fusion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424500" title="Click to go to the Author Index">
             Ananna, Nourin Siddique
            </a>
           </td>
           <td class="r">
            BRAC University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424292" title="Click to go to the Author Index">
             Saif, Mollah Md
            </a>
           </td>
           <td class="r">
            BRAC University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424488" title="Click to go to the Author Index">
             Noor, Maisha
            </a>
           </td>
           <td class="r">
            BRAC University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424539" title="Click to go to the Author Index">
             Awishi, Ishrat Tasnim
            </a>
           </td>
           <td class="r">
            BRAC University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#247553" title="Click to go to the Author Index">
             Rahman, Md. Khalilur
            </a>
           </td>
           <td class="r">
            BRAC University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424558" title="Click to go to the Author Index">
             Alam, Md Golam Rabilul
            </a>
           </td>
           <td class="r">
            BRAC University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2733" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous navigation in crowded environments remains a significant challenge due to the highly dynamic and unpredictable nature of pedestrian movements. This paper presents a novel approach for socially-compliant crowd navigation by leveraging human pose tracking, trajectory prediction, and obstacle avoidance techniques. We introduce PoseTrajNet, an end-to-end autonomous agent navigation pipeline that integrates YOLOv8 for object detection, BlazePose for real-time human pose estimation, and a custom trajectory prediction model drawing on concepts from Social GANs. PoseTrajNet employs pose keypoints as socially-compliant features to anticipate pedestrian trajectories, enabling proactive path planning and dynamic safe radius adjustments for obstacle avoidance. Extensive evaluations on standard datasets demonstrate PoseTrajNet's effectiveness in seamless crowd navigation, outperforming baselines while adhering to social norms.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect12_04">
             11:30-11:35, Paper WeCT12.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1219" name="modify3773" onclick="modify(3773,1219)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3773'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Feasibility-Aware Imitation Learning from Observation through a Hand-Mounted Demonstration Interface
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425949" title="Click to go to the Author Index">
             Takahashi, Kei
            </a>
           </td>
           <td class="r">
            Nara Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#232653" title="Click to go to the Author Index">
             Sasaki, Hikaru
            </a>
           </td>
           <td class="r">
            Nara Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#122480" title="Click to go to the Author Index">
             Matsubara, Takamitsu
            </a>
           </td>
           <td class="r">
            Nara Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3773" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Imitation learning through a demonstration interface is expected to learn policies for robot automation from intuitive human demonstrations. However, due to the differences in human and robot movement characteristics, a human expert might unintentionally demonstrate an action that the robot cannot execute. We propose feasibility-aware behavior cloning from observation (FABCO). In the FABCO framework, the feasibility of each demonstration is assessed using the robot's pre-trained forward and inverse dynamics models. This feasibility information is provided as visual feedback to the demonstrators, encouraging them to refine their demonstrations. During policy learning, estimated feasibility serves as a weight for the demonstration data, improving both the data efficiency and the robustness of the learned policy. We experimentally validated FABCO's effectiveness by applying it to a pipette insertion task involving a pipette and a vial. Four participants assessed the impact of the feasibility feedback and the weighted policy learning in FABCO. Additionally, we used the NASA Task Load Index (NASA-TLX) to evaluate the workload induced by demonstrations with visual feedback.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect12_05">
             11:35-11:40, Paper WeCT12.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1220" name="modify3914" onclick="modify(3914,1220)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3914'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Human-Robot Collaboration for the Remote Control of Mobile Humanoid Robots with Torso-Arm Coordination
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#352008" title="Click to go to the Author Index">
             Boguslavskii, Nikita
            </a>
           </td>
           <td class="r">
            Worcester Polytechnic Institute (WPI)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339412" title="Click to go to the Author Index">
             Genua, Lorena Maria
            </a>
           </td>
           <td class="r">
            Worcester Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#124281" title="Click to go to the Author Index">
             Li, Zhi
            </a>
           </td>
           <td class="r">
            Worcester Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3914" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_factors_and_human_in_the_loop" title="Click to go to the Keyword Index">
               Human Factors and Human-in-the-Loop
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recently, many humanoid robots have been increasingly deployed in various facilities, including hospitals and assisted living environments, where they are often remotely controlled by human operators. Their kinematic redundancy enhances reachability and manipulability, enabling them to navigate complex, cluttered environments and perform a wide range of tasks. However, this redundancy also presents significant control challenges, particularly in coordinating the movements of the robot's macro-micro structure (torso and arms). Therefore, we propose various human-robot collaborative (HRC) methods for coordinating the torso and arm of remotely controlled mobile humanoid robots, aiming to balance autonomy and human input to enhance system efficiency and task execution. The proposed methods include human-initiated approaches, where users manually control torso movements, and robot-initiated approaches, which autonomously coordinate torso and arm based on factors such as reachability, task goal, or inferred human intent. We conducted a user study with N=17 participants to compare the proposed approaches in terms of task performance, manipulability, and energy efficiency, and analyzed which methods were preferred by participants.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect12_06">
             11:40-11:45, Paper WeCT12.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1221" name="modify4987" onclick="modify(4987,1221)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4987'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Soft Human-Robot Handover Using a Vision-Based Pipeline
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#384591" title="Click to go to the Author Index">
             Castellani, Chiara
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#277916" title="Click to go to the Author Index">
             Turco, Enrico
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#277930" title="Click to go to the Author Index">
             Bo, Valerio
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#149511" title="Click to go to the Author Index">
             Malvezzi, Monica
            </a>
           </td>
           <td class="r">
            University of Siena
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105260" title="Click to go to the Author Index">
             Prattichizzo, Domenico
            </a>
           </td>
           <td class="r">
            University of Siena
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#150020" title="Click to go to the Author Index">
             Costante, Gabriele
            </a>
           </td>
           <td class="r">
            University of Perugia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#192164" title="Click to go to the Author Index">
             Pozzi, Maria
            </a>
           </td>
           <td class="r">
            University of Siena
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4987" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Handing over objects is an essential task in human-robot collaborative scenarios. Previous studies have predominantly employed rigid grippers to perform the handover, focusing their efforts on the generation of grasps that avoid physical contact with people. In this paper, instead, we present a vision-based open-palm handover solution where a soft robotic hand exploits on purpose the contact with the human hand for improved grasp success and robustness. In particular, the human-robot physical interaction allows the robotic hand to slide over the human palm surface and firmly cage the object. The identification of the human hand plane and the object pose is achieved through a versatile perception pipeline that exploits a single RGB-D camera. Through several experimental trials we show that the system achieves successful grasps over multiple objects with different geometries and textures. We also conduct a comparative analysis between the proposed soft handover method and a baseline approach, evaluating their robustness to uncertainties on the object position. Lastly, a user study with 30 participants is conducted to evaluate the users’ perception of the human-robot interaction during the handover. Obtained results highlight the effectiveness of the proposed pipeline with different users and an overall users’ preference for the soft handover.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect13">
             <b>
              WeCT13
             </b>
             Regular Session, 316
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1222" name="modifyWeCT13" onclick="modsession(551,1222)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect13" title="Click to go to the Program at a Glance">
             <b>
              Soft Robotic Grasping 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#159640" title="Click to go to the Author Index">
             Wang, Wei
            </a>
           </td>
           <td class="r">
            University of Wisconsin-Madison
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#140014" title="Click to go to the Author Index">
             Vikas, Vishesh
            </a>
           </td>
           <td class="r">
            University of Alabama
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect13_01">
             11:15-11:20, Paper WeCT13.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1223" name="modify2" onclick="modify(2,1223)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Utilizing Bioinspired Soft Modular Appendages for Grasping and Locomotion in Multi-Legged Robots on Ground and Underwater
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#355333" title="Click to go to the Author Index">
             Siddiquee, Abu Nayem Md. Asraf
            </a>
           </td>
           <td class="r">
            Graduate Teaching Assistant - University of Notre Dame
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#149224" title="Click to go to the Author Index">
             Ozkan-Aydin, Yasemin
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft robots can adapt to their environments, which makes them suitable for deploying in disaster areas and agricultural fields, where their mobility is constrained by complex terrain. One of the main challenges in developing soft terrestrial robots is that the robot must be soft enough to adapt to its environment, but also rigid enough to exert adequate force on the ground to locomote. In this letter, we report a pneumatically driven, soft modular appendage made of silicone for a terrestrial robot capable of generating specific mechanical movement to locomote in the desired direction. We used Finite Element Analysis (FEA) simulations to assess the soft leg’s bending behavior, validated against the physical leg. In addition, we performed blocked force analysis to understand its force generation capabilities. We developed a soft-rigid- bodied tethered robot prototype and tested it on the ground and underwater environments to evaluate its locomotion performance. The robot demonstrated successful forward and backward movement as well as left and right turns, both on the ground and underwater. We explored the object manipulation and transportation capability of the robot by adding two additional soft appendages as a gripper. The robot demonstrated its ability to effectively manipulate and transport objects of varying nature, including rigid items such as a 3D-printed plastic box and fragile objects like an egg. The maximum load-carrying capacity of the robot was also investigated both on the ground and the aquatic medium. Our design approach provides a straightforward, cost-effective, and efficient method for creating versatile soft appendages for a robot that is capable of terradynamic locomotion. This approach showcases its potential applicability in underwater search and rescue missions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect13_02">
             11:20-11:25, Paper WeCT13.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1224" name="modify1920" onclick="modify(1920,1224)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1920'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design of a Novel Pneumatic Soft Gripper for Robust Adaptive Grasping
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#150434" title="Click to go to the Author Index">
             Sun, Xiantao
            </a>
           </td>
           <td class="r">
            Anhui University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#439625" title="Click to go to the Author Index">
             Zhong, Mingsheng
            </a>
           </td>
           <td class="r">
            Anhui University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422730" title="Click to go to the Author Index">
             Tang, Zhouzheng
            </a>
           </td>
           <td class="r">
            Anhui University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100810" title="Click to go to the Author Index">
             Chen, Wenjie
            </a>
           </td>
           <td class="r">
            Anhui University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#240297" title="Click to go to the Author Index">
             Chen, Weihai
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1920" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft grippers have shown promising performance in safe and adaptive grasping tasks. However, they often suffer from limitations in grasping force. To address this challenge, this paper presents a novel pneumatic three-finger soft gripper to achieve robust adaptive grasping. The gripper consists of three identical fingers, each containing a pneumatic bending soft actuator and a pneumatic lateral soft actuator. The bending actuator features a tilted pneumatic network structure, which provides superior bending performance compared to traditional vertical pneumatic network structure. The lateral actuator is equipped with three deflection chambers at the finger root to mimic the lateral motions of a human finger. Kinematic and static models are established to predict the bending angle and grasping force of the soft finger under pressurized air. The performance of the proposed soft finger is analyzed through finite element simulations, and the effect of the chamber tilt angle is also examined. The theoretical and simulation results are compared to verify the validity of the analytical models. Finally, the proposed soft gripper is fabricated by 3D printing and molding. Experimental results show that the gripper is capable of grasping various objects of different sizes, shapes, materials, and weights, and can perform dexterous manipulation tasks, such as cap unscrewing. The proposed soft gripper exhibits significant potential for applications in robotic robust grasping tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect13_03">
             11:25-11:30, Paper WeCT13.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1225" name="modify2552" onclick="modify(2552,1225)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2552'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hybrid Gripper with Passive Pneumatic Soft Joints for Grasping Deformable Thin Objects
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423493" title="Click to go to the Author Index">
             Tran, Duy
            </a>
           </td>
           <td class="r">
            Ha Noi University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423490" title="Click to go to the Author Index">
             Ly, Hoang Hiep
            </a>
           </td>
           <td class="r">
            Hanoi University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423507" title="Click to go to the Author Index">
             Nguyen, Thuan
            </a>
           </td>
           <td class="r">
            Hanoi University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#228311" title="Click to go to the Author Index">
             Mac, Thi Thoa
            </a>
           </td>
           <td class="r">
            HUST
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#171078" title="Click to go to the Author Index">
             Nguyen, Anh
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#217645" title="Click to go to the Author Index">
             Ta, Tung D.
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2552" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Grasping a variety of objects remains a key challenge in the development of versatile robotic systems. The human hand is remarkably dexterous, capable of grasping and manipulating objects with diverse shapes, mechanical properties, and textures. Inspired by how humans use two fingers to pick up thin and large objects such as fabric or sheets of paper, we aim to develop a gripper optimized for grasping such deformable objects. Observing how the soft and flexible fingertip joints of the hand approach and grasp thin materials, a hybrid gripper design that incorporates both soft and rigid components was proposed. The gripper utilizes a soft pneumatic ring wrapped around a rigid revolute joint to create a flexible two-fingered gripper. Experiments were conducted to characterize and evaluate the gripper's performance in handling sheets of paper and other objects. Compared to rigid grippers, the proposed design improves grasping efficiency and reduces the gripping distance by up to eightfold.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect13_04">
             11:30-11:35, Paper WeCT13.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1226" name="modify3379" onclick="modify(3379,1226)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3379'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Dexterous Three-Finger Gripper Based on Offset Trimmed Helicoids
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#197811" title="Click to go to the Author Index">
             Guan, Qinghua
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#222424" title="Click to go to the Author Index">
             Cheng, Hung Hon
            </a>
           </td>
           <td class="r">
            EPFL
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#194194" title="Click to go to the Author Index">
             Hughes, Josie
            </a>
           </td>
           <td class="r">
            EPFL
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3379" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study presents an innovative offset-trimmed helicoids (OTH) structure, featuring a tunable deformation center that emulates the flexibility of human fingers. This design significantly reduces the actuation force needed for larger elastic deformations, particularly when dealing with harder materials like thermoplastic polyurethane (TPU). The incorporation of two helically routed tendons within the finger enables both in-plane bending and lateral out-of-plane transitions, effectively expanding its workspace and allowing for variable curvature along its length. Compliance analysis indicates that the compliance at the fingertip can be fine-tuned by adjusting the mounting placement of the fingers. This customization enhances the gripper's adaptability to a diverse range of objects. By leveraging TPU's substantial elastic energy storage capacity, the gripper is capable of dynamically rotating objects at high speeds, achieving approximately 60° in just 15 milliseconds. The three-finger gripper, with its high dexterity across six degrees of freedom, has demonstrated the capability to successfully perform intricate tasks. One such example is the adept spinning of a rod within the gripper's grasp.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect13_05">
             11:35-11:40, Paper WeCT13.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1227" name="modify4008" onclick="modify(4008,1227)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4008'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Improving Grip Stability Using Passive Compliant Microspine Arrays for Soft Robots in Unstructured Terrain
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#383277" title="Click to go to the Author Index">
             Ervin, Lauren
            </a>
           </td>
           <td class="r">
            University of Alabama
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#322030" title="Click to go to the Author Index">
             Bezawada, Harish
            </a>
           </td>
           <td class="r">
            The University of Alabama
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#140014" title="Click to go to the Author Index">
             Vikas, Vishesh
            </a>
           </td>
           <td class="r">
            University of Alabama
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4008" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#compliant_joints_and_mechanisms" title="Click to go to the Keyword Index">
               Compliant Joints and Mechanisms
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Microspine grippers are small spines commonly found on insect legs that reinforce surface interaction by engaging with asperities to increase shear force and traction. An array of such microspines, when integrated into the limbs or undercarriage of a robot, can provide the ability to maneuver uneven terrains, traverse inclines, and even climb walls. Meanwhile, the conformability and adaptability of soft robots makes them ideal candidates for applications involving traversal of complex, unstructured terrains. However, there remains a real-life realization gap for soft locomotors pertaining to their transition from controlled lab environment to the field that can be bridged by improving grip stability through effective integration of microspines. In this research, a passive, compliant microspine stacked array design is proposed to enhance the locomotion capabilities of mobile soft robots. A microspine array integration method effectively addresses the stiffness mismatch between soft, compliant, and rigid components. Additionally, a reduction in complexity results from actuation of the surface-conformable soft limb using a single actuator. The two-row, stacked microspine array configuration offers improved gripping capabilities on steep and irregular surfaces. This design is incorporated into three different robot configurations - the baseline without microspines and two others with different combinations of microspine arrays. Field experiments are conducted on surfaces of varying surface roughness and non-uniformity - concrete, brick, compact sand, and tree roots. Experimental results demonstrate that the inclusion of microspine arrays increases planar displacement an average of 10 times. The improved grip stability, repeatability, and, terrain traversability is reflected by a decrease in the relative standard deviation of the locomotion gaits.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect13_06">
             11:40-11:45, Paper WeCT13.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1228" name="modify4591" onclick="modify(4591,1228)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4591'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hybrid Soft Pneumatic and Tendon Actuated Finger with Selective Locking Chain Link Joints
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#276290" title="Click to go to the Author Index">
             Lin, Keng-Yu
            </a>
           </td>
           <td class="r">
            University of Wisconsin Madison
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#389632" title="Click to go to the Author Index">
             Stonecipher, Jack
            </a>
           </td>
           <td class="r">
            University of Wisconsin-Madison
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405381" title="Click to go to the Author Index">
             Rusch, Zach
            </a>
           </td>
           <td class="r">
            University of Wisconsin-Madison
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#159640" title="Click to go to the Author Index">
             Wang, Wei
            </a>
           </td>
           <td class="r">
            University of Wisconsin-Madison
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#152935" title="Click to go to the Author Index">
             Wehner, Michael
            </a>
           </td>
           <td class="r">
            University of Wisconsin, Madison
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4591" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Rigid robots excel in structured conditions, but struggle in more unpredictable or populated environments. Soft robots address these difficulties, but the compliance which gives them their inherent safety also limits their ability to apply desired forces. Jamming/locking reduces this back-drivability but does not allow for directional application of force. We present a hybrid system including pneumatic and tendon actuation as well as a system of cable-driven locking modules, able lock individual joints. Combining these mechanisms yields a device which can behave as: a soft finger, a fully-rigid finger, and a locally-locking finger which mimics a traditional rigid-link robot. This finger is able to switch between these behaviors on-the-fly, allowing it to adapt to unexpected scenarios, critical for social robots. Using these modes and the ability to adapt real-time, our finger is able to complete common household tasks, difficult for current robots. We characterize the finger’s ability to resist force in three actuation modes (Pneumatic, Cable, and Locked), its ability to apply force, and its ability to actuate in 31 different configurations (plus a static all-locked configuration). We also present a demonstration in which the finger conforms to the shape of a computer mouse then clicks a mouse button, and of the finger conforms to the shape of a heavy door handle, then pulling it open. We present the design, fabrication, and characterization of this finger as a demonstration of the underlying concept, which can be broadly applied to social robotics.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect14">
             <b>
              WeCT14
             </b>
             Regular Session, 402
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1229" name="modifyWeCT14" onclick="modsession(465,1229)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect14" title="Click to go to the Program at a Glance">
             <b>
              Reconfigurable Robots
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#227071" title="Click to go to the Author Index">
             Sun, Jiefeng
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#133682" title="Click to go to the Author Index">
             Mehta, Ankur
            </a>
           </td>
           <td class="r">
            UCLA
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect14_01">
             11:15-11:20, Paper WeCT14.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1230" name="modify327" onclick="modify(327,1230)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('327'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enabling Framework for Constant Complexity Model in Autonomous Inter-Reconfigurable Robots (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#326207" title="Click to go to the Author Index">
             Wan, Ash Yaw Sang
            </a>
           </td>
           <td class="r">
            Singapore University of Technology and Design
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256684" title="Click to go to the Author Index">
             Le, Anh Vu
            </a>
           </td>
           <td class="r">
            Communication and Signal Processing Research Group Faculty of El
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#326199" title="Click to go to the Author Index">
             Moo, Chee Gen
            </a>
           </td>
           <td class="r">
            Singapore University of Technology and Design
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#233095" title="Click to go to the Author Index">
             Sivanantham, Vinu
            </a>
           </td>
           <td class="r">
            Singapore University of Technology and Design
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107677" title="Click to go to the Author Index">
             Elara, Mohan Rajesh
            </a>
           </td>
           <td class="r">
            Singapore University of Technology and Design
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab327" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#cellular_and_modular_robots" title="Click to go to the Keyword Index">
               Cellular and Modular Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In reconfigurable robotics, intra-reconfiguration enables a robot to change its functional abilities, while inter-reconfiguration manipulates the specification limits of the robot hardware. Although the versatility of inter-reconfigurable robots is desired in advanced autonomous systems, the O(n^3) algorithm computational time complexity challenge comes when multiple modular robots combine and reconfigure into a bigger form structure for autonomous navigation tasks. This phenomenon has limited the inter-reconfiguration potential of expansion, versatility, and robustness. In this paper, a navigation framework with non-complex transformation states is proposed for inter-reconfigurable robots to perform combining and splitting control dimensions. Simulations have shown the complexity from	O(n) to constant time O(1) in the reconfiguration states of the framework on a considerable number of robot agents. Additionally, a set of inter-reconfigurable robots, Wasp Biggie, was used to demonstrate the proof-of-concept in experiments as a fully functional centralized planner system. These experiments showed outperforming results on the consistent utility of CPU consumption while performing navigation and reconfiguration.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect14_02">
             11:20-11:25, Paper WeCT14.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1231" name="modify2381" onclick="modify(2381,1231)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2381'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Improving Coverage Performance of a Size-Reconfigurable Robot Based on Overlapping and Reconfiguration Reduction Criteria
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#191819" title="Click to go to the Author Index">
             Muthugala Arachchige, Viraj Jagathpriya Muthugala
            </a>
           </td>
           <td class="r">
            Singapore University of Technology and Design
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#219480" title="Click to go to the Author Index">
             Samarakoon Mudiyanselage, Bhagya Prasangi Samarakoon
            </a>
           </td>
           <td class="r">
            Singapore University of Technology and Design
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#242942" title="Click to go to the Author Index">
             Wijegunawardana, Isira Damsith
            </a>
           </td>
           <td class="r">
            Singapore University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107677" title="Click to go to the Author Index">
             Elara, Mohan Rajesh
            </a>
           </td>
           <td class="r">
            Singapore University of Technology and Design
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2381" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning_under_uncertainty" title="Click to go to the Keyword Index">
               Planning under Uncertainty
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#neural_and_fuzzy_control" title="Click to go to the Keyword Index">
               Neural and Fuzzy Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Size reconfigurable robots have been introduced for coverage applications to improve performance. The size reconfiguration ability allows a robot to access narrow areas in a smaller size while covering open spaces in a larger size, improving productivity. This paper proposes a novel CPP method consisting of an Overlapping Reduction Criterion (ORC) and a Reconfiguration Reduction Criterion (RRC) for a size-reconfigurable robot to improve performance in dynamic workspaces. A Glasius Bio-inspired Neural Network (GBNN) is adapted to guide the robot toward unvisited cells considering neural activity variation. The size variation is managed by utilizing a collection of grid maps generated for various size configurations of the robot. The RRC and ORC penalize the movements requiring size reconfigurations or creating isolated unvisited regions in the decision-making process of next movement selection yielding to reduce reconfigurations and overlapping. According to the results, the proposed CPP method surpasses state of the art in terms of performance indexes reconfiguration count, overlapping, path distance, and coverage time by significant margins.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect14_03">
             11:25-11:30, Paper WeCT14.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1232" name="modify2895" onclick="modify(2895,1232)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2895'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CoCube: A Tabletop Modular Multi-Robot Platform for Education and Research
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#399153" title="Click to go to the Author Index">
             Liang, Shuai
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423600" title="Click to go to the Author Index">
             Zhu, Songyi
            </a>
           </td>
           <td class="r">
            Shanghai Artifcial Intelligence Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423597" title="Click to go to the Author Index">
             Zhonghan, Tang
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421681" title="Click to go to the Author Index">
             Li, Chenhui
            </a>
           </td>
           <td class="r">
            Shanghai Artificial Intelligence Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423624" title="Click to go to the Author Index">
             Wu, Wenjie
            </a>
           </td>
           <td class="r">
            DynaLab
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423676" title="Click to go to the Author Index">
             Han, Jialing
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425723" title="Click to go to the Author Index">
             Lin, Zemin
            </a>
           </td>
           <td class="r">
            Shanghai Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#440357" title="Click to go to the Author Index">
             You, Zhongrui
            </a>
           </td>
           <td class="r">
            Shanghai Artifcial Intelligence Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#441711" title="Click to go to the Author Index">
             Maloney, John
            </a>
           </td>
           <td class="r">
            MicroBlocks
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#441479" title="Click to go to the Author Index">
             Romagosa Carrasquer, Bernat
            </a>
           </td>
           <td class="r">
            SAP
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372118" title="Click to go to the Author Index">
             Zhao, Bin
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#376465" title="Click to go to the Author Index">
             Wang, Zhigang
            </a>
           </td>
           <td class="r">
            Shanghai AI Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354792" title="Click to go to the Author Index">
             Zhang, Zhinan
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372120" title="Click to go to the Author Index">
             Li, Xuelong
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2895" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#education_robotics" title="Click to go to the Keyword Index">
               Education Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#cellular_and_modular_robots" title="Click to go to the Keyword Index">
               Cellular and Modular Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents CoCube, a tabletop modular robotics platform designed for robotics education and multi-robot algorithm research. CoCube is characterized by its low cost, low floors, high ceilings and wide walls, offering flexibility and broad applicability across various use cases. The platform comprises four key components: CoCube robots, which integrate wireless communication, movement and interaction; CoModules, which provide versatile external functionality; CoMaps, which enable high-precision localization via microdot patterns on regular printed paper; and CoTags for interaction. CoCube operates on MicroBlocks, a blocks programming language for physical computing inspired by Scratch, a widely-used coding language with a simple visual interface that makes programming accessible to young learners. It offers users both flexibility and ease of use, with advanced API support for more complex applications. This paper details the design of the CoCube platform and demonstrates its potential in both educational and research contexts.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect14_04">
             11:30-11:35, Paper WeCT14.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1233" name="modify3266" onclick="modify(3266,1233)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3266'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Loopy Movements: Emergence of Rotation in a Multicellular Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#298103" title="Click to go to the Author Index">
             Smith, Trevor
            </a>
           </td>
           <td class="r">
            West Virginia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#146498" title="Click to go to the Author Index">
             Gu, Yu
            </a>
           </td>
           <td class="r">
            West Virginia University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3266" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#cellular_and_modular_robots" title="Click to go to the Keyword Index">
               Cellular and Modular Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Unlike most human-engineered systems, many biological systems rely on emergent behaviors from low-level interactions, enabling greater diversity and superior adaptation to complex, dynamic environments. This study explores emergent decentralized rotation in the Loopy multicellular robot, composed of homogeneous, physically linked, 1-degree-of-freedom cells. Inspired by biological systems like sunflowers, Loopy uses simple local interactions—diffusion, reaction, and active transport of simulated chemicals, called morphogens—without centralized control or knowledge of its global morphology. Through these interactions, the robot self-organizes to achieve coordinated rotational motion and forms lobes—local protrusions created by clusters of motor cells. This study investigates how these interactions drive Loopy’s rotation, the impact of its morphology, and its resilience to actuator failures. Our findings reveal two distinct behaviors: 1) inner valleys between lobes rotate faster than the outer peaks, contrasting with rigid body dynamics, and 2) cells rotate in the opposite direction of the overall morphology. The experiments show that while Loopy’s morphology does not affect its angular velocity relative to its cells, larger lobes increase cellular rotation and decrease morphology rotation relative to the environment. Even with up to one-third of its actuators disabled and significant morphological changes, Loopy maintains its rotational abilities, highlighting the potential of decentralized, bio-inspired strategies for resilient and adaptable robotic systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect14_05">
             11:35-11:40, Paper WeCT14.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1234" name="modify4108" onclick="modify(4108,1234)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4108'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhancing Connection Strength in Freeform Modular Reconfigurable Robots through Holey Sphere and Gripper Mechanisms
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#390676" title="Click to go to the Author Index">
             Wang, Peiqi
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267777" title="Click to go to the Author Index">
             Liang, Guanqi
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#312461" title="Click to go to the Author Index">
             Zhao, Da
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#113090" title="Click to go to the Author Index">
             Lam, Tin Lun
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong, Shenzhen
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4108" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#cellular_and_modular_robots" title="Click to go to the Keyword Index">
               Cellular and Modular Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Freeform modular self-reconfigurable robot (MSRR) systems overcome traditional docking limitations, enabling rapid and continuous connections between modules in any direction. Recent advancements in freeform MSRR technology have significantly enhanced connectivity and mobility. However, limitations in connector strength and operational efficiency in existing designs restrict performance. This paper proposes a rigid freeform connector and a rigid magnetic track design to improve the connection and motion performance of the SnailBot. Each SnailBot is equipped with a multi-channel rope-driven gripper, a metal spherical shell with densely distributed circular holes on the back, and a rigid chain design conforming to the spherical surface. This combination allows each SnailBot to move precisely along the surface of a peer, facilitated by the ferromagnetic spherical shell and magnetic track. The integration of the gripper and spherical shell hole array provides robust inter-module connections in any position and orientation. The effectiveness of these designs has been validated through a series of experiments and analyses, demonstrating improved connection and motion performance in the SnailBot dual-mode connector system and expanding its potential applications and functional capabilities.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect15">
             <b>
              WeCT15
             </b>
             Regular Session, 403
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1235" name="modifyWeCT15" onclick="modsession(85,1235)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect15" title="Click to go to the Program at a Glance">
             <b>
              Bimanual Manipulation 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#102922" title="Click to go to the Author Index">
             Asfour, Tamim
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#107914" title="Click to go to the Author Index">
             Gupta, Satyandra K.
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect15_01">
             11:15-11:20, Paper WeCT15.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1236" name="modify1620" onclick="modify(1620,1236)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1620'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Dexterous Bimanual Catch Skills through Adversarial-Cooperative Heterogeneous-Agent Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#163715" title="Click to go to the Author Index">
             Kim, Taewoo
            </a>
           </td>
           <td class="r">
            Electronics and Telecommunications Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#130175" title="Click to go to the Author Index">
             Yoon, Youngwoo
            </a>
           </td>
           <td class="r">
            Electronics and Telecommunications Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#130395" title="Click to go to the Author Index">
             Kim, Jaehong
            </a>
           </td>
           <td class="r">
            ETRI
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1620" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#bimanual_manipulation" title="Click to go to the Keyword Index">
               Bimanual Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic catching has traditionally focused on single-handed systems, which are limited in their ability to handle larger or more complex objects. In contrast, bimanual catching offers significant potential for improved dexterity and object handling but introduces new challenges in coordination and control. In this paper, we propose a novel framework for learning dexterous bimanual catching skills using Heterogeneous-Agent Reinforcement Learning (HARL). Our approach introduces an adversarial reward scheme, where a throw agent increases the difficulty of throws adjusting speed while a catch agent learns to coordinate both hands to catch objects under these evolving conditions. We evaluate the framework in simulated environments using 15 different objects, demonstrating robustness and versatility in handling diverse objects. Our method achieved approximately a 2x increase in catching reward compared to single-agent baselines across 15 diverse objects.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect15_02">
             11:20-11:25, Paper WeCT15.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1237" name="modify2912" onclick="modify(2912,1237)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2912'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Flat'n'Fold: A Diverse Multi-Modal Dataset for Garment Perception and Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424780" title="Click to go to the Author Index">
             Zhuang, Lipeng
            </a>
           </td>
           <td class="r">
            University of Glasgow
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419490" title="Click to go to the Author Index">
             Fan, Shiyu
            </a>
           </td>
           <td class="r">
            University of Glasgow
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423524" title="Click to go to the Author Index">
             Ru, Yingdong
            </a>
           </td>
           <td class="r">
            University of Glasgow
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#328143" title="Click to go to the Author Index">
             Audonnet, Florent
            </a>
           </td>
           <td class="r">
            University of Glasgow
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419477" title="Click to go to the Author Index">
             Henderson, Paul
            </a>
           </td>
           <td class="r">
            University of Glasgow
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#172642" title="Click to go to the Author Index">
             Aragon-Camarasa, Gerardo
            </a>
           </td>
           <td class="r">
            University of Glasgow
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2912" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#bimanual_manipulation" title="Click to go to the Keyword Index">
               Bimanual Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present Flat'n'Fold, a novel large-scale dataset for garment manipulation that addresses critical gaps in existing datasets. Comprising 1,212 human and 887 robot demonstrations of flattening and folding 44 unique garments across 8 categories, Flat'n'Fold surpasses prior datasets in size, scope, and diversity. Our dataset uniquely captures the entire manipulation process from crumpled to folded states, providing synchronized multi-view RGB-D images, point clouds, and action data, including hand or gripper positions and rotations. We quantify the dataset's diversity and complexity compared to existing benchmarks and show that our dataset features natural and diverse manipulations of real-world demonstrations of human and robot demonstrations in terms of visual and action information. To showcase Flat'n'Fold utility, we establish new benchmarks for grasping point prediction and subtask decomposition. Our evaluation of state-of-the-art models on these tasks reveals significant room for improvement. This underscores Flat'n'Fold's potential to drive advances in robotic perception and manipulation of deformable objects. Our dataset can be downloaded at https://cvas-ug.github.io/flat-n-fold
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect15_03">
             11:25-11:30, Paper WeCT15.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1238" name="modify4005" onclick="modify(4005,1238)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4005'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              TWIN: Two-Handed Intelligent Benchmark for Bimanual Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#188389" title="Click to go to the Author Index">
             Grotz, Markus
            </a>
           </td>
           <td class="r">
            University of Washington (UW)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#241498" title="Click to go to the Author Index">
             Shridhar, Mohit
            </a>
           </td>
           <td class="r">
            University of Washington
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#198471" title="Click to go to the Author Index">
             Chao, Yu-Wei
            </a>
           </td>
           <td class="r">
            NVIDIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102922" title="Click to go to the Author Index">
             Asfour, Tamim
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104592" title="Click to go to the Author Index">
             Fox, Dieter
            </a>
           </td>
           <td class="r">
            University of Washington
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4005" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#bimanual_manipulation" title="Click to go to the Keyword Index">
               Bimanual Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#software_tools_for_benchmarking_and_reproducibility" title="Click to go to the Keyword Index">
               Software Tools for Benchmarking and Reproducibility
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Bimanual manipulation is challenging due to precise spatial and temporal coordination required between two arms. While there exist several real-world bimanual systems, there is a lack of simulated benchmarks with a large task diversity for systematically studying bimanual capabilities across a wide range of tabletop tasks. This paper addresses the gap by presenting a benchmark for bimanual manipulation. A key functionality is the ability to autonomously generate training data without the necessity of human demonstrations to the robot. We open-source our code and benchmark, which comprises 13 new tasks with 23 unique task variations, each requiring a high degree of coordination and adaptability. To initiate the benchmark, we extended multiple state-of-the-art techniques to the domain of bimanual manipulation. The project website with code is available at: http://bimanual.github.io.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect15_04">
             11:30-11:35, Paper WeCT15.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1239" name="modify4503" onclick="modify(4503,1239)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4503'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Active Vision Might Be All You Need: Exploring Active Vision in Bimanual Robotic Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#380749" title="Click to go to the Author Index">
             Chuang, Ian
            </a>
           </td>
           <td class="r">
            University of California, Davis
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426374" title="Click to go to the Author Index">
             Lee, Andrew
            </a>
           </td>
           <td class="r">
            University of California, Davis
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426388" title="Click to go to the Author Index">
             Gao, Dechen
            </a>
           </td>
           <td class="r">
            University of California, Davis
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#450896" title="Click to go to the Author Index">
             Naddaf Shargh, Mohammad Mahdi
            </a>
           </td>
           <td class="r">
            University of California - Davis
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#310737" title="Click to go to the Author Index">
             Soltani, Iman
            </a>
           </td>
           <td class="r">
            University of California, Davis
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4503" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dual_arm_manipulation" title="Click to go to the Keyword Index">
               Dual Arm Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Imitation learning has demonstrated significant potential in performing high-precision manipulation tasks using visual feedback. However, it is common practice in imitation learning for cameras to be fixed in place, resulting in issues like occlusion and limited field of view. Furthermore, cameras are often placed in broad, general locations, without an effective viewpoint specific to the robot's task. In this work, we investigate the utility of active vision (AV) for imitation learning and manipulation, in which, in addition to the manipulation policy, the robot learns an AV policy from human demonstrations to dynamically change the robot's camera viewpoint to obtain better information about its environment and the given task. We introduce AV-ALOHA, a new bimanual teleoperation robot system with AV, an extension of the ALOHA 2 robot system, incorporating an additional 7-DoF robot arm that only carries a stereo camera and is solely tasked with finding the best viewpoint. This camera streams stereo video to an operator wearing a virtual reality (VR) headset, allowing the operator to control the camera pose using head and body movements. The system provides an immersive teleoperation experience, with bimanual first-person control, enabling the operator to dynamically explore and search the scene and simultaneously interact with the environment. We conduct imitation learning experiments of our system both in real-world and in simulation, across a variety of tasks that emphasize viewpoint planning. Our results demonstrate the effectiveness of human-guided AV for imitation learning, showing significant improvements over fixed cameras in tasks with limited visibility. Project website: https://soltanilara.github.io/av-aloha/
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect15_05">
             11:35-11:40, Paper WeCT15.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1240" name="modify4504" onclick="modify(4504,1240)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4504'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Force-Conditioned Diffusion Policies for Compliant Sheet Separation Tasks in Bimanual Robotic Cells
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#304593" title="Click to go to the Author Index">
             Shukla, Rishabh
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426093" title="Click to go to the Author Index">
             Talan, Raj
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398309" title="Click to go to the Author Index">
             Moode, Samrudh
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#254126" title="Click to go to the Author Index">
             Dhanaraj, Neel
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378711" title="Click to go to the Author Index">
             Kang, Jeon Ho
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107914" title="Click to go to the Author Index">
             Gupta, Satyandra K.
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4504" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#bimanual_manipulation" title="Click to go to the Keyword Index">
               Bimanual Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#disassembly" title="Click to go to the Keyword Index">
               Disassembly
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Disassembly is a critical challenge in maintenance and service tasks, particularly in high-precision operations such as electric vehicle (EV) battery recycling. Tasks like prying-open sealed battery covers require precise manipulation and controlled force application. In our approach we collect human demonstrations using a motion capture system, enabling the robot to learn from human-expert disassembly strategies. These demonstrations train a bimanual robotic system in which one arm exerts force with a specialized tool while the other manipulates and removes sealed components. Our method builds on a diffusion-based policy and integrates real-time force sensing to adapt its actions as contact conditions change. We decompose the demonstrations into distinct sub-tasks and apply data augmentation, thereby reducing the number of demonstrations needed and mitigating potential task failures. Our results show that the proposed method, even with a small dataset, achieves a high task success rate and efficiency compared to a standard diffusion technique. We demonstrate in a real-world application that the bimanual system effectively executes chiseling and peeling actions to separate bonded sheet from a substrate.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect15_06">
             11:40-11:45, Paper WeCT15.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1241" name="modify4893" onclick="modify(4893,1241)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4893'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Comparison of Imitation Learning Algorithms for Bimanual Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#268390" title="Click to go to the Author Index">
             Drolet, Michael
            </a>
           </td>
           <td class="r">
            Technische Universität Darmstadt
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#192216" title="Click to go to the Author Index">
             Stepputtis, Simon
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#332340" title="Click to go to the Author Index">
             Kailas, Siva
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#193710" title="Click to go to the Author Index">
             Jain, Ajinkya
            </a>
           </td>
           <td class="r">
            Intrinsic Innovation LLC
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104326" title="Click to go to the Author Index">
             Peters, Jan
            </a>
           </td>
           <td class="r">
            Technische Universität Darmstadt
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102004" title="Click to go to the Author Index">
             Schaal, Stefan
            </a>
           </td>
           <td class="r">
            Google X
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#130054" title="Click to go to the Author Index">
             Ben Amor, Heni
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4893" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#bimanual_manipulation" title="Click to go to the Keyword Index">
               Bimanual Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Amidst the wide popularity of imitation learning algorithms in robotics, their properties regarding hyperparameter sensitivity, ease of training, data efficiency, and performance have not been well-studied in high-precision industry-inspired environments. In this work, we demonstrate the limitations and benefits of prominent imitation learning approaches and analyze their capabilities regarding these properties. We evaluate each algorithm on a complex bimanual manipulation task involving an over-constrained dynamics system in a setting involving multiple contacts between the manipulated object and the environment. While we find that imitation learning is well suited to solve such complex tasks, not all algorithms are equal in terms of handling environmental and hyperparameter perturbations, training requirements, performance, and ease of use. We investigate the empirical influence of these key characteristics by employing a carefully designed experimental procedure and learning environment.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect16">
             <b>
              WeCT16
             </b>
             Regular Session, 404
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1242" name="modifyWeCT16" onclick="modsession(147,1242)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect16" title="Click to go to the Program at a Glance">
             <b>
              Grasping 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#101853" title="Click to go to the Author Index">
             Jia, Yan-Bin
            </a>
           </td>
           <td class="r">
            Iowa State University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#106228" title="Click to go to the Author Index">
             Spenko, Matthew
            </a>
           </td>
           <td class="r">
            Illinois Institute of Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect16_01">
             11:15-11:20, Paper WeCT16.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1243" name="modify253" onclick="modify(253,1243)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('253'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Trajectory Optimization for Dynamically Grasping Irregular Objects
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#196876" title="Click to go to the Author Index">
             Vu, Minh Nhat
            </a>
           </td>
           <td class="r">
            TU Wien, Austria
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#414782" title="Click to go to the Author Index">
             Grander, Florian
            </a>
           </td>
           <td class="r">
            EGGER Holzwerkstoffe Brilon GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#171078" title="Click to go to the Author Index">
             Nguyen, Anh
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397505" title="Click to go to the Author Index">
             Unger, Christoph
            </a>
           </td>
           <td class="r">
            TU Wien
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab253" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a novel trajectory optimization framework for grasping a thin object with the schunk (SDH2) hand-mounted on a Kuka robot. Unlike a conventional grasping task, we aim to achieve a ``dynamic grasp'' of the object, which requires continuous movement during the grasping process. The trajectory framework comprises two phases. Firstly, in a specified time limit of SI{10}{second}, initial offline trajectories are computed for a seamless motion from an initial configuration of the robot to grasp the object and deliver it to a pre-defined target location. Secondly, fast online trajectory optimization is implemented to update robot trajectories in real time within 100 milliseconds. This helps to mitigate pose estimation errors from the vision system. To account for model inaccuracies, disturbances, and other non-modeled effects, trajectory tracking controllers for both the robot and the gripper are implemented to execute the optimal trajectories from the proposed framework. Simulation and experimental results effectively demonstrate the performance of the trajectory planning framework in real-world scenarios.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect16_02">
             11:20-11:25, Paper WeCT16.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1244" name="modify264" onclick="modify(264,1244)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('264'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DistillGrasp: Integrating Features Correlation with Knowledge Distillation for Depth Completion of Transparent Objects
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#383132" title="Click to go to the Author Index">
             Huang, Yiheng
            </a>
           </td>
           <td class="r">
            Guangdong University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#245461" title="Click to go to the Author Index">
             Chen, Junhong
            </a>
           </td>
           <td class="r">
            Guangdong University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#387553" title="Click to go to the Author Index">
             Michiels, Nick
            </a>
           </td>
           <td class="r">
            Hasselt University - Flanders Make - Expertise Centre for Digita
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#387601" title="Click to go to the Author Index">
             Asim, Muhammad
            </a>
           </td>
           <td class="r">
            Guangdong University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#331956" title="Click to go to the Author Index">
             Claesen, Luc
            </a>
           </td>
           <td class="r">
            Hasselt Univeristy
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#245537" title="Click to go to the Author Index">
             Liu, Wenyin
            </a>
           </td>
           <td class="r">
            Guangdong University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab264" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Due to the visual properties of reflection and refraction, RGB-D cameras cannot accurately capture the depth of transparent objects, leading to incomplete depth maps. To fill in the missing points, recent studies tend to explore new visual features and design complex networks to reconstruct the depth, however, these approaches tremendously increase computation, and the correlation of different visual features remains a problem. To this end, we propose an efficient depth completion network named DistillGrasp which distillates knowledge from the teacher branch to the student branch. Specifically, in the teacher branch, we design a position correlation block (PCB) that leverages RGB images as the query and key to search for the corresponding values, guiding the model to establish correct correspondence between two features and transfer it to the transparent areas. For the student branch, we propose a consistent feature correlation module (CFCM) that retains the reliable regions of RGB images and depth maps respectively according to the consistency and adopts a CNN to capture the pairwise relationship for depth completion. To avoid the student branch only learning regional features from the teacher branch, we devise a distillation loss that not only considers the distance loss but also the object structure and edge information. Extensive experiments conducted on the ClearGrasp dataset manifest that our teacher network outperforms state-of-the-art methods in terms of accuracy and generalization, and the student network achieves competitive results with a higher speed of 48 FPS. In addition, the significant improvement in a real-world robotic grasping system illustrates the effectiveness and robustness of our proposed system.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect16_03">
             11:25-11:30, Paper WeCT16.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1245" name="modify2486" onclick="modify(2486,1245)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2486'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Real-Time Grasp Quality in Boundary-Constrained Granular Swarm Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#271881" title="Click to go to the Author Index">
             Mulroy, Declan
            </a>
           </td>
           <td class="r">
            Illinois Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#340567" title="Click to go to the Author Index">
             Cañones Bonham, David Francesc
            </a>
           </td>
           <td class="r">
            Illinois Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106228" title="Click to go to the Author Index">
             Spenko, Matthew
            </a>
           </td>
           <td class="r">
            Illinois Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#271891" title="Click to go to the Author Index">
             Srivastava, Ankit
            </a>
           </td>
           <td class="r">
            Illinois Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2486" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft robotic grippers offer advantages over rigid end effectors but are typically coupled to a rigid robot for locomotion. In contrast, this paper details a soft robot for both locomotion and grasping. The system is a type of boundary- constrained granular swarm robot, which is composed of a closed-loop series of active (capable of locomotion) sub-robots. Prior work has shown how this type of robot is capable of loco- motion and grasping. For this paper, we propose a new grasping strategy and demonstrate real-time grasp quality evaluation using pressure sensors and the Ferrari-Canny grasp metric. The grasping strategy leverages gradient-based control via distance functions and dynamic system planning to achieve desired robot geometries for effective grasping. Previous research primarily used pull tests to evaluate grasping efficacy, which lacked real- time feedback on grasp quality. Simulated and experimental results confirm the effectiveness of this method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect16_04">
             11:30-11:35, Paper WeCT16.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1246" name="modify2901" onclick="modify(2901,1246)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2901'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Dual-Arm Coordination for Grasping Large Flat Objects
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#304562" title="Click to go to the Author Index">
             Wang, Yongliang
            </a>
           </td>
           <td class="r">
            University of Groningen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#169824" title="Click to go to the Author Index">
             Kasaei, Hamidreza
            </a>
           </td>
           <td class="r">
            University of Groningen
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2901" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#bimanual_manipulation" title="Click to go to the Keyword Index">
               Bimanual Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dual_arm_manipulation" title="Click to go to the Keyword Index">
               Dual Arm Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Grasping large flat objects, such as books or keyboards lying horizontally, presents significant challenges for single-arm robotic systems, often requiring extra actions like pushing objects against walls or moving them to the edge of a surface to facilitate grasping. In contrast, dual-arm manipulation, inspired by human dexterity, offers a more refined solution by directly coordinating both arms to lift and grasp the object without the need for complex repositioning. In this paper, we propose a model-free deep reinforcement learning (DRL) framework to enable dual-arm coordination for grasping large flat objects. We utilize a large scale grasp pose detection model as a backbone to extract high-dimensional features from input images, which are then used as the state representation in a reinforcement learning (RL) model. A CNN-based Proximal Policy Optimization (PPO) algorithm with shared Actor-Critic layers is employed to learn coordinated dual-arm grasp actions. The system is trained and tested in Isaac Gym and deployed to real robots. Experimental results demonstrate that our policy can effectively grasp large flat objects without requiring additional maneuvers. Furthermore, the policy exhibits strong generalization capabilities, successfully handling unseen objects. Importantly, it can be directly transferred to real robots without fine-tuning, consistently outperforming baseline methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect16_05">
             11:35-11:40, Paper WeCT16.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1247" name="modify3033" onclick="modify(3033,1247)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3033'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              QDGset: A Large Scale Grasping Dataset Generated with Quality-Diversity
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338725" title="Click to go to the Author Index">
             Huber, Johann
            </a>
           </td>
           <td class="r">
            ISIR, Sorbonne Université
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#266764" title="Click to go to the Author Index">
             Hélénon, François
            </a>
           </td>
           <td class="r">
            Sorbonne Université
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#393054" title="Click to go to the Author Index">
             Kappel, Mathilde
            </a>
           </td>
           <td class="r">
            Institut Des Systèmes Intelligents Et De Robotique
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424515" title="Click to go to the Author Index">
             Páez Ubieta, Ignacio de Loyola
            </a>
           </td>
           <td class="r">
            University of Alicante
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#132706" title="Click to go to the Author Index">
             Gil, Pablo
            </a>
           </td>
           <td class="r">
            University of Alicante
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104432" title="Click to go to the Author Index">
             Puente, Santiago
            </a>
           </td>
           <td class="r">
            University of Alicante
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102570" title="Click to go to the Author Index">
             Ben Amar, Faiz
            </a>
           </td>
           <td class="r">
            Université Pierre Et Marie Curie, Paris 6
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#110325" title="Click to go to the Author Index">
             Doncieux, Stéphane
            </a>
           </td>
           <td class="r">
            Sorbonne University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3033" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#evolutionary_robotics" title="Click to go to the Keyword Index">
               Evolutionary Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent advances in AI have led to significant results in robotic learning, but skills like grasping remain partially solved. Many recent works exploit synthetic grasping datasets to learn to grasp unknown objects. However, those datasets were generated using simple grasp sampling methods using priors. Recently, Quality-Diversity (QD) algorithms have been proven to make grasp sampling significantly more efficient. In this work, we extend QDG-6DoF, a QD framework for generating object-centric grasps, to scale up the production of synthetic grasping datasets. We propose a data augmentation method that combines the transformation of object meshes with transfer learning from previous grasping repertoires. The conducted experiments show that this approach reduces the number of required evaluations per discovered robust grasp by up to 20%. We used this approach to generate QDGset, a dataset of 6DoF grasp poses that contains about 3.5 and 4.5 times more grasps and objects, respectively, than the previous state-of-the-art. Our method allows anyone to easily generate data, eventually contributing to a large-scale collaborative dataset of synthetic grasps.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect16_06">
             11:40-11:45, Paper WeCT16.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1248" name="modify3579" onclick="modify(3579,1248)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3579'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Patch Tree: Exploiting the Gauss Map and Principal Component Analysis for Robotic Grasping
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101853" title="Click to go to the Author Index">
             Jia, Yan-Bin
            </a>
           </td>
           <td class="r">
            Iowa State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#218824" title="Click to go to the Author Index">
             Xue, Yuechuan
            </a>
           </td>
           <td class="r">
            Amazon.com
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#336805" title="Click to go to the Author Index">
             Tang, Ling
            </a>
           </td>
           <td class="r">
            Iowa State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3579" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#in_hand_manipulation" title="Click to go to the Keyword Index">
               In-Hand Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Grasp planning must consider an object's local geometry (at the finger contacts), for the range of applicable wrenches under friction, and its global geometry, for force closure and grasp quality. Most everyday objects have curved surfaces unamenable to a pure combinatorial approach but treatable with tools from differential geometry. Our idea is to ``discretize'' such a surface in a top-down fashion into elementary patches (e-patches), each consisting of points that would yield close enough wrenches. Preprocessing based on Gaussian curvature decomposes the surface into strictly convex, strictly concave, ruled, and saddle patches. The Gauss map guides the subdivision of any patch with a large variation in the contact force direction, with the aid of a Platonic solid. The principal component analysis (PCA) further subdivides any patch that has a large variation in torque. The final structure is called a {it patch tree}, which stores e-patches at its leaves, and force or torque ranges at its internal nodes. Grasp synthesis and optimization operates on the patch tree with a stack to efficiently prune away non-promising finger placements. Simulation and experiment with a Shadow Hand have been conducted over everyday items. The patch tree exhibits different levels of surface granularity. It has a good promise for efficient planning of finger gaits to carry out grasping and tool manipulation.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect17">
             <b>
              WeCT17
             </b>
             Regular Session, 405
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1249" name="modifyWeCT17" onclick="modsession(259,1249)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect17" title="Click to go to the Program at a Glance">
             <b>
              Localization 4
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#105917" title="Click to go to the Author Index">
             Napp, Nils
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#236390" title="Click to go to the Author Index">
             Laconte, Johann
            </a>
           </td>
           <td class="r">
            French National Research Institute for Agriculture, Food and the Environment (INRAE)
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect17_01">
             11:15-11:20, Paper WeCT17.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1250" name="modify1190" onclick="modify(1190,1250)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1190'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Improved Bag-Of-Words Image Retrieval with Geometric Constraints for Ground Texture Localization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378580" title="Click to go to the Author Index">
             Wilhelm, Aaron
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105917" title="Click to go to the Author Index">
             Napp, Nils
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1190" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Ground texture localization using a downward-facing camera offers a low-cost, high-precision localization solution that is robust to dynamic environments and requires no environmental modification. We present a significantly improved bag-of-words (BoW) image retrieval system for ground texture localization, achieving substantially higher accuracy for global localization and higher precision and recall for loop closure detection in SLAM. Our approach leverages an approximate
             <i>
              k
             </i>
             -means (AKM) vocabulary with soft assignment, and exploits the consistent orientation and constant scale constraints inherent to ground texture localization. Identifying the different needs of global localization vs. loop closure detection for SLAM, we present both high-accuracy and high-speed versions of our algorithm. We test the effect of each of our proposed improvements through an ablation study and demonstrate our method's effectiveness for both global localization and loop closure detection. With numerous ground texture localization systems already using BoW, our method can readily replace other generic BoW systems in their pipeline and immediately improve their results.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect17_02">
             11:20-11:25, Paper WeCT17.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1251" name="modify2850" onclick="modify(2850,1251)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2850'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Improving Indoor Localization Accuracy by Using an Efficient Implicit Neural Map Representation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#246576" title="Click to go to the Author Index">
             Kuang, Haofei
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#284469" title="Click to go to the Author Index">
             Pan, Yue
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#286743" title="Click to go to the Author Index">
             Zhong, Xingguang
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#286641" title="Click to go to the Author Index">
             Wiesmann, Louis
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#137262" title="Click to go to the Author Index">
             Behley, Jens
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101642" title="Click to go to the Author Index">
             Stachniss, Cyrill
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2850" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Globally localizing a mobile robot in a known map is often a foundation for enabling robots to navigate and operate autonomously. In indoor environments, traditional Monte Carlo localization based on occupancy grid maps is considered the gold standard, but its accuracy is limited by the representation capabilities of the occupancy grid map. In this paper, we address the problem of building an effective map representation that allows to accurately perform probabilistic global localization. To this end, we propose an implicit neural map representation that is able to capture positional and directional geometric features from 2D LiDAR scans to efficiently represent the environment and learn a neural network that is able to predict both, the non-projective signed distance and a direction-aware projective distance for an arbitrary point in the mapped environment. This combination of neural map representation with a light-weight neural network allows us to design an efficient observation model within a conventional Monte Carlo localization framework for pose estimation of a robot in real time. We evaluated our approach to indoor localization on a publicly available dataset for global localization and the experimental results indicate that our approach is able to more accurately localize a mobile robot than other localization approaches employing occupancy or existing neural map representations. In contrast to other approaches employing an implicit neural map representation for 2D LiDAR localization, our approach allows to perform real-time pose tracking after convergence and near real-time global localization. The code of our approach is available at: url{https://github.com/PRBonn/enm-mcl}.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect17_03">
             11:25-11:30, Paper WeCT17.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1252" name="modify3077" onclick="modify(3077,1252)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3077'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Semantic and Feature Guided Uncertainty Quantification of Visual Localization for Autonomous Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424754" title="Click to go to the Author Index">
             Wu, Qiyuan
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102926" title="Click to go to the Author Index">
             Campbell, Mark
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3077" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The uncertainty quantification of sensor measurements coupled with deep learning networks is crucial for many robotics systems, especially for safety-critical applications such as self-driving cars. This paper develops an uncertainty quantification approach in the context of visual localization for autonomous driving, where locations are selected based on images. Key to our approach is to learn the measurement uncertainty using light-weight sensor error model, which maps both image feature and semantic information to 2-dimensional error distribution. Our approach enables uncertainty estimation conditioned on the specific context of the matched image pair, implicitly capturing other critical, unannotated factors (e.g., city vs. highway, dynamic vs. static scenes, winter vs. summer) in a latent manner. We demonstrate the accuracy of our uncertainty prediction framework using the Ithaca365 dataset, which includes variations in lighting and weather (sunny, night, snowy). Both the uncertainty quantification of the sensor+network is evaluated, along with Bayesian localization filters using unique sensor gating method. Results show that the measurement error does not follow a Gaussian distribution with poor weather and lighting conditions, and is better predicted by our Gaussian Mixture model.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect17_04">
             11:30-11:35, Paper WeCT17.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1253" name="modify3857" onclick="modify(3857,1253)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3857'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LiLoc: Lifelong Localization Using Adaptive Submap Joining and Egocentric Factor Graph
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#382779" title="Click to go to the Author Index">
             Fang, Yixin
            </a>
           </td>
           <td class="r">
            Southeast University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#268601" title="Click to go to the Author Index">
             Li, Yanyan
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#113640" title="Click to go to the Author Index">
             Qian, Kun
            </a>
           </td>
           <td class="r">
            Southeast University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#123306" title="Click to go to the Author Index">
             Tombari, Federico
            </a>
           </td>
           <td class="r">
            Technische Universität München
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#156231" title="Click to go to the Author Index">
             Wang, Yue
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107947" title="Click to go to the Author Index">
             Lee, Gim Hee
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3857" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes a versatile graph-based lifelong localization framework, LiLoc, which enhances its timeliness by maintaining a single central session while improves the accuracy through multi-modal factors between the central and subsidiary sessions. First, an adaptive submap joining strategy is employed to generate prior submaps (keyframes and poses) for the central session, and to provide priors for subsidiaries when constraints are needed for robust localization. Next, a coarse-to-fine pose initialization for subsidiary sessions is performed using vertical recognition and ICP refinement in the global coordinate frame. To elevate the accuracy of subsequent localization, we propose an egocentric factor graph (EFG) module that integrates the IMU preintegration, LiDAR odometry and scan match factors in a joint optimization manner. Specifically, the scan match factors are constructed by a novel propagation model that efficiently distributes the prior constrains as edges to the relevant prior pose nodes, weighted by noises based on keyframe registration errors. Additionally, the framework supports flexible switching between two modes: relocalization (RLM) and incremental localization (ILM) based on the proposed overlap-based mechanism to select or update the prior submaps from central session. The proposed LiLoc is tested on public and custom datasets, demonstrating accurate localization performance against state-of-the-art methods. Our codes will be publicly available on https://github.com/Yixin-F/LiLoc.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect17_05">
             11:35-11:40, Paper WeCT17.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1254" name="modify4791" onclick="modify(4791,1254)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4791'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ReFeree: Radar-Based Lightweight and Robust Localization Using Feature and Free Space
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#334472" title="Click to go to the Author Index">
             Kim, Hogyun
            </a>
           </td>
           <td class="r">
            Inha University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#334473" title="Click to go to the Author Index">
             Choi, Byunghee
            </a>
           </td>
           <td class="r">
            Inha University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378873" title="Click to go to the Author Index">
             Choi, Euncheol
            </a>
           </td>
           <td class="r">
            Inha University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203908" title="Click to go to the Author Index">
             Cho, Younggun
            </a>
           </td>
           <td class="r">
            Inha University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4791" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Place recognition plays an important role in achieving robust long-term autonomy. Real-world robots face a wide range of weather conditions (e.g. overcast, heavy rain, and snowing) and most sensors (i.e. camera, LiDAR) essentially functioning within or near-visible electromagnetic waves are sensitive to adverse weather conditions,making reliable localization difficult. In contrast, radar is gaining traction due to long electromagnetic waves, which are less affected by environmental changes and weather independence. In this work, we propose a radar-based lightweight and robust place recognition. We achieve rotational invariance and lightweight by selecting a one-dimensional ring-shaped description and robustness by mitigating the impact of false detection utilizing opposite noise characteristics between free space and feature. In addition, the initial heading can be estimated, which can assist in building a SLAM pipeline that combines odometry and registration, which takes into account onboard computing. The proposed method was tested for rigorous validation across various scenarios (i.e. single session, multi-session, and different weather conditions). In particular, we validate our descriptor achieving reliable place recognition performance through the results of extreme environments that lacked structural information such as an OORD dataset.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect17_06">
             11:40-11:45, Paper WeCT17.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1255" name="modify5010" onclick="modify(5010,1255)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5010'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              On the Consistency of Multi-Robot Cooperative Localization: A Transformation-Based Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267966" title="Click to go to the Author Index">
             Hao, Ning
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#255205" title="Click to go to the Author Index">
             He, Fenghua
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#344468" title="Click to go to the Author Index">
             Tian, Chungeng
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#292329" title="Click to go to the Author Index">
             Hou, Yi
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5010" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper investigates the inconsistency problem caused by the mismatch of observability properties commonly found in multi-robot cooperative localization (CL) and simultaneous localization and mapping (SLAM). To address this issue, we propose a transformation-based approach that introduces a linear time-varying transformation to ensure the transformed system possesses a state-independent unobservable subspace. Consequently, its observability properties remain unaffected by the linearization points. We establish the relationship between the unobservable subspaces of the original and transformed systems, guiding the design of the time-varying transformation. We then present a novel estimator based on this method, referred to as the Transformed EKF (T-EKF), which utilizes the transformed system for state estimation, thereby ensuring correct observability and thus consistency. The proposed approach has been extensively validated through both Monte Carlo simulations and real-world experiments, demonstrating better performance in terms of both accuracy and consistency compared to state-of-the-art methods.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect18">
             <b>
              WeCT18
             </b>
             Regular Session, 406
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1256" name="modifyWeCT18" onclick="modsession(563,1256)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect18" title="Click to go to the Program at a Glance">
             <b>
              Software Tools 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#327249" title="Click to go to the Author Index">
             Wauters, Jolan
            </a>
           </td>
           <td class="r">
            Ghent University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#106806" title="Click to go to the Author Index">
             Schlegel, Christian
            </a>
           </td>
           <td class="r">
            University of Applied Sciences Ulm
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect18_01">
             11:15-11:20, Paper WeCT18.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1257" name="modify1957" onclick="modify(1957,1257)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1957'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Chemistry3D: Robotic Interaction Toolkit for Chemistry Experiments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#308276" title="Click to go to the Author Index">
             Li, Shoujie
            </a>
           </td>
           <td class="r">
            Tsinghua Shenzhen International Graduate School
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#373239" title="Click to go to the Author Index">
             Huang, Yan
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421465" title="Click to go to the Author Index">
             Guo, Changqing
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#373387" title="Click to go to the Author Index">
             Wu, Tong
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351188" title="Click to go to the Author Index">
             Zhang, Jiawei
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#322963" title="Click to go to the Author Index">
             Zhang, Linrui
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#318552" title="Click to go to the Author Index">
             Ding, Wenbo
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1957" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#software_tools_for_benchmarking_and_reproducibility" title="Click to go to the Keyword Index">
               Software Tools for Benchmarking and Reproducibility
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#software_architecture_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Software Architecture for Robotic and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#methods_and_tools_for_robot_system_design" title="Click to go to the Keyword Index">
               Methods and Tools for Robot System Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The advent of simulation engines has revolutionized learning and operational efficiency for robots, offering cost-effective and swift pipelines. However, the lack of a universal simulation platform tailored for chemical scenarios impedes progress in robotic manipulation and visualization of reaction processes. Addressing this void, we present Chemistry3D, an innovative toolkit that integrates extensive chemical and robotic knowledge. Chemistry3D not only enables robots to perform chemical experiments but also provides real-time visualization of temperature, color, and pH changes during reactions. Built on the NVIDIA Omniverse platform, Chemistry3D offers interfaces for robot operation, visual inspection, and liquid flow control, facilitating the simulation of special objects such as liquids and transparent entities. Leveraging this toolkit, we have devised RL tasks, object detection, and robot operation scenarios. Additionally, to discern disparities between the rendering engine and the real world, we conducted transparent object detection experiments using Sim2Real, validating the toolkit's exceptional simulation performance. The source code is available at https://github.com/huangyan28/Chemistry3D, and a related tutorial can be found at https://www.omni-chemistry.com.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect18_02">
             11:20-11:25, Paper WeCT18.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1258" name="modify2790" onclick="modify(2790,1258)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2790'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Introducing KUGE: A Simultaneous Control Co-Design Architecture and Its Application to Aerial Robotics Development
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#327249" title="Click to go to the Author Index">
             Wauters, Jolan
            </a>
           </td>
           <td class="r">
            Ghent University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#209623" title="Click to go to the Author Index">
             Lefebvre, Tom
            </a>
           </td>
           <td class="r">
            Ghent University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#208200" title="Click to go to the Author Index">
             Crevecoeur, Guillaume
            </a>
           </td>
           <td class="r">
            Ghent University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2790" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#methods_and_tools_for_robot_system_design" title="Click to go to the Keyword Index">
               Methods and Tools for Robot System Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The increasing complexity of tasks performed by hybrid aerial robotic systems, such as tail-sitters, demands a more integrated approach to their design. Traditional sequential design methods fall short because they separate the control system design from the conceptual design, limiting the potential for discovering coupled solutions. This disjointed process constrains the design space, making it difficult to optimize both the control performance and system dynamics simultaneously. In response to this limitation, there has been growing interest in mission-specific dynamic design procedures, which aim to address specific operational challenges by integrating control and design early in the development process. The multi-disciplinary approach of control co-design (CCD) expands the design space by solving control and system design problems concurrently. The recently introduced DAIMYO framework demonstrated that combining multi-fidelity modelling with a nested CCD approach can tackle the sim-to-real gap. However, DAIMYO’s reliance on Bayesian optimization to account for the computational cost increase of a nested formulation limits its scalability. To address these issues, we propose KUGE, a simultaneous CCD strategy that reduces computational complexity and overcomes dimensionality restrictions through a combined effort of stochastic optimization and Gaussian processes. We validate the effectiveness of KUGE by applying it to the dynamic design of a tail-sitter, showing that it is competitive with the DAIMYO architecture while offering greater computational efficiency.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect18_03">
             11:25-11:30, Paper WeCT18.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1259" name="modify3463" onclick="modify(3463,1259)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3463'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              HEROES: Unreal Engine-Based Human and Emergency Robot Operation Education System
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379050" title="Click to go to the Author Index">
             Chaudhary, Anav
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203104" title="Click to go to the Author Index">
             Tiwari, Kshitij
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#167990" title="Click to go to the Author Index">
             Bera, Aniket
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3463" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning_under_uncertainty" title="Click to go to the Keyword Index">
               Planning under Uncertainty
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Training and preparing first responders and humanitarian robots for Mass Casualty Incidents (MCIs) often poses a challenge owing to the lack of realistic and easily accessible test facilities. While such facilities can offer realistic scenarios post an MCI that can serve training and educational purposes for first responders and humanitarian robots, they are often hard to access owing to logistical constraints. To overcome this challenge, we present HEROES- a versatile Unreal Engine-based simulator for designing novel training simulations for humans and emergency robots for such urban search and rescue operations. The proposed HEROES simulator is capable of generating synthetic datasets for machine learning pipelines that are used for training robot navigation. This work addresses the necessity for a comprehensive training platform in the robotics community, ensuring pragmatic and efficient preparation for real-world emergency scenarios. The strengths of our simulator lie in its adaptability, scalability, and ability to facilitate collaboration between robot developers and first responders, fostering synergy in developing effective strategies for search and rescue operations in MCIs. We conducted a preliminary user study with an average score of 8.1 out of 10 supporting the ability of HEROES to generate sufficiently varied environments and a score of 7.8 out of 10 affirming the usefulness of the simulation environment. HEROES has been integrated with ROS and has been used to train an RL model for a real robot as a proof of concept.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect18_04">
             11:30-11:35, Paper WeCT18.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1260" name="modify3998" onclick="modify(3998,1260)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3998'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              On the Necessity of Real-Time Principles in GPU-Driven Autonomous Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422244" title="Click to go to the Author Index">
             Ali, Syed
            </a>
           </td>
           <td class="r">
            University of North Carolina at Chapel Hill
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354052" title="Click to go to the Author Index">
             Angelopoulos, Angelos
            </a>
           </td>
           <td class="r">
            University of North Carolina at Chapel Hill
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422250" title="Click to go to the Author Index">
             Massey, Denver
            </a>
           </td>
           <td class="r">
            University of North Carolina at Chapel Hill
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424602" title="Click to go to the Author Index">
             Haddix, Sarah Barnes
            </a>
           </td>
           <td class="r">
            The University of North Carolina at Chapel Hill
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422208" title="Click to go to the Author Index">
             Georgiev, Alexander
            </a>
           </td>
           <td class="r">
            University of North Carolina at Chapel Hill
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422246" title="Click to go to the Author Index">
             Goh, Joseph
            </a>
           </td>
           <td class="r">
            University of North Carolina at Chapel Hill
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426326" title="Click to go to the Author Index">
             Wagle, Rohan
            </a>
           </td>
           <td class="r">
            University of North Carolina at Chapel Hill
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#120406" title="Click to go to the Author Index">
             Sarathy, Prakash
            </a>
           </td>
           <td class="r">
            Northrop Grumman
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422488" title="Click to go to the Author Index">
             Anderson, James
            </a>
           </td>
           <td class="r">
            University of North Carolina at Chapel Hill
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107129" title="Click to go to the Author Index">
             Alterovitz, Ron
            </a>
           </td>
           <td class="r">
            University of North Carolina at Chapel Hill
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3998" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#software_architecture_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Software Architecture for Robotic and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#software__middleware_and_programming_environments" title="Click to go to the Keyword Index">
               Software, Middleware and Programming Environments
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robot autonomy is driving an ever-increasing demand for computational power, including on-board multi-core CPUs and accelerators such as GPUs, to enable fast perception, planning, control, and more. Careful scheduling of these computational tasks on the CPU cores and GPUs is important to prevent locking up the finite computational capacity in ways that hinder other critical workloads; delays in computing time-critical tasks like obstacle detection and control can have huge negative consequences for autonomous robots, potentially resulting in damage, substantial financial loss, or even loss of life. In this paper, we leverage recent advances from real-time systems research. We apply TimeWall, a component-based real-time framework, to the computational components of an autonomous drone and experimentally show that the timeliness and safe operation properties of a drone are preserved even in the presence of increasing interfering computational processes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect18_05">
             11:35-11:40, Paper WeCT18.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1261" name="modify4124" onclick="modify(4124,1261)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4124'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              HPRM: High-Performance Robotic Middleware for Intelligent Autonomous Systems
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#390357" title="Click to go to the Author Index">
             Kwok, Jacky
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#396369" title="Click to go to the Author Index">
             Li, Shulu
            </a>
           </td>
           <td class="r">
            UC Berkeley, Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#396990" title="Click to go to the Author Index">
             Lohstroh, Marten
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#196310" title="Click to go to the Author Index">
             Lee, Edward A.
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4124" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#software_architecture_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Software Architecture for Robotic and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_architecture_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Computer Architecture for Robotic and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#software__middleware_and_programming_environments" title="Click to go to the Keyword Index">
               Software, Middleware and Programming Environments
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The rise of intelligent autonomous systems, especially in robotics and autonomous agents, has created a critical need for robust communication middleware that can ensure real-time processing of extensive sensor data. Current robotics middleware like Robot Operating System (ROS) 2 faces challenges with nondeterminism and high communication latency when dealing with large data across multiple subscribers on a multi-core compute platform. To address these issues, we present High-Performance Robotic Middleware (HPRM), built on top of the deterministic coordination language Lingua Franca (LF). HPRM employs optimizations including an in-memory object store for efficient zero-copy transfer of large payloads, adaptive serialization to minimize serialization overhead, and an eager protocol with real-time sockets to reduce handshake latency. Benchmarks show HPRM achieves up to 114x lower latency than ROS2 when broadcasting large messages to multiple nodes. We then demonstrate the benefits of HPRM by integrating it with the CARLA simulator and running reinforcement learning agents along with object detection workloads. In the CARLA autonomous driving application, HPRM attains 91.1% lower latency than ROS2. The deterministic coordination semantics of HPRM, combined with its optimized IPC mechanisms, enable efficient and predictable real-time communication for intelligent autonomous systems. Code and videos can be found on our project page: https://hprm-robotics.github.io/HPRM
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect18_06">
             11:40-11:45, Paper WeCT18.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1262" name="modify4977" onclick="modify(4977,1262)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4977'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CusADi: A GPU Parallelization Framework for Symbolic Expressions and Optimal Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#313251" title="Click to go to the Author Index">
             Jeon, Se Hwan
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#225837" title="Click to go to the Author Index">
             Hong, Seungwoo
            </a>
           </td>
           <td class="r">
            MIT (Massachusetts Institute of Technology)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#369781" title="Click to go to the Author Index">
             Lee, Ho Jae
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#241512" title="Click to go to the Author Index">
             Khazoom, Charles
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106208" title="Click to go to the Author Index">
             Kim, Sangbae
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4977" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#software_tools_for_robot_programming" title="Click to go to the Keyword Index">
               Software Tools for Robot Programming
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The parallelism afforded by GPUs presents significant advantages in training controllers through reinforcement learning (RL). However, integrating model-based optimization into this process remains challenging due to the complexity of formulating and solving optimization problems across thousands of instances. In this work, we present CusADi, an extension of the CasADi symbolic framework to support the parallelization of arbitrary closed-form expressions on GPUs with CUDA. We also formulate a closed-form approximation for solving general optimal control problems, enabling large-scale parallelization and evaluation of MPC controllers. Our results show a ten-fold speedup relative to similar MPC implementation on the CPU, and we demonstrate the use of CusADi for various applications, including parallel simulation, parameter sweeps, and policy training.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect19">
             <b>
              WeCT19
             </b>
             Regular Session, 407
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1263" name="modifyWeCT19" onclick="modsession(583,1263)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect19" title="Click to go to the Program at a Glance">
             <b>
              System Design
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#101815" title="Click to go to the Author Index">
             Roberts, Rodney
            </a>
           </td>
           <td class="r">
            Florida State University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#107418" title="Click to go to the Author Index">
             Wen, John
            </a>
           </td>
           <td class="r">
            Rensselaer Polytechnic Institute
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect19_01">
             11:15-11:20, Paper WeCT19.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1264" name="modify764" onclick="modify(764,1264)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('764'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Optimal Design Manifolds to Design More Practical Robotic Systems
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#367846" title="Click to go to the Author Index">
             Baumgärtner, Jan
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#367847" title="Click to go to the Author Index">
             Puchta, Alexander
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#298566" title="Click to go to the Author Index">
             Fleischer, Jürgen
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology (KIT)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab764" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#methods_and_tools_for_robot_system_design" title="Click to go to the Keyword Index">
               Methods and Tools for Robot System Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces the optimal design manifold as a novel approach for understanding and optimizing the design of robotic systems. Existing optimization frameworks often jointly optimize design and behavior but lack insight into why specific designs are optimal for given tasks. Additionally, a functionally optimal design may not always be the most practical to build and practicality cannot always be captured by an objective function. By defining and learning the optimal design manifold, which represents the space of all optimal solutions, we provide a systematic method for exploring the design space and selecting the most practical optimal design. We apply the optimal design manifold to robot cell layout optimization, robot design optimization, and multi-camera placement and demonstrate its effectiveness in enhancing design choices by enabling a deeper understanding of what makes a design optimal.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect19_02">
             11:20-11:25, Paper WeCT19.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1265" name="modify1673" onclick="modify(1673,1265)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1673'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Monotone Subsystem Decomposition for Efficient Multi-Objective Robot Design
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#325559" title="Click to go to the Author Index">
             Wilhelm, Andrew
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105917" title="Click to go to the Author Index">
             Napp, Nils
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1673" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#methods_and_tools_for_robot_system_design" title="Click to go to the Keyword Index">
               Methods and Tools for Robot System Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#formal_methods_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Formal Methods in Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Automating design minimizes errors, accelerates the design process, and reduces cost. However, automating robot design is challenging due to recursive constraints, multiple design objectives, and cross-domain design complexity possibly spanning multiple abstraction layers. Here we look at the problem of component selection, a combinatorial optimization problem in which a designer, given a robot model, must select compatible components from an extensive catalog. The goal is to satisfy high-level task specifications while optimally balancing trade-offs between competing design objectives. In this paper, we extend our previous constraint programming approach to multi-objective design problems and propose the novel technique of monotone subsystem decomposition to efficiently compute a Pareto front of solutions for large-scale problems. We prove that subsystems can be optimized for their Pareto fronts and, under certain conditions, these results can be used to determine a globally optimal Pareto front. Furthermore, subsystems serve as an intuitive design abstraction and can be reused across various design problems. Using an example quadcopter design problem, we compare our method to a linear programming approach and demonstrate our method scales better for large catalogs, solving a multi-objective problem of 10^25 component combinations in seconds. We then expand the original problem and solve a task-oriented, multi-objective design problem to build a fleet of quadcopters to deliver packages. We compute a Pareto front of solutions in seconds where each solution contains an optimal component-level design and an optimal package delivery schedule for each quadcopter.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect19_03">
             11:25-11:30, Paper WeCT19.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1266" name="modify1689" onclick="modify(1689,1266)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1689'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robust Reinforcement Learning-Based Locomotion for Resource-Constrained Quadrupeds with Exteroceptive Sensing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422036" title="Click to go to the Author Index">
             Plozza, Davide
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422024" title="Click to go to the Author Index">
             Apostol, Patricia
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415905" title="Click to go to the Author Index">
             Joseph, Paul
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423318" title="Click to go to the Author Index">
             Schläpfer, Simon
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335799" title="Click to go to the Author Index">
             Magno, Michele
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1689" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#engineering_for_robotic_systems" title="Click to go to the Keyword Index">
               Engineering for Robotic Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Compact quadrupedal robots are proving increasingly suitable for deployment in real-world scenarios. Their smaller size fosters easy integration into human environments. Nevertheless, real-time locomotion on uneven terrains remains challenging, particularly due to the high computational demands of terrain perception. This paper presents a robust reinforcement learning-based exteroceptive locomotion controller for resource-constrained small-scale quadrupeds in challenging terrains, which exploits real-time elevation mapping, supported by a careful depth sensor selection. We concurrently train both a policy and a state estimator, which together provide an odometry source for elevation mapping, optionally fused with visual-inertial odometry (VIO). We demonstrate the importance of positioning an additional time-of-flight sensor for maintaining robustness even without VIO, thus having the potential to free up computational resources. We experimentally demonstrate that the proposed controller can flawlessly traverse steps up to 17.5 cm in height and achieve an 80% success rate on 22.5 cm steps, both with and without VIO. The proposed controller also achieves accurate forward and yaw velocity tracking of up to 1.0 m/s and 1.5 rad/s respectively. We open-source our training code at github.com/ETH-PBL/elmap-rl-controller.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect19_04">
             11:30-11:35, Paper WeCT19.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1267" name="modify4522" onclick="modify(4522,1267)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4522'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              AeroSafe: Mobile Indoor Air Purification Using Aerosol Residence Time Analysis and Robotic Cough Emulator Testbed
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426834" title="Click to go to the Author Index">
             Tonmoy, Tanjid
            </a>
           </td>
           <td class="r">
            University of California San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426835" title="Click to go to the Author Index">
             Malladi, Rahath
            </a>
           </td>
           <td class="r">
            Plaksha University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426889" title="Click to go to the Author Index">
             Singh, Kaustubh
            </a>
           </td>
           <td class="r">
            Plaksha University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426893" title="Click to go to the Author Index">
             Forsad, Al Hossain
            </a>
           </td>
           <td class="r">
            University of Massachusetts
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#400720" title="Click to go to the Author Index">
             Gupta, Rajesh Kumar
            </a>
           </td>
           <td class="r">
            Halicioglu Data Science Institute, UC San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426897" title="Click to go to the Author Index">
             Martinez, Andres Tejada
            </a>
           </td>
           <td class="r">
            University of Florida
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#289724" title="Click to go to the Author Index">
             Rahman, Tauhidur
            </a>
           </td>
           <td class="r">
            University of California San Diego
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4522" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#software_hardware_integration_for_robot_systems" title="Click to go to the Keyword Index">
               Software-Hardware Integration for Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_based_control" title="Click to go to the Keyword Index">
               Sensor-based Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Indoor air quality plays an essential role in the safety and well-being of occupants, especially in the context of airborne diseases. This paper introduces AeroSafe, a novel approach aimed at enhancing the efficacy of indoor air purification systems through a robotic cough emulator testbed and a digital-twins-based aerosol residence time analysis. Current portable air filters often overlook the concentrations of respiratory aerosols generated by coughs, posing a risk, particularly in high-exposure environments like healthcare facilities and public spaces. To address this gap, we present a robotic dual-agent physical emulator comprising a manoeuvrable mannequin simulating cough events and a portable air purifier autonomously responding to aerosols. The generated data from this emulator trains a digital twins model, combining a physics-based compartment model with a machine learning approach, using Long Short-Term Memory (LSTM) networks and graph convolution layers. Experimental results demonstrate the model's ability to predict aerosol concentration dynamics with a mean residence time prediction error within 35 seconds. The proposed system's real-time intervention strategies outperform static air filter placement, showcasing its potential in mitigating airborne pathogen risks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect19_05">
             11:35-11:40, Paper WeCT19.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1268" name="modify4916" onclick="modify(4916,1268)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4916'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Remote Inspection Techniques: A Review of Autonomous Robotic Inspection for Marine Vessels (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#271702" title="Click to go to the Author Index">
             Andersen, Rasmus Eckholdt
            </a>
           </td>
           <td class="r">
            Technicel University of Denmark
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#284074" title="Click to go to the Author Index">
             Brogaard, Rune Y.
            </a>
           </td>
           <td class="r">
            Explicit Aps
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#180541" title="Click to go to the Author Index">
             Boukas, Evangelos
            </a>
           </td>
           <td class="r">
            Technical University of Denmark
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4916" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Due to the harsh environment and heavy use that modern marine vessels are subjected to, they are required to undergo periodic inspections to determine their current condition. The use of autonomous remote inspection systems can alleviate some of the dangers and shortcomings associated with manual inspection. While there has been research on the use of robotic platforms, none of the works in the literature evaluates the current state of the art with respect to the specifications of the classification societies, who are the most important stakeholders among the end users. The aim of this paper is to provide an overview of the existing literature and evaluate the works individually in collaboration with classification societies. The papers included in this review are either directly developed for, or have properties potentially transferable to, the marine vessel inspection process. To structure the review, an expertise-engineering separation is proposed based on the contributions of the individual paper. This separation shows which part of the inspection process has received the most attention, as well as where the shortcomings of each approach lay. The findings indicate that while there are promising approaches, there is still a gap between the classification societies’ requirements and the state of the art. Our results indicate that, there is quality work in the literature, but there is a lack of integrated development activities that achieve sufficient completeness.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect19_06">
             11:40-11:45, Paper WeCT19.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1269" name="modify4933" onclick="modify(4933,1269)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4933'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Toward Fully Automated Aviation: PIBOT, a Humanoid Robot Pilot, for Human-Centric Aircraft Cockpits
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#285592" title="Click to go to the Author Index">
             Min, Sungjae
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology (KAIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#381132" title="Click to go to the Author Index">
             Kang, Gyuree
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology (KAIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#393823" title="Click to go to the Author Index">
             Kim, Hyungjoo
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology (KAIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104593" title="Click to go to the Author Index">
             Shim, David Hyunchul
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4933" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#humanoid_robot_systems" title="Click to go to the Keyword Index">
               Humanoid Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#engineering_for_robotic_systems" title="Click to go to the Keyword Index">
               Engineering for Robotic Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Humanoid robots have been considered ideal for automating daily tasks, though most research has centered on bipedal locomotion. Many activities we do routinely, such as driving a car, require real-time system manipulation as well as substantial field-specific knowledge. Recent breakthroughs in natural language processing, particularly with large language models (LLMs), are empowering humanoid robots to access and process vast information sources and operate systems with an unprecedented level of autonomy. This article introduces PIBOT, a humanoid robot that can pilot unmodified general aviation (GA) aircraft, physically manipulating instruments while following strict rules of the air and verbally communicating with copilots and air traffic controllers (ATCs). Building on these capabilities, we developed an LLM-based task planner that interprets natural language commands, translating them into action sequences. Then, the behavior decision module breaks tasks into precise limb movements, enabling humanlike control of cockpit instruments. In a series of rigorous simulations, PIBOT demonstrates its capabilities to successfully take off and land an airplane from a cold-and-dark start, showcasing its potential for a fully autonomous robot pilot.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect20">
             <b>
              WeCT20
             </b>
             Regular Session, 408
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1270" name="modifyWeCT20" onclick="modsession(161,1270)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect20" title="Click to go to the Program at a Glance">
             <b>
              Human-Aware Robot Motion
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#104560" title="Click to go to the Author Index">
             Murphey, Todd
            </a>
           </td>
           <td class="r">
            Northwestern University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#119426" title="Click to go to the Author Index">
             Carlone, Luca
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect20_01">
             11:15-11:20, Paper WeCT20.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1271" name="modify1109" onclick="modify(1109,1271)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1109'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Sampling-Based Grasp and Collision Prediction for Assisted Teleoperation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#171397" title="Click to go to the Author Index">
             Manschitz, Simon
            </a>
           </td>
           <td class="r">
            Honda Research Institute Europe
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#321433" title="Click to go to the Author Index">
             Güler, Berk
            </a>
           </td>
           <td class="r">
            TU Darmstadt
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#377295" title="Click to go to the Author Index">
             Ma, Wei
            </a>
           </td>
           <td class="r">
            Honda Research Institute Europe
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#118732" title="Click to go to the Author Index">
             Ruiken, Dirk
            </a>
           </td>
           <td class="r">
            Honda Research Institute Europe
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1109" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Shared autonomy allows for combining the global planning capabilities of a human operator with the strengths of a robot such as repeatability and accurate control. In a real-time teleoperation setting, one possibility for shared autonomy is to let the human operator decide for the rough movement and to let the robot do fine adjustments, e.g., when the view of the operator is occluded. We present a learning-based concept for shared autonomy that aims at supporting the human operator in a real-time teleoperation setting. At every step, our system tracks the target pose set by the human operator as accurately as possible while at the same time satisfying a set of constraints which influence the robot’s behavior. An important characteristic is that the constraints can be dynamically activated and deactivated which allows the system to provide task-specific assistance. Since the system must generate robot commands in real-time, solving an optimization problem in every iteration is not feasible. Instead, we sample potential target configurations and use Neural Networks for predicting the constraint costs for each configuration. By evaluating each configuration in parallel, our system is able to select the target configuration which satisfies the constraints and has the minimum distance to the operator’s target pose with minimal delay. We evaluate the framework with a pick and place task on a bi-manual setup with two Franka Emika Panda robot arms with Robotiq grippers.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect20_02">
             11:20-11:25, Paper WeCT20.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1272" name="modify1177" onclick="modify(1177,1272)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1177'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Inverse Mixed Strategy Games with Generative Trajectory Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#275550" title="Click to go to the Author Index">
             Sun, Max Muchen
            </a>
           </td>
           <td class="r">
            Northwestern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#135211" title="Click to go to the Author Index">
             Trautman, Peter
            </a>
           </td>
           <td class="r">
            Honda Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104560" title="Click to go to the Author Index">
             Murphey, Todd
            </a>
           </td>
           <td class="r">
            Northwestern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1177" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#probabilistic_inference" title="Click to go to the Keyword Index">
               Probabilistic Inference
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Game-theoretic models are effective tools for modeling multi-agent interactions, especially when robots need to coordinate with humans. However, applying these models requires inferring their specifications from observed behaviors---a challenging task known as the inverse game problem. Existing inverse game approaches often struggle to account for behavioral uncertainty and measurement noise, and leverage both offline and online data. To address these limitations, we propose an inverse game method that integrates a generative trajectory model into a differentiable mixed-strategy game framework. By representing the mixed strategy with a conditional variational autoencoder (CVAE), our method can infer high-dimensional, multi-modal behavior distributions from noisy measurements while adapting in real-time to new observations. We extensively evaluate our method in a simulated navigation benchmark, where the observations are generated by an unknown game model. Despite the model mismatch, our method can infer Nash-optimal actions comparable to those of the ground-truth model and the oracle inverse game baseline, even in the presence of uncertain agent objectives and noisy measurements.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect20_03">
             11:25-11:30, Paper WeCT20.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1273" name="modify3218" onclick="modify(3218,1273)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3218'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              AToM: Adaptive Theory-Of-Mind-Based Human Motion Prediction in Long-Term Human-Robot Interactions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421949" title="Click to go to the Author Index">
             Liao, Yuwen
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#224101" title="Click to go to the Author Index">
             Cao, Muqing
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#353500" title="Click to go to the Author Index">
             Xu, Xinhang
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#115410" title="Click to go to the Author Index">
             Xie, Lihua
            </a>
           </td>
           <td class="r">
            NanyangTechnological University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3218" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intention_recognition" title="Click to go to the Keyword Index">
               Intention Recognition
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#long_term_interaction" title="Click to go to the Keyword Index">
               Long term Interaction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Humans learn from observations and experiences to adjust their behaviours towards better performance. Interacting with such dynamic humans is challenging, as the robot needs to predict the humans accurately for safe and efficient operations. Long-term interactions with dynamic humans have not been extensively studied by prior works. We propose an adaptive human prediction model based on the Theory-of-Mind (ToM), a fundamental social-cognitive ability that enables humans to infer others’ behaviours and intentions. We formulate the human internal belief about others using a game-theoretic model, which predicts the future motions of all agents in a navigation scenario. To estimate an evolving belief, we use an Unscented Kalman Filter to update the behavioural parameters in the human internal model. Our formulation provides unique interpretability to dynamic human behaviours by inferring how the human predicts the robot. We demonstrate through long-term experiments in both simulations and real-world settings that our prediction effectively promotes safety and efficiency in downstream robot planning. Code will be available at https://github.com/centiLinda/AToM-human-prediction.git.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect20_04">
             11:30-11:35, Paper WeCT20.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1274" name="modify4003" onclick="modify(4003,1274)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4003'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Dynamic Weight Adjustment for Spatial-Temporal Trajectory Planning in Crowd Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#224101" title="Click to go to the Author Index">
             Cao, Muqing
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#353500" title="Click to go to the Author Index">
             Xu, Xinhang
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#352827" title="Click to go to the Author Index">
             Yang, Yizhuo
            </a>
           </td>
           <td class="r">
            Nangyang Technological Univercity
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#349094" title="Click to go to the Author Index">
             Li, Jianping
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#388426" title="Click to go to the Author Index">
             Jin, Tongxing
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#195430" title="Click to go to the Author Index">
             Wang, Pengfei
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419080" title="Click to go to the Author Index">
             Hung, Tzu-Yi
            </a>
           </td>
           <td class="r">
            Delta Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#192959" title="Click to go to the Author Index">
             Lin, Guosheng
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#115410" title="Click to go to the Author Index">
             Xie, Lihua
            </a>
           </td>
           <td class="r">
            NanyangTechnological University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4003" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robot navigation in dense human crowds poses a significant challenge due to the complexity of human behavior in dynamic and obstacle-rich environments. In this work, we propose a dynamic weight adjustment scheme using a neural network to predict the optimal weights of objectives in an optimization-based motion planner. We adopt a spatial-temporal trajectory planner and incorporate diverse objectives to achieve a balance among safety, efficiency, and goal achievement in complex and dynamic environments. We design the network structure, observation encoding, and reward function to effectively train the policy network using reinforcement learning, allowing the robot to adapt its behavior in real time based on environmental and pedestrian information. Simulation results show improved safety compared to the fixed-weight planner and the state-of-the-art learning-based methods, and verify the ability of the learned policy to adaptively adjust the weights based on the observed situations. The feasibility of the approach is demonstrated in a navigation task using an autonomous delivery robot across a crowded corridor over a 300 m distance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect20_05">
             11:35-11:40, Paper WeCT20.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1275" name="modify4055" onclick="modify(4055,1275)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4055'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              COLLAGE: COLLAborative Human-Agent Interaction Generation Using Hierarchical Latent Diffusion and Language Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#371698" title="Click to go to the Author Index">
             Daiya, Divyanshu
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354530" title="Click to go to the Author Index">
             Conover, Damon
            </a>
           </td>
           <td class="r">
            DEVCOM Army Research Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#167990" title="Click to go to the Author Index">
             Bera, Aniket
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4055" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_and_humanoid_motion_analysis_and_synthesis" title="Click to go to the Keyword Index">
               Human and Humanoid Motion Analysis and Synthesis
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#modeling_and_simulating_humans" title="Click to go to the Keyword Index">
               Modeling and Simulating Humans
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose a novel framework COLLAGE for generating collaborative agent-object-agent interactions by leveraging large language models (LLMs) and hierarchical motion-specific vector-quantized variational autoencoders (VQ-VAEs). Our model addresses the lack of rich datasets in this domain by incorporating the knowledge and reasoning abilities of LLMs to guide a generative diffusion model. The hierarchical VQ-VAE architecture captures different motion-specific characteristics at multiple levels of abstraction, avoiding redundant concepts and enabling efficient multi-resolution representation. We introduce a diffusion model that operates in the latent space and incorporates LLM-generated motion planning cues to guide the denoising process, resulting in prompt-specific motion generation with greater control and diversity. Experimental results on the CORE-4D, and InterHuman datasets demonstrate the effectiveness of our approach in generating realistic and diverse collaborative human-object-human interactions, outperforming state-of-the-art methods. Our work opens up new possibilities for modeling complex interactions in various domains, such as robotics, graphics and computer vision.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect20_06">
             11:40-11:45, Paper WeCT20.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1276" name="modify4895" onclick="modify(4895,1276)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4895'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Long-Term Human Trajectory Prediction Using 3D Dynamic Scene Graphs
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#362995" title="Click to go to the Author Index">
             Gorlo, Nicolas
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#238677" title="Click to go to the Author Index">
             Schmid, Lukas M.
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology (MIT)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#119426" title="Click to go to the Author Index">
             Carlone, Luca
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4895" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_and_humanoid_motion_analysis_and_synthesis" title="Click to go to the Keyword Index">
               Human and Humanoid Motion Analysis and Synthesis
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#datasets_for_human_motion" title="Click to go to the Keyword Index">
               Datasets for Human Motion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#long_term_interaction" title="Click to go to the Keyword Index">
               Long term Interaction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a novel approach for long-term human trajectory prediction in indoor human-centric environments, which is essential for long-horizon robot planning in these environments. State-of-the-art human trajectory prediction methods are limited by their focus on collision avoidance and short-term planning, and their inability to model complex interactions of humans with the environment. In contrast, our approach overcomes these limitations by predicting sequences of human interactions with the environment and using this information to guide trajectory predictions over a horizon of up to 60s. We leverage Large Language Models (LLMs) to predict interactions with the environment by conditioning the LLM prediction on rich contextual information about the scene. This information is given as a 3D Dynamic Scene Graph that encodes the geometry, semantics, and traversability of the environment into a hierarchical representation. We then ground these interaction sequences into multi-modal spatio-temporal distributions over human positions using a probabilistic approach based on continuous-time Markov Chains. To evaluate our approach, we introduce a new semi-synthetic dataset of long-term human trajectories in complex indoor environments, which also includes annotations of human-object interactions. We show in thorough experimental evaluations that our approach achieves a 54% lower average negative log-likelihood (NLL) and a 26.5% lower Best-of-20 displacement error compared to the best non-privileged (i.e., evaluated in a zero-shot fashion on the dataset) baselines for a time horizon of 60s.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect21">
             <b>
              WeCT21
             </b>
             Regular Session, 410
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1277" name="modifyWeCT21" onclick="modsession(495,1277)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect21" title="Click to go to the Program at a Glance">
             <b>
              Robot Foundation Models 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#106689" title="Click to go to the Author Index">
             Posner, Ingmar
            </a>
           </td>
           <td class="r">
            Oxford University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#203352" title="Click to go to the Author Index">
             Zhu, Yuke
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect21_01">
             11:15-11:20, Paper WeCT21.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1278" name="modify999" onclick="modify(999,1278)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('999'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LUMOS: Language-Conditioned Imitation Learning with World Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#236721" title="Click to go to the Author Index">
             Nematollahi, Iman
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420203" title="Click to go to the Author Index">
             DeMoss, Branton
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420120" title="Click to go to the Author Index">
             L Chandra, Akshay
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#116406" title="Click to go to the Author Index">
             Hawes, Nick
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101785" title="Click to go to the Author Index">
             Burgard, Wolfram
            </a>
           </td>
           <td class="r">
            University of Technology Nuremberg
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106689" title="Click to go to the Author Index">
             Posner, Ingmar
            </a>
           </td>
           <td class="r">
            Oxford University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab999" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce LUMOS, a language-conditioned multi-task imitation learning framework for robotics. LUMOS learns skills by practicing them over many long-horizon rollouts in the latent space of a learned world model and transfers these skills zero-shot to a real robot. By learning on-policy in the latent space of the learned world model, our algorithm mitigates policy-induced distribution shift which most offline imitation learning methods suffer from. LUMOS learns from unstructured play data with fewer than 1% hindsight language annotations but is steerable with language commands at test time. We achieve this coherent long-horizon performance by combining latent planning with both image- and language-based hindsight goal relabeling during training, and by optimizing an intrinsic reward defined in the latent space of the world model over multiple time steps, effectively reducing covariate shift. In experiments on the difficult long-horizon CALVIN benchmark, LUMOS outperforms prior learning-based methods with comparable approaches on chained multi-task evaluations. To the best of our knowledge, we are the first to learn a language-conditioned continuous visuomotor control for a real-world robot within an offline world model. Videos, dataset and code are available at http://lumos.cs.uni-freiburg.de.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect21_02">
             11:20-11:25, Paper WeCT21.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1279" name="modify1175" onclick="modify(1175,1279)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1175'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LIMT: Language-Informed Multi-Task Visual World Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#291311" title="Click to go to the Author Index">
             Aljalbout, Elie
            </a>
           </td>
           <td class="r">
            University of Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420546" title="Click to go to the Author Index">
             Sotirakis, Nikolaos
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107642" title="Click to go to the Author Index">
             van der Smagt, Patrick
            </a>
           </td>
           <td class="r">
            Volkswagen Group
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#175184" title="Click to go to the Author Index">
             Karl, Maximilian
            </a>
           </td>
           <td class="r">
            Foundation Robotics Labs
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#149404" title="Click to go to the Author Index">
             Chen, Nutan
            </a>
           </td>
           <td class="r">
            Volkswagen Group
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1175" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Most recent successes in robot reinforcement learning involve learning a specialized single-task agent. However, robots capable of performing multiple tasks can be much more valuable in real-world applications. Multi-task reinforcement learning can be very challenging due to the increased sample complexity and the potentially conflicting task objectives. Previous work on this topic is dominated by model-free approaches. The latter can be very sample inefficient even when learning specialized single-task agents. In this work, we focus on model-based multi-task reinforcement learning. We propose a method for learning multi-task visual world models, leveraging pre-trained language models to extract semantically meaningful task representations. These representations are used by the world model and policy to reason about task similarity in dynamics and behavior. Our results highlight the benefits of using language-driven task representations for world models and a clear advantage of model-based multi-task learning over the more common model-free paradigm.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect21_03">
             11:25-11:30, Paper WeCT21.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1280" name="modify2349" onclick="modify(2349,1280)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2349'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Towards Robust Autonomous Driving: Conditional Multimodal Large Language Models for Fine-Grained Perception
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418277" title="Click to go to the Author Index">
             Sun, Fengzhao
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#367323" title="Click to go to the Author Index">
             Yu, Jun
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420230" title="Click to go to the Author Index">
             Zhang, Yunxiang
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421320" title="Click to go to the Author Index">
             Hou, Jiaming
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420422" title="Click to go to the Author Index">
             Lu, Xilong
            </a>
           </td>
           <td class="r">
            University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422662" title="Click to go to the Author Index">
             Song, Heng
            </a>
           </td>
           <td class="r">
            China Railway No.4 Engineering Group Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#311807" title="Click to go to the Author Index">
             Gao, Fang
            </a>
           </td>
           <td class="r">
            Guangxi University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2349" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multimodal large language models (MLLMs) have shown remarkable performance across various visual understanding tasks. However, most existing MLLMs still lack image detail perception, limiting their effectiveness in tasks that require detailed visual information. In this paper, we introduce Percept-DriveLM, a novel MLLM designed to tackle the fine-grained perception challenges in autonomous driving tasks. At the core of our model is the Visual Fusion Module, which integrates several innovative components: a dynamic resolution mechanism that combines both high and low resolution features, and an RoI conditional mechanism to incorporate object/region-level features identified by offline detectors, further refining the model's fine-grained perception abilities. Trained in a two-stage process, our model demonstrates exceptional performance, outperforming existing MLLMs with comparable parameter sizes and excelling in both autonomous driving perception and general vision-language tasks. The effectiveness of our approach is validated through extensive empirical studies. Code will be available at https://github.com/DebuggerSunfz/PerceptDriveLM.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect21_04">
             11:30-11:35, Paper WeCT21.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1281" name="modify3724" onclick="modify(3724,1281)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3724'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Automated Hybrid Reward Scheduling Via Large Language Models for Robotic Skill Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#285101" title="Click to go to the Author Index">
             Huang, Changxin
            </a>
           </td>
           <td class="r">
            Shenzhen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423492" title="Click to go to the Author Index">
             Liang, Junyang
            </a>
           </td>
           <td class="r">
            Shenzhen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423961" title="Click to go to the Author Index">
             Chang, Yanbin
            </a>
           </td>
           <td class="r">
            Shenzhen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423959" title="Click to go to the Author Index">
             Xu, Jingzhao
            </a>
           </td>
           <td class="r">
            Shenzhen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#130785" title="Click to go to the Author Index">
             Li, Jianqiang
            </a>
           </td>
           <td class="r">
            Shenzhen University,
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3724" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Enabling a high-degree-of-freedom robot to learn specific skills is a challenging task due to the complexity of robotic dynamics. Reinforcement learning (RL) has emerged as a promising solution; however, addressing such problems requires the design of multiple reward functions to account for various constraints in robotic motion. Existing approaches typically sum all reward components indiscriminately to optimize the RL value function and policy. We argue that this uniform inclusion of all reward components in policy optimization is inefficient and limits the robot’s learning performance. To address this, we propose an Automated Hybrid Reward Scheduling (AHRS) framework based on Large Language Models (LLMs). This paradigm dynamically adjusts the learning intensity of each reward component throughout the policy optimization process, enabling robots to acquire skills in a gradual and structured manner. Specifically, we design a multi-branch value network, where each branch corresponds to a distinct reward component. During policy optimization, each branch is assigned a weight that reflects its importance, and these weights are automatically computed based on rules designed by LLMs. The LLM generates a rule set in advance, derived from the task description, and during training, it selects a weight calculation rule from the library based on language prompts that evaluate the performance of each branch. Experimental results demonstrate that the AHRS method achieves an average 6.48% performance improvement across multiple high-degree-of-freedom robotic tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect21_05">
             11:35-11:40, Paper WeCT21.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1282" name="modify4115" onclick="modify(4115,1282)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4115'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RT-Affordance: Affordances Are Versatile Intermediate Representations for Robot Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#291297" title="Click to go to the Author Index">
             Nasiriany, Soroush
            </a>
           </td>
           <td class="r">
            The University of Austin at Texas
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#315580" title="Click to go to the Author Index">
             Kirmani, Sean
            </a>
           </td>
           <td class="r">
            Google DeepMind
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#313414" title="Click to go to the Author Index">
             Ding, Tianli
            </a>
           </td>
           <td class="r">
            Google
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#268839" title="Click to go to the Author Index">
             Smith, Laura
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203352" title="Click to go to the Author Index">
             Zhu, Yuke
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#205427" title="Click to go to the Author Index">
             Driess, Danny
            </a>
           </td>
           <td class="r">
            TU Berlin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#195462" title="Click to go to the Author Index">
             Sadigh, Dorsa
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#241254" title="Click to go to the Author Index">
             Xiao, Ted
            </a>
           </td>
           <td class="r">
            Google DeepMind
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4115" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#big_data_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Big Data in Robotics and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We explore how intermediate policy representations can facilitate generalization by providing guidance on how to perform manipulation tasks. Existing representations such as language, goal images, and trajectory sketches have been shown to be helpful, but these representations either do not provide enough context or provide over-specified context that yields less robust policies. We propose conditioning policies on affordances, which capture the pose of the robot at key stages of the task. Affordances offer expressive yet lightweight abstractions, are easy for users to specify, and facilitate efficient learning by transferring knowledge from large internet datasets. Our method, RT-Affordance, is a hierarchical model that first proposes an affordance plan given the task language, and then conditions the policy on this affordance plan to perform manipulation. Our model can flexibly bridge heterogeneous sources of supervision including large web datasets and robot trajectories. We additionally train our model on cheap-to-collect in-domain affordance images, allowing us to learn new tasks without collecting any additional costly robot trajectories. We show on a diverse set of novel tasks how RT-Affordance exceeds the performance of existing methods by over 50%, and we empirically demonstrate that affordances are robust to novel settings. Videos available at https://snasiriany.me/rt-affordance
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect21_06">
             11:40-11:45, Paper WeCT21.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1283" name="modify4141" onclick="modify(4141,1283)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4141'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Real-To-Sim-To-Real Approach to Robotic Manipulation with VLM-Generated Iterative Keypoint Rewards
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416945" title="Click to go to the Author Index">
             Patel, Shivansh
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426348" title="Click to go to the Author Index">
             Yin, Xinchen
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#308977" title="Click to go to the Author Index">
             Huang, Wenlong
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426336" title="Click to go to the Author Index">
             Garg, Shubham
            </a>
           </td>
           <td class="r">
            Amazon
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426323" title="Click to go to the Author Index">
             Nayyeri, Hooshang
            </a>
           </td>
           <td class="r">
            Amazon
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#142990" title="Click to go to the Author Index">
             Fei-Fei, Li
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#133971" title="Click to go to the Author Index">
             Lazebnik, Svetlana
            </a>
           </td>
           <td class="r">
            University of Illinois
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#237816" title="Click to go to the Author Index">
             Li, Yunzhu
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4141" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensorimotor_learning" title="Click to go to the Keyword Index">
               Sensorimotor Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Task specification for robotic manipulation in open-world environments is challenging, requiring flexible and adaptive objectives that align with human intentions and can evolve through iterative feedback. We introduce Iterative Keypoint Reward (IKER), a visually grounded, Python-based reward function that serves as a dynamic task specification. Our framework leverages VLMs to generate and refine these reward functions for multi-step manipulation tasks. Given RGB-D observations and free-form language instructions, we sample keypoints in the scene and generate a reward function conditioned on these keypoints. IKER operates on the spatial relationships between keypoints, leveraging commonsense priors about the desired behaviors, and enabling precise SE(3) control. We reconstruct real-world scenes in simulation and use the generated rewards to train reinforcement learning (RL) policies, which are then deployed into the real world-forming a real-to-sim-to-real loop. Our approach demonstrates notable capabilities across diverse scenarios, including both prehensile and non-prehensile tasks, showcasing multi-step task execution, spontaneous error recovery, and on-the-fly strategy adjustments. The results highlight IKER's effectiveness in enabling robots to perform multi-step tasks in dynamic environments through iterative reward shaping.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect22">
             <b>
              WeCT22
             </b>
             Regular Session, 411
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1284" name="modifyWeCT22" onclick="modsession(185,1284)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect22" title="Click to go to the Program at a Glance">
             <b>
              Imitation Learning 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#137912" title="Click to go to the Author Index">
             Johns, Edward
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#103153" title="Click to go to the Author Index">
             Kaelbling, Leslie
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect22_01">
             11:15-11:20, Paper WeCT22.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1285" name="modify531" onclick="modify(531,1285)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('531'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Task Specifications from Demonstrations As Probabilistic Automata
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417729" title="Click to go to the Author Index">
             Baert, Mattijs
            </a>
           </td>
           <td class="r">
            Ghent University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#266622" title="Click to go to the Author Index">
             Leroux, Sam
            </a>
           </td>
           <td class="r">
            Ghent University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#211019" title="Click to go to the Author Index">
             Simoens, Pieter
            </a>
           </td>
           <td class="r">
            Ghent University - Imec
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab531" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Specifying tasks for robotic systems traditionally requires coding expertise, deep domain knowledge, and significant time investment. While learning from demonstration offers a promising alternative, existing methods often struggle with tasks of longer horizons. To address this limitation, we introduce a computationally efficient approach for learning probabilistic deterministic finite automata (PDFA) that capture task structures and expert preferences directly from demonstrations. Our approach infers sub-goals and their temporal dependencies, producing an interpretable task specification that domain experts can easily understand and adjust. We validate our method through experiments involving object manipulation tasks, showcasing how our method enables a robot arm to effectively replicate diverse expert strategies while adapting to changing conditions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect22_02">
             11:20-11:25, Paper WeCT22.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1286" name="modify720" onclick="modify(720,1286)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('720'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robot Utility Models: General Policies for Zero-Shot Deployment in New Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#393660" title="Click to go to the Author Index">
             Etukuru, Haritheja
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418850" title="Click to go to the Author Index">
             Naka, Norihito
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418852" title="Click to go to the Author Index">
             Hu, Zijin
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#296072" title="Click to go to the Author Index">
             Lee, Seungjae
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418849" title="Click to go to the Author Index">
             Mehu, Julian
            </a>
           </td>
           <td class="r">
            Hello Robot Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#118894" title="Click to go to the Author Index">
             Edsinger, Aaron
            </a>
           </td>
           <td class="r">
            Hello Robot
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#171475" title="Click to go to the Author Index">
             Paxton, Chris
            </a>
           </td>
           <td class="r">
            Meta AI
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#291566" title="Click to go to the Author Index">
             Chintala, Soumith
            </a>
           </td>
           <td class="r">
            Facebook AI Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#161575" title="Click to go to the Author Index">
             Pinto, Lerrel
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#314022" title="Click to go to the Author Index">
             Shafiullah, Nur Muhammad (Mahi)
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab720" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#big_data_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Big Data in Robotics and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robot models, particularly those trained with large amounts of data, have recently shown a plethora of real-world manipulation and navigation capabilities. Several independent efforts have shown that given sufficient training data in an environment, robot policies can generalize to demonstrated variations in that environment. However, needing to finetune robot models to every new environment stands in stark contrast to models in language or vision that can be deployed zero-shot for open-world problems. In this work, we present Robot Utility Models (RUMs), a framework for training and deploying zero-shot robot policies that can directly generalize to new environments without any finetuning. To create RUMs efficiently, we develop new tools to quickly collect data for mobile manipulation tasks, integrate such data into a policy with multi-modal imitation learning, and deploy policies on-device on Hello Robot Stretch, a cheap commodity robot, with an external mLLM verifier for retrying. We train five such utility models for opening cabinet doors, opening drawers, picking up napkins, picking up paper bags, and reorienting fallen objects. Our system, on average, achieves 90% success rate in unseen, novel environments interacting with unseen objects. Moreover, the utility models can also succeed in different robot and camera set-ups with no further data, training, or fine-tuning. Primary among our lessons are the importance of training data over training algorithm and policy class, guidance about data scaling, necessity for diverse yet high-quality demonstrations, and a recipe for robot introspection and retrying to improve performance on individual environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect22_03">
             11:25-11:30, Paper WeCT22.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1287" name="modify1143" onclick="modify(1143,1287)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1143'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              R+X: Retrieval and Execution from Everyday Human Videos
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#286276" title="Click to go to the Author Index">
             Papagiannis, Georgios
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#291572" title="Click to go to the Author Index">
             Di Palo, Norman
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420588" title="Click to go to the Author Index">
             Vitiello, Pietro
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#137912" title="Click to go to the Author Index">
             Johns, Edward
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1143" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#continual_learning" title="Click to go to the Keyword Index">
               Continual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present R+X, a framework which enables robots to learn skills from long, unlabelled, first-person videos of humans performing everyday tasks. Given a language command from a human, R+X first retrieves short video clips containing relevant behaviour, and then executes the skill by conditioning an in-context imitation learning method on this behaviour. By leveraging a Vision Language Model (VLM) for retrieval, R+X does not require any manual annotation of the videos, and by leveraging in-context learning for execution, robots can perform commanded skills immediately, without requiring a period of training on the retrieved videos. Experiments studying a range of everyday household tasks show that R+X succeeds at translating unlabelled human videos into robust robot skills, and that R+X outperforms several recent alternative methods. Appendix and videos are available at https://www.robot-learning.uk/r-plus-x.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect22_04">
             11:30-11:35, Paper WeCT22.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1288" name="modify2919" onclick="modify(2919,1288)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2919'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ARCap: Collecting High-Quality Human Demonstrations for Robot Learning with Augmented Reality Feedback
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#315905" title="Click to go to the Author Index">
             Chen, Sirui
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#222003" title="Click to go to the Author Index">
             Wang, Chen
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424594" title="Click to go to the Author Index">
             Nguyen, Kaden
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#142990" title="Click to go to the Author Index">
             Fei-Fei, Li
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#132937" title="Click to go to the Author Index">
             Liu, Karen
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2919" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#virtual_reality_and_interfaces" title="Click to go to the Keyword Index">
               Virtual Reality and Interfaces
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent progress in imitation learning from human demonstrations has shown promising results in teaching robots manipulation skills. To further scale up training datasets, recent works start to use portable data collection devices without the need for physical robot hardware. However, due to the absence of on-robot feedback during data collection, the data quality depends heavily on user expertise, and many devices are limited to specific robot embodiments. We propose ARCap, a portable data collection system that provides visual feedback through augmented reality (AR) and haptic warnings to guide users in collecting high-quality demonstrations. Through extensive user studies, we show that ARCap enables novice users to collect robot-executable data that matches robot kinematics and avoids collisions with the scenes. With data collected from ARCap, robots can perform challenging tasks, such as manipulation in cluttered environments and long-horizon cross-embodiment manipulation. ARCap is fully open-source and easy to calibrate; all components are built from off-the-shelf products. More details can be found on our website: href{https://stanford-tml.github.io/ARCap}{stanford-tml.gi thub.io/ARCap}
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect22_05">
             11:35-11:40, Paper WeCT22.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1289" name="modify3327" onclick="modify(3327,1289)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3327'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              XMoP: Whole-Body Control Policy for Zero-Shot Cross-Embodiment Neural Motion Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#382101" title="Click to go to the Author Index">
             Rath, Prabin Kumar
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#160888" title="Click to go to the Author Index">
             Gopalan, Nakul
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3327" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#whole_body_motion_planning_and_control" title="Click to go to the Keyword Index">
               Whole-Body Motion Planning and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Classical manipulator motion planners work across different robot embodiments. However they plan on a pre-specified static environment representation, and are not scalable to unseen dynamic environments. Neural Motion Planners (NMPs) are an appealing alternative to conventional planners as they incorporate different environmental constraints to learn motion policies directly from raw sensor observations. Contemporary state-of-the-art NMPs can successfully plan across different environments. However none of the existing NMPs generalize across robot embodiments. In this paper we propose Cross-Embodiment Motion Policy (XMoP), a neural policy for learning to plan over a distribution of manipulators. XMoP implicitly learns to satisfy kinematic constraints for a distribution of robots and zero-shot transfers the planning behavior to unseen robotic manipulators within this distribution. We achieve this generalization by formulating a whole-body control policy that is trained on planning demonstrations from over three million procedurally sampled robotic manipulators in different simulated environments. Despite being completely trained on synthetic embodiments and environments, our policy exhibits strong sim-to-real generalization across manipulators with different kinematic variations and degrees of freedom with a single set of frozen policy parameters. We evaluate XMoP on 7 commercial manipulators and show successful cross-embodiment motion planning, achieving an average 70% success rate on baseline benchmarks. Furthermore, we demonstrate sim-to-real deployment on two unseen manipulators solving novel planning problems across three real-world domains even with dynamic obstacles.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect22_06">
             11:40-11:45, Paper WeCT22.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1290" name="modify3336" onclick="modify(3336,1290)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3336'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              KALM: Keypoint Abstraction Using Large Models for Object-Relative Imitation Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#298963" title="Click to go to the Author Index">
             Fang, Xiaolin
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425386" title="Click to go to the Author Index">
             Huang, Bo-Ruei
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#337529" title="Click to go to the Author Index">
             Mao, Jiayuan
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425414" title="Click to go to the Author Index">
             Shone, Jasmine
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#202511" title="Click to go to the Author Index">
             Tenenbaum, Joshua
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106519" title="Click to go to the Author Index">
             Lozano-Perez, Tomas
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103153" title="Click to go to the Author Index">
             Kaelbling, Leslie
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3336" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Generalization to novel object configurations and instances across diverse tasks and environments is a critical challenge in robotics. Keypoint-based representations have been proven effective as a succinct representation for capturing essential object features, and for establishing a reference frame in action prediction, enabling data-efficient learning of robot skills. However, their manual design nature and reliance on additional human labels limit their scalability. In this paper, we propose KALM, a framework that leverages large pre-trained vision-language models (LMs) to automatically generate task-relevant and cross-instance consistent keypoints. KALM distills robust and consistent keypoints across views and objects by generating proposals using LMs and verifies them against a small set of robot demonstration data. Based on the generated keypoints, we can train keypoint-conditioned policy models that predict actions in keypoint-centric frames, enabling robots to generalize effectively across varying object poses, camera views, and object instances with similar functional shapes. Our method demonstrates strong performance in the real world, adapting to different tasks and environments from only a handful of demonstrations while requiring no additional labels. Videos can be found at https://kalm-il.github.io/.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wect23">
             <b>
              WeCT23
             </b>
             Regular Session, 412
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1291" name="modifyWeCT23" onclick="modsession(71,1291)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wect23" title="Click to go to the Program at a Glance">
             <b>
              Autonomous Vehicle Perception 5
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#385745" title="Click to go to the Author Index">
             Chun, Il Yong
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#113395" title="Click to go to the Author Index">
             Baca, José
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University-Corpus Christi
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect23_01">
             11:15-11:20, Paper WeCT23.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1292" name="modify130" onclick="modify(130,1292)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('130'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              AutoSplat: Constrained Gaussian Splatting for Autonomous Driving Scene Reconstruction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#412502" title="Click to go to the Author Index">
             Khan, Mustafa
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#336027" title="Click to go to the Author Index">
             Fazlali, Hamidreza
            </a>
           </td>
           <td class="r">
            Noah's Ark Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#287161" title="Click to go to the Author Index">
             Sharma, Dhruv
            </a>
           </td>
           <td class="r">
            Huawei Research Canada
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#310909" title="Click to go to the Author Index">
             Cao, Tongtong
            </a>
           </td>
           <td class="r">
            Noah's Ark Lab, Huawei Technologies
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#306966" title="Click to go to the Author Index">
             Bai, Dongfeng
            </a>
           </td>
           <td class="r">
            Noah's Ark Lab, Huawei Technologies
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#245101" title="Click to go to the Author Index">
             Ren, Yuan
            </a>
           </td>
           <td class="r">
            Noah's Ark Lab, Huawei Technologies Canada Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#123603" title="Click to go to the Author Index">
             Liu, Bingbing
            </a>
           </td>
           <td class="r">
            Huawei Technologies
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab130" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Realistic scene reconstruction and view synthesis are essential for advancing autonomous driving systems by simulating safety-critical scenarios. 3D Gaussian Splatting excels in real-time rendering and static scene reconstructions but struggles with modeling driving scenarios due to complex backgrounds, dynamic objects, and sparse camera views. We propose AutoSplat, a framework employing Gaussian splatting to realistically reconstruct autonomous driving scenes. By imposing geometric constraints on Gaussians representing the road and sky regions, our method enables multi-view consistent simulation of challenging scenarios, including lane changes. Leveraging 3D templates, we introduce a reflected Gaussian consistency constraint to supervise both the visible and unseen side of foreground objects. Moreover, to model the dynamic appearance of foreground objects, we estimate temporally-dependent residual spherical harmonics for each foreground Gaussian. Extensive experiments on Pandaset and KITTI demonstrate that AutoSplat outperforms state-of-the-art methods in scene reconstruction and novel view synthesis across diverse driving scenarios. Our project page can be found here: https://autosplat.github.io/
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect23_02">
             11:20-11:25, Paper WeCT23.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1293" name="modify2685" onclick="modify(2685,1293)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2685'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Diffusion-Based Generative Models for 3D Occupancy Prediction in Autonomous Driving
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416208" title="Click to go to the Author Index">
             Wang, Yunshen
            </a>
           </td>
           <td class="r">
            Beijing University of Posts and Telecommunications
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#298913" title="Click to go to the Author Index">
             Liu, Yicheng
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395631" title="Click to go to the Author Index">
             Yuan, Tianyuan
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#363178" title="Click to go to the Author Index">
             Mao, Yucheng
            </a>
           </td>
           <td class="r">
            University of Science and Techonology Beijing
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421486" title="Click to go to the Author Index">
             Liang, Yingshi
            </a>
           </td>
           <td class="r">
            Beijing University of Posts and Telecommunications
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#347077" title="Click to go to the Author Index">
             Yang, Xiuyu
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420309" title="Click to go to the Author Index">
             Zhang, Honggang
            </a>
           </td>
           <td class="r">
            Beijing University of Posts and Telecommunications
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#207381" title="Click to go to the Author Index">
             Zhao, Hang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2685" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurately predicting 3D occupancy grids from visual inputs is critical for autonomous driving, but current discriminative methods struggle with noisy data, incomplete observations, and the complex structures inherent in 3D scenes. In this work, we reframe 3D occupancy prediction as a generative modeling task using diffusion models, which learn the underlying data distribution and incorporate 3D scene priors. This approach enhances prediction consistency, noise robustness, and better handles the intricacies of 3D spatial structures. Our extensive experiments show that diffusion-based generative models outperform state-of-the-art discriminative approaches, delivering more realistic and accurate occupancy predictions, especially in occluded or low-visibility regions. Moreover, the improved predictions significantly benefit downstream planning tasks, highlighting the practical advantages of our method for real-world autonomous driving applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect23_03">
             11:25-11:30, Paper WeCT23.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1294" name="modify2921" onclick="modify(2921,1294)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2921'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Interactive4D: Interactive 4D LiDAR Segmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419680" title="Click to go to the Author Index">
             Fradlin, Ilya
            </a>
           </td>
           <td class="r">
            Rwth Aachen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#343290" title="Click to go to the Author Index">
             Zulfikar, Idil Esen
            </a>
           </td>
           <td class="r">
            RWTH Aachen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#375202" title="Click to go to the Author Index">
             Yilmaz, Kadir
            </a>
           </td>
           <td class="r">
            RWTH Aachen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#228314" title="Click to go to the Author Index">
             Kontogianni, Theodora
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#115270" title="Click to go to the Author Index">
             Leibe, Bastian
            </a>
           </td>
           <td class="r">
            RWTH Aachen University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2921" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Interactive segmentation has an important role in facilitating the annotation process of future LiDAR datasets. Existing approaches sequentially segment individual objects at each LiDAR scan, repeating the process throughout the entire sequence, which is redundant and ineffective. In this work, we propose interactive 4D segmentation, a new paradigm that allows segmenting multiple objects on multiple LiDAR scans simultaneously, and Interactive4D, the first interactive 4D segmentation model that segments multiple objects on superimposed consecutive LiDAR scans in a single iteration by utilizing the sequential nature of LiDAR data. While performing interactive segmentation, our model leverages the entire space- time volume, leading to more efficient segmentation. Operating on the 4D volume, it directly provides consistent instance IDs over time and also simplifies tracking annotations. Moreover, we show that click simulations are crucial for successful model training on LiDAR point clouds. To this end, we design a click simulation strategy that is better suited for the char- acteristics of LiDAR data. To demonstrate its accuracy and effectiveness, we evaluate Interactive4D on multiple LiDAR datasets, where Interactive4D achieves a new state-of-the-art by a large margin. We publicly release the code and models at https://vision.rwth-aachen.de/Interactive4D.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect23_04">
             11:30-11:35, Paper WeCT23.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1295" name="modify3290" onclick="modify(3290,1295)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3290'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robust Scene Change Detection Using Visual Foundation Models and Cross-Attention Mechanisms
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419778" title="Click to go to the Author Index">
             Lin, Chun-Jung
            </a>
           </td>
           <td class="r">
            The University of Adelaide
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#196783" title="Click to go to the Author Index">
             Garg, Sourav
            </a>
           </td>
           <td class="r">
            University of Adelaide
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#204257" title="Click to go to the Author Index">
             Chin, Tat-Jun
            </a>
           </td>
           <td class="r">
            The University of Adelaide
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#116733" title="Click to go to the Author Index">
             Dayoub, Feras
            </a>
           </td>
           <td class="r">
            The University of Adelaide
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3290" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#environment_monitoring_and_management" title="Click to go to the Keyword Index">
               Environment Monitoring and Management
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a novel method for scene change detection that leverages the robust feature extraction capabilities of a visual foundational model, DINOv2, and integrates full-image cross-attention to address key challenges such as varying lighting, seasonal variations, and viewpoint differences. In order to effectively learn correspondences and mis-correspondences between an image pair for the change detection task, we propose to a) “freeze” the backbone in order to retain the generality of dense foundation features, and b) employ “full-image” cross-attention to better tackle the viewpoint variations between the image pair. We evaluate our approach on two benchmark datasets, VL-CMU-CD and PSCD, along with their viewpoint-varied versions. Our experiments demonstrate significant improvements in F1-score, particularly in scenarios involving geometric changes between image pairs. The results indicate our method’s superior generalization capabilities over existing state-of-the-art approaches, showing robustness against photometric and geometric variations as well as better overall generalization when fine-tuned to adapt to new environments. Detailed ablation studies further validate the contributions of each component in our architecture. Our source code is available at: https://github.com/ChadLin9596/Robust-Scene-Change-Detection.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect23_05">
             11:35-11:40, Paper WeCT23.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1296" name="modify3381" onclick="modify(3381,1296)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3381'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LaB-CL: Localized and Balanced Contrastive Learning for Improving Parking Slot Detection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421816" title="Click to go to the Author Index">
             Jeong, U Jin
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425201" title="Click to go to the Author Index">
             Roh, Sumin
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#385745" title="Click to go to the Author Index">
             Chun, Il Yong
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3381" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Parking slot detection is an essential technology in autonomous parking systems. In general, the classification problem of parking slot detection consists of two tasks, a task determining whether localized candidates are junctions of parking slots or not, and the other that identifies a shape of detected junctions. Both classification tasks can easily face biased learning toward the majority class, degrading classification performances. Yet, the data imbalance issue has been overlooked in parking slot detection. We propose the first supervised contrastive learning framework for parking slot detection, Localized and Balanced Contrastive Learning for improving parking slot detection (LaB-CL). The proposed LaB-CL framework uses two main approaches. First, we propose to include class prototypes to consider representations from all classes in every mini batch, from the local perspective. Second, we propose a new hard negative sampling scheme that selects local representations with high prediction error. Experiments with the benchmark dataset demonstrate that the proposed LaB-CL framework can outperform existing parking slot detection methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wect23_06">
             11:40-11:45, Paper WeCT23.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1297" name="modify4958" onclick="modify(4958,1297)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4958'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LiCROcc: Teach Radar for Accurate Semantic Occupancy Prediction Using LiDAR and Camera
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#324369" title="Click to go to the Author Index">
             Ma, Yukai
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#337892" title="Click to go to the Author Index">
             Mei, Jianbiao
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#272741" title="Click to go to the Author Index">
             Yang, Xuemeng
            </a>
           </td>
           <td class="r">
            Shanghai Artificial Intelligence Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#272739" title="Click to go to the Author Index">
             Wen, Licheng
            </a>
           </td>
           <td class="r">
            Shanghai AI Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#412023" title="Click to go to the Author Index">
             Xu, Weihua
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#412016" title="Click to go to the Author Index">
             Zhang, Jiangning
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#209861" title="Click to go to the Author Index">
             Zuo, Xingxing
            </a>
           </td>
           <td class="r">
            Caltech
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#371887" title="Click to go to the Author Index">
             Shi, Botian
            </a>
           </td>
           <td class="r">
            Shanghai AI Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#122966" title="Click to go to the Author Index">
             Liu, Yong
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4958" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Semantic Scene Completion (SSC) is pivotal in autonomous driving perception, frequently confronted with the complexities of weather and illumination changes. The long-term strategy involves fusing multi-modal information to bolster the system's robustness. Radar, increasingly utilized for 3D target detection, is gradually replacing LiDAR in autonomous driving applications, offering a robust sensing alternative. In this paper, we focus on the potential of 3D radar in semantic scene completion, pioneering cross-modal refinement techniques for improved robustness against weather and illumination changes and enhancing SSC performance. Regarding model architecture, we propose a three-stage tight fusion approach on BEV to realize a fusion framework for point clouds and images. Based on this foundation, we designed three cross-modal distillation modules—CMRD, BRD, and PDD. Our approach enhances the performance in radar-only (R-LiCROcc) and radar-camera (RC-LiCROcc) settings by distilling to them the rich semantic and structural information of the fused features of LiDAR and camera. Finally, our LC-Fusion, R-LiCROcc and RC-LiCROcc achieve the best performance on the nuScenes-Occupancy dataset, with mIOU exceeding the baseline by 22.9%, 44.1%, and 15.5%, respectively. The project page is available at url{https://hr-zju.github.io/LiCROcc/}.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="welb2r">
             <b>
              WeLB2R
             </b>
             Poster Session, Hall A1/A2
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1298" name="modifyWeLB2R" onclick="modsession(673,1298)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#welb2r" title="Click to go to the Program at a Glance">
             <b>
              Late Breaking Results 4
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_01">
             14:45-15:15, Paper WeLB2R.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1299" name="modify5266" onclick="modify(5266,1299)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5266'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ChicGrasp: Imitation-Learning Control for Dual-Finger Manipulation of Delicate, Irregular, and Bio-Products
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457489" title="Click to go to the Author Index">
             Davar, Amirreza
            </a>
           </td>
           <td class="r">
            University of Arkansas
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#357663" title="Click to go to the Author Index">
             Xu, Zhengtong
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457256" title="Click to go to the Author Index">
             Mahmoudi, Siavash
            </a>
           </td>
           <td class="r">
            University of Arkansas at Fayetteville
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#184771" title="Click to go to the Author Index">
             She, Yu
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#297215" title="Click to go to the Author Index">
             Shou, Wan
            </a>
           </td>
           <td class="r">
            University of Arkansas
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#413738" title="Click to go to the Author Index">
             Wang, Dongyi
            </a>
           </td>
           <td class="r">
            University of Arkansas
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5266" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The pick-and-rehang operation in poultry processing remains manual even with other advancements in automation. In this paper, we present ChicGrasp, an imitative-learning setup that enables a UR10e robot with an independently controlled dual-jaw pneumatic gripper to perform the process of picking up and rehanging chicken. A conditional denoising diffusion model is conditioned on 50 teleoperation demonstrations (RGB image, proprioception, and gripper state) to acquire continuous robot motion and discrete gripper movement; continuous jaw logits during runtime are thresholded to control an Arduino-actuated solenoid valve. Experimental trials demonstrate that the diffusion-based policy, together with our custom gripper, achieved a 40.6% grasp-and-lift success rate and took 38 seconds to complete the entire pick-to-shackle task (with 10 seconds for placement), while an Implicit Behavior Cloning baseline failed completely. In addition, a fixed seven-waypoint trajectory achieved 100% rehang consistency if picking was successful. These findings demonstrate the effectiveness of diffusion policies, in conjunction with task-specific end-effectors, to handle fragile, non-regular objects in semi-real factory environments. Real-time force/torque sensing will be included in future work, and a motion capture teleoperation system will be used for the rehanging process. Moreover, other algorithms, such as LSTM-GMM and 3D diffusion policy will be investigated.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_02">
             14:45-15:15, Paper WeLB2R.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1300" name="modify5267" onclick="modify(5267,1300)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5267'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Uncertainty-Aware Scan Planning for Autonomous Robotic Welding
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104339" title="Click to go to the Author Index">
             Yamane, Katsu
            </a>
           </td>
           <td class="r">
            Path Robotics Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457490" title="Click to go to the Author Index">
             Nehete, Ashwin
            </a>
           </td>
           <td class="r">
            Path Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#291751" title="Click to go to the Author Index">
             Baskaran, Amrish
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#366524" title="Click to go to the Author Index">
             Balajepalli, Surag
            </a>
           </td>
           <td class="r">
            Path Robotics Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457491" title="Click to go to the Author Index">
             Alex, Trazkovich
            </a>
           </td>
           <td class="r">
            Path Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#139648" title="Click to go to the Author Index">
             Klein, Matthew
            </a>
           </td>
           <td class="r">
            Path Robotics, Inc
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5267" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#planning_under_uncertainty" title="Click to go to the Keyword Index">
               Planning under Uncertainty
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Obtaining good scans of the part around seams is critical for realizing accurate welds using an autonomous robotic system where part placement may have errors. We present a pipeline for planning scan trajectories that realizes high scan quality under part placement uncertainty. The planning is done offline to minimize the cycle time. The poster describes a metric for evaluating the uncertainty awareness that can be computed efficiently using the concepts of control variate and importance sampling. We also present the underlying scan trajectory planning algorithm that optimizes the stability of Iterative Closest Point (ICP) algorithm.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_03">
             14:45-15:15, Paper WeLB2R.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1301" name="modify5268" onclick="modify(5268,1301)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5268'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Automated Fabrication of Magnetic Soft Microrobots (MSRs)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457365" title="Click to go to the Author Index">
             Xie, Siwen
            </a>
           </td>
           <td class="r">
            McMaster University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457366" title="Click to go to the Author Index">
             Clancy, Kaitlyn
            </a>
           </td>
           <td class="r">
            McMaster University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203713" title="Click to go to the Author Index">
             Onaizah, Onaizah
            </a>
           </td>
           <td class="r">
            McMaster University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5268" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_and_flexible_manufacturing" title="Click to go to the Keyword Index">
               Intelligent and Flexible Manufacturing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The advent of 3D printing has revolutionized many industries and has had similar improvements for soft robots. However, many challenges persist for these functional devices. Magnetic soft robots require the addition of magnetic particles that must be correctly oriented. There is a significant gap in the automated fabrication of 3D geometric structures with 3D magnetization direction. A fully automated 3D printer was designed to improve accuracy, speed, and reproducibility. This design was able to achieve a circular spot size(voxels) of 1.6mm in diameter. An updated optical system can improve the resolution to a square spot size of 50μm by 50μm. The new system achieves higher resolution designs as shown through magneto-mechanical simulations. Various microrobots including 'worm', 'gripper' and 'zipper' designs are evaluated with the new spot size.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_04">
             14:45-15:15, Paper WeLB2R.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1302" name="modify5270" onclick="modify(5270,1302)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5270'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design and Control of an Ankle Foot Prosthesis with a Novel Spring Geometry
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#341003" title="Click to go to the Author Index">
             Carmichael, Nathan
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#178162" title="Click to go to the Author Index">
             Shepherd, Max
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5270" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#prosthetics_and_exoskeletons" title="Click to go to the Keyword Index">
               Prosthetics and Exoskeletons
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic prostheses have the potential to dramatically improve amputee mobility, but many current state-of-the-art robotic devices cannot perform high-fidelity force control, and many are not powerful enough to emulate peak ankle torque at biological speeds. Current robotic systems suffer from excessive torque-tracking error, poor torque control bandwidth, and inability to precisely render passive mechanics. To overcome these obstacles, we have designed and manufactured the NEUfoot, a powerful platform for patient preference. To harness patient perception to tune a controller that is effective within the expected task space, the NEUfoot needs to emulate passive dynamics at a higher resolution than subjects can detect. To enable high fidelity ankle torque sensing for closed loop control, our system employs an ultra-high-resolution encoder for measuring spring deflection and a torque sensor, producing torque tracking that is both precise and accurate. By combining this encoder with a harmonic drive and a novel composite spring, we have achieved excellent torque control and the highest peak torque at biological speeds of any state-of-the-art foot-ankle prosthesis. We show that we can achieve good zero-impedance torque tracking at a high control loop frequency, which will enable high fidelity impedance control for patient preference experiments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_05">
             14:45-15:15, Paper WeLB2R.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1303" name="modify5271" onclick="modify(5271,1303)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5271'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              AI-Based Wearable Gait Analysis for Proactive Fall Risk Prediction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457494" title="Click to go to the Author Index">
             Kim, Patrick
            </a>
           </td>
           <td class="r">
            The Governor's Academy
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5271" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#datasets_for_human_motion" title="Click to go to the Keyword Index">
               Datasets for Human Motion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study presents an AI-based framework for detecting anomalous gait patterns using deep learning techniques. We leveraged the UCI Human Activity Recognition dataset containing tri-axial accelerometer and gyroscope data from smartphones. Two models were developed: an autoencoder that reconstructs typical gait patterns and a GAN that distinguishes between normal and abnormal sequences. Data preprocessing involved window segmentation (2s, 50% overlap) and normalization. Models were trained exclusively on normal gait data, with synthetic anomalies introduced for evaluation. The autoencoder achieved 92.5% accuracy (sensitivity: 0.90, specificity: 0.94) with normal segments showing low reconstruction error (0.08±0.01) compared to anomalous segments (0.20±0.03). The GAN demonstrated comparable performance with 93.2% accuracy (sensitivity: 0.92, specificity: 0.93). These findings highlight deep learning's potential to detect subtle gait abnormalities, enabling early intervention and continuous monitoring in clinical settings, though limited dataset size warrants future research with diverse cohorts and real-world perturbations.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_06">
             14:45-15:15, Paper WeLB2R.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1304" name="modify5272" onclick="modify(5272,1304)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5272'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design of a Quasi-Passive Ankle Prosthesis with Two Degrees of Stiffness Variability
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457497" title="Click to go to the Author Index">
             Lee, Kathryn
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#178162" title="Click to go to the Author Index">
             Shepherd, Max
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5272" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#prosthetics_and_exoskeletons" title="Click to go to the Keyword Index">
               Prosthetics and Exoskeletons
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#wearable_robotics" title="Click to go to the Keyword Index">
               Wearable Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper will outline an approach to the design, control, and validation of a quasi-passive variable stiffness ankle prosthesis. The prosthesis can vary its overall stiffness via a novel linkage-based variable transmission. This transmission presents an improvement over prior designs in the field by eliminating backlash and maintaining the neutral ankle angle during stiffness variation. The prosthesis can additionally vary its plantarflexion stiffness via a sliding fulcrum. This adds a second degree of stiffness variation: the dorsiflexion to plantarflexion stiffness ratio. The stiffness of the foot will be characterized, and the ability of the foot to be used in an optimization procedure for user stiffness preference will be validated. This foot may be used as a clinical tool to facilitate the incorporation of stiffness preference into the prosthesis prescription process. It may be coupled with a task-identifying algorithm to serve as a daily-use prosthesis that can adjust stiffness based on the present gait task.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_07">
             14:45-15:15, Paper WeLB2R.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1305" name="modify5273" onclick="modify(5273,1305)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5273'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Automated 3D-Printing of Magnetic Soft Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457366" title="Click to go to the Author Index">
             Clancy, Kaitlyn
            </a>
           </td>
           <td class="r">
            McMaster University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203713" title="Click to go to the Author Index">
             Onaizah, Onaizah
            </a>
           </td>
           <td class="r">
            McMaster University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5273" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_and_flexible_manufacturing" title="Click to go to the Keyword Index">
               Intelligent and Flexible Manufacturing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Magnetic soft robots (MSRs) are a viable tool for many biomedical applications, such as targeted drug delivery and minimally invasive surgery, since they can be actuated remotely using external magnetic fields. These robots are developed by programming ferromagnetic domains with specific magnetizations using magnetic particles embedded in a flexible substrate. Existing fabrication methods rely on partially automated or manual processes, which limit production rates and realistic design iterations. To address these challenges, a fully automated workflow that translates robot simulations into an instruction set for a stereolithography three-dimensional (3D) printer is presented. In this process, a rotating permanent magnet is used to program 3D magnetizations by reorienting hard magnetic particles within a photosensitive resin. Geometric resolutions of 1.6 mm are achieved with a layer height of 0.1 mm. Demonstrated applications include rolling and climbing locomotion in a maze and independent control of each arm in a multiarmed robot. By enabling fast, repeatable production of MSRs within 30 min, this automated system shortens the feedback loop from design to application, advancing their potential as a biomedical tool.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_08">
             14:45-15:15, Paper WeLB2R.8
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1306" name="modify5274" onclick="modify(5274,1306)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5274'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Post-Convergence Sim-To-Real Policy Transfer: A Principled Alternative to Cherry-Picking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#443079" title="Click to go to the Author Index">
             Khor, Dylan
            </a>
           </td>
           <td class="r">
            Iowa State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#238455" title="Click to go to the Author Index">
             Weng, Bowen
            </a>
           </td>
           <td class="r">
            Iowa State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5274" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#probability_and_statistical_methods" title="Click to go to the Keyword Index">
               Probability and Statistical Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Learning-based approaches, particularly reinforcement learning (RL), have become widely used for developing policies for autonomous agents, such as locomotion policies for legged robots. RL training typically maximizes a predefined reward (or minimizes a corresponding cost/loss) by iteratively optimizing policies within a simulator. Starting from a randomly initialized policy, the empirical expected reward follows a trajectory with an overall increasing trend. While some policies become temporarily stuck in local optima, a well-defined training process generally converges to a reward level with noisy oscillations. However, selecting a policy for real-world deployment is rarely an analytical decision (i.e., simply choosing the one with the highest reward) and is instead often performed through trial and error. To improve sim-to-real transfer, some focus on the pre-convergence stage, employing techniques such as domain randomization, multi-fidelity training, adversarial training, and architectural innovations. However, these methods do not eliminate the inevitable convergence trajectory and noisy oscillations of rewards, leading to heuristic policy selection or cherry-picking. This project addresses the post-convergence sim-to-real transfer problem by introducing a worst-case performance transference optimization approach, formulated as an optimization problem. Extensive experiments demonstrate its effectiveness in transferring locomotion policies from simulation to real-world.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_09">
             14:45-15:15, Paper WeLB2R.9
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1307" name="modify5275" onclick="modify(5275,1307)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5275'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Deep Monocular Vision-Inertial State Estimation for Autonomous UAV Shipboard Landing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457495" title="Click to go to the Author Index">
             Wickramasuriya, Maneesha
            </a>
           </td>
           <td class="r">
            The George Washington University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#161383" title="Click to go to the Author Index">
             Lee, Taeyoung
            </a>
           </td>
           <td class="r">
            George Washington University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457509" title="Click to go to the Author Index">
             Snyder, Murray
            </a>
           </td>
           <td class="r">
            The George Washington University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5275" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work presents a deep learning-based monocular vision-inertial system for relative state estimation of an unmanned aerial vehicle (UAV) during autonomous shipboard landing. Building on our prior Transformer Neural Network Multi Object(TNN-MO) for pose estimation from monocular images, we integrate inertial measurements through an Extended Kalman Filter (EKF) for robust state estimation under motion blur, challenging dynamic lighting conditions, and GPS-denied conditions. The TNN-MO is trained to detect 2D keypoints of predefined ship structures using a synthetic dataset rendered in Blender with diverse textures, lighting, and viewpoints. 	 We validate our system through both indoor and outdoor experiments. Indoor tests utilize our vision-in-the-loop simulation framework based on photo-realistic environments created with 3D Gaussian Splatting (3DGS). Outdoor validation is performed through in-situ flight experiments using the US Naval Academy research vessel. Results show enhanced accuracy and robustness over vision-only and GPS-based methods, demonstrating the system’s effectiveness for autonomous UAV operations in dynamic maritime environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_10">
             14:45-15:15, Paper WeLB2R.10
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1308" name="modify5276" onclick="modify(5276,1308)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5276'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Efficient Social Navigation: Leveraging Discrete Morse Theory for Dynamic Agent Interaction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#452917" title="Click to go to the Author Index">
             Mursalin, S.M. Faiaz
            </a>
           </td>
           <td class="r">
            Missouri State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#149314" title="Click to go to the Author Index">
             Ekenna, Chinwe
            </a>
           </td>
           <td class="r">
            University at Albany
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#187435" title="Click to go to the Author Index">
             Ghosh, Mukulika
            </a>
           </td>
           <td class="r">
            Missouri State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5276" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic navigation in dynamic environments presents significant challenges, particularly in managing interactions with moving agents while ensuring efficient path planning. We introduce a novel integration of social navigation strategies with topological path planning, leveraging Discrete Morse Theory, Vietoris-Rips complex, and a homotopical framework to enhance adaptability. Our method dynamically assesses path feasibility and optimizes trajectory selection through three key strategies: waiting, deflection, and diverse path selection. By incorporating Morse values into a sampling-based roadmap, our approach prioritizes critical configurations for efficient motion planning. Unlike existing methods that rely on static heuristics or extensive learning-based predictions, our framework offers a real-time, adaptive mechanism for congestion-aware navigation. Experimental evaluations demonstrate an efficient solution(&lt; 100s in computation) with improved path adaptability, resulting in 30 − 60% increase in traversal time in environments containing 3 − 9 degrees of freedom robot and 15 − 60 dynamic agents.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_11">
             14:45-15:15, Paper WeLB2R.11
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1309" name="modify5277" onclick="modify(5277,1309)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5277'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Model-Based Learning for High-Resolution Radar Imaging in Autonomous Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457505" title="Click to go to the Author Index">
             Zheng, Ruxin
            </a>
           </td>
           <td class="r">
            The University of Alabama]
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457500" title="Click to go to the Author Index">
             Sun, Shunqiao
            </a>
           </td>
           <td class="r">
            The University of Alabama
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457502" title="Click to go to the Author Index">
             Liu, Hongshan
            </a>
           </td>
           <td class="r">
            The University of Alabama
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457506" title="Click to go to the Author Index">
             Chen, Honglei
            </a>
           </td>
           <td class="r">
            The MathWorks
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457508" title="Click to go to the Author Index">
             Li, Jian
            </a>
           </td>
           <td class="r">
            University of Florida
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5277" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Millimeter-wave (mmWave) radars are indispensable for perception tasks of autonomous vehicles, thanks to their resilience in challenging weather and light conditions. Yet, their deployment is often limited by insufficient spatial resolution for precise semantic scene interpretation. Classical super-resolution techniques adapted from optical imaging inadequately address the distinct characteristics of radar data. In response, our study herein redefines super-resolution radar imaging as a one-dimensional (1D) signal super-resolution spectra estimation problem by harnessing the radar signal domain knowledge, introducing innovative data normalization, signal-level augmentation, and a domain-informed signal-to-noise ratio (SNR)-guided loss function. Like an image drawn with points and lines, radar imaging can be viewed as generated from points (antenna elements) and lines (frequency spectra). Our tailored deep learning network for automotive radar imaging exhibits remarkable scalability and parameter efficiency, alongside enhanced performance in terms of radar imaging quality and resolution. We further present a novel real-world dataset, pivotal for both advancing radar imaging and refining super-resolution spectra estimation techniques. Extensive testing confirms that our SR-SPECNet sets a new benchmark in producing high-resolution radar range-azimuth images, outperforming existing methods. The source code is available at https://github.com/ruxinzh/SR-SPECNet.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_12">
             14:45-15:15, Paper WeLB2R.12
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1310" name="modify5278" onclick="modify(5278,1310)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5278'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Energy-Aware Informative Path Planning for Heterogeneous Multi-Robot System
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#313179" title="Click to go to the Author Index">
             Munir, Aiman
            </a>
           </td>
           <td class="r">
            University of Georgia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#159383" title="Click to go to the Author Index">
             Dutta, Ayan
            </a>
           </td>
           <td class="r">
            University of North Florida
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#152911" title="Click to go to the Author Index">
             Parasuraman, Ramviyas
            </a>
           </td>
           <td class="r">
            University of Georgia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5278" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Effective energy management is essential for maximizing information gathering in networked mobile robots, particularly for large-scale, energy-intensive tasks such as agricultural monitoring and wildfire mapping. This paper presents a novel framework that integrates robots’ energy profiles with confidence bounds of their assigned regions to optimize sampling targets. Designed for persistent, long-term deployments, the framework employs Gaussian Process Regression (GPR) to maximize data acquisition and accurately reconstruct unknown spatial distributions (e.g., algae outbreaks or humidity maps). The method enables seamless transitions between exploration (mapping uncertain regions when energy is high), exploitation (refining maps at moderate energy levels), and recharging (navigating to charging stations when energy is low). Rigorous theoretical analysis ensures appropriate mode transitions, achieving optimal energy-balanced informative path planning. Numerical evaluations demonstrate the approach’s effectiveness in generating energy-efficient, distinct paths for heterogeneous robots, delivering up to 32% energy savings while maintaining high reconstruction accuracy.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_13">
             14:45-15:15, Paper WeLB2R.13
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1311" name="modify5279" onclick="modify(5279,1311)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5279'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              PINNClothSim: Using Physics-Informed Neural Network to Simulate the Cloth Behavior
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423524" title="Click to go to the Author Index">
             Ru, Yingdong
            </a>
           </td>
           <td class="r">
            University of Glasgow
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#172642" title="Click to go to the Author Index">
             Aragon-Camarasa, Gerardo
            </a>
           </td>
           <td class="r">
            University of Glasgow
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5279" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#cognitive_modeling" title="Click to go to the Keyword Index">
               Cognitive Modeling
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Pinn has been proven to solve inverse problems of parameter estimation and forward problem of solving energy equilibrium thin-shell theory. The idea is to use PINN to build a dynamic simulator for fabric. The contribution will be: 1. the first PINN-based dynamic neural solver for real-time cloth behavior simulation. 2. the kernel-based global collision method integrates interactions over all point pairs using smooth, differentiable kernel functions, emphasizing close contacts in a globally consistent manner, unlike traditional local methods that rely solely on nearest distance metrics. 3. the coulomb friction equation is added as another physics constrain penalty form. Later, after building the simulator, it can be added in model-based reinforcement learning and train the policy for fabric manipulation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_14">
             14:45-15:15, Paper WeLB2R.14
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1312" name="modify5280" onclick="modify(5280,1312)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5280'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Self-Supervised Framework for Embodied Active Event Perception
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#435489" title="Click to go to the Author Index">
             Chen, Zhou
            </a>
           </td>
           <td class="r">
            Auburn University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#314475" title="Click to go to the Author Index">
             Kundu, Sanjoy
            </a>
           </td>
           <td class="r">
            Auburn University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#185122" title="Click to go to the Author Index">
             Baweja, Harsimran
            </a>
           </td>
           <td class="r">
            San Diego State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#285728" title="Click to go to the Author Index">
             Aakur, Sathyanarayanan
            </a>
           </td>
           <td class="r">
            Auburn University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5280" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Real-world robotic systems must perceive, interpret, and act on dynamic events in real-time, without relying on large labeled datasets, handcrafted rewards, or storing sensitive data. Motivated by these challenges, we introduce EASE, a self-supervised framework for embodied event perception and control that minimizes predictive free energy as an intrinsic signal for learning. EASE integrates a hierarchical perception module, which anticipates feature-level sensory observations, with a reinforcement learning-based motor policy that selects actions to reduce spatial uncertainty over time. This closed-loop architecture enables agents to segment, summarize, and track salient actors without predefined task supervision or post-hoc processing. Through experiments in simulation and on a LoCoBot platform, we demonstrate that EASE achieves competitive accuracy on segmentation and tracking benchmarks, while also exhibiting emergent behaviors such as implicit memory, target reacquisition, and motion-contingent exploration. By eliminating the need for stored visual data and enabling real-time adaptation, EASE offers a scalable and privacy-preserving solution for interactive event understanding.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_15">
             14:45-15:15, Paper WeLB2R.15
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1313" name="modify5281" onclick="modify(5281,1313)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5281'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Equi-RO: A 4D Millimeter-Wave Radar Odometry Based on Equivariant Networks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#370805" title="Click to go to the Author Index">
             Han, Zeyu
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#131371" title="Click to go to the Author Index">
             Ghaffari, Maani
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#216343" title="Click to go to the Author Index">
             Wang, Jianqiang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5281" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurate odometry estimation is crucial for autonomous systems in GPS-denied environments. While LiDARs and cameras struggle under extreme weather, 4D mmWave radar emerges as a robust alternative with all-weather operability and velocity measurement. In this paper, we propose Equi-RO, an equivariant network-based framework for 4D radar odometry. Our method pre-processes Doppler velocity into invariant features and employs separate networks to process equivariant and invariant features. A graph-based architecture enhances feature aggregation in sparse radar data, improving inter-frame correspondence. Experiments on the open-source dataset show Equi-RO outperforms state-of-the-art methods in accuracy and robustness.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_16">
             14:45-15:15, Paper WeLB2R.16
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1314" name="modify5282" onclick="modify(5282,1314)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5282'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Framework to Evaluate LLM’s Ability to Reason about Physical Disabilities from Medical Perspective
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457510" title="Click to go to the Author Index">
             Kashyap, Atharva
            </a>
           </td>
           <td class="r">
            University of Michigan, Ann Arbor
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#173021" title="Click to go to the Author Index">
             Alves-Oliveira, Patrícia
            </a>
           </td>
           <td class="r">
            Amazon Lab126
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5282" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#physically_assistive_devices" title="Click to go to the Keyword Index">
               Physically Assistive Devices
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_factors_and_human_in_the_loop" title="Click to go to the Keyword Index">
               Human Factors and Human-in-the-Loop
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#long_term_interaction" title="Click to go to the Keyword Index">
               Long term Interaction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Physically Assistive Robots help people with physical disabilities perform various activities of daily living. Largely, these robots overfit particular populations or groups of people, prompting a need for personalization. In this work, we present a work-in-progress framework to evaluate the performance of Large Language Models (LLM) in their ability to reason about physical disabilities, especially in context of supporting personalization. We compiled a dataset that includes five physical disabilities, generated several anatomically accurate physical functions of the body, and curated brief real medical histories for people with a particular physical disability. Using the disability dataset, real patient histories, and body functions, we designed prompts. We expect to use zero-shot prompting techniques to evaluate LLM performance in this context. Our next step is to conduct an LLM evaluation study against ground truth compiled through a data collection study with doctors.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_17">
             14:45-15:15, Paper WeLB2R.17
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1315" name="modify5283" onclick="modify(5283,1315)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5283'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Predicting Subjective Values of Trust with Interdependence Variables
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#328343" title="Click to go to the Author Index">
             Perkins, Russell
            </a>
           </td>
           <td class="r">
            Umass Lowell
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#328342" title="Click to go to the Author Index">
             Rezaei Khavas, Zahra
            </a>
           </td>
           <td class="r">
            Umass Lowell
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#160355" title="Click to go to the Author Index">
             Azadeh, Reza
            </a>
           </td>
           <td class="r">
            University of Massachusetts Lowell
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#128212" title="Click to go to the Author Index">
             Robinette, Paul
            </a>
           </td>
           <td class="r">
            University of Massachusetts Lowell
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5283" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#cognitive_modeling" title="Click to go to the Keyword Index">
               Cognitive Modeling
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_experience" title="Click to go to the Keyword Index">
               Learning from Experience
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#acceptability_and_trust" title="Click to go to the Keyword Index">
               Acceptability and Trust
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study investigates the use of variables described in interdependence theory to model human perceptions of robotic behavior in trust-based scenarios. An XGBoost model was trained to predict the average reported Likert scores of participants that rated the morality and performance of a simulated robot. Reflexive control (RC), fate control (FC), and bilateral control (BC), which quantify self-influence, collaborator influence, and mutual dependence, were calculated from payoff matrices and used as input features. The model was trained on scaled data from more than 200 participant evaluations, achieving a mean squared error of 0.18 in the standardized space, equivalent to approximately 1.27 Likert points of average prediction error. Participants engaged in a repeated trust game with a simulated robot partner during a search and rescue mission, where cooperation was incentivized through a team bonus and trust violations were introduced in later rounds. After each interaction, the participants rated the robot’s morality and performance on a 7-point Likert scale. The results demonstrate that the interdependence variables capture the latent structure of human-robot trust dynamics and offer a promising framework for predicting subjective evaluations of robotic behavior.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_18">
             14:45-15:15, Paper WeLB2R.18
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1316" name="modify5284" onclick="modify(5284,1316)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5284'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Configuration-Dependent Robot Kinematics Model and Calibration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#331022" title="Click to go to the Author Index">
             Lu, Chen-Lung
            </a>
           </td>
           <td class="r">
            Rensselaer Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#301044" title="Click to go to the Author Index">
             He, Honglu
            </a>
           </td>
           <td class="r">
            Rensselaer Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#121978" title="Click to go to the Author Index">
             Julius, Agung
            </a>
           </td>
           <td class="r">
            Rensselaer Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107418" title="Click to go to the Author Index">
             Wen, John
            </a>
           </td>
           <td class="r">
            Rensselaer Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5284" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#calibration_and_identification" title="Click to go to the Keyword Index">
               Calibration and Identification
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurate robot kinematics is critical for precise tool placement using joint control of an articulated robot. Traditional kinematics calibration using Denavit-Hartenberg parameters is sensitive to joint-axis directions. Product-of-Exponentials (POE) parameterization is more robust but is non-minimal. Robot kinematics is also affected by the pose of the robot in different parts of the workspace due to joint tolerance, especially for massive payloads. This paper compares multiple POE-based kinematics calibration methods. We propose a configuration-dependent parameterization which is shown to have the best overall performance. In addition, for a traditional 6-DoF elbow manipulator, the configuration dependency is mostly on the shoulder and elbow angles. We show that the configuration dependence of the kinematics parameters may be adequately captured by these two angles.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_19">
             14:45-15:15, Paper WeLB2R.19
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1317" name="modify5285" onclick="modify(5285,1317)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5285'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Robot Path Planning Using Natural Language Instructions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#396898" title="Click to go to the Author Index">
             Bhattacharjee, Saswati
            </a>
           </td>
           <td class="r">
            University at Albany
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#205992" title="Click to go to the Author Index">
             Sinha, Anirban
            </a>
           </td>
           <td class="r">
            GE Aerospace Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#149314" title="Click to go to the Author Index">
             Ekenna, Chinwe
            </a>
           </td>
           <td class="r">
            University at Albany
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5285" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work presents an efficient natural language-assisted navigation planning framework for mobile robots. The proposed system integrates a language model with a modified Rapidly Exploring Random Tree (RRT) algorithm, enabling robots to interpret user instructions. In our preliminary work, the planner improves efficiency by focusing on specific areas of the robot’s workspace based on these instructions, making it faster and less resource-intensive. It significantly reduces the number of nodes by approximately 55% and the number of queries by approximately 80% compared to traditional RRT methods. The approach was validated in both simulated and real-world environments involving complex navigation scenarios, consistently demonstrating superior performance. We plan to extend this work to multi-robot systems using a decoupled, priority-based strategy, where priority is assigned based on the trajectory length of the robots—the highest priority is assigned to the robot with the longest trajectory. The overall approach will demonstrate the effectiveness of language-guided planning for real-world robotic navigation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_20">
             14:45-15:15, Paper WeLB2R.20
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1318" name="modify5286" onclick="modify(5286,1318)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5286'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Open-Source Soft Robotic Platform for Autonomous Aerial Manipulation in the Wild
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#325364" title="Click to go to the Author Index">
             Blöchlinger, Marc
            </a>
           </td>
           <td class="r">
            ETHZ
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#325366" title="Click to go to the Author Index">
             Bauer, Erik
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#325365" title="Click to go to the Author Index">
             Strauch, Pascal
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#325362" title="Click to go to the Author Index">
             Raayatsanati, Arman
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#164300" title="Click to go to the Author Index">
             Katzschmann, Robert Kevin
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5286" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Aerial manipulation combines the versatility and speed of flying platforms with the functional capabilities of mobile manipulation, which presents significant challenges due to the need for precise localization and control. Traditionally, researchers have relied on offboard perception systems, which are limited to expensive and impractical specially equipped indoor environments. In this work, we introduce a novel platform for autonomous aerial manipulation that exclusively utilizes onboard perception systems. Our platform can perform aerial manipulation in various indoor and outdoor environments without depending on external perception systems. Our experimental results demonstrate the platform's ability to autonomously grasp various objects in diverse settings. This advancement significantly improves the scalability and practicality of aerial manipulation applications by eliminating the need for costly tracking solutions. To accelerate future research, we open source our ROS 2 software stack and custom hardware design, making our contributions accessible to the broader research community.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_21">
             14:45-15:15, Paper WeLB2R.21
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1319" name="modify5287" onclick="modify(5287,1319)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5287'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Collaborative Human-Robot Manipulation for Composite Sheet Layup Applications
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#357701" title="Click to go to the Author Index">
             Aksoy, Burak
            </a>
           </td>
           <td class="r">
            Rensselaer Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107418" title="Click to go to the Author Index">
             Wen, John
            </a>
           </td>
           <td class="r">
            Rensselaer Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5287" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work presents a collaborative human-robot manipulation framework tailored for composite layup applications, where fiber-reinforced sheets must be precisely placed and affixed onto mold surfaces. Building upon a dual-mode control architecture, the proposed system supports (1) obstacle- and stress-aware collaborative transportation of flexible sheets and (2) contact-intensive layup operations involving human-robot coordination. In the first mode, robots assist with fabric positioning while ensuring safe manipulation through predictive simulation and control barrier functions (CBFs). The second mode leverages real-time Position-Based Dynamics (PBD) simulation to estimate sheet deformation, stress, and contact states, enabling robots to dynamically adjust holding poses and maintain sheet tautness as the human operator manually presses the material onto the mold. By incorporating simulation-informed control into a shared autonomy framework, the system preserves material integrity and avoids overstressing or accidental detachment during layup. Experimental results demonstrate the feasibility of this approach in handling complex, curved mandrel surfaces with minimal wrinkling and improved operator ergonomics. This work highlights a scalable, safety-aware control strategy for collaborative manipulation of 2D deformable objects in manufacturing environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_22">
             14:45-15:15, Paper WeLB2R.22
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1320" name="modify5288" onclick="modify(5288,1320)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5288'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Stretch, but Don’t Snap: Coordinating Multi-Agent Teams under Competing Goals
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421269" title="Click to go to the Author Index">
             Oliva, Federico
            </a>
           </td>
           <td class="r">
            Technion - Israel Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424514" title="Click to go to the Author Index">
             Sherf, Ido
            </a>
           </td>
           <td class="r">
            Technion - Israel Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107478" title="Click to go to the Author Index">
             Degani, Amir
            </a>
           </td>
           <td class="r">
            Technion - Israel Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5288" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robotics_and_automation_in_construction" title="Click to go to the Keyword Index">
               Robotics and Automation in Construction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work explores coordination strategies for heterogeneous multi-agent systems. The team comprises larger leader agents and smaller follower agents (children), each equipped with UWB antennas to measure relative distances within a limited range. We frame the coordination challenge as a trade-off between expansion and contraction: the former aims to cover the environment, while the latter maintains proximity for communication and task execution. These conflicting goals are modeled through a lightweight, decentralized optimization framework in which each agent balances local objectives with team-level robustness constraints.
             <p>
              To analyze and guide this coordination, we define three key metrics: coverage (to assess spatial expansion), connectivity (based on edge cuts and inter-agent distances), and dispersion (using the Laplacian of the positioned graph). The trade-off between team and local goals is modeled through a convex combination of expansion and contraction tasks. Through both centralized and decentralized optimization scenarios, we show how tuning the dispersion constraint impacts the team’s behavior, shaping feasible configurations that preserve connectivity while maximizing the current task.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_23">
             14:45-15:15, Paper WeLB2R.23
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1321" name="modify5298" onclick="modify(5298,1321)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5298'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              From Reals to Logic and Back: Learning World Models for Planning from Raw Data
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#245107" title="Click to go to the Author Index">
             Shah, Naman
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457523" title="Click to go to the Author Index">
             Nagpal, Jayesh
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#169037" title="Click to go to the Author Index">
             Srivastava, Siddharth
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5298" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Humans are able to learn to solve complex tasks based on simple demonstrations. However, this is a challenging problem for robotics; current training data requirements make it difficult to develop reliable autonomous robots for settings where test tasks feature more objects and longer horizons than those encountered during learning. We show that enabling a robot to autonomously invent well-founded concepts can allow it to learn and transfer knowledge more efficiently from small batches of demonstrations on simple tasks. The robot is then able to learn world models and solve new, complex tasks at a level comparable with hand-crafted models. Empirical results indicate that this framework allows robots to solve new tasks with much longer execution horizons and many more objects than those encountered in demonstrations (up to 18x more objects), in zero-shot fashion. This yields the first known approach for autonomously inventing relational concepts and for learning logic-based generalizable world models from small batches of unannotated high-dimensional, real-valued robot demonstrations.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_24">
             14:45-15:15, Paper WeLB2R.24
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1322" name="modify5290" onclick="modify(5290,1322)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5290'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Imaginative World Modeling with Scene Graphs for Embodied Agent Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#323563" title="Click to go to the Author Index">
             Hu, Yue
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#381664" title="Click to go to the Author Index">
             Xu, Ruihan
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#453428" title="Click to go to the Author Index">
             Wu, Junzhe
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#131371" title="Click to go to the Author Index">
             Ghaffari, Maani
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5290" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#agent_based_systems" title="Click to go to the Keyword Index">
               Agent-Based Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The semantic navigation task requires an agent to navigate toward a specified target in an unseen environment. Employing an imaginative navigation strategy, which predicts future scenes before taking action, can significantly improve efficiency. However, current imaginative navigation methods primarily depend on image-based world modeling that forecasts future image viewpoints, resulting in substantial computational overhead and failing to deliver consistent global predictions. To address these issues, we introduce SGImagineNav, a novel symbolic world modeling-based proactive navigation framework that builds a global environmental representation with hierarchical scene graph and leverages large language models (LLMs) to predict unseen parts of the environment. During navigation, SGImagineNav maintains an incomplete local scene graph of observed areas, while LLMs infer the likely structure of unobserved regions. With this more complete scene graph, the agent then estimates the target’s location, identifies an optimal viewpoint, and proceeds toward it. Extensive evaluations on HM3D benchmarks show that SGImagineNav outperforms previous state-of-the-art methods, demonstrating notable improvements in reasoning capability and navigation efficiency.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_25">
             14:45-15:15, Paper WeLB2R.25
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1323" name="modify5292" onclick="modify(5292,1323)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5292'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Consensus Building in Human-Robot Co-Learning Via Bias Controlled Nonlinear Opinion Dynamics and Nonverbal Communication through Robotic Eyes
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#382441" title="Click to go to the Author Index">
             Kumar, Rajul
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#186935" title="Click to go to the Author Index">
             Yao, Ningshi
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5292" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_teaming" title="Click to go to the Keyword Index">
               Human-Robot Teaming
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_factors_and_human_in_the_loop" title="Click to go to the Keyword Index">
               Human Factors and Human-in-the-Loop
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Consensus between humans and robots is crucial as robotic agents become more prevalent and deeply integrated into our daily lives. This integration presents both unprecedented opportunities and notable challenges for effective collaboration. However, the active guidance of human actions and their integration in co-learning processes, where humans and robots mutually learn from each other, remain under-explored. This work demonstrates how consensus between human and robot opinions can be established by modeling decision-making processes as nonlinear opinion dynamics. We utilize dynamic bias as a control parameter to steer the robot’s opinion toward consensus and employ visual cues via a robotic eye gaze to guide human decisions. These cues non-verbally communicate the robot’s future intentions, gradually guiding human decisions to align with them. To design robot behavior for consensus, we integrate a human opinion observation algorithm with the robot’s opinion formation, controlling its actions based on that formed opinion. Experiments with 51 participants (N=51) in a two-choice decision-making task show that effective consensus and trust can be built in a human-robot co-learning setting by guiding human decisions through nonverbal robotic cues and using bias-controlled opinion dynamics to shape robot behavior. Finally, we provide detailed insights into perceived cognitive load and the behavior of robotic eyes based on user feedback and post-experiment interviews.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_26">
             14:45-15:15, Paper WeLB2R.26
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1324" name="modify5293" onclick="modify(5293,1324)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5293'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Landmark-Based 3D LiDAR Segmentation SLAM for Logistic Warehouses : Preliminary Result
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#402645" title="Click to go to the Author Index">
             Yang, Dayeon
            </a>
           </td>
           <td class="r">
            Korea Institute of Industrial Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#211875" title="Click to go to the Author Index">
             Ju, Chanyoung
            </a>
           </td>
           <td class="r">
            Korea Institute of Industrial Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5293" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study proposes a landmark-based 3D LiDAR semantic segmentation approach tailored for agricultural logistics warehouse environments and presents preliminary experimental results. Conventional SLAM systems often experience degraded map quality and localization inaccuracies in indoor settings with numerous dynamic objects. To address these challenges, we collected 3D point cloud data using a LiDAR sensor deployed in an agricultural logistics warehouse and annotated key semantic entities such as boxes, pallets, workers, and forklifts. Based on this annotated dataset, we are currently training a RandLA-Net-based semantic segmentation model capable of distinguishing between dynamic and static objects. The segmentation results will be integrated into a SLAM framework to suppress noise caused by dynamic elements and improve overall map consistency. Initial results demonstrate the feasibility and potential of applying semantic SLAM technologies to complex agricultural logistics scenarios. Future work will focus on developing a fully integrated semantic SLAM system to support real-time autonomous navigation and intelligent logistics automation of agricultural environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_27">
             14:45-15:15, Paper WeLB2R.27
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1325" name="modify5294" onclick="modify(5294,1325)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5294'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ECHO: A Testbed for High-Fidelity Synthetic Martian Terrain Simulations Using Unreal Engine
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#310161" title="Click to go to the Author Index">
             Mohanty, Adyasha
            </a>
           </td>
           <td class="r">
            Harvey Mudd
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5294" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Mars exploration presents unique navigation challenges due to unstructured terrain, edge-case environments, and limited availability of annotated training data. Traditional physical testbeds—such as those built in desert environments—lack the ability to simulate diverse and repeatable Martian conditions. We present Echo, an open-source digital testbed designed to simulate Martian terrain environments and enable rapid evaluation of autonomous perception frameworks. Built in Unreal Engine, Echo allows researchers to construct realistic 3D landscapes that include rare or extreme terrain classes, simulate environmental variables and generate synthetic datasets for computer vision tasks. The platform supports integrated pipelines for object detection and semantic segmentation, facilitating the development and benchmarking of navigation algorithms in reproducible, high-fidelity settings.
             <p>
              Echo currently features a custom rover simulator with first- and third-person camera perspectives, in-simulation image capture tools, and a working YOLO-based object detection model trained on a custom 3D asset. Planned work include the development of labeled Martian terrain datasets and real-time semantic segmentation of surface types such as sand, bedrock, and large rocks. Echo’s modular design can aid student researchers, educators, and the wider autonomy community to prototype and test vision-based algorithms for improving autonomy in Martian applications.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_28">
             14:45-15:15, Paper WeLB2R.28
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1326" name="modify5295" onclick="modify(5295,1326)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5295'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Biomimetic Robotic Hand with Anatomically Correct 3D Braided Tendons - towards the Scalable Production of Complex Bio-Inspired Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#254276" title="Click to go to the Author Index">
             Tasi, Benedek József
            </a>
           </td>
           <td class="r">
            Pázmány Péter Catholic University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#432997" title="Click to go to the Author Index">
             Pelyva, Dávid László
            </a>
           </td>
           <td class="r">
            Pázmány Péter Catholic University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#432999" title="Click to go to the Author Index">
             Holló, Dávid
            </a>
           </td>
           <td class="r">
            Pázmány Péter Catholic University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#433000" title="Click to go to the Author Index">
             Nguyen, Zsófia
            </a>
           </td>
           <td class="r">
            Pázmány Péter Catholic University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#433002" title="Click to go to the Author Index">
             Gombkötő-Molnár, Boróka
            </a>
           </td>
           <td class="r">
            Pázmány Péter Catholic University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#433003" title="Click to go to the Author Index">
             Kráz, Balázs
            </a>
           </td>
           <td class="r">
            Pázmány Péter Catholic University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#433004" title="Click to go to the Author Index">
             Klenczner, Márton István
            </a>
           </td>
           <td class="r">
            Pázmány Péter Catholic University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#433005" title="Click to go to the Author Index">
             Kiss, Veronika
            </a>
           </td>
           <td class="r">
            Pázmány Péter Catholic University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#433006" title="Click to go to the Author Index">
             Formanek, Balázs István
            </a>
           </td>
           <td class="r">
            Pázmány Péter Catholic University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#433007" title="Click to go to the Author Index">
             Naszlady, Márton Bese
            </a>
           </td>
           <td class="r">
            Pázmány Péter Catholic University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5295" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#biomimetics" title="Click to go to the Keyword Index">
               Biomimetics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             With the recent advancements in the fields of humanoid robotics and multi-fingered hands, production demand for such systems is increasing rapidly as more and more applications are emerging for dexterous manipulation. Robotic solutions advanced enough for such capabilities usually bear significant costs, however, mostly due to their high complexity - their mechanical subsystems alone comprise a large number of separate components, often of elaborate shape or structure, each with their unique supply chain, materials, machining, tooling and assembly requirements. This is especially true when striving to mimic the human hand’s soft and durable tissues and complex biomechanics more closely - an aspiration of many developers towards increasing the naturality of movements and human-likeness for better embodiment and safer human interactions. There is therefore a strong need to address value chain complexity, assembly time, and thus total cost of manufacturing, by simplifying complicated designs and reducing the number of components - without negatively impacting functionality. For this purpose, this work presents an anatomically accurate robotic hand designed and built using modern design automation methods and advanced textile technologies, to exemplify how such practices can be utilized for leveraging the inherent benefits of highly biomimetic constructions while keeping production and assembly simple and cost-effective.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="welb2r_29">
             14:45-15:15, Paper WeLB2R.29
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1327" name="modify5296" onclick="modify(5296,1327)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5296'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Path Planning and Optimization for Cuspidal 6R Manipulators
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#342440" title="Click to go to the Author Index">
             Elias, Alexander
            </a>
           </td>
           <td class="r">
            Rensselaer Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107418" title="Click to go to the Author Index">
             Wen, John
            </a>
           </td>
           <td class="r">
            Rensselaer Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5296" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#industrial_robots" title="Click to go to the Keyword Index">
               Industrial Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Cuspidal robots switch inverse kinematics (IK) solutions without crossing singularities. This means classical path planning algorithms may fail for cuspidal robots. The feasibility of a given task-space path depends on the choice of IK solution, but industrial simulators from ABB and FANUC do not return all IK solutions. Furthermore, a given tasks-space path entirely in the workspace may not be feasible at all, even though there are valid IK solutions for each point along the path.
             <p>
              We introduce three new algorithms for cuspidal robot identification and path planning. These algorithms are enabled by IK-Geo, our highly efficient IK solver which can find all IK solutions for any robot using subproblem decomposition. First, we propose a new efficient method for cuspidal robot identification. For the first time, we identified that the ABB GoFa and some robots with three parallel axes are cuspidal. Next, we propose a new path planning method for cuspidal robots by finding all IK solutions for each point along a task-space path and constructing a graph to connect each vertex corresponding to an IK solution. Graph edges have a weight based on the optimization metric, such as minimizing joint velocity. The optimal feasible path is the shortest path in the graph. Finally, we incorporate this path planning method into a path optimization algorithm. We find the optimal rigid-body offset of a given end effector path.
             </p>
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt1">
             <b>
              WeDT1
             </b>
             Regular Session, 302
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1328" name="modifyWeDT1" onclick="modsession(77,1328)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt1" title="Click to go to the Program at a Glance">
             <b>
              Autonomous Vehicles 1
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#382101" title="Click to go to the Author Index">
             Rath, Prabin Kumar
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#398529" title="Click to go to the Author Index">
             Li, Xiaopeng
            </a>
           </td>
           <td class="r">
            University of Wisconsin-Madison
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt1_01">
             15:15-15:20, Paper WeDT1.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1329" name="modify213" onclick="modify(213,1329)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('213'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Diverse Controllable Diffusion Policy with Signal Temporal Logic
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#236419" title="Click to go to the Author Index">
             Meng, Yue
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#217837" title="Click to go to the Author Index">
             Fan, Chuchu
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab213" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Generating realistic simulations is critical for autonomous system applications such as self-driving and human-robot interactions. However, driving simulators nowadays still have difficulty in generating controllable, diverse, and rule-compliant behaviors for road participants: Rule-based models cannot produce diverse behaviors and require careful tuning, whereas learning-based methods imitate the policy from data but are not designed to follow the rules explicitly. Besides, the real-world datasets are by nature "single-outcome", making the learning method hard to generate diverse behaviors. In this paper, we leverage Signal Temporal Logic (STL) and Diffusion Models to learn controllable, diverse, and rule-aware policy. We first calibrate the STL on the real-world data, then generate diverse synthetic data using trajectory optimization, and finally learn the rectified diffusion policy on the augmented dataset. We test on the NuScenes dataset and our approach can achieve the most diverse rule-compliant trajectories compared to other baselines, with a runtime 1/17X to the second-best approach. In closed-loop testing, our approach reaches the highest diversity, rule satisfaction rate, and the lowest collision rate. Our method can generate varied characteristics conditional on different STL parameters in testing. A case study on human-robot encounter scenarios shows our approach can generate diverse and closed-to-oracle trajectories. The annotation tool, augmented dataset, and code are available at https://github.com/mengyuest/pSTL-diffusion-policy.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt1_02">
             15:20-15:25, Paper WeDT1.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1330" name="modify1691" onclick="modify(1691,1330)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1691'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Dual-Conditioned Temporal Diffusion Modeling for Driving Scene Generation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417448" title="Click to go to the Author Index">
             Bai, Xiangyu
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419654" title="Click to go to the Author Index">
             Luo, Yedi
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418426" title="Click to go to the Author Index">
             Jiang, Le
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418386" title="Click to go to the Author Index">
             Ostadabbas, Sarah
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1691" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Diffusion models have proven effective at generating high-quality images from learned distributions, but their application to the temporal domain, especially for driving scenarios, remains underexplored. Our work addresses key challenges in existing simulations, such as limited data quality, diversity, and high costs, by extending diffusion models to generate realistic long driving videos. We introduce the Dual-conditioned Temporal Diffusion Model (DcTDM), an open-source method that incorporates dual conditioning to enforce temporal consistency by guiding frame transitions. Alongside DcTDM, we present DriveSceneDDM, a comprehensive driving video dataset featuring textual scene descriptions, dense depth maps, and canny edge data. We evaluate DcTDM using common video quality metrics, demonstrating its superior performance over other video diffusion models by producing long, temporally consistent driving videos up to 40s, achieving over 25% improvement in consistency and frame quality.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt1_03">
             15:25-15:30, Paper WeDT1.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1331" name="modify2369" onclick="modify(2369,1331)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2369'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RL-OGM-Parking: Lidar OGM-Based Hybrid Reinforcement Learning Planner for Autonomous Parking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424111" title="Click to go to the Author Index">
             Wang, Zhitao
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#413330" title="Click to go to the Author Index">
             Chen, Zhe
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424047" title="Click to go to the Author Index">
             Jiang, Mingyang
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#204568" title="Click to go to the Author Index">
             Qin, Tong
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#146916" title="Click to go to the Author Index">
             Yang, Ming
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2369" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous parking has become a critical application in automatic driving research and development. Parking operations often suffer from limited space and complex environments, requiring accurate perception and precise maneuvering. Traditional rule-based parking algorithms struggle to adapt to diverse and unpredictable conditions, while learning-based algorithms lack consistent and stable performance in various scenarios. Therefore, a hybrid approach is necessary that combines the stability of rule-based methods and the generalizability of learning-based methods. Recently, reinforcement learning (RL) based policy has shown robust capability in planning tasks. However, the simulation-to-reality (sim-to-real) transfer gap seriously blocks the real-world deployment. To address these problems, we employ a hybrid policy, consisting of a rule-based Reeds-Shepp (RS) planner and a learning-based reinforcement learning (RL) planner. A real-time LiDAR-based Occupancy Grid Map (OGM) representation is adopted to bridge the sim-to-real gap, leading the hybrid policy can be applied to real-world systems seamlessly. We conducted extensive experiments both in the simulation environment and real-world scenarios, and the result demonstrates that the proposed method outperforms pure rule-based and learning-based methods. The real-world experiment further validates the feasibility and efficiency of the proposed method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt1_04">
             15:30-15:35, Paper WeDT1.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1332" name="modify2579" onclick="modify(2579,1332)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2579'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Task Invariant Representation Imitation Learning for Autonomous Driving
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416136" title="Click to go to the Author Index">
             Peng, Jinghan
            </a>
           </td>
           <td class="r">
            East China Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421135" title="Click to go to the Author Index">
             Yu, Xing
            </a>
           </td>
           <td class="r">
            East China Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421111" title="Click to go to the Author Index">
             Wang, Jingwen
            </a>
           </td>
           <td class="r">
            East China Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421170" title="Click to go to the Author Index">
             Tian, Lili
            </a>
           </td>
           <td class="r">
            East China Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421425" title="Click to go to the Author Index">
             Dehui, Du
            </a>
           </td>
           <td class="r">
            East China Normal University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2579" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Imitation learning is a promising approach to acquiring autonomous driving policies by mimicking human driver behaviors. However, a major drawback of existing driving policies derived from imitation learning is their proneness to capturing spurious correlations, owing to the lack of an explicit causal model. Deploying such policies in unpredictable real-world environments poses severe risks, as spurious correlations may result in flawed decisions that compromise safety. To tackle this challenge, we introduce a novel approach called Multi-Task Invariant Representation Imitation Learning (MIRIL). MIRIL combines invariant learning with imitation learning to identify cross-environment invariant causal representations from driving demonstrations in various scenarios. These representations are then fed into multiple downstream branches for multi-task learning, including policy learning, perception prediction, invariant representation learning, and transition dynamics learning. Through the multi-task learning approach, the model not only makes consistent driving decisions across different environments but also perceives the vehicle's surroundings, thereby improving adaptability and robustness in diverse driving conditions. This enables MIRIL to effectively handle a wide range of driving scenarios, ensuring safety and efficiency. Supported by clear metrics, this paper details our comprehensive experimental setup, including datasets, benchmarks, and comparative analyses, underscoring the capability of MIRIL to significantly boost system generalization and excel in decision-making significantly.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt1_05">
             15:35-15:40, Paper WeDT1.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1333" name="modify2595" onclick="modify(2595,1333)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2595'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Occ-LLM: Enhancing Autonomous Driving with Occupancy-Based Large Language Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#374758" title="Click to go to the Author Index">
             Xu, Tianshuo
            </a>
           </td>
           <td class="r">
            Hongkong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418075" title="Click to go to the Author Index">
             Lu, Hao
            </a>
           </td>
           <td class="r">
            HKUST-GZ
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#294988" title="Click to go to the Author Index">
             Yan, Xu
            </a>
           </td>
           <td class="r">
            Chinese University of Hong Kong, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418060" title="Click to go to the Author Index">
             Cai, Yingjie
            </a>
           </td>
           <td class="r">
            Huawei
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#123603" title="Click to go to the Author Index">
             Liu, Bingbing
            </a>
           </td>
           <td class="r">
            Huawei Technologies
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#375388" title="Click to go to the Author Index">
             Chen, Yingcong
            </a>
           </td>
           <td class="r">
            The University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2595" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#big_data_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Big Data in Robotics and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Large Language Models (LLMs) have made substantial advancements in the field of robotic and autonomous driving. This study presents the first Occupancy-based Large Language Model (Occ-LLM), which represents a pioneering effort to integrate LLMs with an important representation. To effectively encode occupancy as input for the LLM and address the category imbalances associated with occupancy, we propose Motion Separation Variational Autoencoder (MS-VAE). This innovative approach utilizes prior knowledge to distinguish dynamic objects from static scenes before inputting them into a tailored Variational Autoencoder (VAE). This separation enhances the model's capacity to concentrate on dynamic trajectories while effectively reconstructing static scenes. The efficacy of Occ-LLM has been validated across key tasks, including 4D occupancy forecasting, self-ego planning, and occupancy-based scene question answering. Comprehensive evaluations demonstrate that Occ-LLM significantly surpasses existing state-of-the-art methodologies, achieving gains of about 6% in Intersection over Union (IoU) and 4% in mean Intersection over Union (mIoU) for the task of 4D occupancy forecasting. These findings highlight the transformative potential of Occ-LLM in reshaping current paradigms within robotic and autonomous driving.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt1_06">
             15:40-15:45, Paper WeDT1.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1334" name="modify3532" onclick="modify(3532,1334)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3532'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DISC: Dataset for Analyzing Driving Styles in Simulated Crashes for Mixed Autonomy
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#396027" title="Click to go to the Author Index">
             Senthil Kumar, Sandip Sharan
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397005" title="Click to go to the Author Index">
             Thalapanane, Sandeep
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398250" title="Click to go to the Author Index">
             Appiya Dilipkumar Peethambari, Guru Nandhan
            </a>
           </td>
           <td class="r">
            University of Maryland College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397586" title="Click to go to the Author Index">
             Sri hari, Sourang
            </a>
           </td>
           <td class="r">
            University of Maryland College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#277405" title="Click to go to the Author Index">
             Zheng, Laura
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101887" title="Click to go to the Author Index">
             Lin, Ming C.
            </a>
           </td>
           <td class="r">
            University of Maryland at College Park
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3532" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#virtual_reality_and_interfaces" title="Click to go to the Keyword Index">
               Virtual Reality and Interfaces
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Handling pre-crash scenarios is still a major challenge for self-driving cars due to limited data &amp; human-driving behavior datasets. We introduce DISC, one of the first datasets designed to capture various driving styles &amp; behaviors in pre-crash scenarios for mixed autonomy analysis. DISC includes over 8 classes of driving styles/behaviors from hundreds of drivers navigating a simulated vehicle through a virtual city, encountering rare-event traffic scenarios. This dataset enables the classification of pre-crash human driving behaviors in unsafe conditions, supporting individualized trajectory prediction based on observed driving patterns. It offers the potential to improve autonomous vehicle safety by accounting for diverse human driving behaviors in stressful traffic &amp; rare accident scenarios, which are otherwise difficult or risky to capture. By utilizing a VR-based driving simulator, TRAVERSE, data was collected through a driver-centric study involving human drivers encountering 12 simulated accident scenarios. This dataset fills a critical gap in human-centric driving data for rare events involving interactions with autonomous vehicles. It enables autonomous systems to better react to human drivers &amp; optimize trajectory prediction in mixed autonomy environments involving both human-driven &amp; self-driving cars. It includes essential data such as acceleration, braking &amp; vehicle pose providing a foundation for machine-learning models in autonomous vehicles. In addition, individual driving behaviors are classified through a set of standardized questionnaires, carefully designed to identify &amp; categorize driving behavior. We correlate data features with driving behaviors, showing that the simulated environment reflects real-world driving styles. DISC is the first dataset to capture how various driving styles respond to accident scenarios, offering significant potential to enhance autonomous vehicle safety and driving behavior analysis in mixed autonomy environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt1_07">
             15:45-15:50, Paper WeDT1.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1335" name="modify3991" onclick="modify(3991,1335)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3991'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Real-World Automated Vehicle Longitudinal Stability Analysis: Controller Design and Field Test
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398521" title="Click to go to the Author Index">
             Ma, Ke
            </a>
           </td>
           <td class="r">
            University of Wisconsin-Madison
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398564" title="Click to go to the Author Index">
             Zhang, Yuqin
            </a>
           </td>
           <td class="r">
            Chang’an University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#399340" title="Click to go to the Author Index">
             Zhou, Hang
            </a>
           </td>
           <td class="r">
            University of Wisconsin-Madison
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398534" title="Click to go to the Author Index">
             Liang, Zhaohui
            </a>
           </td>
           <td class="r">
            University of Wisconsin Madison
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398529" title="Click to go to the Author Index">
             Li, Xiaopeng
            </a>
           </td>
           <td class="r">
            University of Wisconsin-Madison
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3991" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_control" title="Click to go to the Keyword Index">
               Integrated Planning and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Although extensive research has been conducted on modeling the stable longitudinal controller of automated vehicles (AVs) to dampen traffic oscillations, the real-world performance of these controllers in actual vehicles remains uncertain. In the operation of real-world AVs, the delay between actual dynamics and the commands prevents the controller's command from being effectively implemented to dampen traffic oscillations. Thus, this study adapts the designed controllers within an AV test platform to compare the theoretically stable conditions with the actual oscillation dampening performance. Initially, we compute the stable conditions for both the traditional car-following controller, which assumes no delay, and the longitudinal controller that accounts for the dynamic response of the vehicle. Through empirical experiments, we demonstrate that the longitudinal controller predicts vehicle stability more accurately than conventional car-following controller, showing an improvement from an average prediction accuracy rate of 0.59 to 0.91. Also, the experiments uncover specific delays inherent in dynamics systems, with a response delay of 0.34 seconds. Our work makes two principal contributions to the field of AV control systems. First, it empirically validates that the longitudinal model, which accounts for the vehicle's dynamic responses, offers a more precise representation of vehicular behavior. Second, the relatively brief response delay identified expands the stability region, thereby enhancing vehicle control and safety. The longitudinal controller is critical for enhancing AV performance and reliability in dampening traffic oscillations.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt2">
             <b>
              WeDT2
             </b>
             Regular Session, 301
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1336" name="modifyWeDT2" onclick="modsession(241,1336)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt2" title="Click to go to the Program at a Glance">
             <b>
              Learning-Based SLAM 1
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#187379" title="Click to go to the Author Index">
             Pagani, Alain
            </a>
           </td>
           <td class="r">
            German Research Center for Artificial Intelligence
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#180955" title="Click to go to the Author Index">
             McGuire, Steve
            </a>
           </td>
           <td class="r">
            University of California at Santa Cruz
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt2_01">
             15:15-15:20, Paper WeDT2.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1337" name="modify183" onclick="modify(183,1337)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('183'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RoDyn-SLAM: Robust Dynamic Dense RGB-D SLAM with Neural Radiance Fields
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#386514" title="Click to go to the Author Index">
             Jiang, Haochen
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#337819" title="Click to go to the Author Index">
             Xu, Yueming
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#238588" title="Click to go to the Author Index">
             Li, Kejie
            </a>
           </td>
           <td class="r">
            The University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256634" title="Click to go to the Author Index">
             Feng, Jianfeng
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#320317" title="Click to go to the Author Index">
             Zhang, Li
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab183" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Leveraging neural implicit representation to conduct dense RGB-D SLAM has been studied in recent years. However, this approach relies on a static environment assumption and does not work robustly within a dynamic environment due to the inconsistent observation of geometry and photometry. To address the challenges presented in dynamic environments, we propose a novel dynamic SLAM framework with neural radiance field. Specifically, we introduce a motion mask generation method to filter out the invalid sampled rays. This design effectively fuses the optical flow mask and semantic mask to enhance the precision of motion mask. To further improve the accuracy of pose estimation, we have designed a divide-and-conquer pose optimization algorithm that distinguishes between keyframes and non-keyframes. The proposed edge warp loss can effectively enhance the geometry constraints between adjacent frames. Extensive experiments are conducted on the two challenging datasets, and the results show that RoDyn-SLAM achieves state-of-the-art performance among recent neural RGB-D methods in both accuracy and robustness.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt2_02">
             15:20-15:25, Paper WeDT2.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1338" name="modify407" onclick="modify(407,1338)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('407'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              HS-SLAM: Hybrid Representation with Structural Supervision for Improved Dense SLAM
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416701" title="Click to go to the Author Index">
             Gong, Ziren
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#224960" title="Click to go to the Author Index">
             Tosi, Fabio
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#336514" title="Click to go to the Author Index">
             Zhang, Youmin
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#224965" title="Click to go to the Author Index">
             Mattoccia, Stefano
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#223499" title="Click to go to the Author Index">
             Poggi, Matteo
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab407" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             NeRF-based SLAM has recently achieved promising results in tracking and reconstruction. However, existing methods face challenges in providing sufficient scene representation, capturing structural information, and maintaining global consistency in scenes emerging significant movement or being forgotten. To this end, we present HS-SLAM to tackle these problems. To enhance scene representation capacity, we propose a hybrid encoding network that combines the complementary strengths of hash-grid, tri-planes, and one-blob, improving the completeness and smoothness of reconstruction. Additionally, we introduce structural supervision by sampling patches of non-local pixels rather than individual rays to better capture the scene structure. To ensure global consistency, we implement an active global bundle adjustment (BA) to eliminate camera drifts and mitigate accumulative errors. Experimental results demonstrate that HS-SLAM outperforms the baselines in tracking and reconstruction accuracy while maintaining the efficiency required for robotics.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt2_03">
             15:25-15:30, Paper WeDT2.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1339" name="modify1652" onclick="modify(1652,1339)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1652'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Gassidy: Gaussian Splatting SLAM in Dynamic Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#337488" title="Click to go to the Author Index">
             Wen, Long
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#414576" title="Click to go to the Author Index">
             Li, Shixin
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372916" title="Click to go to the Author Index">
             Zhang, Yu
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#218645" title="Click to go to the Author Index">
             Huang, Yuhong
            </a>
           </td>
           <td class="r">
            Technische Universität München
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#218370" title="Click to go to the Author Index">
             Lin, Jianjie
            </a>
           </td>
           <td class="r">
            Technische Universität München
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#248440" title="Click to go to the Author Index">
             Pan, Fengjunjie
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#195330" title="Click to go to the Author Index">
             Bing, Zhenshan
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105608" title="Click to go to the Author Index">
             Knoll, Alois
            </a>
           </td>
           <td class="r">
            Tech. Univ. Muenchen TUM
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1652" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             3D Gaussian Splatting (3DGS) allows flexible adjustments to scene representation, enabling continuous optimization of scene quality during dense visual simultaneous localization and mapping (SLAM) in static environments. However, 3DGS faces challenges in handling environmental disturbances from dynamic objects with irregular movement, leading to degradation in both camera tracking accuracy and map reconstruction quality. To address this challenge, we develop an RGB-D dense SLAM which is called Gaussian Splatting SLAM in Dynamic Environments (Gassidy). This approach calculates Gaussians to generate rendering loss flows for each environmental component based on a designed photometric-geometric loss function. To distinguish and filter environmental disturbances, we iteratively analyze rendering loss flows to detect features characterized by changes in loss values between dynamic objects and static components. This process ensures a clean environment for accurate scene reconstruction. Compared to state-of-the-art SLAM methods, experimental results on open datasets show that Gassidy improves camera tracking precision by up to 97.9% and enhances map quality by up to 6%.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt2_04">
             15:30-15:35, Paper WeDT2.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1340" name="modify1809" onclick="modify(1809,1340)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1809'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Large-Scale Gaussian Splatting SLAM
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#232868" title="Click to go to the Author Index">
             Xin, Zhe
            </a>
           </td>
           <td class="r">
            Meituan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397915" title="Click to go to the Author Index">
             Wu, Chenyang
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418641" title="Click to go to the Author Index">
             Huang, Penghui
            </a>
           </td>
           <td class="r">
            Meituan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#291452" title="Click to go to the Author Index">
             Zhang, Yanyong
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267538" title="Click to go to the Author Index">
             Mao, Yinian
            </a>
           </td>
           <td class="r">
            Meituan-Dianping Group
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#114431" title="Click to go to the Author Index">
             Huang, Guoquan (Paul)
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1809" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The recently developed Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have shown encouraging and impressive results for visual SLAM. However, most representative methods require RGBD sensors and are only available for indoor environments. The robustness of reconstruction in large-scale outdoor scenarios remains unexplored. This paper introduces a large-scale 3DGS-based visual SLAM with stereo cameras, termed LSG-SLAM. The proposed LSG-SLAM employs a multi-modality strategy to estimate prior poses under large view changes. In tracking, we introduce feature-alignment warping constraints to alleviate the adverse effects of appearance similarity in rendering losses. For the scalability of large-scale scenarios, we introduce continuous Gaussian Splatting submaps to tackle unbounded scenes with limited memory. Loops are detected between GS submaps by place recognition and the relative pose between looped keyframes is optimized utilizing rendering and feature warping losses. After the global optimization of camera poses and Gaussian points, a structure refinement module enhances the reconstruction quality. With extensive evaluations on the EuRoc and KITTI datasets, LSG SLAM achieves superior performance over existing Neural, 3DGS-based, and even traditional approaches.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt2_05">
             15:35-15:40, Paper WeDT2.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1341" name="modify1992" onclick="modify(1992,1341)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1992'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              OpenGS-SLAM: Open-Set Dense Semantic SLAM with 3D Gaussian Splatting for Object-Level Scene Understanding
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354310" title="Click to go to the Author Index">
             Yang, Dianyi
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#324050" title="Click to go to the Author Index">
             Gao, Yu
            </a>
           </td>
           <td class="r">
            Beijing Institude of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#353535" title="Click to go to the Author Index">
             Wang, Xihan
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#205136" title="Click to go to the Author Index">
             Yue, Yufeng
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#128868" title="Click to go to the Author Index">
             Yang, Yi
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#128869" title="Click to go to the Author Index">
             Fu, Mengyin
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1992" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent advancements in 3D Gaussian Splatting have significantly improved the efficiency and quality of dense semantic SLAM. However, previous methods are generally constrained by limited-category pre-trained classifiers and implicit semantic representation, which hinder their performance in open-set scenarios and restrict 3D object-level scene understanding. To address these issues, we propose OpenGS-SLAM, an innovative framework that utilizes 3D Gaussian representation to perform dense semantic SLAM in open-set environments. Our system integrates explicit semantic labels derived from 2D foundational models into the 3D Gaussian framework, facilitating robust 3D object-level scene understanding. We introduce Gaussian Voting Splatting to enable fast 2D label map rendering and scene updating. Additionally, we propose a Confidence-based 2D Label Consensus method to ensure consistent labeling across multiple views. Furthermore, we employ a Segmentation Counter Pruning strategy to improve the accuracy of semantic scene representation. Extensive experiments on both synthetic and real-world datasets demonstrate the effectiveness of our method in scene understanding, tracking, and mapping, achieving 10× faster semantic rendering and 2× lower storage costs compared to existing methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt2_06">
             15:40-15:45, Paper WeDT2.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1342" name="modify2195" onclick="modify(2195,1342)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2195'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SAP-SLAM: Semantic-Assisted Perception SLAM with 3D Gaussian Splatting
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423442" title="Click to go to the Author Index">
             Yang, Yuheng
            </a>
           </td>
           <td class="r">
            Shenzhen International Graduate School, Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423704" title="Click to go to the Author Index">
             Lin, Yudong
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#347326" title="Click to go to the Author Index">
             Yang, Wenming
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#227843" title="Click to go to the Author Index">
             Wang, Guijin
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#324012" title="Click to go to the Author Index">
             Liao, Qingmin
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2195" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The integration of 3D Gaussians has introduced a novel scene representation in Simultaneous Localization and Mapping (SLAM), characterized by explicit representation and differentiable rendering capabilities that enhance scene reconstruction and understanding. However, most current SLAM systems only exploit the basic representational capacity of 3D Gaussians, neglecting their potential to offer richer information and facilitate higher-dimensional scene comprehension. Furthermore, these systems often struggle with reconstruction when encountering rapid camera movements or depth missing. Drawing inspiration from 3D language field, which explores the intrinsic relationships among scene objects, we propose SAP-SLAM, a dense SLAM system that combines robust tracking, high-fidelity reconstruction, and advanced semantic understanding. Our approach leverages pre-trained visual models to extract semantic features, which are then fused, dimensionally reduced, and encoded into the 3D Gaussian model for optimization and rendering. The integration of these features improves the systems’ semantic comprehension and scene representation, ultimately enabling the creation of high-precision 3D semantic maps. Additionally, we introduce a semantic-guided Gaussian densification and pruning strategy, which uses semantic consistency to prioritize attention on poorly reconstructed areas, greatly improving performance in complex scenarios. SAP-SLAM achieves competitive results on both synthetic and real-world datasets, demonstrating superior capabilities in semantic understanding and reconstruction.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt2_07">
             15:45-15:50, Paper WeDT2.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1343" name="modify4415" onclick="modify(4415,1343)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4415'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Gaussian-LIC: Real-Time Photo-Realistic SLAM with Gaussian Splatting and LiDAR-Inertial-Camera Fusion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#293969" title="Click to go to the Author Index">
             Lang, Xiaolei
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#325876" title="Click to go to the Author Index">
             Li, Laijian
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#195500" title="Click to go to the Author Index">
             Wu, Chenming
            </a>
           </td>
           <td class="r">
            Baidu Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#394858" title="Click to go to the Author Index">
             Zhao, Chen
            </a>
           </td>
           <td class="r">
            Baidu Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#334693" title="Click to go to the Author Index">
             Liu, Lina
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#122966" title="Click to go to the Author Index">
             Liu, Yong
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#246892" title="Click to go to the Author Index">
             Lv, Jiajun
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#209861" title="Click to go to the Author Index">
             Zuo, Xingxing
            </a>
           </td>
           <td class="r">
            Caltech
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4415" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we present a real-time photo-realistic SLAM method based on marrying Gaussian Splatting with LiDAR-Inertial-Camera SLAM. Most existing radiance-field-based SLAM systems mainly focus on bounded indoor environments, equipped with RGB-D or RGB sensors. However, they are prone to decline when expanding to unbounded scenes or encountering adverse conditions, such as violent motions and changing illumination. In contrast, oriented to general scenarios, our approach additionally tightly fuses LiDAR, IMU, and camera for robust pose estimation and photo-realistic online mapping. To compensate for regions unobserved by the LiDAR, we propose to integrate both the triangulated visual points from images and LiDAR points for initializing 3D Gaussians. In addition, the modeling of the sky and varying camera exposure have been realized for high-quality rendering. Notably, we implement our system purely with C++ and CUDA, and meticulously design a series of strategies to accelerate the online optimization of the Gaussian-based scene representation. Extensive experiments demonstrate that our method outperforms its counterparts while maintaining real-time capability. Impressively, regarding photo-realistic mapping, our method with our estimated poses even surpasses all the compared approaches that utilize privileged ground-truth poses for mapping. Our code will be released on project page https://xingxingzuo.github.io/gaussian_lic.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt3">
             <b>
              WeDT3
             </b>
             Regular Session, 303
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1344" name="modifyWeDT3" onclick="modsession(449,1344)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt3" title="Click to go to the Program at a Glance">
             <b>
              Planning for Autonomous Racing
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#211475" title="Click to go to the Author Index">
             Miao, Fei
            </a>
           </td>
           <td class="r">
            University of Connecticut
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#238029" title="Click to go to the Author Index">
             Laine, Forrest
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt3_01">
             15:15-15:20, Paper WeDT3.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1345" name="modify1617" onclick="modify(1617,1345)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1617'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Risk-Averse Model Predictive Control for Racing in Adverse Conditions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#241063" title="Click to go to the Author Index">
             Lew, Thomas
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#229061" title="Click to go to the Author Index">
             Greiff, Marcus
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#314650" title="Click to go to the Author Index">
             Djeumou, Franck
            </a>
           </td>
           <td class="r">
            University of Texas, Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422013" title="Click to go to the Author Index">
             Suminaka, Makoto
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338201" title="Click to go to the Author Index">
             Thompson, Michael
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#283513" title="Click to go to the Author Index">
             Subosits, John
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1617" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#planning_under_uncertainty" title="Click to go to the Keyword Index">
               Planning under Uncertainty
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Model predictive control (MPC) algorithms can be sensitive to model mismatch when used in challenging nonlinear control tasks. In particular, the performance of MPC for vehicle control at the limits of handling suffers when the underlying model overestimates the vehicle’s performance capability. In this work, we propose a risk-averse MPC framework that explicitly accounts for uncertainty over friction limits and tire parameters. Our approach leverages a sample-based approximation of an optimal control problem with a conditional value at risk (CVaR) constraint. This sample-based formulation enables planning with a set of expressive vehicle dynamics models using different tire parameters. Moreover, this formulation enables efficient numerical resolution via sequential quadratic programming and GPU parallelization. Experiments on a Lexus LC 500 show that risk-averse MPC unlocks reliable performance, while a deterministic baseline that plans using a single dynamics model may lose control of the vehicle in adverse road conditions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt3_02">
             15:20-15:25, Paper WeDT3.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1346" name="modify2076" onclick="modify(2076,1346)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2076'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Kineto-Dynamical Planning and Accurate Execution of Minimum-Time Maneuvers on Three-Dimensional Circuits
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#277983" title="Click to go to the Author Index">
             Piccinini, Mattia
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423357" title="Click to go to the Author Index">
             Taddei, Sebastiano
            </a>
           </td>
           <td class="r">
            University of Trento, Politecnico Di Bari
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#268360" title="Click to go to the Author Index">
             Betz, Johannes
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#224143" title="Click to go to the Author Index">
             Biral, Francesco
            </a>
           </td>
           <td class="r">
            University of Trento
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2076" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Online planning and execution of minimum-time maneuvers on three-dimensional (3D) circuits is an open challenge in autonomous vehicle racing. In this paper, we present an artificial race driver (ARD) to learn the vehicle dynamics, plan and execute minimum-time maneuvers on a 3D track. ARD integrates a novel kineto-dynamical (KD) vehicle model for trajectory planning with economic nonlinear model predictive control (E-NMPC). We use a high-fidelity vehicle simulator (VS) to compare the closed-loop ARD results with a minimum-lap-time optimal control problem (MLT-VS), solved offline with the same VS. Our ARD sets lap times close to the MLT-VS, and the new KD model outperforms a literature benchmark. Finally, we study the vehicle trajectories, to assess the re-planning capabilities of ARD under execution errors. A video with the main results is available as supplementary material.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt3_03">
             15:25-15:30, Paper WeDT3.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1347" name="modify3036" onclick="modify(3036,1347)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3036'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safety Guaranteed Robust Multi-Agent Reinforcement Learning with Hierarchical Control for Connected and Automated Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#299699" title="Click to go to the Author Index">
             Zhang, Zhili
            </a>
           </td>
           <td class="r">
            University of Connecticut
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#341289" title="Click to go to the Author Index">
             Ahmad, H M Sabbir
            </a>
           </td>
           <td class="r">
            Boston University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#329380" title="Click to go to the Author Index">
             Sabouni, Ehsan
            </a>
           </td>
           <td class="r">
            Boston University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#377079" title="Click to go to the Author Index">
             Sun, Yanchao
            </a>
           </td>
           <td class="r">
            JPMorgan Chase
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#377946" title="Click to go to the Author Index">
             Huang, Furong
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#206069" title="Click to go to the Author Index">
             Li, Wenchao
            </a>
           </td>
           <td class="r">
            Boston University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#211475" title="Click to go to the Author Index">
             Miao, Fei
            </a>
           </td>
           <td class="r">
            University of Connecticut
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3036" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_control" title="Click to go to the Keyword Index">
               Integrated Planning and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning_under_uncertainty" title="Click to go to the Keyword Index">
               Planning under Uncertainty
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We address the problem of coordination and control of Connected and Automated Vehicles (CAVs) in the presence of imperfect observations in mixed traffic environment. A commonly used approach is learning-based decision-making, such as reinforcement learning (RL). However, most existing safe RL methods suffer from two limitations: (i) they assume accurate state information, and (ii) safety is generally defined over the expectation of the trajectories. It remains challenging to design optimal coordination between multi-agents while ensuring hard safety constraints under system state uncertainties (e.g., those that arise from noisy sensor measurements, communication, or state estimation methods) at every time step. We propose a safety guaranteed hierarchical coordination and control scheme called Safe-RMM to address the challenge. Specifically, the high-level coordination policy of CAVs in mixed traffic environment is trained by the Robust Multi-Agent Proximal Policy Optimization (RMAPPO) method. Though trained without uncertainty, our method leverages a worst-case Q network to ensure the model's robust performances when state uncertainties are present during testing. The low-level controller is implemented using model predictive control (MPC) with robust Control Barrier Functions (CBFs) to guarantee safety through their forward invariance property. We compare our method with baselines in different road networks in the CARLA simulator. Results show that our method provides the best evaluated safety and efficiency in challenging mixed traffic environments with uncertainties.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt3_04">
             15:30-15:35, Paper WeDT3.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1348" name="modify3189" onclick="modify(3189,1348)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3189'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Does Bilevel Optimization Result in More Competitive Racing Behavior?
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#301552" title="Click to go to the Author Index">
             Cinar, Andrew
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#238029" title="Click to go to the Author Index">
             Laine, Forrest
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3189" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Two-vehicle racing is natural example of a competitive dynamic game. As with most dynamic games, there are many ways in which the underlying solution concept can be structured, resulting in different equilibrium concepts. The assumed solution concept influences the behaviors of two interacting players in racing. For example, blocking behavior emerges naturally in leader-follower play, but to achieve this in Nash play the costs would have to be chosen specifically to trigger this behavior. In this work, we develop a novel model for competitive two-player vehicle racing, represented as an equilibrium problem, complete with simplified aerodynamic drag and drafting effects, as well as position-dependent collision-avoidance responsibility. We use our model to explore how different solution concepts affect competitiveness. We develop a solution for bilevel optimization problems, enabling a large-scale empirical study comparing bilevel strategies (either as leader or follower), Nash equilibrium strategy and a single-player constant velocity baseline. We find the choice of strategies significantly affects competitive performance and safety.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt3_05">
             15:35-15:40, Paper WeDT3.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1349" name="modify3544" onclick="modify(3544,1349)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3544'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Gate-Aware Online Planning for Two-Player Autonomous Drone Racing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354526" title="Click to go to the Author Index">
             Zhao, Fangguo
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#388363" title="Click to go to the Author Index">
             Mei, Jiahao
            </a>
           </td>
           <td class="r">
            Zhejiang University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354528" title="Click to go to the Author Index">
             Zhou, Jin
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423261" title="Click to go to the Author Index">
             Chen, Yuanyi
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#163844" title="Click to go to the Author Index">
             Chen, Jiming
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#230382" title="Click to go to the Author Index">
             Li, Shuo
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3544" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The flying speed of autonomous quadrotors has increased significantly in the field of autonomous drone racing. However, most research primarily focuses on the aggressive flight of a single quadrotor, simplifying the racing gate traversal problem to a waypoint passing problem that neglects the orientations of the racing gates {or implicitly considers the waypoint direction during path planning}. In this paper, we propose a systematic method called Pairwise Model Predictive Control (PMPC) that can guide two quadrotors online to navigate racing gates with minimal time and without collisions. The flight task is initially simplified as a point-mass model waypoint passing problem to provide time optimal reference through an efficient two-step velocity search method. Subsequently, we utilize the spatial configuration of the racing track to compute the optimal heading at each gate, maximizing the visibility of subsequent gates for the quadrotors. To address varying gate orientations, we introduce a novel Magnetic Induction Line-based spatial curve to guide the quadrotors through racing gates of different orientations. Furthermore, we formulate a nonlinear optimization problem that uses the point-mass trajectory as initial values and references to enhance solving efficiency. The feasibility of the proposed method is validated through both simulation and real-world experiments. In real-world tests, the two quadrotors achieved a top speed of 6.1 m/s on a 7-waypoint racing track within a compact flying arena of 5 m * 4 m * 2 m.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt3_06">
             15:40-15:45, Paper WeDT3.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1350" name="modify5051" onclick="modify(5051,1350)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5051'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              TC-Driver: A Trajectory Conditioned Reinforcement Learning Approach to Zero-Shot Autonomous Racing (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335798" title="Click to go to the Author Index">
             Ghignone, Edoardo
            </a>
           </td>
           <td class="r">
            ETH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335794" title="Click to go to the Author Index">
             Baumann, Nicolas
            </a>
           </td>
           <td class="r">
            ETH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335799" title="Click to go to the Author Index">
             Magno, Michele
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5051" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous racing challenges perception, planning, and control algorithms, serving as a testbed for general autonomous driving. While traditional methods like MPC can generate optimal control sequences, they are sensitive to modeling parameter accuracy. This paper introduces TC-Driver, a Reinforcement Learning (RL) approach for robust control in autonomous racing, addressing tire parameter modeling inaccuracies. TC-Driver is conditioned by a trajectory from any high-level planner, combining RL’s learning capabilities with the reliability of traditional planning. Trained under varying tire conditions, it aims to generalize across different model parameters, enhancing real-world racing performance. Experimental results show TC-Driver improves generalization robustness compared to a state-of-the-art end-to-end architecture. It achieves a 29-fold improvement in crash ratio when facing model mismatch and successfully transfers to unseen tracks with new features, while the baseline fails. In physical deployment, TC-Driver demonstrates zero-shot Sim2Real capabilities, outperforming end-to-end agents 10-fold in crash ratio while maintaining similar driving characteristics in reality as in simulation. This hybrid RL architecture leverages traditional planning methods’ reliability while exploiting RL’s ability to handle model uncertainties, offering a robust solution for autonomous racing challenges.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt3_07">
             15:45-15:50, Paper WeDT3.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1351" name="modify5067" onclick="modify(5067,1351)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5067'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Er.autopilot 1.1: A Software Stack for Autonomous Racing on Oval and Road Course Tracks (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#386864" title="Click to go to the Author Index">
             Raji, Ayoub
            </a>
           </td>
           <td class="r">
            University of Modena and Reggio Emilia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#194984" title="Click to go to the Author Index">
             Caporale, Danilo
            </a>
           </td>
           <td class="r">
            Centro Di Ricerca E. Piaggio
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#431946" title="Click to go to the Author Index">
             Gatti, Francesco
            </a>
           </td>
           <td class="r">
            Hipert Srl
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#431948" title="Click to go to the Author Index">
             Toschi, Alessandro
            </a>
           </td>
           <td class="r">
            University of Modena and Reggio Emlilia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#431952" title="Click to go to the Author Index">
             Musiu, Nicola
            </a>
           </td>
           <td class="r">
            University of Modena and Reggio Emilia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#302591" title="Click to go to the Author Index">
             Verucchi, Micaela
            </a>
           </td>
           <td class="r">
            University of Modena and Reggio Emilia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#431953" title="Click to go to the Author Index">
             Prignoli, Francesco
            </a>
           </td>
           <td class="r">
            University of Modena and Reggio Emilia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#431954" title="Click to go to the Author Index">
             Malatesta, Davide
            </a>
           </td>
           <td class="r">
            Technology Innovation Institute -Autonomous Robotics Research Ce
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#431956" title="Click to go to the Author Index">
             Jesus, André Fialho
            </a>
           </td>
           <td class="r">
            Technology Innovation Institute - Autonomous Robotics Research C
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338065" title="Click to go to the Author Index">
             Finazzi, Andrea
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#235828" title="Click to go to the Author Index">
             Amerotti, Francesco
            </a>
           </td>
           <td class="r">
            Università Di Pisa
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#431957" title="Click to go to the Author Index">
             Bagni, Fabio
            </a>
           </td>
           <td class="r">
            Hipert Srl
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#431958" title="Click to go to the Author Index">
             Mascaro, Eugenio
            </a>
           </td>
           <td class="r">
            University of Modena and Reggio Emilia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#431959" title="Click to go to the Author Index">
             Musso, Pietro
            </a>
           </td>
           <td class="r">
            University of Modena and Reggio Emilia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#348717" title="Click to go to the Author Index">
             Marko, Bertogna
            </a>
           </td>
           <td class="r">
            Unimore
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5067" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#software_architecture_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Software Architecture for Robotic and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In its first two seasons, the Indy Autonomous Challenge (IAC) organized a series of autonomous racing events across some of the most renowned oval racetracks, introducing various challenges including high-speed solo runs, static obstacle avoidance, and complex head-to-head passing competitions. In 2023, the challenge expanded to include a time-trial event on the iconic F1 Monza road course. This paper outlines the complete software architecture utilized by team TII Unimore Racing (formerly TII EuroRacing), er.autopilot 1.1, encompassing all modules necessary for static obstacle avoidance, active overtakes, achieving speeds over 75 m/s (270 km/h), and navigating complex road course tracks. Building on the previous version, this updated stack integrates new features such as LiDAR-based localization, lateral velocity estimation, a radar-based local controller for safe pull-overs, and refined vehicle modeling for the Model Predictive Controller. We present the overall results along with insights and lessons learned from the first two seasons, during which the team consistently achieved the podium.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt4">
             <b>
              WeDT4
             </b>
             Regular Session, 304
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1352" name="modifyWeDT4" onclick="modsession(537,1352)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt4" title="Click to go to the Program at a Glance">
             <b>
              Sensor Fusion 3
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#215820" title="Click to go to the Author Index">
             Chen, Boyuan
            </a>
           </td>
           <td class="r">
            Duke University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#168686" title="Click to go to the Author Index">
             Huai, Zheng
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt4_01">
             15:15-15:20, Paper WeDT4.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1353" name="modify809" onclick="modify(809,1353)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('809'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              FlatFusion: Delving into Details of Sparse Transformer-Based Camera-LiDAR Fusion for Autonomous Driving
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#414101" title="Click to go to the Author Index">
             Zhu, Yutao
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#286829" title="Click to go to the Author Index">
             Jia, Xiaosong
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#341590" title="Click to go to the Author Index">
             Yang, Xinyu
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#297306" title="Click to go to the Author Index">
             Yan, Junchi
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab809" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The integration of data from various sensor modalities (e.g. camera and LiDAR) constitutes a prevalent methodology within the ambit of autonomous driving scenarios. Recent advancements in efficient point cloud transformers have underscored the efficacy of integrating information in sparse formats. When it comes to fusion, since image patches are dense in pixel space with ambiguous depth, it necessitates additional design considerations for effective fusion. In this paper, we conduct a comprehensive exploration of design choices for transformer-based sparse camera-LiDAR fusion. This investigation encompasses strategies for image-to-3D and LiDAR-to-2D mapping, attention neighbor grouping, single modal tokenizer, and micro-structure of Transformer. By amalgamating the most effective principles uncovered through our investigation, we introduce FlatFusion, a carefully designed framework for sparse camera-LiDAR fusion. Notably, FlatFusion significantly outperforms state-of-the-art sparse Transformer-based methods, including UniTR, CMT, and SparseFusion, achieving 73.7 NDS on the nuScenes validation set with 10.1 FPS with PyTorch.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt4_02">
             15:20-15:25, Paper WeDT4.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1354" name="modify2493" onclick="modify(2493,1354)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2493'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A2DO: Adaptive Anti-Degradation Odometry with Deep Multi-Sensor Fusion for Autonomous Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420161" title="Click to go to the Author Index">
             Lai, Hui
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#374012" title="Click to go to the Author Index">
             Chen, Qi
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#198108" title="Click to go to the Author Index">
             Zhang, Junping
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#276122" title="Click to go to the Author Index">
             Pu, Jian
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2493" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurate localization is essential for the safe and effective navigation of autonomous vehicles, and Simultaneous Localization and Mapping (SLAM) is a cornerstone technology in this context. However, The performance of the SLAM system can deteriorate under challenging conditions such as low light, adverse weather, or obstructions due to sensor degradation. We present A2DO, a novel end-to-end multi- sensor fusion odometry system that enhances robustness in these scenarios through deep neural networks. A2DO integrates LiDAR and visual data, employing a multi-layer, multi-scale feature encoding module augmented by an attention mechanism to mitigate sensor degradation dynamically. The system is pre- trained extensively on simulated datasets covering a broad range of degradation scenarios and fine-tuned on a curated set of real-world data, ensuring robust adaptation to complex scenarios. Our experiments demonstrate that A2DO maintains superior localization accuracy and robustness across various degradation conditions, showcasing its potential for practical implementation in autonomous vehicle systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt4_03">
             15:25-15:30, Paper WeDT4.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1355" name="modify2789" onclick="modify(2789,1355)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2789'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Tunable Virtual IMU Frame by Weighted Averaging of Multiple Non-Collocated IMUs
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424039" title="Click to go to the Author Index">
             Gao, Yizhou
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#115139" title="Click to go to the Author Index">
             Barfoot, Timothy
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2789" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_inertial_slam" title="Click to go to the Keyword Index">
               Visual-Inertial SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a new method to combine several rigidly connected but physically separated IMUs through a weighted average into a single virtual IMU (VIMU). This has the benefits of (i) reducing process noise through averaging, and (ii) allowing for tuning the location of the VIMU. The VIMU can be placed to be coincident with, for example, a camera frame or GNSS frame, thereby offering a quality-of-life improvement for users. Specifically, our VIMU removes the need to consider any lever-arm terms in the propagation model.	We also present a quadratic programming method for selecting the weights to minimize the noise of the VIMU while still selecting the placement of its reference frame. We tested our method in simulation and validated it on a real dataset. The results show that our averaging technique works for IMUs with large separation and performance gain is observed in both the simulation and the real experiment compared to using only a single IMU.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt4_04">
             15:30-15:35, Paper WeDT4.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1356" name="modify3223" onclick="modify(3223,1356)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3223'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              WildFusion: Multimodal Implicit 3D Reconstructions in the Wild
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425072" title="Click to go to the Author Index">
             Liu, Yanbaihui
            </a>
           </td>
           <td class="r">
            Duke University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#215820" title="Click to go to the Author Index">
             Chen, Boyuan
            </a>
           </td>
           <td class="r">
            Duke University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3223" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose WildFusion, a novel approach for 3D scene reconstruction in unstructured, in-the-wild environments using multimodal implicit neural representations. WildFusion integrates signals from LiDAR, RGB camera, contact microphones, tactile sensors, and IMU. This multimodal fusion generates comprehensive, continuous environmental representations, including pixel-level geometry, color, semantics, and traversability. Through real-world experiments on legged robot navigation in challenging forest environments, WildFusion demonstrates improved route selection by accurately predicting traversability. Our results highlight its potential to advance robotic navigation and 3D mapping in complex outdoor terrains.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt4_05">
             15:35-15:40, Paper WeDT4.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1357" name="modify3386" onclick="modify(3386,1357)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3386'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Steering Prediction Via a Multi-Sensor System for Autonomous Racing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#340024" title="Click to go to the Author Index">
             Zhou, Zhuyun
            </a>
           </td>
           <td class="r">
            University of Burgundy (Université De Bourgogne), France
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#285487" title="Click to go to the Author Index">
             Wu, Zongwei
            </a>
           </td>
           <td class="r">
            University of Wurzburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395390" title="Click to go to the Author Index">
             Bolli, Florian
            </a>
           </td>
           <td class="r">
            University of Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#116702" title="Click to go to the Author Index">
             Boutteau, Rémi
            </a>
           </td>
           <td class="r">
            Université De Rouen Normandie
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339756" title="Click to go to the Author Index">
             Yang, Fan
            </a>
           </td>
           <td class="r">
            Univ. Bourgogne Franche-Comté
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#145365" title="Click to go to the Author Index">
             Timofte, Radu
            </a>
           </td>
           <td class="r">
            University of Wurzburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#158998" title="Click to go to the Author Index">
             Ginhac, Dominique
            </a>
           </td>
           <td class="r">
            Univ Burgundy
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#164327" title="Click to go to the Author Index">
             Delbruck, Tobi
            </a>
           </td>
           <td class="r">
            Univ. of Zurich &amp; ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3386" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous racing has rapidly gained research attention. Traditionally, racing cars rely on 2D LiDAR as their primary visual system. In this work, we explore the integration of an event camera with the existing system to provide enhanced temporal information. Our goal is to fuse the 2D LiDAR data with event data in an end-to-end learning framework for steering prediction, which is crucial for autonomous racing. To the best of our knowledge, this is the first study addressing this challenging research topic. We start by creating a multisensor dataset specifically for steering prediction. Using this dataset, we establish a benchmark by evaluating various SOTA fusion methods. Our observations reveal that existing methods often incur substantial computational costs. To address this, we apply low-rank techniques to propose a novel, efficient, and effective fusion design. We introduce a new fusion learning policy to guide the fusion process, enhancing robustness against misalignment. Our fusion architecture provides better steering prediction than LiDAR alone, significantly reducing the RMSE from 7.72 to 1.28. Compared to the second-best fusion method, our work represents only 11% of the learnable parameters while achieving better accuracy. The source code, dataset, and benchmark will be released to promote future research.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt4_06">
             15:40-15:45, Paper WeDT4.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1358" name="modify4953" onclick="modify(4953,1358)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4953'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Are Doppler Velocity Measurements Useful for Spinning Radar Odometry?
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#295983" title="Click to go to the Author Index">
             Lisus, Daniil
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#237999" title="Click to go to the Author Index">
             Burnett, Keenan
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#196386" title="Click to go to the Author Index">
             Yoon, David Juny
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411824" title="Click to go to the Author Index">
             Poulton, Richard
            </a>
           </td>
           <td class="r">
            Navtech Radar
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411825" title="Click to go to the Author Index">
             Marshall, John
            </a>
           </td>
           <td class="r">
            Navtech Radar
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#115139" title="Click to go to the Author Index">
             Barfoot, Timothy
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4953" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Spinning, frequency-modulated continuous-wave (FMCW) radars with 360 degree coverage have been gaining popularity for autonomous-vehicle navigation. However, unlike 'fixed' automotive radar, commercially available spinning radar systems typically do not produce radial velocities due to the lack of repeated measurements in the same direction and the fundamental hardware setup. To make these radial velocities observable, we modified the firmware of a commercial spinning radar to use triangular frequency modulation. In this paper, we develop a novel way to use this modulation to extract radial Doppler velocity measurements from consecutive azimuths of a radar intensity scan, without any data association. We show that these noisy, error-prone measurements contain enough information to provide good ego-velocity estimates, and incorporate these estimates into different modern odometry pipelines. We extensively evaluate the pipelines on over 110 km of driving data in progressively more geometrically challenging autonomous-driving environments. We show that Doppler velocity measurements improve odometry in well-defined geometric conditions and enable it to continue functioning even in severely geometrically degenerate environments, such as long tunnels.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt5">
             <b>
              WeDT5
             </b>
             Regular Session, 305
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1359" name="modifyWeDT5" onclick="modsession(33,1359)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt5" title="Click to go to the Program at a Glance">
             <b>
              Aerial Robots: Mechanics and Control 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#108037" title="Click to go to the Author Index">
             Khorrami, Farshad
            </a>
           </td>
           <td class="r">
            New York University Tandon School of Engineering
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#169065" title="Click to go to the Author Index">
             Garcia de Marina, Hector
            </a>
           </td>
           <td class="r">
            Universidad De Granada
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt5_01">
             15:15-15:20, Paper WeDT5.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1360" name="modify58" onclick="modify(58,1360)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('58'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Skater: A Novel Bi-Modal Bi-Copter Robot for Adaptive Locomotion in Air and Diverse Terrain
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#352845" title="Click to go to the Author Index">
             Lin, Junxiao
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#275156" title="Click to go to the Author Index">
             Zhang, Ruibin
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#288062" title="Click to go to the Author Index">
             Pan, Neng
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#213352" title="Click to go to the Author Index">
             Xu, Chao
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#200893" title="Click to go to the Author Index">
             Gao, Fei
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab58" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this letter, we present a novel bi-modal bi-copter robot called Skater, which is adaptable to air and various ground surfaces. Skater consists of a bi-copter moving along its longitudinal direction with two passive wheels on both sides. Using a longitudinally arranged bi-copter as the unified actuation system for both aerial and ground modes, this robot not only keeps a concise and lightweight mechanism but also possesses exceptional terrain traversing capability and strong steering capacity. Moreover, leveraging the vectored thrust characteristic of bi-copters, the Skater can actively generate the centripetal force needed for steering, enabling it to achieve stable movement even on slippery surfaces. Furthermore, we model the comprehensive dynamics of the Skater, analyze its differential flatness, and introduce a controller using nonlinear model predictive control for trajectory tracking. The outstanding performance of the system is verified by extensive real-world experiments and benchmark comparisons.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt5_02">
             15:20-15:25, Paper WeDT5.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1361" name="modify1509" onclick="modify(1509,1361)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1509'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Inverse Kinematics on Guiding Vector Fields for Robot Path Following
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405856" title="Click to go to the Author Index">
             Zhou, Yu
            </a>
           </td>
           <td class="r">
            INRIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#371877" title="Click to go to the Author Index">
             Bautista, Jesús
            </a>
           </td>
           <td class="r">
            Universidad De Granada
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#189263" title="Click to go to the Author Index">
             Yao, Weijia
            </a>
           </td>
           <td class="r">
            Hunan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#169065" title="Click to go to the Author Index">
             Garcia de Marina, Hector
            </a>
           </td>
           <td class="r">
            Universidad De Granada
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1509" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Inverse kinematics is a fundamental technique for motion and positioning control in robotics, typically applied to end-effectors. In this paper, we extend the concept of inverse kinematics to guiding vector fields for path following in autonomous mobile robots. The desired path is defined by its implicit equation, i.e., by a collection of points belonging to one or more zero-level sets. These level sets serve as a reference to construct an error signal that drives the guiding vector field toward the desired path, enabling the robot to converge and travel along the path by following such a vector field. We start with the formal exposition on how inverse kinematics can be applied to guiding vector fields for single-integrator robots in an m-dimensional Euclidean space. Then, we leverage inverse kinematics to ensure that the level-set error signal behaves as a linear system, facilitating control over the robot's transient motion toward the desired path and allowing for the injection of feed-forward signals to induce precise motion behavior along the path. We then propose solutions to the theoretical and practical challenges of applying this technique to unicycles with constant speeds to follow 2D paths with precise transient control. We finish by validating the predicted theoretical results through real flights with fixed-wing drones.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt5_03">
             15:25-15:30, Paper WeDT5.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1362" name="modify1933" onclick="modify(1933,1362)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1933'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Dragonfly Drone: A Novel Tilt-Rotor Aerial Platform with Body-Morphing Capability
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422682" title="Click to go to the Author Index">
             Hameed, Syed Waqar
            </a>
           </td>
           <td class="r">
            NTU
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422751" title="Click to go to the Author Index">
             Liew Jun Jie, Alex
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#227936" title="Click to go to the Author Index">
             Nursultan, Imanberdiyev
            </a>
           </td>
           <td class="r">
            Agency for Science, Technology and Research (A*STAR)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203750" title="Click to go to the Author Index">
             Camci, Efe
            </a>
           </td>
           <td class="r">
            Institute for Infocomm Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#196715" title="Click to go to the Author Index">
             Yau, Wei-Yun
            </a>
           </td>
           <td class="r">
            I2R
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#271962" title="Click to go to the Author Index">
             Feroskhan, Mir
            </a>
           </td>
           <td class="r">
            Nanyang Technological University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1933" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The development of unmanned aerial vehicles (UAVs) with extended maneuverability has unlocked new applications such as complex inspection tasks at height. In this work, we introduce the Dragonfly drone, a novel tilt-rotor body-morphing UAV, capable of altering its shape and orientation without compromising its position tracking. Unlike most existing UAV designs that only target at decoupling position and orientation control, Dragonfly can also perform unique body-morphing in flight, featuring all six degrees of freedom in every morphology. This enables navigation into tight gaps with irregular shapes, conforming to obstacles of varying geometries, and maintaining physical contact with uneven surfaces. Such capabilities make our design particularly effective for complex inspection tasks at height, such as pipe or bridge inspection. Our contributions include the mechanical design of the system, the modeling and control strategies employed, and the real-robot experiments with a prototype platform. See Dragonfly drone in action: https://youtu.be/YxoV_Qt_5XE.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt5_04">
             15:30-15:35, Paper WeDT5.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1363" name="modify2106" onclick="modify(2106,1363)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2106'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Omnidirectional Non-Tethered Aerial Prototype with Fixed Uni-Directional Thrusters
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#204761" title="Click to go to the Author Index">
             Hamandi, Mahmoud
            </a>
           </td>
           <td class="r">
            New York University Abu Dhabi
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423454" title="Click to go to the Author Index">
             Ali, Abdullah Mohamed
            </a>
           </td>
           <td class="r">
            New York University Abu Dhabi
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103188" title="Click to go to the Author Index">
             Kyriakopoulos, Kostas
            </a>
           </td>
           <td class="r">
            New York University - Abu Dhabi
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106618" title="Click to go to the Author Index">
             Tzes, Anthony
            </a>
           </td>
           <td class="r">
            New York University Abu Dhabi
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#108037" title="Click to go to the Author Index">
             Khorrami, Farshad
            </a>
           </td>
           <td class="r">
            New York University Tandon School of Engineering
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2106" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#product_design__development_and_prototyping" title="Click to go to the Keyword Index">
               Product Design, Development and Prototyping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents the first worldwide functional prototype omnidirectional multi-rotor aerial vehicle with fixed uni-directional thrusters, with an on-board power source. An optimization algorithm computes the positions and orientations of the propellers in the body frame of the prototype to achieve the omnidirectional capability, while minimizing the platform's weight and the required thrust to hover at any orientation, in addition to other construction requirements. The effect of the aerodynamic interaction between the different propellers is identified experimentally, and the ensuing results are included in the optimization algorithm to avoid such interactions during flight. The prototype's performance is assessed in real experiments demonstrating the decoupling between the forces and moments of the drone, its ability to track concurrently independent positions and orientations, and its ability to hover at a fixed position while rotating.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt5_05">
             15:35-15:40, Paper WeDT5.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1364" name="modify4462" onclick="modify(4462,1364)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4462'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Dense Fixed-Wing Swarming Using Receding-Horizon NMPC
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#294447" title="Click to go to the Author Index">
             Madabushi, Varun
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#353937" title="Click to go to the Author Index">
             Kopel, Yocheved
            </a>
           </td>
           <td class="r">
            The Johns Hopkins University Applied Physics Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#289508" title="Click to go to the Author Index">
             Polevoy, Adam
            </a>
           </td>
           <td class="r">
            Johns Hopkins University Applied Physics Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#148235" title="Click to go to the Author Index">
             Moore, Joseph
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4462" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we present an approach for controlling a team of agile fixed-wing aerial vehicles in close proximity to one another. Our approach relies on receding-horizon nonlinear model predictive control (NMPC) to plan maneuvers across an expanded flight envelope to enable inter-agent collision avoidance. To facilitate robust collision avoidance and characterize the likelihood of inter-agent collisions, we compute a statistical bound on the probability of the system leaving a tube around the planned nominal trajectory. Finally, we propose a metric for evaluating highly dynamic swarms and use this metric to evaluate our approach. We successfully demonstrated our approach through both simulation and hardware experiments, and to our knowledge, this the first time close-quarters swarming has been achieved with physical aerobatic fixed-wing vehicles.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt5_06">
             15:40-15:45, Paper WeDT5.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1365" name="modify4964" onclick="modify(4964,1365)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4964'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              HPA-MPC: Hybrid Perception-Aware Nonlinear Model Predictive Control for Quadrotors with Suspended Loads
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#413138" title="Click to go to the Author Index">
             Sarvaiya, Mrunal
            </a>
           </td>
           <td class="r">
            Agile Robotics and Perception Lab, NYU
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#218133" title="Click to go to the Author Index">
             Li, Guanrui
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#142369" title="Click to go to the Author Index">
             Loianno, Giuseppe
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4964" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Quadrotors equipped with cable-suspended loads represent a versatile, low-cost, and energy efficient solution for aerial transportation, construction, and manipulation tasks. However, their real-world deployment is hindered by several challenges. The system is difficult to control because it is nonlinear, underactuated, involves hybrid dynamics due to slack-taut cable modes, and evolves on complex configuration spaces. Additionally, it is crucial to estimate the full state and the cable’s mode transitions in real-time using on-board sensors and computation. To address these challenges, we present a novel Hybrid Perception-Aware Nonlinear Model Predictive Control (HPA-MPC) control approach for quadrotors with suspended loads. Our method considers the complete hybrid system dynamics and includes a perception-aware cost to ensure the payload remains visible in the robot’s camera during navigation. Furthermore, the full state and hybrid dynamics’ transitions are estimated using onboard sensors. Experimental results demonstrate that our approach enables stable load tracking control, even during slack-taut transitions, and operates entirely onboard. The experiments also show that the perception-aware term effectively keeps the payload in the robot’s camera field of view when a human operator interacts with the load.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt6">
             <b>
              WeDT6
             </b>
             Regular Session, 307
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1366" name="modifyWeDT6" onclick="modsession(405,1366)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt6" title="Click to go to the Program at a Glance">
             <b>
              Perception for Grasping and Manipulation
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#102604" title="Click to go to the Author Index">
             Dudek, Gregory
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#238613" title="Click to go to the Author Index">
             Zhi, Weiming
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt6_01">
             15:15-15:20, Paper WeDT6.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1367" name="modify242" onclick="modify(242,1367)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('242'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Unifying Representation and Calibration with 3D Foundation Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#238613" title="Click to go to the Author Index">
             Zhi, Weiming
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#404812" title="Click to go to the Author Index">
             Tang, Haozhan
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#266906" title="Click to go to the Author Index">
             Zhang, Tianyi
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#118789" title="Click to go to the Author Index">
             Johnson-Roberson, Matthew
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab242" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Representing the environment is a central challenge in robotics, and is essential for effective decision-making. Traditionally, before capturing images with a manipulator-mounted camera, users need to calibrate the camera using a specific external marker, such as a checkerboard or AprilTag. However, recent advances in computer vision have led to the development of 3D foundation models. These are large, pre-trained neural networks that can establish fast and accurate multi-view correspondences with very few images, even in the absence of rich visual features. This paper advocates for the integration of 3D foundation models into scene representation approaches for robotic systems equipped with manipulator-mounted RGB cameras. Specifically, we propose the Joint Calibration and Representation (JCR) method. JCR uses RGB images, captured by a manipulator-mounted camera, to simultaneously construct an environmental representation and calibrate the camera relative to the robot's end-effector, in the absence of specific calibration markers. The resulting 3D environment representation is aligned with the robot's coordinate frame and maintains physically accurate scales. We demonstrate that JCR can build effective scene representations using a low-cost RGB camera attached to a manipulator, without prior calibration.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt6_02">
             15:20-15:25, Paper WeDT6.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1368" name="modify315" onclick="modify(315,1368)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('315'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ReVLA: Reverting Visual Domain Limitation of Robotic Foundation Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#299165" title="Click to go to the Author Index">
             Dey, Sombit
            </a>
           </td>
           <td class="r">
            InSAIT, Sofia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#277864" title="Click to go to the Author Index">
             Zaech, Jan-Nico
            </a>
           </td>
           <td class="r">
            Sofia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#217843" title="Click to go to the Author Index">
             Nikolov, Nikolay
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107640" title="Click to go to the Author Index">
             Van Gool, Luc
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#171278" title="Click to go to the Author Index">
             Paudel, Danda Pani
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab315" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent progress in large language models and access to large-scale robotic datasets has sparked a paradigm shift in robotics models transforming them into generalists able to adapt to various tasks, scenes, and robot modalities. A large step for the community are open Vision Language Action models which showcase strong performance in a wide variety of tasks. In this work, we study the visual generalization capabilities of three existing robotic foundation models, and propose a corresponding evaluation framework. Our study shows that the existing models do not exhibit robustness to visual out-of-domain scenarios. This is poten- tially caused by limited variations in the training data and/or catastrophic forgetting, leading to domain limitations in the vision foundation models. We further explore OpenVLA, which uses two pre-trained vision foundation models and is, therefore, expected to generalize to out-of-domain experiments. However, we showcase catastrophic forgetting by DINO-v2 in OpenVLA through its failure to fulfill the task of depth regression. To overcome the aforementioned issue of visual catastrophic forgetting, we propose a gradual backbone reversal approach founded on model merging. This enables OpenVLA – which requires the adaptation of the visual backbones during initial training – to regain its visual generalization ability. Regaining this capability enables our ReVLA model to improve over OpenVLA by a factor of 77% and 66% for grasping and lifting in visual OOD tasks. We will make our source code and OOD evaluation framework publicly available
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt6_03">
             15:25-15:30, Paper WeDT6.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1369" name="modify367" onclick="modify(367,1369)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('367'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MonoDiff9D: Monocular Category-Level 9D Object Pose Estimation Via Diffusion Model
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#384956" title="Click to go to the Author Index">
             Liu, Jian
            </a>
           </td>
           <td class="r">
            National Engineering Research Center of Robot Vision Perception
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#207095" title="Click to go to the Author Index">
             Sun, Wei
            </a>
           </td>
           <td class="r">
            Hunan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#386182" title="Click to go to the Author Index">
             Yang, Hui
            </a>
           </td>
           <td class="r">
            Hunan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#298638" title="Click to go to the Author Index">
             Zheng, Jin
            </a>
           </td>
           <td class="r">
            Central South University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416364" title="Click to go to the Author Index">
             Geng, Zichen
            </a>
           </td>
           <td class="r">
            The University of Western Australia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339811" title="Click to go to the Author Index">
             Rahmani, Hossein
            </a>
           </td>
           <td class="r">
            Lancaster University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#323854" title="Click to go to the Author Index">
             Mian, Ajmal
            </a>
           </td>
           <td class="r">
            University of Western Australia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab367" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Object pose estimation is a core means for robots to understand and interact with their environment. For this task, monocular category-level methods are attractive as they require only a single RGB camera. However, current methods rely on shape priors or CAD models of the intra-class known objects. We propose a diffusion-based monocular category-level 9D object pose generation method, MonoDiff9D. Our motivation is to leverage the probabilistic nature of diffusion models to alleviate the need for shape priors, CAD models, or depth sensors for intra-class unknown object pose estimation. We first estimate coarse depth via DINOv2 from the monocular image in a zero-shot manner and convert it into a point cloud. We then fuse the global features of the point cloud with the input image and use the fused features along with the encoded time step to condition MonoDiff9D. Finally, we design a transformer-based denoiser to recover the object pose from Gaussian noise. Extensive experiments on two popular benchmark datasets show that MonoDiff9D achieves state-of-the-art monocular category-level 9D object pose estimation accuracy without the need for shape priors or CAD models at any stage. Our code will be made public at https://github.com/CNJianLiu/MonoDiff9D.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt6_04">
             15:30-15:35, Paper WeDT6.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1370" name="modify500" onclick="modify(500,1370)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('500'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Full-Optical Pre-Touch Dual-Modal and Dual-Mechanism (PDM²) Sensor for Robotic Grasping
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#233448" title="Click to go to the Author Index">
             Fang, Cheng
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#393298" title="Click to go to the Author Index">
             Yan, Zhiyu
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#315365" title="Click to go to the Author Index">
             Guo, Fengzhi
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338189" title="Click to go to the Author Index">
             Li, Shuangliang
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101712" title="Click to go to the Author Index">
             Song, Dezhen
            </a>
           </td>
           <td class="r">
            Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#233384" title="Click to go to the Author Index">
             Zou, Jun
            </a>
           </td>
           <td class="r">
            Texas A&amp;M University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab500" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We report a new full-optical pre-touch dual-modal and dual-mechanism (PDM²) sensor based on an air-coupled fiber-tip surface micromachined optical ultrasound transducer (SMOUT). Compared with the ring-shaped piezoelectric acoustic receivers in previous PDM² sensors, the acoustic signal received by the new fiber-tip SMOUT is readout optically, which is naturally resistant to surrounding electromagnetic interference (EMI) and making the complex grounding and shielding unnecessary. In addition, the new fiber-tip SMOUT receiver has a much smaller size, which makes it possible to further miniaturize the sensor package into a more compact structure. For verification, a prototype of the full-optical PDM² sensor has been designed, fabricated, and characterized. The experimental results show that even with the much smaller acoustic receiver, the new sensor can still achieve comparable ranging and material/structure sensing performances with the previous ones. Therefore, the new full-optical PDM² sensor design is promising to provide a practical and miniaturized solution for ranging and material/structure sensing to assist robotic grasping of unknown objects.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt6_05">
             15:35-15:40, Paper WeDT6.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1371" name="modify503" onclick="modify(503,1371)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('503'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Active Tactile Perception through Belief-Space Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#291994" title="Click to go to the Author Index">
             Tremblay, Jean-François
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102603" title="Click to go to the Author Index">
             Meger, David Paul
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#198199" title="Click to go to the Author Index">
             Hogan, Francois
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102604" title="Click to go to the Author Index">
             Dudek, Gregory
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab503" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning_under_uncertainty" title="Click to go to the Keyword Index">
               Planning under Uncertainty
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robots operating in an open world will encounter novel objects with unknown physical properties, such as mass, friction, or size. These robots will need to sense these properties through interaction prior to performing downstream tasks with the objects. We propose a method that autonomously learns tactile exploration policies by developing a generative world model that is leveraged to 1) estimate the object's physical parameters using a differentiable Bayesian filtering algorithm and 2) develop an exploration policy using an information-gathering model predictive controller. We evaluate our method on three simulated tasks where the goal is to estimate a desired object property (mass, height or toppling height) through physical interaction. We find that our method is able to discover policies that efficiently gather information about the desired property in an intuitive manner. Finally, we validate our method on a real robot system for the height estimation task, where our method is able to successfully learn and execute an information-gathering policy from scratch.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt6_06">
             15:40-15:45, Paper WeDT6.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1372" name="modify1189" onclick="modify(1189,1372)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1189'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Detection of Fast-Moving Objects with Neuromorphic Hardware
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#234063" title="Click to go to the Author Index">
             Ziegler, Andreas
            </a>
           </td>
           <td class="r">
            University of Tübingen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#394062" title="Click to go to the Author Index">
             Vetter, Karl
            </a>
           </td>
           <td class="r">
            University of Tübingen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#337131" title="Click to go to the Author Index">
             Gossard, Thomas
            </a>
           </td>
           <td class="r">
            University of Tübingen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#244038" title="Click to go to the Author Index">
             Tebbe, Jonas
            </a>
           </td>
           <td class="r">
            University of Tübingen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#190656" title="Click to go to the Author Index">
             Otte, Sebastian
            </a>
           </td>
           <td class="r">
            University of Lübeck
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105216" title="Click to go to the Author Index">
             Zell, Andreas
            </a>
           </td>
           <td class="r">
            University of Tübingen
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1189" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#neurorobotics" title="Click to go to the Keyword Index">
               Neurorobotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Neuromorphic Computing (NC) and Spiking Neural Networks (SNNs) in particular are often viewed as the next generation of neural networks. NC is a novel bio-inspired paradigm for energy efficient neural computation, often relying on SNNs in which neurons communicate via spikes in a sparse, event-based manner. This communication via spikes can be exploited by neuromorphic hardware implementations very effectively and results in drastic reductions of energy consumption and latency in contrast to regular GPU-based neural networks. In recent years, neuromorphic hardware has become more accessible and the support of learning frameworks has improved. However, available hardware is partially still experimental, and it is not transparent what these solutions are effectively capable of, how they integrate into real world robotics applications, and how they realistically benefit energy efficiency and latency. In this work, we provide the robotics research community with an overview of what is possible with SNNs on neuromorphic hardware focusing on real-time processing. We introduce a benchmark of three popular neuromorphic hardware devices for the task of event based object detection. Moreover, we show that an SNN on a neuromorphic hardware is able to run in real-time in a closed loop robotic system embedded within a challenging table tennis robot scenario.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt6_07">
             15:45-15:50, Paper WeDT6.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1373" name="modify4910" onclick="modify(4910,1373)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4910'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Grasp, See, and Place: Efficient Unknown Object Rearrangement with Policy Structure Prior
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#293898" title="Click to go to the Author Index">
             Xu, Kechun
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#286412" title="Click to go to the Author Index">
             Zhou, Zhongxiang
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#286413" title="Click to go to the Author Index">
             Wu, Jun
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#184494" title="Click to go to the Author Index">
             Lu, Haojian
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#113216" title="Click to go to the Author Index">
             Xiong, Rong
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#156231" title="Click to go to the Author Index">
             Wang, Yue
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4910" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Deep Learning in Robotics and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_and_flexible_manufacturing" title="Click to go to the Keyword Index">
               Intelligent and Flexible Manufacturing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We focus on the task of unknown object rearrangement, where a robot is supposed to re-configure the objects into a desired goal configuration specified by an RGB-D image. Recent works explore unknown object rearrangement systems by incorporating learning-based perception modules. However, they are sensitive to perception error, and pay less attention to task-level performance. In this paper, we aim to develop an effective system for unknown object rearrangement amidst perception noise. We theoretically reveal the noisy perception impacts grasp and place in a decoupled way, and show such a decoupled structure is valuable to improve task optimality. We propose GSP, a dual-loop system with the decoupled structure as prior. For the inner loop, we learn a see policy for self-confident in-hand object matching. For the outer loop, we learn a grasp policy aware of object matching and grasp capability guided by task-level rewards. We leverage the foundation model CLIP for object matching, policy learning and self-termination. A series of experiments indicate that GSP can conduct unknown object rearrangement with higher completion rates and fewer steps.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt7">
             <b>
              WeDT7
             </b>
             Regular Session, 309
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1374" name="modifyWeDT7" onclick="modsession(399,1374)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt7" title="Click to go to the Program at a Glance">
             <b>
              Perception 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#398529" title="Click to go to the Author Index">
             Li, Xiaopeng
            </a>
           </td>
           <td class="r">
            University of Wisconsin-Madison
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#191889" title="Click to go to the Author Index">
             Yel, Esen
            </a>
           </td>
           <td class="r">
            Rensselaer Polytechnic Institute
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt7_01">
             15:15-15:20, Paper WeDT7.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1375" name="modify672" onclick="modify(672,1375)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('672'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LightStereo: Channel Boost Is All You Need for Efficient 2D Cost Aggregation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#336518" title="Click to go to the Author Index">
             Guo, Xianda
            </a>
           </td>
           <td class="r">
            School of Computer Science, Wuhan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397597" title="Click to go to the Author Index">
             Zhang, Chenming
            </a>
           </td>
           <td class="r">
            Waytous
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#336514" title="Click to go to the Author Index">
             Zhang, Youmin
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#249923" title="Click to go to the Author Index">
             Zheng, Wenzhao
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397575" title="Click to go to the Author Index">
             Nie, Dujun
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#223499" title="Click to go to the Author Index">
             Poggi, Matteo
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#167297" title="Click to go to the Author Index">
             Chen, Long
            </a>
           </td>
           <td class="r">
            Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab672" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present LightStereo, a cutting-edge stereo-matching network crafted to accelerate the matching process. Departing from conventional methodologies that rely on aggregating computationally intensive 4D costs, LightStereo adopts the 3D cost volume as a lightweight alternative. While similar approaches have been explored previously, our breakthrough lies in enhancing performance through a dedicated focus on the channel dimension of the 3D cost volume, where the distribution of matching costs is encapsulated. Our exhaustive exploration has yielded plenty of strategies to amplify the capacity of the pivotal dimension, ensuring both precision and efficiency. We compare the proposed LightStereo with existing state-of-the-art methods across various benchmarks, which demonstrate its superior performance in speed, accuracy, and resource utilization. LightStereo achieves a competitive EPE metric in the SceneFlow datasets while demanding a minimum of only 22 GFLOPs and 17 ms of runtime, and ranks 1st on KITTI 2015 among real-time models. Our comprehensive analysis reveals the effect of 2D cost aggregation for stereo matching, paving the way for real-world applications of efficient stereo systems. Code is available at https://github.com/XiandaGuo/OpenStereo.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt7_02">
             15:20-15:25, Paper WeDT7.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1376" name="modify1134" onclick="modify(1134,1376)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1134'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SurfaceAug: Toward Versatile, Multimodally Consistent Ground Truth Sampling
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#412216" title="Click to go to the Author Index">
             Rubel, Ryan
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#412214" title="Click to go to the Author Index">
             Clark, Nathan
            </a>
           </td>
           <td class="r">
            Noblis, Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#365733" title="Click to go to the Author Index">
             Dudash, Andrew
            </a>
           </td>
           <td class="r">
            Noblis
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1134" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Despite recent advances in both model architectures and data augmentation, multimodal object detectors still barely outperform their LiDAR-only counterparts. This shortcoming has been attributed to a lack of sufficiently powerful multimodal data augmentation. To address this, we present SurfaceAug, a novel ground truth sampling algorithm. SurfaceAug pastes objects by resampling both images and point clouds, enabling object-level transformations in both modalities. We evaluate our algorithm by training a multimodal detector on KITTI and compare its performance to previous works. We show experimentally that SurfaceAug demonstrates promising improvements on car detection tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt7_03">
             15:25-15:30, Paper WeDT7.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1377" name="modify1174" onclick="modify(1174,1377)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1174'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Uncertainty-Guided Enhancement on Driving Perception System Via Foundation Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420589" title="Click to go to the Author Index">
             Yang, Yunhao
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420696" title="Click to go to the Author Index">
             Hu, Yuxin
            </a>
           </td>
           <td class="r">
            Cruise
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#313070" title="Click to go to the Author Index">
             Ye, Mao
            </a>
           </td>
           <td class="r">
            The University of Texas, Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420605" title="Click to go to the Author Index">
             Zhang, Zaiwei
            </a>
           </td>
           <td class="r">
            Cruise
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420607" title="Click to go to the Author Index">
             Lu, Zhichao
            </a>
           </td>
           <td class="r">
            Cruise LLC
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#286128" title="Click to go to the Author Index">
             Xu, Yi
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#131686" title="Click to go to the Author Index">
             Topcu, Ufuk
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420610" title="Click to go to the Author Index">
             Snyder, Ben
            </a>
           </td>
           <td class="r">
            Cruise
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1174" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#calibration_and_identification" title="Click to go to the Keyword Index">
               Calibration and Identification
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#probability_and_statistical_methods" title="Click to go to the Keyword Index">
               Probability and Statistical Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multimodal foundation models offer promising advancements for enhancing driving perception systems, but their high computational and financial costs pose challenges. We develop a method that leverages foundation models to refine predictions from existing driving perception models---such as enhancing object classification accuracy---while minimizing the frequency of using these resource-intensive models. The method quantitatively characterizes uncertainties in the perception model's predictions and engages the foundation model only when these uncertainties exceed a pre-specified threshold. Specifically, it characterizes uncertainty by calibrating the perception model’s confidence scores into theoretical lower bounds on the probability of correct predictions using conformal prediction. Then, it sends images to the foundation model and queries for refining the predictions only if the theoretical bound of the perception model's outcome is below the threshold. Additionally, we propose a temporal inference mechanism that enhances prediction accuracy by integrating historical predictions, leading to tighter theoretical bounds. The method demonstrates a 10 to 15 percent improvement in prediction accuracy and reduces the number of queries to the foundation model by 50 percent, based on quantitative evaluations from driving datasets.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt7_04">
             15:30-15:35, Paper WeDT7.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1378" name="modify1426" onclick="modify(1426,1378)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1426'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Complementary Information Guided Occupancy Prediction Via Multi-Level Representation Fusion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#348411" title="Click to go to the Author Index">
             Xu, Rongtao
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences, Beijing, C
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#384045" title="Click to go to the Author Index">
             Lin, Jinzhou
            </a>
           </td>
           <td class="r">
            Beijing University of Posts and Communications
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421550" title="Click to go to the Author Index">
             Zhou, Jialei
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#334878" title="Click to go to the Author Index">
             Dong, Jiahua
            </a>
           </td>
           <td class="r">
            Shenyang Institute of Automation Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#308764" title="Click to go to the Author Index">
             Wang, Changwei
            </a>
           </td>
           <td class="r">
            Casia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#311710" title="Click to go to the Author Index">
             Wang, Ruisheng
            </a>
           </td>
           <td class="r">
            University of Calgary
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#384261" title="Click to go to the Author Index">
             Guo, Li
            </a>
           </td>
           <td class="r">
            BUPT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#222958" title="Click to go to the Author Index">
             Xu, Shibiao
            </a>
           </td>
           <td class="r">
            Beijing University of Posts and Telecommunications
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#227063" title="Click to go to the Author Index">
             Liang, Xiaodan
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1426" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Camera-based occupancy prediction is a mainstream approach for 3D perception in autonomous driving, aiming to infer complete 3D scene geometry and semantics from 2D images. Almost existing methods focus on improving performance through structural modifications, such as lightweight backbones and complex cascaded frameworks, with good yet limited performance. Few studies explore from the perspective of representation fusion, leaving the rich diversity of features in 2D images underutilized. Motivated by this, we propose CIGOcc, a two-stage occupancy prediction framework based on multi-level representation fusion. CIGOcc extracts segmentation, graphics, and depth features from an input image and introduces a deformable multi-level fusion mechanism to fuse these three multi-level features. Additionally, CIGOcc incorporates knowledge distilled from SAM to further enhance prediction accuracy. Without increasing training costs, CIGOcc achieves state-of-the-art performance on the SemanticKITTI benchmark. The code is provided in the supplementary material and will be released at https://github.com/VitaLemonTea1/CIGOcc.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt7_05">
             15:35-15:40, Paper WeDT7.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1379" name="modify1450" onclick="modify(1450,1379)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1450'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Domain Adaptation-Based Crossmodal Knowledge Distillation for 3D Semantic Segmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#391701" title="Click to go to the Author Index">
             Kang, Jialiang
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#350817" title="Click to go to the Author Index">
             Wang, Jiawen
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#152071" title="Click to go to the Author Index">
             Luo, Dingsheng
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1450" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Semantic segmentation of 3D LiDAR data plays a pivotal role in autonomous driving. Traditional approaches rely on extensive annotated data for point cloud analysis, incurring high costs and time investments. In contrast, real-world image datasets offer abundant availability and substantial scale. To mitigate the burden of annotating 3D LiDAR point clouds, we propose two crossmodal knowledge distillation methods: Unsupervised Domain Adaptation Knowledge Distillation (UDAKD) and Feature and Semantic-based Knowledge Distillation (FSKD). Leveraging readily available spatio-temporally synchronized data from cameras and LiDARs in autonomous driving scenarios, we directly apply a pretrained 2D image model to unlabeled 2D data. Through crossmodal knowledge distillation with known 2D-3D correspondence, we actively align the output of the 3D network with the corresponding points of the 2D network, thereby obviating the necessity for 3D annotations. Our focus is on preserving modality-general information while filtering out modality-specific details during crossmodal distillation. To achieve this, we deploy self-calibrated convolution on 3D point clouds as the foundation of our domain adaptation module. Rigorous experimentation validates the effectiveness of our proposed methods, consistently surpassing the performance of state-of-the-art approaches in the field. Code will be released upon publication.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt7_06">
             15:40-15:45, Paper WeDT7.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1380" name="modify1618" onclick="modify(1618,1380)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1618'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Nonlinear Motion-Guided and Spatio-Temporal Aware Network for Unsupervised Event-Based Optical Flow
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417420" title="Click to go to the Author Index">
             Liu, Zuntao
            </a>
           </td>
           <td class="r">
            Northeastern University of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#345467" title="Click to go to the Author Index">
             Zhuang, Hao
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#345466" title="Click to go to the Author Index">
             Jiang, Junjie
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418291" title="Click to go to the Author Index">
             Song, Yuhang
            </a>
           </td>
           <td class="r">
            Northeastern University - China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#121608" title="Click to go to the Author Index">
             Fang, Zheng
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1618" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Event cameras have the potential to capture continuous motion information over time and space, making them well-suited for optical flow estimation. However, most existing learning-based methods for event-based optical flow adopt frame-based techniques, ignoring the spatio-temporal characteristics of events. Additionally, these methods assume linear motion between consecutive events within the loss time window, which increases optical flow errors in long-time sequences. In this work, we observe that rich spatio-temporal information and accurate nonlinear motion between events are crucial for event-based optical flow estimation. Therefore, we propose E-NMSTFlow, a novel unsupervised event-based optical flow network focusing on long-time sequences. We propose a Spatio-Temporal Motion Feature Aware (STMFA) module and an Adaptive Motion Feature Enhancement (AMFE) module, both of which utilize rich spatio-temporal information to learn spatio-temporal data associations. Meanwhile, we propose a nonlinear motion compensation loss that utilizes the accurate nonlinear motion between events to improve the unsupervised learning of our network. Extensive experiments demonstrate the effectiveness and superiority of our method. Remarkably, our method ranks first among unsupervised learning methods on the MVSEC and DSEC-Flow datasets.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt7_07">
             15:45-15:50, Paper WeDT7.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1381" name="modify1636" onclick="modify(1636,1381)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1636'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              V2X-DG: Domain Generalization for Vehicle-To-Everything Cooperative Perception
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#370016" title="Click to go to the Author Index">
             Li, Baolu
            </a>
           </td>
           <td class="r">
            Cleveland State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422038" title="Click to go to the Author Index">
             Xu, Zongzhe
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#311148" title="Click to go to the Author Index">
             Li, Jinlong
            </a>
           </td>
           <td class="r">
            Cleveland State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#373280" title="Click to go to the Author Index">
             Liu, Xinyu
            </a>
           </td>
           <td class="r">
            Cleveland State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#237524" title="Click to go to the Author Index">
             Fang, Jianwu
            </a>
           </td>
           <td class="r">
            Xian Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398529" title="Click to go to the Author Index">
             Li, Xiaopeng
            </a>
           </td>
           <td class="r">
            University of Wisconsin-Madison
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#288655" title="Click to go to the Author Index">
             Yu, Hongkai
            </a>
           </td>
           <td class="r">
            Cleveland State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1636" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             LiDAR-based Vehicle-to-Everything (V2X) cooperative perception has demonstrated its impact on the safety and effectiveness of autonomous driving. Since current cooperative perception algorithms are trained and tested on the same dataset, the generalization ability of cooperative perception systems remains underexplored. This paper is the first work to study the Domain Generalization problem for LiDAR-based V2X cooperative perception (V2X-DG) based on four widely-used open source datasets: OPV2V, V2XSet, V2V4Real and DAIR-V2X. Our research seeks to sustain high performance not only within the source domain but also across other unseen domains, achieved solely through training on source domain. To this end, we propose Cooperative Mixup Augmentation based Generalization (CMAG) to improve the model generalization capability by simulating the unseen cooperation, which is designed compactly for the domain gaps in cooperative perception. Furthermore, we propose a constraint for the regularization of the robust generalized feature representation learning: Cooperation Feature Consistency (CFC), which aligns the intermediately fused features of the generalized cooperation by CMAG and the early fused features of the original cooperation in source domain. Extensive experiments demonstrate that our approach achieves significant performance gains when generalizing to other unseen datasets while it also maintains strong performance on the source dataset.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt8">
             <b>
              WeDT8
             </b>
             Regular Session, 311
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1382" name="modifyWeDT8" onclick="modsession(483,1382)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt8" title="Click to go to the Program at a Glance">
             <b>
              Representation Learning 3
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#297966" title="Click to go to the Author Index">
             Zheng, Sifa
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#254317" title="Click to go to the Author Index">
             Sun, Lingfeng
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt8_01">
             15:15-15:20, Paper WeDT8.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1383" name="modify2051" onclick="modify(2051,1383)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2051'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              IMOST: Incremental Memory Mechanism with Online Self-Supervision for Continual Traversability Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#393119" title="Click to go to the Author Index">
             Ma, Kehui
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422865" title="Click to go to the Author Index">
             Sun, Zhen
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423012" title="Click to go to the Author Index">
             Xiong, Chaoran
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#370846" title="Click to go to the Author Index">
             Zhu, Qiumin
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422853" title="Click to go to the Author Index">
             Wang, Kewei
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#204900" title="Click to go to the Author Index">
             Pei, Ling
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2051" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#incremental_learning" title="Click to go to the Keyword Index">
               Incremental Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Traversability estimation is the foundation of path planning for a general navigation system. However, complex and dynamic environments pose challenges for the latest methods using self-supervised learning (SSL) technique. Firstly, existing SSL-based methods generate sparse annotations lacking detailed boundary information. Secondly, their strategies focus on hard samples for rapid adaptation, leading to forgetting and biased predictions. In this work, we propose IMOST, a continual traversability learning framework composed of two key modules: incremental dynamic memory (IDM) and self-supervised annotation (SSA). By mimicking human memory mechanisms, IDM allocates novel data samples to new clusters according to information expansion criterion. It also updates clusters based on diversity rule, ensuring a representative characterization of new scene. This mechanism enhances scene-aware knowledge diversity while maintaining a compact memory capacity. The SSA module, integrating FastSAM, utilizes point prompts to generate complete annotations in real time which reduces training complexity. Furthermore, IMOST has been successfully deployed on the quadruped robot, with performance evaluated during the online learning process. Experimental results on both public and self-collected datasets demonstrate that our IMOST outperforms current state-of-the-art method, maintains robust recognition capabilities and adaptability across various scenarios. The code is available at https://github.com/SJTU-MKH/OCLTrav.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt8_02">
             15:20-15:25, Paper WeDT8.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1384" name="modify2392" onclick="modify(2392,1384)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2392'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SparseDrive: End-To-End Autonomous Driving Via Sparse Scene Representation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418275" title="Click to go to the Author Index">
             Sun, Wenchao
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418444" title="Click to go to the Author Index">
             Lin, Xuewu
            </a>
           </td>
           <td class="r">
            Horizon
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#344312" title="Click to go to the Author Index">
             Shi, Yining
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418296" title="Click to go to the Author Index">
             Zhang, Chuang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#355549" title="Click to go to the Author Index">
             Wu, Haoran
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#297966" title="Click to go to the Author Index">
             Zheng, Sifa
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2392" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The well-established modular autonomous driving system is decoupled into different standalone tasks, e.g. perception, prediction and planning, suffering from information loss and error accumulation across modules. In contrast, end-to-end paradigms unify multi-tasks into a fully differentiable framework, allowing for optimization in a planning-oriented spirit. Despite the great potential of end-to-end paradigms, both the performance and efficiency of existing methods are not satisfactory, particularly in terms of planning safety. We attribute this to the computationally expensive BEV (bird's eye view) features and the straightforward design for prediction and planning. To this end, we explore the sparse representation and review the task design for end-to-end autonomous driving, proposing a new paradigm named SparseDrive. Concretely, SparseDrive consists of a symmetric sparse perception module and a parallel motion planner. The sparse perception module unifies detection, tracking and online mapping with a symmetric model architecture, learning a fully sparse representation of the driving scene. For motion prediction and planning, we review the great similarity between these two tasks, leading to a parallel design for motion planner. Based on this parallel design, which models planning as a multi-modal problem, we propose a hierarchical planning selection strategy, which incorporates a collision-aware rescore module, to select a rational and safe trajectory as the final planning output. With such effective designs, SparseDrive surpasses previous state-of-the-arts by a large margin in performance of all tasks, while achieving much higher training and inference efficiency.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt8_03">
             15:25-15:30, Paper WeDT8.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1385" name="modify2490" onclick="modify(2490,1385)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2490'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MOTION TRACKS: A Unified Representation for Human-Robot Transfer in Few-Shot Imitation Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424325" title="Click to go to the Author Index">
             Ren, Juntao
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#248751" title="Click to go to the Author Index">
             Sundaresan, Priya
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#195462" title="Click to go to the Author Index">
             Sadigh, Dorsa
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#160608" title="Click to go to the Author Index">
             Choudhury, Sanjiban
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#116883" title="Click to go to the Author Index">
             Bohg, Jeannette
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2490" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#transfer_learning" title="Click to go to the Keyword Index">
               Transfer Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Teaching robots to autonomously complete everyday tasks remains a challenge. Imitation Learning (IL) is a powerful approach that imbues robots with skills via demonstrations, but is limited by the labor-intensive process of collecting teleoperated robot data. Human videos offer a scalable alternative, but it remains difficult to directly train IL policies from them due to the lack of robot action labels. To address this, we propose to represent actions as short-horizon 2D trajectories on an image. These actions, or
             <i>
              motion tracks
             </i>
             , capture the predicted direction of motion for both human hands and robot end-effectors. We instantiate an IL policy called Motion Track Policy (MT-π) which receives image observations and outputs motion tracks as actions. By leveraging this unified, cross-embodiment action space, MT-π completes tasks with high success given just minutes of human video and limited additional robot demonstrations. At test time, we predict motion tracks from two camera views, recovering 6DoF trajectories via multi-view synthesis. MT-π achieves an average success rate of 86.5% across 4 real-world tasks, outperforming state-of-the-art IL baselines which do not leverage human data or our action space by 40%, and generalizes to scenarios seen only in human videos. Code and videos are available on our website (https://portal-cornell.github.io/motion_track_policy/).
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt8_04">
             15:30-15:35, Paper WeDT8.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1386" name="modify2581" onclick="modify(2581,1386)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2581'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Discrete Policy: Learning Disentangled Action Space for Multi-Task Robotic Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#341578" title="Click to go to the Author Index">
             Wu, Kun
            </a>
           </td>
           <td class="r">
            Syracuse University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#319251" title="Click to go to the Author Index">
             Zhu, Yichen
            </a>
           </td>
           <td class="r">
            Midea Group
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#377137" title="Click to go to the Author Index">
             Li, Jinming
            </a>
           </td>
           <td class="r">
            Shanghai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#377303" title="Click to go to the Author Index">
             Wen, Junjie
            </a>
           </td>
           <td class="r">
            East China Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338817" title="Click to go to the Author Index">
             Liu, Ning
            </a>
           </td>
           <td class="r">
            Beijing Innovation Center of Humanoid Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338492" title="Click to go to the Author Index">
             Xu, Zhiyuan
            </a>
           </td>
           <td class="r">
            Midea Group
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#322428" title="Click to go to the Author Index">
             Tang, Jian
            </a>
           </td>
           <td class="r">
            Midea Group (Shanghai) Co., Ltd
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2581" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Learning visuomotor policy for multi-task robotic manipulation has been a long-standing challenge for the robotics community. The difficulty lies in the diversity of action space: typically, a goal can be accomplished in multiple ways, resulting in a multimodal action distribution for a single task. The complexity of action distribution escalates as the number of tasks increases. In this work, we propose Discrete Policy, a robot learning method for training universal agents capable of multi-task manipulation skills. Discrete Policy employs vector quantization to map action sequences into a discrete latent space, facilitating the learning of task-specific codes. These codes are then reconstructed into the action space conditioned on observations and language instruction. We evaluate our method on both simulation and multiple real-world embodiments, including both single-arm and bimanual robot settings. We demonstrate that our proposed Discrete Policy outperforms a well-established Diffusion Policy baseline and many state-of-the-art approaches, including ACT, Octo, and OpenVLA. For example, in a real-world multi-task training setting with five tasks, Discrete Policy achieves an average success rate that is 26% higher than Diffusion Policy and 15% higher than OpenVLA. As the number of tasks increases to 12, the performance gap between Discrete Policy and Diffusion Policy widens to 32.5%, further showcasing the advantages of our approach. Our work empirically demonstrates that learning multi-task policies within the latent space is a vital step toward achieving general-purpose agents.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt8_05">
             15:35-15:40, Paper WeDT8.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1387" name="modify3839" onclick="modify(3839,1387)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3839'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              AnyCar to Anywhere: Learning Universal Dynamics Model for Agile and Adaptive Mobility
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379763" title="Click to go to the Author Index">
             Xiao, Wenli
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#355073" title="Click to go to the Author Index">
             Xue, Haoru
            </a>
           </td>
           <td class="r">
            University of California Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#326263" title="Click to go to the Author Index">
             Tao, Tony
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#311910" title="Click to go to the Author Index">
             Kalaria, Dvij
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104857" title="Click to go to the Author Index">
             Dolan, John M.
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#236627" title="Click to go to the Author Index">
             Shi, Guanya
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3839" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robot_learning" title="Click to go to the Keyword Index">
               Data Sets for Robot Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent works in the robot learning community have successfully introduced generalist models capable of controlling various robot embodiments across a wide range of tasks, such as navigation and locomotion. However, achieving agile control, which pushes the limits of robotic performance, still relies on specialist models that require extensive parameter tuning. To leverage generalist-model adaptability and flexibility while achieving specialist-level agility, we propose AnyCar, a transformer-based generalist dynamics model designed for agile control of various wheeled robots. To collect training data, we unify multiple simulators and leverage different physics backends to simulate vehicles with diverse sizes, scales, and physical properties across various terrains. With robust training and real-world fine-tuning, our model enables precise adaptation to different vehicles, even in the wild and under large state estimation errors. In real-world experiments, AnyCar shows both few-shot and zero-shot generalization across a wide range of vehicles and environments, where our model, combined with a sampling-based MPC, outperforms specialist models by up to 54%. These results represent a key step toward building a foundation model for agile wheeled robot control. AnyCar is fully open-source to support further research.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt8_06">
             15:40-15:45, Paper WeDT8.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1388" name="modify4178" onclick="modify(4178,1388)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4178'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Dynamics of a Ball with Differentiable Factor Graph and Roto-Translational Invariant Representations
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#271076" title="Click to go to the Author Index">
             Xiao, Qingyu
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#288397" title="Click to go to the Author Index">
             Wu, Zixuan
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#160727" title="Click to go to the Author Index">
             Gombolay, Matthew
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4178" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#probabilistic_inference" title="Click to go to the Keyword Index">
               Probabilistic Inference
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robots in dynamic environments need fast, accurate models of how objects move in their environments to support agile planning. In sports such as ping pong, analytical models often struggle to accurately predict ball trajectories with spins due to complex aerodynamics, elastic behaviors, and the challenges of modeling sliding and rolling friction. On the other hand, despite the promise of data-driven methods, machine learning struggles to make accurate, consistent predictions without precise input. In this paper, we propose an end-to-end learning framework that can jointly train a dynamics model and a factor graph estimator. Our approach leverages a Gram-Schmidt (GS) process to extract roto-translational invariant representations to improve the model performance, which can further reduce the validation error compared to data augmentation method. Additionally, we propose a network architecture that enhances nonlinearity by using self-multiplicative bypasses in the layer connections. By leveraging these novel methods, our proposed approach predicts the ball's position with an RMSE of 37.2 mm of the paddle radius at the apex after the first bounce, and 71.5 mm after the second bounce.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt9">
             <b>
              WeDT9
             </b>
             Regular Session, 312
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1389" name="modifyWeDT9" onclick="modsession(335,1389)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt9" title="Click to go to the Program at a Glance">
             <b>
              Motion Planning 5
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#177144" title="Click to go to the Author Index">
             Xiao, Xuesu
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#236252" title="Click to go to the Author Index">
             Lee, Ki Myung Brian
            </a>
           </td>
           <td class="r">
            University of California San Diego
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt9_01">
             15:15-15:20, Paper WeDT9.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1390" name="modify122" onclick="modify(122,1390)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('122'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Semi-Supervised Active Learning for Semantic Segmentation in Unknown Environments Using Informative Path Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#301556" title="Click to go to the Author Index">
             Rückin, Julius
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#274849" title="Click to go to the Author Index">
             Magistri, Federico
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101642" title="Click to go to the Author Index">
             Stachniss, Cyrill
            </a>
           </td>
           <td class="r">
            University of Bonn
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#193502" title="Click to go to the Author Index">
             Popovic, Marija
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab122" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Semantic segmentation enables robots to perceive and reason about their environments beyond geometry. Most of such systems build upon deep learning approaches. As autonomous robots are commonly deployed in initially unknown environments, pre-training on static datasets cannot always capture the variety of domains and limits the robot’s perception performance during missions. Recently, self-supervised and fully supervised active learning methods emerged to improve robotic vision. These approaches rely on large in-domain pre-training datasets or require substantial human labelling effort. We propose a planning method for semi-supervised active learning of semantic segmentation that substantially reduces human labelling requirements compared to fully supervised approaches. We leverage an adaptive map-based planner guided towards the frontiers of unexplored space with high model uncertainty, collecting training data for human labelling. A key aspect of our approach is to combine the sparse high-quality human labels with pseudo labels automatically extracted from highly certain environment map areas. Experimental results show that our method reaches segmentation performance close to fully supervised approaches with drastically reduced human labelling effort while outperforming self-supervised approaches.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt9_02">
             15:20-15:25, Paper WeDT9.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1391" name="modify1257" onclick="modify(1257,1391)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1257'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              FutureNet-LOF: Joint Trajectory Prediction and Lane Occupancy Field Prediction with Future Context Encoding
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#336903" title="Click to go to the Author Index">
             Wang, Mingkun
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339394" title="Click to go to the Author Index">
             Ren, Xiaoguang
            </a>
           </td>
           <td class="r">
            Academy of Military Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339373" title="Click to go to the Author Index">
             Jin, Ruochun
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#269415" title="Click to go to the Author Index">
             Li, Minglong
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420868" title="Click to go to the Author Index">
             Zhang, Xiaochuan
            </a>
           </td>
           <td class="r">
            Academy of Military Science
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339429" title="Click to go to the Author Index">
             Yu, Changqian
            </a>
           </td>
           <td class="r">
            Meituan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339328" title="Click to go to the Author Index">
             Wang, Mingxu
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#226679" title="Click to go to the Author Index">
             Yang, Wenjing
            </a>
           </td>
           <td class="r">
            State Key Laboratory of High Performance Computing (HPCL), Schoo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1257" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Most prior motion prediction endeavors in autonomous driving have inadequately encoded future scenarios, leading to predictions that may fail to accurately capture the diverse movements of agents (e.g., vehicles or pedestrians). To address this, we propose FutureNet, which explicitly integrates initially predicted trajectories into the future scenario and further encodes these future contexts to enhance subsequent forecasting. Additionally, most previous motion forecasting works have focused on predicting independent futures for each agent. However, safe and smooth autonomous driving requires accurately predicting the diverse future behaviors of numerous surrounding agents jointly in complex dynamic environments. Given that all agents occupy certain potential travel spaces and possess lane driving priority, we propose Lane Occupancy Field (LOF), a new representation with lane semantics for motion forecasting in autonomous driving. LOF can simultaneously capture the joint probability distribution of all road participants' future spatial-temporal positions. Due to the high compatibility between lane occupancy field prediction and trajectory prediction, we propose a novel network for joint prediction of these two tasks. Our approach ranks 1st on two large-scale motion forecasting benchmarks: Argoverse 1 and Argoverse 2, while it is also the champion method of the CVPR 2024 Argoverse 2 motion forecasting challenge.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt9_03">
             15:25-15:30, Paper WeDT9.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1392" name="modify1434" onclick="modify(1434,1392)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1434'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hierarchical Reinforcement Learning for Safe Mapless Navigation with Congestion Estimation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#331670" title="Click to go to the Author Index">
             Gao, Jianqi
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology (Shenzhen)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#317840" title="Click to go to the Author Index">
             Pang, Xizheng
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#271275" title="Click to go to the Author Index">
             Liu, Qi
            </a>
           </td>
           <td class="r">
            Northeastern University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#200738" title="Click to go to the Author Index">
             Li, Yanjie
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology (Shenzhen)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1434" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Reinforcement learning-based mapless navigation holds significant potential. However, it faces challenges in indoor environments with local minima area. This paper introduces a safe mapless navigation framework utilizing hierarchical reinforcement learning (HRL) to enhance navigation through such areas. The high-level policy creates a sub-goal to direct the navigation process. Notably, we have developed a sub-goal update mechanism that considers environment congestion, efficiently avoiding the entrapment of the robot in local minimum areas. The low-level motion planning policy, trained through safe reinforcement learning, outputs real-time control instructions based on acquired sub-goal. Specifically, to enhance the robot's environmental perception, we introduce a new obstacle encoding method that evaluates the impact of obstacles on the robot's motion planning. To validate the performance of our HRL-based navigation framework, we conduct simulations in office, home, and restaurant environments. The findings demonstrate that our HRL-based navigation framework excels in both static and dynamic scenarios. Finally, we implement the HRL-based navigation framework on a TurtleBot3 robot for physical validation experiments, which exhibits its strong generalization capabilities.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt9_04">
             15:30-15:35, Paper WeDT9.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1393" name="modify2402" onclick="modify(2402,1393)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2402'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hierarchical End-To-End Autonomous Driving: Integrating BEV Perception with Deep Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#306351" title="Click to go to the Author Index">
             Lu, Siyi
            </a>
           </td>
           <td class="r">
            Central South University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420517" title="Click to go to the Author Index">
             He, Lei
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#297960" title="Click to go to the Author Index">
             Li, Shengbo Eben
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#194498" title="Click to go to the Author Index">
             Luo, Yugong
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#216343" title="Click to go to the Author Index">
             Wang, Jianqiang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#194499" title="Click to go to the Author Index">
             Li, Keqiang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2402" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_control" title="Click to go to the Keyword Index">
               Integrated Planning and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             End-to-end autonomous driving offers a streamlined alternative to the traditional modular pipeline, integrating perception, prediction, and planning within a single framework. While Deep Reinforcement Learning (DRL) has recently gained traction in this domain, existing approaches often overlook the critical connection between feature extraction of DRL and perception. In this paper, we bridge this gap by mapping the DRL feature extraction network directly to the perception phase, enabling clearer interpretation through semantic segmentation. By leveraging Bird’s-Eye-View (BEV) representations, we propose a novel DRL-based end-to-end driving framework that utilizes multi-sensor inputs to construct a unified three-dimensional understanding of the environment. This BEV-based system extracts and translates critical environmental features into high-level abstract states for DRL, facilitating more informed control. Extensive experimental evaluations demonstrate that our approach not only enhances interpretability but also significantly outperforms state-of-the-art methods in autonomous driving control tasks, reducing the collision rate by 20%. The code of our approach is publicly available at https://github.com/CBDES-e2e/PEDe2e-driving
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt9_05">
             15:35-15:40, Paper WeDT9.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1394" name="modify2829" onclick="modify(2829,1394)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2829'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Goal Motion Memory
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#322384" title="Click to go to the Author Index">
             Lu, Yuanjie
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#376423" title="Click to go to the Author Index">
             Das, Dibyendu
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102421" title="Click to go to the Author Index">
             Plaku, Erion
            </a>
           </td>
           <td class="r">
            U.S. National Science Foundation
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#177144" title="Click to go to the Author Index">
             Xiao, Xuesu
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2829" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous mobile robots (e.g., warehouse logistics robots) often need to traverse complex, obstacle-rich, and changing environments to reach multiple fixed goals (e.g., warehouse shelves). Traditional motion planners need to calculate the entire multi-goal path from scratch in response to changes in the environment, which results in a large consumption of computing resources. This process is not only time-consuming but also may not meet real-time requirements in application scenarios that require rapid response to environmental changes. In this paper, we provide a novel Multi-Goal Motion Memory technique that allows robots to use previous planning experiences to accelerate future multi-goal planning in changing environments. Specifically, our technique predicts collision-free and dynamically-feasible trajectories and distances between goal pairs to guide the sampling process to build a roadmap, to inform a Traveling Salesman Problem (TSP) solver to compute a tour, and to efficiently produce motion plans. Experiments conducted with a vehicle and a snake-like robot in obstacle-rich environments show that the proposed Motion Memory technique can substantially accelerate planning speed by up to 90%. Furthermore, the solution quality is comparable to state-of-the-art algorithms and even better in some environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt9_06">
             15:40-15:45, Paper WeDT9.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1395" name="modify4082" onclick="modify(4082,1395)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4082'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Dual-BEV Nav: Dual-Layer BEV-Based Heuristic Path Planning for Robotic Navigation in Unstructured Outdoor Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379251" title="Click to go to the Author Index">
             Zhang, Jianfeng
            </a>
           </td>
           <td class="r">
            East China Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379081" title="Click to go to the Author Index">
             Dong, Hanlin
            </a>
           </td>
           <td class="r">
            East China Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379065" title="Click to go to the Author Index">
             Yang, Jian
            </a>
           </td>
           <td class="r">
            Information Engineering University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#377197" title="Click to go to the Author Index">
             Liu, Jiahui
            </a>
           </td>
           <td class="r">
            Fujian Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424322" title="Click to go to the Author Index">
             Huang, Shibo
            </a>
           </td>
           <td class="r">
            East China Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#184340" title="Click to go to the Author Index">
             Li, Ke
            </a>
           </td>
           <td class="r">
            Information Engineering University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379133" title="Click to go to the Author Index">
             Tang, Xuan
            </a>
           </td>
           <td class="r">
            East China Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#311837" title="Click to go to the Author Index">
             Wei, Xian
            </a>
           </td>
           <td class="r">
            East China Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379882" title="Click to go to the Author Index">
             You, Xiong
            </a>
           </td>
           <td class="r">
            Information Engineering University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4082" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Path planning with strong environmental adaptability plays a crucial role in robotic navigation in unstructured outdoor environments, especially in the case of low-quality location and map information. The path planning ability of a robot depends on the identification of the traversability of global and local ground areas. In real-world scenarios, the complexity of outdoor open environments makes it difficult for robots to identify the traversability of ground areas that lack a clearly defined structure. Moreover, most existing methods have rarely analyzed the integration of local and global traversability identifications in unstructured outdoor scenarios. To address this problem, we propose a novel method, Dual-BEV Nav, first introducing Bird’s Eye View (BEV) representations into local planning to generate high-quality traversable paths. Then, these paths are projected into the global traversability probability map generated by the global BEV planning model to obtain the optimal path. By integrating the traversability from both local and global BEV, we establish a dual-layer BEV heuristic planning paradigm, enabling long-distance navigation in unstructured outdoor environments. We test our approach through both public dataset evaluations and real-world robot deployments, yielding promising results. Compared to baselines, the Dual-BEV Nav improved temporal distance prediction accuracy by up to 18.26%. In the real-world deployment, under conditions significantly different from the training set and with notable occlusions in the global BEV, the Dual-BEV Nav successfully achieved a 65-meter-long outdoor navigation. Further analysis demonstrates that the local BEV representation significantly enhances the rationality of the planning, while the global BEV probability map ensures the robustness of the overall plan
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt9_07">
             15:45-15:50, Paper WeDT9.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1396" name="modify4162" onclick="modify(4162,1396)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4162'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Risk-Aware Integrated Task and Motion Planning for Versatile Snake Robots under Localization Failures
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#218616" title="Click to go to the Author Index">
             M. Jasour, Ashkan
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354700" title="Click to go to the Author Index">
             Daddi, Guglielmo
            </a>
           </td>
           <td class="r">
            Politecnico Di Torino
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#321259" title="Click to go to the Author Index">
             Endo, Masafumi
            </a>
           </td>
           <td class="r">
            Keio University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#164568" title="Click to go to the Author Index">
             Vaquero, Tiago
            </a>
           </td>
           <td class="r">
            JPL, Caltech
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#173522" title="Click to go to the Author Index">
             Paton, Michael
            </a>
           </td>
           <td class="r">
            Jet Propulsion Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#244837" title="Click to go to the Author Index">
             Strub, Marlin Polo
            </a>
           </td>
           <td class="r">
            NASA Jet Propulsion Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#383959" title="Click to go to the Author Index">
             Corpino, Sabrina
            </a>
           </td>
           <td class="r">
            Politecnico Di Torino
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#367913" title="Click to go to the Author Index">
             Ingham, Michel
            </a>
           </td>
           <td class="r">
            NASA-JPL
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#201080" title="Click to go to the Author Index">
             Ono, Masahiro
            </a>
           </td>
           <td class="r">
            California Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#171494" title="Click to go to the Author Index">
             Thakker, Rohan
            </a>
           </td>
           <td class="r">
            Nasa's Jet Propulsion Laboratory, Caltech
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4162" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#planning_under_uncertainty" title="Click to go to the Keyword Index">
               Planning under Uncertainty
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Snake robots enable mobility through extreme terrains and confined environments in terrestrial and space applications. However, robust perception and localization for snake robots remain an open challenge due to the proximity of the sensor payload to the ground coupled with a limited field of view. To address this issue, we propose Blind-motion with Intermittently Scheduled Scans (BLISS) which combines proprioception-only mobility with intermittent scans to be resilient against both localization failures and collision risks. BLISS is formulated as an integrated task and motion planning (TAMP) problem that leads to a chance-constrained hybrid partially observable Markov decision process (CC-HPOMDP), known to be computationally intractable due to the curse of history. Our novelty lies in reformulating CC-HPOMDP as a tractable, convex mixed integer linear program. This allows us to solve BLISS-TAMP significantly faster and jointly derive optimal task-motion plans. Simulations and hardware experiments on the EELS snake robot show our method achieves over an order of magnitude computational improvement compared to state-of-the-art POMDP planners and &gt; 50% better navigation time optimality versus classical two-stage planners.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt10">
             <b>
              WeDT10
             </b>
             Regular Session, 313
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1397" name="modifyWeDT10" onclick="modsession(371,1397)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt10" title="Click to go to the Program at a Glance">
             <b>
              Multi-Robot Systems 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#137758" title="Click to go to the Author Index">
             Au, Tsz-Chiu
            </a>
           </td>
           <td class="r">
            Texas State University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#104345" title="Click to go to the Author Index">
             Bhattacharya, Sourabh
            </a>
           </td>
           <td class="r">
            Iowa State University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt10_01">
             15:15-15:20, Paper WeDT10.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1398" name="modify210" onclick="modify(210,1398)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('210'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Formation Rotation and Assignment: Avoiding Obstacles in Multi-Robot Scenarios
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#385827" title="Click to go to the Author Index">
             Zhang, Zhan
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#386096" title="Click to go to the Author Index">
             Li, Yan
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#386238" title="Click to go to the Author Index">
             Gu, Zhiyang
            </a>
           </td>
           <td class="r">
            School of Automation, Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#386099" title="Click to go to the Author Index">
             Wang, Zhong
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab210" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Current formation assignment and optimization methods frequently overlook the influence of rotational dynamics, limiting their operational flexibility. Additionally, these methods typically neglect the impact of obstacles, which may also hinder their effectiveness in obstacle-rich environments. To address these limitations, this paper proposes a novel approach that incorporates both rotation and assignment into the formation optimization of multi-robot systems. This approach allows for dynamic adjustment of the formation orientation and introduces a collaborative obstacle avoidance strategy. This strategy is specifically designed to assess and integrate the influence of obstacles into the optimization process, thereby enhancing the ability to maneuver around obstacles. Simulation experiments, including scenarios involving the encirclement of stationary and moving targets, validate the effectiveness of the proposed algorithm. The proposed algorithm outperforms non-rotational methods in maintaining formations under the influence of various types of obstacles while encircling targets. Furthermore, real-world flight experiments demonstrate the robustness and feasibility of the algorithm.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt10_02">
             15:20-15:25, Paper WeDT10.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1399" name="modify249" onclick="modify(249,1399)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('249'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Streamlined Heuristic for the Problem of Min-Time Coverage in Constricted Environments (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338918" title="Click to go to the Author Index">
             Kim, Young-In
            </a>
           </td>
           <td class="r">
            ISyE, Georgia Tech
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102255" title="Click to go to the Author Index">
             Reveliotis, Spiridon
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab249" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robotics_in_hazardous_fields" title="Click to go to the Keyword Index">
               Robotics in Hazardous Fields
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The problem of min-time coverage in constricted environments concerns the employment of robotic fleets to support routine inspection and service operations within well-structured but constricted environments. In our previous work we have provided a detailed definition of this problem, specifying the objectives and the constraints involved, a Mixed Integer Programming (MIP) formulation for it, a formal analysis of its worst-case computational complexity, and additional structural properties of the optimal solutions that enable a partial relaxation of the original MIP formulation which preserves optimal performance. We have further employed these structural results towards the development of a construction heuristic for this problem. But while the worst-case computational complexity of the construction heuristic is polynomial with respect to the size of the problem-defining elements, its practical scalability has been limited by the requirement to formulate and solve a large number of linear programming formulations. In order to address this issue, this work presents a modified version of the heuristic that significantly reduces the computational times involved. Furthermore, we develop a local search method that further improves the solution obtained from the modified heuristic.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt10_03">
             15:25-15:30, Paper WeDT10.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1400" name="modify311" onclick="modify(311,1400)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('311'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Scalable Multi-Agent Surveillance: A Kernel-Based Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#292186" title="Click to go to the Author Index">
             Mandal, Shashwata
            </a>
           </td>
           <td class="r">
            Iowa State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104345" title="Click to go to the Author Index">
             Bhattacharya, Sourabh
            </a>
           </td>
           <td class="r">
            Iowa State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab311" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computational_geometry" title="Click to go to the Keyword Index">
               Computational Geometry
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this work, we address the deployment problem for a team of mobile guards that tries to maintain a line-of-sight with an unpredictable mobile intruder. First, we present a computationally efficient strategy for generating a set of points, called `kernel points`, that covers the entire polygon. We then introduce a polygon partitioning technique based on the location of the kernel points. Next, we propose control laws for a free guard to track an intruder in general polygonal environments based on the analysis of a pursuit-evasion game around a single corner basepaper. Finally, we present several variations of the proposed control laws that include capture and search, and illustrate the improvement in the overall visual footprint of the team of mobile guards based on extensive simulations.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt10_04">
             15:30-15:35, Paper WeDT10.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1401" name="modify3186" onclick="modify(3186,1401)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3186'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Contingency Formation Planning for Interactive Drone Light Shows
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#137758" title="Click to go to the Author Index">
             Au, Tsz-Chiu
            </a>
           </td>
           <td class="r">
            Texas State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3186" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             One of the most appealing applications of drone swarms is drone light shows, in which a group of drones displays an animation by showing a sequence of light patterns in the sky. In this paper, we consider using drone swarms as video game platforms and utilize planning techniques to display pixels in animations correctly while providing a fast response to user inputs. We devise a new sampling algorithm to solve a contingency formation planning problem, which aims to find a contingency formation plan such that drones can always move to the correct positions to display every possible future frame regardless of the user inputs in the future. The algorithm provides interactivity by preemptively relocating hidden drones, which move in stealth mode to the locations of all possible future frames. Our experiments show that the size of the frame buffer and the ratio between the number of drones and the number of pixels can greatly affect the performance of our system.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt10_05">
             15:35-15:40, Paper WeDT10.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1402" name="modify4344" onclick="modify(4344,1402)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4344'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design of a Formation Control System to Assist Human Operators in Flying a Swarm of Robotic Blimps
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#386896" title="Click to go to the Author Index">
             Wu, Tianfu
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425992" title="Click to go to the Author Index">
             Fu, Jiaqi
            </a>
           </td>
           <td class="r">
            Beijing Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#386335" title="Click to go to the Author Index">
             Meng, Wugang
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#179172" title="Click to go to the Author Index">
             Cho, Sungjin
            </a>
           </td>
           <td class="r">
            Sunchon National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425960" title="Click to go to the Author Index">
             Zhan, Huanzhe
            </a>
           </td>
           <td class="r">
            Emory University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107391" title="Click to go to the Author Index">
             Zhang, Fumin
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4344" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Formation control is essential for swarm robotics, enabling coordinated behavior in complex environments. In this paper, we introduce a novel formation control system for an indoor blimp swarm using a specialized leader-follower approach enhanced with a dynamic leader-switching mechanism. This strategy allows any blimp to take on the leader role, distributing maneuvering demands across the swarm and enhancing overall formation stability. Only the leader blimp is manually controlled by a human operator, while follower blimps use onboard monocular cameras and a laser altimeter for relative position and altitude estimation. A leader-switching scheme is proposed to assist the human operator to maintain stability of the swarm, especially when a sharp turn is performed. Experimental results confirm that the leader-switching mechanism effectively maintains stable formations and adapts to dynamic indoor environments while assisting human operator.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt10_06">
             15:40-15:45, Paper WeDT10.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1403" name="modify4769" onclick="modify(4769,1403)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4769'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Agent Exploration with Similarity Score Map and Topological Memory
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#202688" title="Click to go to the Author Index">
             Lee, Eun Sun
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#255082" title="Click to go to the Author Index">
             Kim, Young Min
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4769" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-robot exploration can be a collaborative solution for navigating a large-scale area. However, it is not trivial to optimally assign tasks among agents because the state dynamically changes while the local observations of multiple agents concurrently update the global map. Furthermore, the individual robots may not have access to accurate relative poses of others or global layouts. We propose an efficient spatial abstraction for multi-agent exploration based on topological graph memories. Each agent creates a topological graph, a lightweight spatial representation whose nodes contain minimal image features. The information in graphs is aggregated to compare individual nodes and is used to update the similarity scores in real-time. Then, the agents effectively fulfill distributed task goals by examining the dynamic similarity scores of frontier nodes. We further exploit extracted visual features to refine the relative poses among topological graphs. Our proposed pipeline can efficiently explore large-scale areas among various scene and robot configurations without sharing precise geometric information.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt10_07">
             15:45-15:50, Paper WeDT10.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1404" name="modify4994" onclick="modify(4994,1404)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4994'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DREAM: Decentralized Real-Time Asynchronous Probabilistic Trajectory Planning for Collision-Free Multi-Robot Navigation in Cluttered Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#233064" title="Click to go to the Author Index">
             Şenbaşlar, Baskın
            </a>
           </td>
           <td class="r">
            NVIDIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101856" title="Click to go to the Author Index">
             Sukhatme, Gaurav
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4994" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#probabilistic_trajectory_planning" title="Click to go to the Keyword Index">
               Probabilistic Trajectory Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Collision-free navigation in cluttered environments with static and dynamic obstacles is essential for many multi-robot tasks.Dynamic obstacles may also be interactive, i.e., their behavior varies based on the behavior of other entities.We propose a novel representation for interactive behavior of dynamic obstacles and a decentralized real-time multi-robot trajectory planning algorithm allowing inter-robot collision avoidance as well as static and dynamic obstacle avoidance.Our planner simulates the behavior of dynamic obstacles, accounting for interactivity.We account for the perception inaccuracy of static and prediction inaccuracy of dynamic obstacles.We handle asynchronous planning between teammates and message delays, drops, and re-orderings.We evaluate our algorithm in simulations using 25400 random cases and compare it against three state-of-the-art baselines using 2100 random cases.Our algorithm achieves up to 1.68x success rate using as low as 0.28x time in single-robot, and up to 2.15x success rate using as low as 0.36x time in multi-robot cases compared to the best baseline.We implement our planner on real quadrotors to show its real-world applicability.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt11">
             <b>
              WeDT11
             </b>
             Regular Session, 314
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1405" name="modifyWeDT11" onclick="modsession(141,1405)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt11" title="Click to go to the Program at a Glance">
             <b>
              Foundation Models for Manipulation
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#266873" title="Click to go to the Author Index">
             Rivera, Corban
            </a>
           </td>
           <td class="r">
            Johns Hopkins University Applied Physics Lab
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#117613" title="Click to go to the Author Index">
             Kober, Jens
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt11_01">
             15:15-15:20, Paper WeDT11.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1406" name="modify25" onclick="modify(25,1406)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('25'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhancing the LLM-Based Robot Manipulation through Human-Robot Collaboration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#381779" title="Click to go to the Author Index">
             Liu, Haokun
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#231952" title="Click to go to the Author Index">
             Zhu, Yaonan
            </a>
           </td>
           <td class="r">
            University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#301372" title="Click to go to the Author Index">
             Kato, Kenji
            </a>
           </td>
           <td class="r">
            National Center for Geriatrics and Gerontology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#125696" title="Click to go to the Author Index">
             Tsukahara, Atsushi
            </a>
           </td>
           <td class="r">
            Shinshu University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#224059" title="Click to go to the Author Index">
             Kondo Izumi, Kondo Izumi
            </a>
           </td>
           <td class="r">
            National Center for Geriatrics and Gerontology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#114338" title="Click to go to the Author Index">
             Aoyama, Tadayoshi
            </a>
           </td>
           <td class="r">
            Nagoya University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101240" title="Click to go to the Author Index">
             Hasegawa, Yasuhisa
            </a>
           </td>
           <td class="r">
            Nagoya University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab25" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Large Language Models (LLMs) are gaining popularity in the field of robotics. However, LLM-based robots are limited to simple, repetitive motions due to the poor integration between language models, robots, and the environment. This paper proposes a novel approach to enhance the performance of LLM-based autonomous manipulation through Human-Robot Collaboration (HRC). The approach involves using a prompted GPT-4 language model to decompose high-level language commands into sequences of motions that can be executed by the robot. The system also employs a YOLO-based perception algorithm, providing visual cues to the LLM, which aids in planning feasible motions within the specific environment. Additionally, an HRC method is proposed by combining teleoperation and Dynamic Movement Primitives (DMP), allowing the LLM-based robot to learn from human guidance. Real-world experiments have been conducted using the Toyota Human Support Robot for manipulation tasks. The outcomes indicate that tasks requiring complex trajectory planning and reasoning over environments can be efficiently accomplished through the incorporation of human demonstrations.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt11_02">
             15:20-15:25, Paper WeDT11.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1407" name="modify1296" onclick="modify(1296,1407)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1296'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              In-Context Learning Enables Robot Action Prediction in LLMs
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#361135" title="Click to go to the Author Index">
             Yin, Yida
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418373" title="Click to go to the Author Index">
             Wang, Zekai
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418375" title="Click to go to the Author Index">
             Sharma, Yuvan
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418374" title="Click to go to the Author Index">
             Niu, Dantong
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#140256" title="Click to go to the Author Index">
             Darrell, Trevor
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#293721" title="Click to go to the Author Index">
             Herzig, Roei
            </a>
           </td>
           <td class="r">
            Tel Aviv University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1296" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recently, Large Language Models (LLMs) have achieved remarkable success using in-context learning (ICL) in the language domain. However, leveraging the ICL capabilities within off-the-shelf LLMs to directly predict robot actions remains largely unexplored. In this paper, we introduce RobotPrompt, a framework that enables off-the-shelf text-only LLMs to directly predict robot actions through ICL without training. Our approach first heuristically identifies keyframes that capture important moments from an episode. Next, we extract end-effector actions from these keyframes as well as the estimated initial object poses, and both are converted into textual descriptions. Finally, we construct a structured template to form ICL demonstrations from these textual descriptions and a task instruction. This enables an LLM to directly predict robot actions at test time. Through extensive experiments and analysis, RobotPrompt shows stronger performance over zero-shot and ICL baselines in simulated and real-world settings.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt11_03">
             15:25-15:30, Paper WeDT11.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1408" name="modify1923" onclick="modify(1923,1408)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1923'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              UniAff: A Unified Representation of Affordances for Tool Usage and Articulation with Vision-Language Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#290263" title="Click to go to the Author Index">
             Yu, Qiaojun
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#373130" title="Click to go to the Author Index">
             Huang, Siyuan
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422708" title="Click to go to the Author Index">
             Yuan, Xibin
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335119" title="Click to go to the Author Index">
             Jiang, Zhengkai
            </a>
           </td>
           <td class="r">
            Tencent
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#373301" title="Click to go to the Author Index">
             Hao, Ce
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425307" title="Click to go to the Author Index">
             Li, Xin
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#219127" title="Click to go to the Author Index">
             Chang, Haonan
            </a>
           </td>
           <td class="r">
            Rutgers University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372071" title="Click to go to the Author Index">
             Wang, Junbo
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#371357" title="Click to go to the Author Index">
             Liu, Liu
            </a>
           </td>
           <td class="r">
            Hefei University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#221079" title="Click to go to the Author Index">
             Li, Hongsheng
            </a>
           </td>
           <td class="r">
            Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339574" title="Click to go to the Author Index">
             Gao, Peng
            </a>
           </td>
           <td class="r">
            Shanghai AI Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#224610" title="Click to go to the Author Index">
             Lu, Cewu
            </a>
           </td>
           <td class="r">
            ShangHai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1923" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Previous studies on robotic manipulation are based on a limited understanding of the underlying 3D motion constraints and affordances. To address these challenges, we propose a comprehensive paradigm, termed UniAff, that integrates 3D object-centric manipulation and task understanding in a unified formulation. Specifically, we constructed a dataset labeled with manipulation-related key attributes, comprising 900 articulated objects from 19 categories and 600 tools from 12 categories. Furthermore, we leverage MLLMs to infer object-centric representations for manipulation tasks, including affordance recognition and reasoning about 3D motion constraints. Comprehensive experiments in both simulation and real-world settings indicate that UniAff significantly improves the generalization of robotic manipulation for tools and articulated objects. We hope that UniAff will serve as a general baseline for unified robotic manipulation tasks in the future. Images, videos, dataset and code are published on the project website at:https://sites.google.com/view/uni-aff/home.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt11_04">
             15:30-15:35, Paper WeDT11.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1409" name="modify2409" onclick="modify(2409,1409)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2409'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ConceptAgent: LLM-Driven Precondition Grounding and Tree Search for Robust Task Planning and Execution
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#266873" title="Click to go to the Author Index">
             Rivera, Corban
            </a>
           </td>
           <td class="r">
            Johns Hopkins University Applied Physics Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422028" title="Click to go to the Author Index">
             Byrd, Grayson
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339142" title="Click to go to the Author Index">
             Paul, William
            </a>
           </td>
           <td class="r">
            Johns Hopkins University Applied Physics Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423995" title="Click to go to the Author Index">
             Feldman, Tyler
            </a>
           </td>
           <td class="r">
            Johns Hopkins University Applied Physics Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#342283" title="Click to go to the Author Index">
             Booker, Meghan
            </a>
           </td>
           <td class="r">
            Princeton University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422156" title="Click to go to the Author Index">
             Holmes, Emma
            </a>
           </td>
           <td class="r">
            Johns Hopkins University Applied Physics Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#112970" title="Click to go to the Author Index">
             Handelman, David
            </a>
           </td>
           <td class="r">
            American Android Corp
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422684" title="Click to go to the Author Index">
             Kemp, Bethany
            </a>
           </td>
           <td class="r">
            Johns Hopkins Applied Physics Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422176" title="Click to go to the Author Index">
             Badger, Andrew
            </a>
           </td>
           <td class="r">
            JHUAPL
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424648" title="Click to go to the Author Index">
             Schmidt, Aurora
            </a>
           </td>
           <td class="r">
            Johns Hopkins University Applied Physic Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#184588" title="Click to go to the Author Index">
             Jatavallabhula, Krishna Murthy
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#277722" title="Click to go to the Author Index">
             de Melo, Celso
            </a>
           </td>
           <td class="r">
            CCDC US Army Research Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#279734" title="Click to go to the Author Index">
             Seenivasan, Lalithkumar
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#219453" title="Click to go to the Author Index">
             Unberath, Mathias
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#124257" title="Click to go to the Author Index">
             Chellappa, Rama
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2409" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#agent_based_systems" title="Click to go to the Keyword Index">
               Agent-Based Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic planning and execution in open-world environments is a complex problem due to the vast state spaces and high variability of task embodiment. Recent advances in perception algorithms, combined with Large Language Models (LLMs) for planning, offer promising solutions to these challenges, as the common sense reasoning capabilities of LLMs provide a strong heuristic for efficiently searching the action space. However, prior work fails to address the possibility of hallucinations from LLMs, which results in failures to execute the planned actions largely due to logical fallacies at high- or low-levels. To contend with automation failure due to such hallucinations, we introduce ConceptAgent, a natural language-driven robotic platform designed for task execution in unstructured environments. With a focus on scalability and reliability of LLM-based planning in complex state and action spaces, we present innovations designed to limit these shortcomings, including 1) Predicate Grounding to prevent and recover from infeasible actions, and 2) an embodied version of LLM-guided Monte Carlo Tree Search with self reflection. ConceptAgent combines these planning enhancements with dynamic language aligned 3d scene graphs, and large multi-modal pretrained models to perceive, localize, and interact with its environment, enabling reliable task completion. In simulation experiments, ConceptAgent achieved a 19% task completion rate across three room layouts and 30 easy level embodied tasks outperforming other state-of-the-art LLM-driven reasoning baselines that scored 10.26% and 8.11% on the same benchmark. Additionally, ablation studies on moderate to hard embodied tasks revealed a 20% increase in task completion from the baseline agent to the fully enhanced ConceptAgent, highlighting the individual and combined contributions of Predicate Grounding and LLM-guided Tree Search to enable more robust automation in complex state and action spaces.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt11_05">
             15:35-15:40, Paper WeDT11.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1410" name="modify3253" onclick="modify(3253,1410)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3253'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Towards Generalizable Vision-Language Robotic Manipulation: A Benchmark and LLM-Guided 3D Policy
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#235462" title="Click to go to the Author Index">
             Garcia-Pinel, Ricardo
            </a>
           </td>
           <td class="r">
            Inria
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#332715" title="Click to go to the Author Index">
             Chen, Shizhe
            </a>
           </td>
           <td class="r">
            Inria
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#245500" title="Click to go to the Author Index">
             Schmid, Cordelia
            </a>
           </td>
           <td class="r">
            Inria
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3253" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#software_tools_for_benchmarking_and_reproducibility" title="Click to go to the Keyword Index">
               Software Tools for Benchmarking and Reproducibility
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Generalizing language-conditioned robotic policies to new tasks remains a significant challenge, hampered by the lack of suitable simulation benchmarks. In this paper, we address this gap by introducing GemBench, a novel benchmark to assess generalization capabilities of vision-language robotic manipulation policies. GemBench incorporates seven general action primitives and four levels of generalization, spanning novel placements, rigid and articulated objects, and complex long-horizon tasks. We evaluate state-of-the-art approaches on GemBench and also introduce a new method. Our approach 3D-LOTUS leverages rich 3D information for action prediction conditioned on language. While 3D-LOTUS excels in both efficiency and performance on seen tasks, it struggles with novel tasks. To address this, we present 3D-LOTUS++, a framework that integrates 3D-LOTUS's motion planning capabilities with the task planning capabilities of LLMs and the object grounding accuracy of VLMs. 3D-LOTUS++ achieves state-of-the-art performance on novel tasks of GemBench, setting a new standard for generalization in robotic manipulation. Code, dataset, real robot videos and trained models are available at url{https://www.di.ens.fr/willow/research/gembench/}.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt11_06">
             15:40-15:45, Paper WeDT11.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1411" name="modify4360" onclick="modify(4360,1411)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4360'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Discovering Object Attributes by Prompting Large Language Models with Perception-Action APIs
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#291702" title="Click to go to the Author Index">
             Mavrogiannis, Angelos
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#400056" title="Click to go to the Author Index">
             Yuan, Dehao
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#118557" title="Click to go to the Author Index">
             Aloimonos, Yiannis
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4360" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_architecture_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Computer Architecture for Robotic and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#software__middleware_and_programming_environments" title="Click to go to the Keyword Index">
               Software, Middleware and Programming Environments
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             There has been a lot of interest in grounding natural language to physical entities through visual context. While Vision Language Models (VLMs) can ground linguistic instructions to visual sensory information, they struggle with grounding non-visual attributes, like the weight of an object. Our key insight is that non-visual attribute detection can be effectively achieved by active perception guided by visual reasoning. To this end, we present a perception-action API that consists of VLMs and Large Language Models (LLMs) as backbones, together with a set of robot control functions. When prompted with this API and a natural language query, an LLM generates a program to actively identify attributes given an input image. Offline testing on the Odd-One-Out dataset demonstrates that our framework outperforms vanilla VLMs in detecting attributes like relative object location, size, and weight. Online testing in realistic household scenes on AI2-THOR and a real robot demonstration on a DJI RoboMaster EP robot highlight the efficacy of our approach.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt11_07">
             15:45-15:50, Paper WeDT11.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1412" name="modify4424" onclick="modify(4424,1412)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4424'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ExploRLLM: Guiding Exploration in Reinforcement Learning with Large Language Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#320860" title="Click to go to the Author Index">
             Ma, Runyu
            </a>
           </td>
           <td class="r">
            Tu Delft
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#367957" title="Click to go to the Author Index">
             Luijkx, Jelle Douwe
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#225631" title="Click to go to the Author Index">
             Ajanovic, Zlatan
            </a>
           </td>
           <td class="r">
            RWTH Aachen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#117613" title="Click to go to the Author Index">
             Kober, Jens
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4424" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In robot manipulation, Reinforcement Learning (RL) often suffers from low sample efficiency and uncertain convergence, especially in large observation and action spaces. Foundation Models (FMs) offer an alternative, demonstrating promise in zero-shot and few-shot settings. However, they can be unreliable due to limited physical and spatial understanding. We introduce ExploRLLM, a method that combines the strengths of both paradigms. In our approach, FMs improve RL convergence by generating policy code and efficient representations, while a residual RL agent compensates for the FMs' limited physical understanding. We show that ExploRLLM outperforms both policies derived from FMs and RL baselines in table-top manipulation tasks. Additionally, real-world experiments show that the policies exhibit promising zero-shot sim-to-real transfer. Supplementary material is available at
             <a href='"https://explorllm.github.io"'>
              https://explorllm.github.io
             </a>
             .
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt12">
             <b>
              WeDT12
             </b>
             Regular Session, 315
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1413" name="modifyWeDT12" onclick="modsession(509,1413)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt12" title="Click to go to the Program at a Glance">
             <b>
              Robotics and Automation in Construction and Industry
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#201773" title="Click to go to the Author Index">
             Muratore, Luca
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#111035" title="Click to go to the Author Index">
             Werfel, Justin
            </a>
           </td>
           <td class="r">
            Harvard University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt12_01">
             15:15-15:20, Paper WeDT12.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1414" name="modify1051" onclick="modify(1051,1414)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1051'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Physical Simulation with Force Feedback Aids Robot Factors Design
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420094" title="Click to go to the Author Index">
             Kaeser, Carina
            </a>
           </td>
           <td class="r">
            Student
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#210092" title="Click to go to the Author Index">
             Melenbrink, Nathan
            </a>
           </td>
           <td class="r">
            Harvard University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419667" title="Click to go to the Author Index">
             Karp, Allison
            </a>
           </td>
           <td class="r">
            Harvard
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#111035" title="Click to go to the Author Index">
             Werfel, Justin
            </a>
           </td>
           <td class="r">
            Harvard University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1051" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#product_design__development_and_prototyping" title="Click to go to the Keyword Index">
               Product Design, Development and Prototyping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#haptics_and_haptic_interfaces" title="Click to go to the Keyword Index">
               Haptics and Haptic Interfaces
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             "Robot factors" design, analogous to ergonomics for humans, seeks to create devices and equipment that can be readily operated by robots, by considering typical capabilities of current robots throughout the design process. While a number of principles and heuristics for robot factors design have been identified, the successful design of hardware operable by autonomous robots often depends in practice on the designer's intuition about robot capabilities, developed through personal experience working with robots. Here we present a tool we have developed to help evaluate a potential device design for usability by a robot, by allowing a designer to in effect teleoperate a virtual robot and attempt the operation of the device. The tool uses a 3D physics-based simulation built in Unity, and a Phantom Omni / Geomagic Touch haptic device that controls the virtual robot's end-effector and provides force feedback. Through user studies, we show that the use of this tool can significantly improve a user's estimation of the suitability of a design for robot operation, in two case studies involving replacing a unit in a modular hardware system and unzipping a canvas bag. By incorporating the use of such a tool early in the design cycle, designers can more effectively develop equipment to be used by autonomous robots without themselves needing direct robotics experience; as a result, robots will be able to take on more tasks in the nearer term with current robot technology.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt12_02">
             15:20-15:25, Paper WeDT12.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1415" name="modify1722" onclick="modify(1722,1415)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1722'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Environmental Map Learning with Multiple-Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#302716" title="Click to go to the Author Index">
             Shamshirgaran, Azin
            </a>
           </td>
           <td class="r">
            University of California, Merced
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101923" title="Click to go to the Author Index">
             Carpin, Stefano
            </a>
           </td>
           <td class="r">
            University of California, Merced
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1722" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robotics_and_automation_in_agriculture_and_forestry" title="Click to go to the Keyword Index">
               Robotics and Automation in Agriculture and Forestry
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#agricultural_automation" title="Click to go to the Keyword Index">
               Agricultural Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper explores decision-making processes in robotic systems tasked with reconstructing scalar fields through sensing in uncertain environments. Each robot must handle noisy perception and operate within specific environmental and physical constraints. The complexity increases in multi-agent scenarios, where robots must not only plan their actions but also anticipate the movements and strategies of other agents. Effective coordination is crucial to prevent collisions and minimize redundant tasks. To address this challenge, we propose an online, distributed multi-robot sampling algorithm that combines Monte Carlo Tree Search (MCTS) with Gaussian regression. In this approach, each robot iteratively selects its next sampling point while exchanging limited information with other robots and predicting their future actions. Predictions about other robots future actions are computed with a MCTS that is recomputed at each iteration to incorporate all information collected up to that point. We evaluate the performance of our method across diverse environments and team sizes, comparing it to algorithmic alternatives.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt12_03">
             15:25-15:30, Paper WeDT12.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1416" name="modify2209" onclick="modify(2209,1416)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2209'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SLABIM: A SLAM-BIM Coupled Dataset in HKUST Main Building
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421570" title="Click to go to the Author Index">
             Huang, Haoming
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#269153" title="Click to go to the Author Index">
             Qiao, Zhijian
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#350236" title="Click to go to the Author Index">
             Yu, Zehuan
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#243408" title="Click to go to the Author Index">
             Liu, Chuhao
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#142354" title="Click to go to the Author Index">
             Shen, Shaojie
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107391" title="Click to go to the Author Index">
             Zhang, Fumin
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#218647" title="Click to go to the Author Index">
             Yin, Huan
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2209" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robotics_and_automation_in_construction" title="Click to go to the Keyword Index">
               Robotics and Automation in Construction
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_slam" title="Click to go to the Keyword Index">
               Data Sets for SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Existing indoor SLAM datasets primarily focus on robot sensing, often lacking building architectures. To address this gap, we design and construct the first dataset to couple the SLAM and BIM, named SLABIM. This dataset provides BIM and SLAM-oriented sensor data, both modeling a university building at HKUST. The as-designed BIM is decomposed and converted for ease of use. We employ a multi-sensor suite for multi-session data collection and mapping to obtain the as-built model. All the related data are timestamped and organized, enabling users to deploy and test effectively. Furthermore, we deploy advanced methods and report the experimental results on three tasks: registration, localization and semantic mapping, demonstrating the effectiveness and practicality of SLABIM. We make our dataset open-source at https://github.com/HKUST-Aerial-Robotics/SLABIM.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt12_04">
             15:30-15:35, Paper WeDT12.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1417" name="modify2566" onclick="modify(2566,1417)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2566'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Unified Adaptive and Cooperative Planning Using Multi-Task Coregionalized Gaussian Processes
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#312647" title="Click to go to the Author Index">
             Booth, Lorenzo A.
            </a>
           </td>
           <td class="r">
            University of California Merced
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101923" title="Click to go to the Author Index">
             Carpin, Stefano
            </a>
           </td>
           <td class="r">
            University of California, Merced
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2566" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robotics_and_automation_in_agriculture_and_forestry" title="Click to go to the Keyword Index">
               Robotics and Automation in Agriculture and Forestry
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#agricultural_automation" title="Click to go to the Keyword Index">
               Agricultural Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             For robots tasked with surveying the temporal dynamics of a changing environment, a choice must be made to observe novel regions of the environment or to re-survey previously visited regions, which may have changed. We present a novel multi-robot informative path planner (IPP) that combines an environmental and task kernel to direct mobile robots to gather samples from regions that would result in the greatest expected improvement in map accuracy. Our planner utilizes a multi-output Gaussian process to unify priors about the spatiotemporal environment along with priors about observational correlations between sensing vehicles. Additionally, we extend our analysis into an adaptive planning scenario and examine the performance under different planning configurations. We find that planning performance is largely driven by the choice of environmental priors, and that unrepresentative priors can be improved through adaptive planning.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt12_05">
             15:35-15:40, Paper WeDT12.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1418" name="modify2954" onclick="modify(2954,1418)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2954'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              COIGAN: Controllable Object Inpainting through Generative Adversarial Network for Defect Synthesis in Data Augmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#392425" title="Click to go to the Author Index">
             Biancucci, Massimiliano
            </a>
           </td>
           <td class="r">
            Università Politecnica Delle Marche
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#236272" title="Click to go to the Author Index">
             Galdelli, Alessandro
            </a>
           </td>
           <td class="r">
            Università Politecnica Delle Marche
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#382498" title="Click to go to the Author Index">
             Narang, Gagan
            </a>
           </td>
           <td class="r">
            Università Politecnica Delle Marche
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#312736" title="Click to go to the Author Index">
             Pietrini, Rocco
            </a>
           </td>
           <td class="r">
            Universià Politecnica Delle Marche
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#117754" title="Click to go to the Author Index">
             Mancini, Adriano
            </a>
           </td>
           <td class="r">
            Università Politecnica Delle Marche
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103512" title="Click to go to the Author Index">
             Zingaretti, Primo
            </a>
           </td>
           <td class="r">
            Università Politecnica Delle Marche
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2954" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robotics_and_automation_in_construction" title="Click to go to the Keyword Index">
               Robotics and Automation in Construction
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Predictive maintenance is a key aspect for the safety of critical infrastructure such as bridges, dams, and tunnels, where a failure can lead to catastrophic outcomes in terms of human lives and costs. The surge in Artificial Intelligence-driven visual robotic inspection methods necessitates high-quality datasets containing diverse defect classes with several instances on different conditions (e.g., material, illumination). In this context, we introduce a Controllable Object Inpainting Generative Adversarial Network (COIGAN) to synthetically generate realistic images that augment defect datasets. The effectiveness of the model is quantitatively validated by a Fréchet Inception Distance, which measures the similarity between the generated and training samples. To further evaluate the impact of COIGAN-generated images, a segmentation task was conducted, utilizing key performance metrics such as segmentation accuracy, mAP, mIoU, and F1 score, demonstrating that the synthetic images integrate seamlessly and produce results comparable to real defect images. Subsequently, COIGAN generability was successfully used for the segmentation of a defect-free dataset by inpainting defects. The results showcase COIGAN's ability to learn defect patterns and apply them in new contexts, preserving the original features of the base image and allowing the creation of new datasets with a desired multi-class distribution. Specifically, in the context of predictive maintenance, COIGAN enriches datasets, enabling deep learning models to more effectively identify potential infrastructure anomalies. Project page: https://bit.ly/4bzxwqf.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt12_06">
             15:40-15:45, Paper WeDT12.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1419" name="modify4429" onclick="modify(4429,1419)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4429'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Diffusion Based Robust LiDAR Place Recognition
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425947" title="Click to go to the Author Index">
             Krummenacher, Benjamin
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#291196" title="Click to go to the Author Index">
             Frey, Jonas
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#344080" title="Click to go to the Author Index">
             Tuna, Turcan
            </a>
           </td>
           <td class="r">
            ETH Zurich, Robotic Systems Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#165811" title="Click to go to the Author Index">
             Vysotska, Olga
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#114045" title="Click to go to the Author Index">
             Hutter, Marco
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4429" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robotics_and_automation_in_construction" title="Click to go to the Keyword Index">
               Robotics and Automation in Construction
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Mobile robots on construction sites require accurate pose estimation to perform autonomous surveying and inspection missions. Localization in construction sites is a particularly challenging problem due to the presence of repetitive features such as flat plastered walls and perceptual aliasing due to apartments with similar layouts inter and intra floors. In this paper, we focus on global re-positioning of a robot with respect to an accurate scanned mesh of the building solely using LiDAR data. In our approach, a neural network is trained on synthetic LiDAR point clouds generated by simulating a LiDAR in an accurate real-life large-scale mesh. We train a diffusion model with a PointNet++ backbone, which allows us to model multiple position candidates from a single LiDAR point cloud. The resulting model can successfully predict the global position of the LiDAR in confined and complex sites despite the adverse effects of perceptual aliasing. The learned distribution of potential global positions can provide multi-modal position distribution. We evaluate our approach across five real-world datasets and show the place recognition accuracy of 77% (threshold 2m) on average while outperforming baselines at a factor of 2 in mean error.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt12_07">
             15:45-15:50, Paper WeDT12.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1420" name="modify5026" onclick="modify(5026,1420)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5026'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhancing Robotic Precision in Construction: A Modular Factor Graph-Based Framework to Deflection and Backlash Compensation Using High-Accuracy Accelerometers
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#275322" title="Click to go to the Author Index">
             Kindle, Julien
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#412713" title="Click to go to the Author Index">
             Loetscher, Michael
            </a>
           </td>
           <td class="r">
            ETH Zurich, Hilti
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#207342" title="Click to go to the Author Index">
             Alessandretti, Andrea
            </a>
           </td>
           <td class="r">
            Hilti Group
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#122912" title="Click to go to the Author Index">
             Cadena, Cesar
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#114045" title="Click to go to the Author Index">
             Hutter, Marco
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5026" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robotics_and_automation_in_construction" title="Click to go to the Keyword Index">
               Robotics and Automation in Construction
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurate positioning is crucial in the construction industry, where labor shortages highlight the need for automation. Robotic systems with long kinematic chains are required to reach complex workspaces, including floors, walls, and ceilings. These requirements significantly impact positioning accuracy due to effects such as deflection and backlash in various parts along the kinematic chain. In this letter, we introduce a novel approach that integrates deflection and backlash compensation models with high-accuracy accelerometers, significantly enhancing position accuracy. Our method employs a modular framework based on a factor graph formulation to estimate the state of the kinematic chain, leveraging acceleration measurements to inform the model. Extensive testing on publicly released datasets, reflecting real-world construction disturbances, demonstrates the advantages of our approach. The proposed method reduces the 95% error threshold in the xy-plane by 50% compared to the state-of-the-art Virtual Joint Method, and by 31% when incorporating base tilt compensation.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt13">
             <b>
              WeDT13
             </b>
             Regular Session, 316
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1421" name="modifyWeDT13" onclick="modsession(283,1421)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt13" title="Click to go to the Program at a Glance">
             <b>
              Manipulation and Locomotion Using Magnetic Fields
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#101649" title="Click to go to the Author Index">
             Tanner, Herbert G.
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#103249" title="Click to go to the Author Index">
             Bergbreiter, Sarah
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt13_01">
             15:15-15:20, Paper WeDT13.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1422" name="modify737" onclick="modify(737,1422)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('737'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Open-Loop Position Control of a Miniature Magnetic Robot Using Two-Dimensional Divergence Control of a Magnetic Force
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#412634" title="Click to go to the Author Index">
             Lee, Hakjoon
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology (DGIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339605" title="Click to go to the Author Index">
             Latifi Gharamaleki, Nader
            </a>
           </td>
           <td class="r">
            DGIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#160499" title="Click to go to the Author Index">
             Choi, Hongsoo
            </a>
           </td>
           <td class="r">
            Daegu Gyeongbuk Institute of Science and Technology (DGIST)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab737" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#automation_at_micro_nano_scales" title="Click to go to the Keyword Index">
               Automation at Micro-Nano Scales
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Miniature magnetic robots have attracted considerable attention as promising tools in biomedical applications due to their wireless actuation and precise controllability in a minimally invasive manner. Traditionally, magnetic microrobots have been controlled by globally applied magnetic torques and forces generated by external magnetic actuation systems (MASs), which typically require closed-loop control with real-time vision tracking—a challenging requirement in in-vivo environments. To address this issue, this paper suggests a novel open-loop control scheme for magnetic robots, using two-dimensional (2D) divergence control of a magnetic force generated by stationary electromagnets. Constraint equations for the currents applied to the electromagnets were established to achieve 2D divergence control of a magnetic force. Numerical simulation and experimental validations demonstrate that this approach can generate sufficient magnetic forces that either converge at or diverge from a target point, enabling effective open-loop position control of a miniature magnetic robot. Due to the absence of vision feedback and mechanical motions of magnets, the proposed control strategy could be more clinically applicable for medical applications of magnetic robots.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt13_02">
             15:20-15:25, Paper WeDT13.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1423" name="modify837" onclick="modify(837,1423)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('837'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              An Equilibrium Analysis of Magnetic Quadrupole Force Field with Applications to Microrobotic Swarm Coordination
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419543" title="Click to go to the Author Index">
             Faros, Ioannis
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101649" title="Click to go to the Author Index">
             Tanner, Herbert G.
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab837" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning__scheduling_and_coordination" title="Click to go to the Keyword Index">
               Planning, Scheduling and Coordination
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Controlled microrobots in fluidic environments hold promise for precise drug delivery and cell manipulation, opening new ways for personalized healthcare. However, coordinating magnetic microrobot swarms presents significant challenges due to the complexity of the associated actuation mechanisms. While existing methods to achieve motion differentiation in collections of microrobots rely on design variations among them, the work reported here applies to homogeneous collectives and enables them to be steered as a whole or in fragments, by means of a common externally generated force field. This paper contributes to an emerging set of methods that enable swarm control through manipulation of these force fields. This paper in particular exploits the nature of force field equilibria in a quadrupole workspace configuration as a means of steering the swarm while maintaining its cohesion. The approach also enables splitting the swarm in two subgroups in order to direct each simultaneously to a different location.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt13_03">
             15:25-15:30, Paper WeDT13.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1424" name="modify1091" onclick="modify(1091,1424)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1091'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Ensemble Control of a 2-DOF Parallel Link Arm in a Capsule Robot Using Oscillating External Magnetic Fields
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378568" title="Click to go to the Author Index">
             Zhao, Zihan
            </a>
           </td>
           <td class="r">
            The University of Sheffield
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397465" title="Click to go to the Author Index">
             Hafez, Ahmed
            </a>
           </td>
           <td class="r">
            University of Sheffield
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#113599" title="Click to go to the Author Index">
             Miyashita, Shuhei
            </a>
           </td>
           <td class="r">
            University of Sheffield
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1091" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Providing oral capsule robots with additional degrees of freedom (DOF), such as robotic arms, is crucial for enhancing their functionality within the body. However, a key challenge arises when using rotating magnetic fields to drive the motor within the robot, as the resulting torque causes the entire capsule to rotate. In this work, we propose a novel approach to actuate a 2 DOF parallel link robot arm integrated into a capsule robot, using external magnetic fields. Our method employs two identical magnetic motors we proposed in a previous study, each driven by an oscillating magnetic field, which alternates direction along a specific axis. By independently controlling the rotation of each motor through the same magnetic field, ensemble control is achieved. The symmetrically arranged motors exhibit different angular velocities, enabling dexterous movement of the robot arm. We further theoretically show that this approach significantly reduces the torque exerted on the robot compared to traditional rotating magnetic fields. Finally, we demonstrate the performance of the robot by moving its arms and the attached end-effector along a pre-defined trajectory.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt13_04">
             15:30-15:35, Paper WeDT13.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1425" name="modify3016" onclick="modify(3016,1425)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3016'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Deep Reinforcement Learning-Based Semi-Autonomous Control for Magnetic Micro-Robot Navigation with Immersive Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424599" title="Click to go to the Author Index">
             Mao, Yudong
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#191798" title="Click to go to the Author Index">
             Zhang, Dandan
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3016" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#automation_at_micro_nano_scales" title="Click to go to the Keyword Index">
               Automation at Micro-Nano Scales
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Magnetic micro-robots have demonstrated immense potential in biomedical applications, such as in vivo drug delivery, non-invasive diagnostics, and cell-based therapies, owing to their precise maneuverability and small size. However, current micromanipulation techniques often rely solely on a two-dimensional (2D) microscopic view as sensory feedback, while traditional control interfaces do not provide an intuitive manner for operators to manipulate micro-robots. These limitations increase the cognitive load on operators, who must interpret limited feedback and translate it into effective control actions. To address these challenges, we propose a Deep Reinforcement Learning-Based Semi-Autonomous Control (DRL-SC) framework for magnetic micro-robot navigation in a simulated microvascular system. Our framework integrates Mixed Reality (MR) to facilitate immersive manipulation of micro-robots, thereby enhancing situational awareness and control precision. Simulation and experimental results demonstrate that our approach significantly improves navigation efficiency, reduces control errors, and enhances the overall robustness of the system in simulated microvascular environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt13_05">
             15:35-15:40, Paper WeDT13.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1426" name="modify3403" onclick="modify(3403,1426)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3403'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              OMASTAR Optimal Magnetic Actuation System Arrangement
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#413064" title="Click to go to the Author Index">
             Palanichamy, Veerash
            </a>
           </td>
           <td class="r">
            McMaster University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405501" title="Click to go to the Author Index">
             Saad, Hussein
            </a>
           </td>
           <td class="r">
            McMaster University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#182807" title="Click to go to the Author Index">
             Giamou, Matthew
            </a>
           </td>
           <td class="r">
            McMaster University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203713" title="Click to go to the Author Index">
             Onaizah, Onaizah
            </a>
           </td>
           <td class="r">
            McMaster University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3403" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Microrobots and other miniature robots are able to access millimeter-sized spaces and thus have the potential to solve many challenging problems in healthcare. However, clinical adoption of these robots is rare as these systems are often difficult to scale up. One such issue arises from the actuation systems used to remotely control magnetic microrobots, which tend to be bulky and obstruct the surgeons' workspaces. They also do not guarantee wide ranges of magnetic fields and forces in a large patient-sized workspace. In this paper, we present the design of a permanent magnet-based actuation system that fits within a 40 cm cube of space under an operating table. We also formulate a new set function maximization-based approach for efficiently designing E-optimal magnet arrangements with off-the-shelf convex solvers. Our optimization method is evaluated with synthetic data and a proof-of-concept of the system is simulated.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt13_06">
             15:40-15:45, Paper WeDT13.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1427" name="modify3921" onclick="modify(3921,1427)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3921'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Measuring DNA Microswimmer Locomotion in Complex Flow Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351335" title="Click to go to the Author Index">
             Imamura, Taryn
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#286639" title="Click to go to the Author Index">
             Kent, Teresa
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#273128" title="Click to go to the Author Index">
             Taylor, Rebecca
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103249" title="Click to go to the Author Index">
             Bergbreiter, Sarah
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3921" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#automation_at_micro_nano_scales" title="Click to go to the Keyword Index">
               Automation at Micro-Nano Scales
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Microswimmers are sub-millimeter swimming robots that show potential as a platform for controllable locomotion in applications, including targeted cargo delivery and minimally invasive surgery. To be viable for these target applications, microswimmers will eventually need to be able to navigate environments with dynamic fluid flows and forces. Experimental studies with microswimmers towards this goal are currently rare because of the difficulty of isolating intentional microswimmer locomotion from environment-induced motion. In this work, we present a method for measuring microswimmer locomotion within a complex flow environment using fiducial microspheres. By tracking the particle motion of ferromagnetic and non-magnetic polystyrene fiducial microspheres, we capture the effect of fluid flow and magnetic field gradients on microswimmer trajectories. We then determine the field-driven translation of these microswimmers relative to fluid flow and demonstrate the effectiveness of this method by illustrating the motion of multiple microswimmers through different flows.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt13_07">
             15:45-15:50, Paper WeDT13.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1428" name="modify4932" onclick="modify(4932,1428)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4932'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Position Regulation of a Conductive Nonmagnetic Object with Two Stationary Field Sources
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#321690" title="Click to go to the Author Index">
             Dalton, Devin
            </a>
           </td>
           <td class="r">
            University of Utah
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#301559" title="Click to go to the Author Index">
             Tabor, Griffin
            </a>
           </td>
           <td class="r">
            University of Utah
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#142053" title="Click to go to the Author Index">
             Hermans, Tucker
            </a>
           </td>
           <td class="r">
            University of Utah
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101254" title="Click to go to the Author Index">
             Abbott, Jake J.
            </a>
           </td>
           <td class="r">
            University of Utah
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4932" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#force_control" title="Click to go to the Keyword Index">
               Force Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent research has shown that eddy currents induced by rotating magnetic dipole fields in conductive nonmagnetic objects can produce forces and torques that enable dexterous manipulation. This paradigm shows promise for application in the remediation of space debris. The induced force from each rotating-magnetic-dipole field source always includes a repulsive component, suggesting that the object should be surrounded by field sources to some degree to ensure the object does not leave the dexterous workspace during manipulation. In this paper, we show that it is possible to fully control the position of an object using just two stationary field sources, provided the object is near the midpoint between the field sources. A given position controller requires a low-level force controller. We propose two new force controllers and compare them with the state-of-the-art method from the literature. One of the new force controllers is particularly good at not inducing parasitic torques, which is hypothesized to be beneficial for future tasks manipulating rotating resident space objects. We perform experimental verification using numerical and physical simulators of microgr
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt14">
             <b>
              WeDT14
             </b>
             Regular Session, 402
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1429" name="modifyWeDT14" onclick="modsession(541,1429)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt14" title="Click to go to the Program at a Glance">
             <b>
              Social Navigation 1
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#159826" title="Click to go to the Author Index">
             Mavrogiannis, Christoforos
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#243351" title="Click to go to the Author Index">
             Kästner, Linh
            </a>
           </td>
           <td class="r">
            T-Mobile, TU Berlin
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt14_01">
             15:15-15:20, Paper WeDT14.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1430" name="modify2635" onclick="modify(2635,1430)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2635'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              From Cognition to Precognition: A Future-Aware Framework for Social Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#414223" title="Click to go to the Author Index">
             Gong, Zeying
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#315491" title="Click to go to the Author Index">
             Hu, Tianshuai
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425169" title="Click to go to the Author Index">
             Qiu, Ronghe
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372961" title="Click to go to the Author Index">
             Liang, Junwei
            </a>
           </td>
           <td class="r">
            HKUST (Guangzhou)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2635" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             To navigate safely and efficiently in crowded spaces, robots should not only perceive the current state of the environment but also anticipate future human movements. In this paper, we propose a reinforcement learning architecture, namely Falcon, to tackle socially-aware navigation by explicitly predicting human trajectories and penalizing actions that block future human paths. To facilitate realistic evaluation, we introduce a novel SocialNav benchmark containing two new datasets, Social-HM3D and Social-MP3D. This benchmark offers large-scale photo-realistic indoor scenes populated with a reasonable amount of human agents based on scene area size, incorporating natural human movements and trajectory patterns. We conduct a detailed experimental analysis with the state-of-the-art learning-based method and two classic rule-based path-planning algorithms on the new benchmark. The results demonstrate the importance of future prediction and our method achieves the best task success rate of 55% while maintaining about 90% personal space compliance.	 We will release our code and datasets.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt14_02">
             15:20-15:25, Paper WeDT14.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1431" name="modify3685" onclick="modify(3685,1431)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3685'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              OLiVia-Nav: An Online Lifelong Vision Language Approach for Mobile Robot Social Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#390016" title="Click to go to the Author Index">
             Narasimhan, Siddarth
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256471" title="Click to go to the Author Index">
             Tan, Aaron Hao
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424768" title="Click to go to the Author Index">
             Choi, Daniel
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104747" title="Click to go to the Author Index">
             Nejat, Goldie
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3685" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#service_robotics" title="Click to go to the Keyword Index">
               Service Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#continual_learning" title="Click to go to the Keyword Index">
               Continual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Service robots in human-centered environments such as hospitals, office buildings, and long-term care homes need to navigate while adhering to social norms to ensure the safety and comfortability of the people they are sharing the space with. Furthermore, they need to adapt to new social scenarios that can arise during robot navigation. In this paper, we present a novel Online Lifelong Vision Language architecture, OLiVia-Nav, which uniquely integrates vision-language models (VLMs) with an online lifelong learning framework for robot social navigation. We introduce a unique distillation approach, Social Context Contrastive Language Image Pre-training (SC-CLIP), to transfer the social reasoning capabilities of large VLMs to a lightweight VLM, in order for OLiVia-Nav to directly encode social and environment context during robot navigation. These encoded embeddings are used to generate and select robot social compliant trajectories. The lifelong learning capabilities of SC-CLIP enable OLiVia-Nav to update the robot trajectory planning overtime as new social scenarios are encountered. We conducted extensive real-world experiments in diverse social navigation scenarios. The results showed that OLiVia-Nav outperformed existing state-of-the-art DRL and VLM methods in terms of mean squared error, Hausdorff loss, and personal space violation duration. Ablation studies also verified the design choices for OLiVia-Nav.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt14_03">
             15:25-15:30, Paper WeDT14.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1432" name="modify3961" onclick="modify(3961,1432)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3961'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Arena 4.0: A Comprehensive ROS2 Development and Benchmarking Platform for Human-Centric Navigation Using Generative-Model-Based Environment Generation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398980" title="Click to go to the Author Index">
             Shcherbyna, Volodymyr
            </a>
           </td>
           <td class="r">
            Technical University Berlin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#243351" title="Click to go to the Author Index">
             Kästner, Linh
            </a>
           </td>
           <td class="r">
            T-Mobile, TU Berlin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426131" title="Click to go to the Author Index">
             Diaz, Diego
            </a>
           </td>
           <td class="r">
            Technical University Berlin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416793" title="Click to go to the Author Index">
             Nguyen Huu Truong, Giang
            </a>
           </td>
           <td class="r">
            HaNoi University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426142" title="Click to go to the Author Index">
             Schreff, Maximilian Ho-Kyoung
            </a>
           </td>
           <td class="r">
            Technical University Berlin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#399033" title="Click to go to the Author Index">
             Seeger, Tim
            </a>
           </td>
           <td class="r">
            Technical University Berlin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#399036" title="Click to go to the Author Index">
             Kreutz, Jonas
            </a>
           </td>
           <td class="r">
            Technical University Berlin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#399032" title="Click to go to the Author Index">
             Martban, Ahmed
            </a>
           </td>
           <td class="r">
            Technical University Berlin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#287016" title="Click to go to the Author Index">
             Shen, Zhengcheng
            </a>
           </td>
           <td class="r">
            TU Berlin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#349854" title="Click to go to the Author Index">
             Zeng, Huajian
            </a>
           </td>
           <td class="r">
            Technical University Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#137443" title="Click to go to the Author Index">
             Soh, Harold
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3961" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#software_tools_for_benchmarking_and_reproducibility" title="Click to go to the Keyword Index">
               Software Tools for Benchmarking and Reproducibility
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Building upon the foundations laid by our previous work, this paper introduces Arena 4.0, a significant advancement of Arena 3.0, Arena-Bench, Arena 1.0, and Arena 2.0. Arena 4.0 provides three main novel contributions: 1) a generative-model-based world and scenario generation approach using large language models (LLMs) and diffusion models, to dynamically generate complex, human-centric environments from text prompts or 2D floorplans that can be used for development and benchmarking of social navigation strategies. 2) A comprehensive 3D model database which can be extended with 3D assets and semantically linked and annotated using a variety of metrics for dynamic spawning and arrangements inside 3D worlds. 3) The complete migration towards ROS 2, which ensures operation with state-of-the-art hardware and functionalities for improved navigation, usability, and simplified transfer towards real robots. We evaluated the platforms performance through a comprehensive user study and its world generation capabilities for benchmarking demonstrating significant improvements in usability and efficiency compared to previous versions. Arena 4.0 is openly available at https://github.com/Arena-Rosnav.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt14_04">
             15:30-15:35, Paper WeDT14.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1433" name="modify4857" onclick="modify(4857,1433)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4857'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Active Inference-Based Planning for Safe Human-Robot Interaction: Concurrent Consideration of Human Characteristic and Rationality
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#314740" title="Click to go to the Author Index">
             Nam, Youngim
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#305540" title="Click to go to the Author Index">
             Kwon, Cheolhyeon
            </a>
           </td>
           <td class="r">
            Ulsan National Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4857" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#safety_in_hri" title="Click to go to the Keyword Index">
               Safety in HRI
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning_under_uncertainty" title="Click to go to the Keyword Index">
               Planning under Uncertainty
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes a motion planning strategy for a robot to safely interact with humans exhibiting uncertain actions. The human actions are often encoded by the internal states that are attributed to human characteristics and rationality. First, by leveraging a continuous level of rationality, we compute the belief on human rationality along with his/her characteristic. This systematically reasons out the uncertainty in the observed human action, thereby better assessing the potential safety risks during the interaction. Second, based on the computed belief over the human internal states, we formulate a Stochastic Model Predictive Control (SMPC) problem to plan the robot’s actions such that it safely achieves its goal while also actively inferring on the human internal state. To cope with the expensive computation of the SMPC, we develop a sampling-based technique that efficiently evaluates the robot’s action conditioned on human uncertainty. The experiment results demonstrate that the proposed strategy excels in human action prediction, and significantly improves the safety and efficiency of Human-Robot Interaction (HRI).
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt14_05">
             15:35-15:40, Paper WeDT14.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1434" name="modify4923" onclick="modify(4923,1434)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4923'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Characterizing the Complexity of Social Robot Navigation Scenarios
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378546" title="Click to go to the Author Index">
             Stratton, Andrew
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#123478" title="Click to go to the Author Index">
             Hauser, Kris
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#159826" title="Click to go to the Author Index">
             Mavrogiannis, Christoforos
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4923" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#performance_evaluation_and_benchmarking" title="Click to go to the Keyword Index">
               Performance Evaluation and Benchmarking
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Social robot navigation algorithms are often demonstrated in overly simplified scenarios, prohibiting the extraction of practical insights about their relevance to real-world domains. Our key insight is that an understanding of the inherent complexity of a social robot navigation scenario could help characterize the limitations of existing navigation algorithms and provide actionable directions for improvement. Through an exploration of recent literature, we identify a series of factors contributing to the complexity of a scenario, disambiguating between contextual and robot-related ones. We then conduct a simulation study investigating how manipulations of contextual factors impact the performance of a variety of navigation algorithms. We find that dense and narrow environments correlate most strongly with performance drops, while the heterogeneity of agent policies and directionality of interactions have a less pronounced effect. This motivates a shift towards developing and testing algorithms under higher-complexity settings.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt14_06">
             15:40-15:45, Paper WeDT14.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1435" name="modify5032" onclick="modify(5032,1435)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5032'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Domain Randomization for Learning to Navigate in Human Environments (Resubmission)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#293584" title="Click to go to the Author Index">
             Ah Sen, Nick
            </a>
           </td>
           <td class="r">
            Monash University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#108781" title="Click to go to the Author Index">
             Kulic, Dana
            </a>
           </td>
           <td class="r">
            Monash University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#238637" title="Click to go to the Author Index">
             Carreno, Pamela
            </a>
           </td>
           <td class="r">
            Monash University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5032" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In shared human-robot environments, effective navigation requires robots to adapt to various pedestrian behaviors encountered in the real world. Most existing deep reinforcement learning algorithms for human-aware robot navigation typically assume that pedestrians adhere to a single walking behavior during training, limiting their practicality/performance in scenarios where pedestrians exhibit various types of behavior. In this work, we propose to enhance the generalization capabilities of human-aware robot navigation by employing Domain Randomization (DR) techniques to train navigation policies on a diverse range of simulated pedestrian behaviors with the hope of better generalization to the real world. We evaluate the effectiveness of our method by comparing the generalization capabilities of a robot navigation policy trained with and without DR, both in simulations and through a real-user study, focusing on adaptability to different pedestrian behaviors, performance in novel environments, and users' perceived comfort, sociability and naturalness. Our findings reveal that the use of DR significantly enhances the robot's social compliance in both simulated and real-life contexts.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt15">
             <b>
              WeDT15
             </b>
             Regular Session, 403
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1436" name="modifyWeDT15" onclick="modsession(281,1436)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt15" title="Click to go to the Program at a Glance">
             <b>
              Manipulation Planning
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#226518" title="Click to go to the Author Index">
             Cheng, Xianyi
            </a>
           </td>
           <td class="r">
            Duke University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#217652" title="Click to go to the Author Index">
             Shirai, Yuki
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Research Laboratories
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt15_01">
             15:15-15:20, Paper WeDT15.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1437" name="modify76" onclick="modify(76,1437)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('76'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Characterizing Manipulation Robustness through Energy Margin and Caging Analysis
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#359009" title="Click to go to the Author Index">
             Dong, Yifei
            </a>
           </td>
           <td class="r">
            KTH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#226518" title="Click to go to the Author Index">
             Cheng, Xianyi
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#159924" title="Click to go to the Author Index">
             Pokorny, Florian T.
            </a>
           </td>
           <td class="r">
            KTH Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab76" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             To develop robust manipulation policies, quantifying robustness is essential. Evaluating robustness in general dexterous manipulation, nonetheless, poses significant challenges due to complex hybrid dynamics, combinatorial explosion of possible contact interactions, global geometry, etc. This paper introduces ``caging in motion'', an approach for analyzing manipulation robustness through energy margins and caging-based analysis. Our method assesses manipulation robustness by measuring the energy margin to failure and extends traditional caging concepts for a global analysis of dynamic manipulation. This global analysis is facilitated by a kinodynamic planning framework that naturally integrates global geometry, contact changes, and robot compliance. We validate the effectiveness of our approach in the simulation and real-world experiments of multiple dynamic manipulation scenarios, highlighting its potential to predict manipulation success and robustness.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt15_02">
             15:20-15:25, Paper WeDT15.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1438" name="modify1370" onclick="modify(1370,1438)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1370'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enhancing Adaptivity of Two-Fingered Object Reorientation Using Tactile-Based Online Optimization of Deconstructed Actions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#356079" title="Click to go to the Author Index">
             Huang, Qiyin
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102841" title="Click to go to the Author Index">
             Li, Tiemin
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203704" title="Click to go to the Author Index">
             Jiang, Yao
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1370" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Object reorientation is a critical task for robotic grippers, especially when manipulating objects within constrained environments. The task poses significant challenges for motion planning due to the high-dimensional output actions with the complex input information, including unknown object properties and nonlinear contact forces. Traditional approaches simplify the problem by reducing degrees of freedom, limiting contact forms, or acquiring environment/object information in advance—significantly compromising adaptability. To address these challenges, we deconstruct the complex output actions into three fundamental types based on tactile sensing: task-oriented actions, constraint-oriented actions, and coordinating actions. These actions are then optimized online using gradient optimization to enhance adaptability. Key contributions include simplifying contact state perception, decomposing complex gripper actions, and enabling online action optimization for handling unknown objects or environmental constraints. Experimental results demonstrate that the proposed method is effective across a range of everyday objects, regardless of environmental contact. Additionally, the method exhibits robust performance even in the presence of unknown contacts and nonlinear external disturbances.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt15_03">
             15:25-15:30, Paper WeDT15.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1439" name="modify1526" onclick="modify(1526,1439)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1526'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Full-Cycle Assembly Operation: From Digital Planning to Trajectory Execution Using a Robotic Arm
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378288" title="Click to go to the Author Index">
             Livnat, Dror
            </a>
           </td>
           <td class="r">
            Tel Aviv University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411405" title="Click to go to the Author Index">
             Lavi, Yuval
            </a>
           </td>
           <td class="r">
            Tel Aviv University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107192" title="Click to go to the Author Index">
             Halperin, Dan
            </a>
           </td>
           <td class="r">
            Tel Aviv University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1526" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present an end-to-end framework for planning tight assembly operations, where the input is a set of digital models, and the output is a full execution plan for a physical robotic arm, including the trajectory placement and the grasping. The framework builds on our earlier results on tight assembly planning for free-flying objects and includes the following novel components: (i) the framework itself together with physical demonstrations, (ii) trajectory placement based on novel dynamic pathwise IK and (iii) post processing of the free-flying paths to relax the tightness and smooth the path. The framework provides guarantees as to the quality of the outcome trajectory. For each component we provide the algorithmic details and a full opensource software package for reproducing the process. Lastly, we demonstrate the framework with tight and challenging assembly problems (as well as puzzles, which are planned to be hard to assemble), using a UR5e robotic arm in the real world and in simulation. See the figure at the top for a physical UR5e assembling the alpha-z puzzle (known to be considerably more complicated to assemble than the celebrated alpha puzzle). Full video clips of all the assembly demonstrations together with our open source software are available at our project page: https://tau-cgl.github.io/Full-Cycle-Assembly-Operation/
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt15_04">
             15:30-15:35, Paper WeDT15.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1440" name="modify3217" onclick="modify(3217,1440)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3217'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robust Nonprehensile Dynamic Object Transportation: A Closed-Loop Sensitivity Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#292477" title="Click to go to the Author Index">
             Teimoorzadeh, Ainoor
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#277746" title="Click to go to the Author Index">
             Pupa, Andrea
            </a>
           </td>
           <td class="r">
            University of Modena and Reggio Emilia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#196606" title="Click to go to the Author Index">
             Selvaggio, Mario
            </a>
           </td>
           <td class="r">
            Università Degli Studi Di Napoli Federico II
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#108317" title="Click to go to the Author Index">
             Haddadin, Sami
            </a>
           </td>
           <td class="r">
            Mohamed Bin Zayed University of Artificial Intelligence
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3217" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning_under_uncertainty" title="Click to go to the Keyword Index">
               Planning under Uncertainty
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we propose a closed-loop sensitivity-based approach to enhance the robustness of robotic nonprehensile dynamic manipulation tasks.The proposed method aims at fulfilling the transportation of an object, that is free to move on a tray-shaped robot end–effector, in face of not perfectly known nominal dynamic parameters. The approach is built up on taking the parameterized reference trajectory to be tracked as the optimization variable minimizing a norm of the system closed-loop sensitivity. The resulting optimal reference trajectory is inherently more robust to the parametric variations of object dynamic properties compared to a baseline straight trajectory execution. The tracking performance is assessed and validated along hardware experiments and an extensive simulation campaign assessing the superior robustness of our approach.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt15_05">
             15:35-15:40, Paper WeDT15.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1441" name="modify3698" onclick="modify(3698,1441)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3698'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hierarchical Contact-Rich Trajectory Optimization for Multi-Modal Manipulation Using Tight Convex Relaxations
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#217652" title="Click to go to the Author Index">
             Shirai, Yuki
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Research Laboratories
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#246388" title="Click to go to the Author Index">
             Raghunathan, Arvind
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Research Laboratories
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#192415" title="Click to go to the Author Index">
             Jha, Devesh
            </a>
           </td>
           <td class="r">
            Mitsubishi Electric Research Laboratories
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3698" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_contact_whole_body_motion_planning_and_control" title="Click to go to the Keyword Index">
               Multi-Contact Whole-Body Motion Planning and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Designing trajectories for manipulation through contact is challenging as it requires reasoning of object &amp; robot trajectories as well as complex contact sequences simultaneously. In this paper, we present a novel framework for simultaneously designing trajectories of robots, objects, and contacts efficiently for contact-rich manipulation. We propose a hierarchical optimization framework where Mixed-Integer Linear Program (MILP) selects optimal contacts between robot &amp; object using approximate dynamical constraints, and then a NonLinear Program (NLP) optimizes trajectory of the robot(s) and object considering full nonlinear constraints. We present a convex relaxation of bilinear constraints using binary encoding technique such that MILP can provide tighter solutions with better computational complexity. The proposed framework is evaluated on various manipulation tasks where it can reason about complex multi-contact interactions while providing computational advantages. We also demonstrate our framework in hardware experiments using a bimanual robot system.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt15_06">
             15:40-15:45, Paper WeDT15.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1442" name="modify5015" onclick="modify(5015,1442)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5015'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Constraining Gaussian Process Implicit Surfaces for Robot Manipulation Via Dataset Refinement
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#371882" title="Click to go to the Author Index">
             Kumar, Abhinav
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#237751" title="Click to go to the Author Index">
             Mitrano, Peter
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#113264" title="Click to go to the Author Index">
             Berenson, Dmitry
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5015" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Model-based control faces fundamental challenges in partially-observable environments due to unmodeled obstacles. We propose an online learning and optimization method to identify and avoid unobserved obstacles online. Our method, Constraint Obeying Gaussian Implicit Surfaces (COGIS), infers contact data using a combination of visual input and state tracking, informed by predictions from a nominal dynamics model. We then fit a Gaussian process implicit surface (GPIS) to these data and refine the dataset through a novel method of enforcing constraints on the estimated surface. This allows us to design a Model Predictive Control (MPC) method that leverages the obstacle estimate to complete multiple manipulation tasks. By modeling the environment instead of attempting to directly adapt the dynamics, our method succeeds at both low-dimensional peg-in-hole tasks and high-dimensional deformable object manipulation tasks. Our method succeeds in 10/10 trials vs 1/10 for a baseline on a real-world cable manipulation task under partial observability of the environment.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt16">
             <b>
              WeDT16
             </b>
             Regular Session, 404
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1443" name="modifyWeDT16" onclick="modsession(395,1443)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt16" title="Click to go to the Program at a Glance">
             <b>
              Optimization and Trajectory Planning
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#151054" title="Click to go to the Author Index">
             Figueroa, Nadia
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#232910" title="Click to go to the Author Index">
             Zinage, Vrushabh
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt16_01">
             15:15-15:20, Paper WeDT16.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1444" name="modify953" onclick="modify(953,1444)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('953'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Optimizing Complex Control Systems with Differentiable Simulators: A Hybrid Approach to Reinforcement Learning and Trajectory Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#312779" title="Click to go to the Author Index">
             Parag, Amit
            </a>
           </td>
           <td class="r">
            Sintef Ocean AS
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103132" title="Click to go to the Author Index">
             Mansard, Nicolas
            </a>
           </td>
           <td class="r">
            CNRS
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#204295" title="Click to go to the Author Index">
             Misimi, Ekrem
            </a>
           </td>
           <td class="r">
            SINTEF Ocean
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab953" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Deep reinforcement learning (RL) often relies on simulators as abstract oracles to model interactions within complex environments. While differentiable simulators have recently emerged for multi-body robotic systems, they remain underutilized, despite their potential to provide richer information. This underutilization, coupled with the high computational cost of exploration-exploitation in high-dimensional state spaces, limits the practical application of RL in the real-world. We propose a method that integrates learning with differentiable simulators to enhance the efficiency of exploration-exploitation. Our approach learns value functions, state trajectories, and control policies from locally optimal runs of a model-based trajectory optimizer. The learned value function acts as a proxy to shorten the preview horizon, while approximated state and control policies guide the trajectory optimization. We benchmark our algorithm on three classical control problems and a torque-controlled 7 degree-of-freedom robot manipulator arm, demonstrating faster convergence and a more efficient symbiotic relationship between learning and simulation for end-to-end training of complex, poly-articulated systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt16_02">
             15:20-15:25, Paper WeDT16.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1445" name="modify1240" onclick="modify(1240,1445)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1240'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              TransformerMPC: Accelerating Model Predictive Control Via Transformers
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#232910" title="Click to go to the Author Index">
             Zinage, Vrushabh
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420531" title="Click to go to the Author Index">
             Khalil, Ahmed
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#162425" title="Click to go to the Author Index">
             Bakolas, Efstathios
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1240" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we address the problem of reducing the computational burden of Model Predictive Control (MPC) for real-time robotic applications. We propose TransformerMPC, a method that enhances the computational efficiency of MPC algorithms by leveraging the attention mechanism in transformers for both online constraint removal and better warm start initialization. Specifically, TransformerMPC accelerates the computation of optimal control inputs by selecting only the active constraints to be included in the MPC problem, while simultaneously providing a warm start to the optimization process. This approach ensures that the original constraints are satisfied at optimality. TransformerMPC is designed to be seamlessly integrated with any solver, irrespective of its implementation. To guarantee constraint satisfaction after removing inactive constraints, we perform an offline verification to ensure that the optimal control inputs generated by the solver meet all constraints. The effectiveness of TransformerMPC is demonstrated through extensive numerical simulations on complex robotic systems, achieving up to 35x improvement in runtime without any loss in performance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt16_03">
             15:25-15:30, Paper WeDT16.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1446" name="modify3441" onclick="modify(3441,1446)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3441'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A New Semidefinite Relaxation for Linear and Piecewise Affine Optimal Control with Time Scaling
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#312680" title="Click to go to the Author Index">
             Yang, Lujie
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#193934" title="Click to go to the Author Index">
             Marcucci, Tobia
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425570" title="Click to go to the Author Index">
             Parrilo, Pablo
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105841" title="Click to go to the Author Index">
             Tedrake, Russ
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3441" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce a semidefinite relaxation for optimal control of linear systems with time scaling. These problems are inherently nonconvex, since the system dynamics involves bilinear products between the discretization time step and the system state and controls. The proposed relaxation is closely related to the standard second-order semidefinite relaxation for quadratic constraints, but we carefully select a subset of the possible bilinear terms and apply a change of variables to achieve empirically tight relaxations while keeping the computational load light. We further extend our method to handle piecewise-affine (PWA) systems by formulating the PWA optimal-control problem as a shortest-path problem in a graph of convex sets (GCS). In this GCS, different paths represent different mode sequences for the PWA system, and the convex sets model the relaxed dynamics within each mode. By combining a tight convex relaxation of the GCS problem with our semidefinite relaxation with time scaling, we can solve PWA optimal-control problems through a single semidefinite program.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt16_04">
             15:30-15:35, Paper WeDT16.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1447" name="modify3855" onclick="modify(3855,1447)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3855'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              C-Uniform Trajectory Sampling for Fast Motion Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354606" title="Click to go to the Author Index">
             Poyrazoglu, Oguzhan Goktug
            </a>
           </td>
           <td class="r">
            University of Minnesota
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425721" title="Click to go to the Author Index">
             Cao, Yukang
            </a>
           </td>
           <td class="r">
            University of Minnesota
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101719" title="Click to go to the Author Index">
             Isler, Volkan
            </a>
           </td>
           <td class="r">
            University of Minnesota
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3855" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We study the problem of sampling robot trajectories and introduce the notion of C-Uniformity. As opposed to the standard method of uniformly sampling control inputs (which lead to biased samples of the configuration space), C-Uniform trajectories are generated by control actions which lead to uniform sampling of the configuration space. After presenting an intuitive closed-form solution to generate C-Uniform trajectories for the 1D random-walker, we present a network flow based optimization method to precompute C-Uniform trajectories for general robot systems. We apply the notion of C-Uniformity to the design of Model Predictive Path Integral controllers. Through simulation experiments, we show that using C-Uniform trajectories significantly improves the performance of MPPI-style controllers, achieving up to 40% coverage performance gain compared to the best baseline. We demonstrate the practical applicability of our method with an implementation on a 1/10th scale racer.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt16_05">
             15:35-15:40, Paper WeDT16.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1448" name="modify4186" onclick="modify(4186,1448)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4186'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ADMM-MCBF-LCA: A Layered Control Architecture for Safe Real-Time Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#305233" title="Click to go to the Author Index">
             Srikanthan, Anusha
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#362593" title="Click to go to the Author Index">
             Xue, Yifan
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104342" title="Click to go to the Author Index">
             Kumar, Vijay
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#121906" title="Click to go to the Author Index">
             Matni, Nikolai
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#151054" title="Click to go to the Author Index">
             Figueroa, Nadia
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4186" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_control" title="Click to go to the Keyword Index">
               Integrated Planning and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We consider the problem of safe real-time navigation of a robot in a dynamic environment with moving obstacles of arbitrary smooth geometries and input saturation constraints. We assume that the robot detects and models nearby obstacle boundaries with a short-range sensor and that this detection is error-free. This problem presents three main challenges: i) input constraints, ii) safety, and iii) real-time computation. To tackle all three challenges, we present a layered control architecture (LCA) consisting of an offline path library generation layer, and an online path selection and safety layer. To overcome the limitations of reactive methods, our offline path library consists of feasible controllers, feedback gains, and reference trajectories. To handle computational burden and safety, we solve online path selection and generate safe inputs that run at 100 Hz. Through simulations on Gazebo and Fetch hardware in an indoor environment, we evaluate our approach against baselines that are layered, end-to-end, or reactive. Our experiments demonstrate that among all algorithms, only our proposed LCA is able to complete tasks such as reaching a goal, safely. When comparing metrics such as safety, input error, and success rate, we show that our approach generates safe and feasible inputs throughout the robot execution.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt16_06">
             15:40-15:45, Paper WeDT16.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1449" name="modify4976" onclick="modify(4976,1449)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4976'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Experimental Validation of Sensitivity-Aware Trajectory Planning for a Redundant Robotic Manipulator under Payload Uncertainty
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#340884" title="Click to go to the Author Index">
             Srour, Ali
            </a>
           </td>
           <td class="r">
            CNRS
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104988" title="Click to go to the Author Index">
             Franchi, Antonio
            </a>
           </td>
           <td class="r">
            University of Twente / Sapienza University of Rome
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103169" title="Click to go to the Author Index">
             Robuffo Giordano, Paolo
            </a>
           </td>
           <td class="r">
            Irisa Cnrs Umr6074
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#146784" title="Click to go to the Author Index">
             Cognetti, Marco
            </a>
           </td>
           <td class="r">
            LAAS-CNRS and Université Toulouse III - Paul Sabatier
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4976" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning_under_uncertainty" title="Click to go to the Keyword Index">
               Planning under Uncertainty
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we experimentally validate the recent concepts of closed-loop state and input sensitivity in the context of robust manipulation control for a robot manipulator. Our objective is to assess how optimizing trajectories with respect to sensitivity metrics can enhance the closed-loop system’s performance w.r.t. model uncertainties, such as those arising from payload variations during precise manipulation tasks. We conduct a series of experiments to validate our optimization approach across different trajectories, focusing primarily on evaluating the precision of the manipulator’s end-effector at critical moments where high accuracy is essential. Our findings offer valuable insights into improving the closed-loop robustness of the robot’s state and inputs against physical parametric uncertainties that could otherwise degrade the system performance.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt17">
             <b>
              WeDT17
             </b>
             Regular Session, 405
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1450" name="modifyWeDT17" onclick="modsession(557,1450)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt17" title="Click to go to the Program at a Glance">
             <b>
              Soft Robotics: Modeling, Control, and Learning
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#106951" title="Click to go to the Author Index">
             Zhang, Jianwei
            </a>
           </td>
           <td class="r">
            University of Hamburg
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#187232" title="Click to go to the Author Index">
             Sun, Ye
            </a>
           </td>
           <td class="r">
            University of Virginia
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt17_01">
             15:15-15:20, Paper WeDT17.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1451" name="modify420" onclick="modify(420,1451)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('420'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Composite Learning Neural Network Tracking Control of Articulated Soft Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#361076" title="Click to go to the Author Index">
             Zou, Zhigang
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#301088" title="Click to go to the Author Index">
             Li, Zhiwen
            </a>
           </td>
           <td class="r">
            Sun Yat-Set University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#220958" title="Click to go to the Author Index">
             Li, Weibing
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#181302" title="Click to go to the Author Index">
             Pan, Yongping
            </a>
           </td>
           <td class="r">
            Peng Cheng Laboratory
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab420" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#compliant_joints_and_mechanisms" title="Click to go to the Keyword Index">
               Compliant Joints and Mechanisms
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#neural_and_fuzzy_control" title="Click to go to the Keyword Index">
               Neural and Fuzzy Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Controlling articulated soft robots (ASRs) driven by variable stiffness actuators (VSAs) is challenging because they are highly nonlinear and difficult to model accurately. This paper proposes an efficient neural network (NN) learning control solution for ASRs driven by agonistic-antagonistic (AA)-VSAs to guarantee tracking performance without exact robot models. Composite learning resorts to memory regressor extension to enhance adaptive parameter estimation such that parameter convergence can be guaranteed without the stringent condition of persistent excitation. In the proposed method, an NN-based controller is constructed for the position tracking of AA-VSA- driven ASRs, and an NN weight update law based on composite learning is developed to enhance online modeling and control capabilities. Experiments are carried out on an ASR with three degrees of freedom and qbmove Advance actuators (a kind of AA-VSAs), which have validated the effectiveness and superiority of the proposed method in terms of modeling and tracking accuracy compared with existing control methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt17_02">
             15:20-15:25, Paper WeDT17.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1452" name="modify1677" onclick="modify(1677,1452)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1677'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Segment Soft Robot Control Via Deep Koopman-Based Model Predictive Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417337" title="Click to go to the Author Index">
             Lv, Lei
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#382123" title="Click to go to the Author Index">
             Liu, Lei
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417590" title="Click to go to the Author Index">
             Bao, Lei
            </a>
           </td>
           <td class="r">
            Beijing Soft Robot Tech Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#134089" title="Click to go to the Author Index">
             Sun, Fuchun
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417532" title="Click to go to the Author Index">
             Dong, Jiahong
            </a>
           </td>
           <td class="r">
            Tsinghua University Affiliated Beijing Tsinghua Changgung Hospit
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106951" title="Click to go to the Author Index">
             Zhang, Jianwei
            </a>
           </td>
           <td class="r">
            University of Hamburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417475" title="Click to go to the Author Index">
             Shan, Xuemei
            </a>
           </td>
           <td class="r">
            Beijing Soft Robot Tech Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#407379" title="Click to go to the Author Index">
             Sun, Kai
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#361289" title="Click to go to the Author Index">
             Huang, Hao
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#289522" title="Click to go to the Author Index">
             Luo, Yu
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1677" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft robots, compared to regular rigid robots, as their multiple segments with soft materials bring flexibility and compliance, have the advantages of safe interaction and dexterous operation in the environment. However, due to its characteristics of high dimensional, nonlinearity, time-varying nature, and infinite degree of freedom, it has been challenges in achieving precise and dynamic control such as trajectory tracking and position reaching. To address these challenges, we propose a framework of Deep Koopman-based Model Predictive Control (DK-MPC) for handling multi-segment soft robots. We first employ a deep learning approach with sampling data to approximate the Koopman operator, which therefore linearizes the high-dimensional nonlinear dynamics of the soft robots into a finite-dimensional linear representation. Secondly, this linearized model is utilized within a model predictive control framework to compute optimal control inputs that minimize the tracking error between the desired and actual state trajectories. The real-world experiments on the soft robot “Chordata” demonstrate that DK-MPC could achieve high-precision control, showing the potential of DK-MPC for future applications to soft robots. More visualization results can be found at https://pinkmoon-io.github.io/DKMPC/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt17_03">
             15:25-15:30, Paper WeDT17.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1453" name="modify1973" onclick="modify(1973,1453)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1973'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Physics-Informed Split Koopman Operators for Data-Efficient Soft Robotic Simulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422869" title="Click to go to the Author Index">
             Ristich, Eron
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#290889" title="Click to go to the Author Index">
             Zhang, Lei
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#206066" title="Click to go to the Author Index">
             Ren, Yi
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#227071" title="Click to go to the Author Index">
             Sun, Jiefeng
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1973" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Koopman operator theory provides a powerful data-driven technique for modeling nonlinear dynamical systems in a linear framework, in comparison to computationally expensive and highly nonlinear physics-based simulations. However, Koopman operator-based models for soft robots are very high dimensional and require considerable amounts of data to properly resolve. Inspired by physics-informed techniques from machine learning, we present a novel physics-informed Koopman operator identification method that improves simulation accuracy for small dataset sizes. Through Strang splitting, the method takes advantage of both continuous and discrete Koopman operator approximation to obtain information both from trajectory and phase space data. The method is validated on a tendon-driven soft robotic arm, showing orders of magnitude improvement over standard methods in terms of the shape error. We envision this method can significantly reduce the data requirement of Koopman operators for systems with partially known physical models, and thus reduce the cost of obtaining data. More info: https://sunrobotics.lab.asu.edu/blog/2024/ristich-icra-2025/
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt17_04">
             15:30-15:35, Paper WeDT17.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1454" name="modify2798" onclick="modify(2798,1454)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2798'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robust Swimming Controller for Soft Robots Via Drop-Out Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#278301" title="Click to go to the Author Index">
             Monica, Josephine
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102926" title="Click to go to the Author Index">
             Campbell, Mark
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2798" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A novel framework for training a robotic fish to learn how to swim, even in the presence of degradations or failures in actuators is developed. Robotic underwater robots, particularly soft fish-inspired designs have gained significant attention due to their distinct benefits, including superior maneuverability, energy efficiency, versatile applications, and seamless integration with marine environments. However, their material properties and actuators can degrade, leading to pre-mature system failures. In this paper, we introduce the concept of actuator drop-out during training, to enable the robot to learn how to swim even when one or more actuators are degraded or non-functional. A Soft Actor-Critic Deep Reinforcement Learning architecture is used to learn a policy, with actuator degradations/failures introduced during training. A four actuator koi fish is modeled and simulated using the FishGym environment. Navigation-based validation tests show little degradation with one actuator failure, and much more robust swimming behaviors and performance compared to training with no failures, even when two or three actuators fail. These results will improve long-term operational reliability, ensuring robot fish functionality even in challenging underwater conditions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt17_05">
             15:35-15:40, Paper WeDT17.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1455" name="modify4397" onclick="modify(4397,1455)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4397'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Optimal Gait Control for a Tendon-Driven Soft Quadruped Robot by Model-Based Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#382946" title="Click to go to the Author Index">
             Niu, Xuezhi
            </a>
           </td>
           <td class="r">
            Uppsala University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#318667" title="Click to go to the Author Index">
             Tan, Kaige
            </a>
           </td>
           <td class="r">
            KTH Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#370521" title="Click to go to the Author Index">
             Gurdur Broo, Didem
            </a>
           </td>
           <td class="r">
            Uppsala University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#148352" title="Click to go to the Author Index">
             Feng, Lei
            </a>
           </td>
           <td class="r">
            KTH Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4397" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_sensors_and_actuators" title="Click to go to the Keyword Index">
               Soft Sensors and Actuators
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study presents an innovative approach to optimal gait control for a soft quadruped robot enabled by four compressible tendon-driven soft actuators. Soft quadruped robots, compared to their rigid counterparts, are widely recognized for offering enhanced safety, lower weight, and simpler fabrication and control mechanisms. However, their highly deformable structure introduces nonlinear dynamics, making precise gait locomotion control complex. To solve this problem, we propose a novel model-based reinforcement learning (MBRL) method. The study employs a multi-stage approach, including state space restriction, data-driven surrogate model training, and MBRL development. Compared to benchmark methods, the proposed approach significantly improves the efficiency and performance of gait control policies. The developed policy is both robust and adaptable to the robot's deformable morphology. The study concludes by highlighting the practical applicability of these findings in real-world scenarios.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt17_06">
             15:40-15:45, Paper WeDT17.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1456" name="modify4898" onclick="modify(4898,1456)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4898'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Physics-Guided Deep Learning Enabled Surrogate Modeling for Pneumatic Soft Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#391595" title="Click to go to the Author Index">
             Beaber, Sameh I.
            </a>
           </td>
           <td class="r">
            University of Virginia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#383364" title="Click to go to the Author Index">
             Liu, Zhen
            </a>
           </td>
           <td class="r">
            University of Virginia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#187232" title="Click to go to the Author Index">
             Sun, Ye
            </a>
           </td>
           <td class="r">
            University of Virginia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4898" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft robots, formulated by soft and compliant materials, have grown significantly in recent years toward safe and adaptable operations and interactions with dynamic environments. Modeling the complex, nonlinear behaviors and controlling the deformable structures of soft robots present challenges. This study aims to establish a physics-guided deep learning (PGDL) computational framework that integrates physical models into deep learning framework as surrogate models for soft robots. Once trained, these models can replace computationally expensive numerical simulations to shorten the computation time and enable real-time control. This PGDL framework is among the first to integrate first principle physics of soft robots into deep learning toward highly accurate yet computationally affordable models for soft robot modeling and control. The proposed framework has been implemented and validated using three different pneumatic soft fingers with different behaviors and geometries, along with two training and testing approaches, to demonstrate its effectiveness and generalizability. The results showed that the mean square error (MSE) of predicted deformed curvature and the maximum and minimum deformation at various loading conditions were as low as 10−4 mm2. The proposed PGDL framework is constructed from first principle physics and intrinsically can be applicable to various conditions by carefully considering the governing equations, auxiliary equations, and the corresponding boundary and initial conditions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt17_07">
             15:45-15:50, Paper WeDT17.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1457" name="modify4914" onclick="modify(4914,1457)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4914'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning-Based Nonlinear Model Predictive Control of Articulated Soft Robots Using Recurrent Neural Networks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#412407" title="Click to go to the Author Index">
             Schaefke, Hendrik
            </a>
           </td>
           <td class="r">
            Leibniz University Hannover
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#289491" title="Click to go to the Author Index">
             Habich, Tim-Lukas
            </a>
           </td>
           <td class="r">
            Leibniz University Hannover
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#412408" title="Click to go to the Author Index">
             Muhmann, Christian
            </a>
           </td>
           <td class="r">
            Leibniz University Hannover
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#266600" title="Click to go to the Author Index">
             Ehlers, Simon F. G.
            </a>
           </td>
           <td class="r">
            Leibniz University Hannover
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#196337" title="Click to go to the Author Index">
             Seel, Thomas
            </a>
           </td>
           <td class="r">
            Leibniz Universität Hannover
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#188177" title="Click to go to the Author Index">
             Schappler, Moritz
            </a>
           </td>
           <td class="r">
            Institute of Mechatronic Systems, Leibniz Universitaet Hannover
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4914" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Soft robots pose difficulties in terms of control, requiring novel strategies to effectively manipulate their compliant structures. Model-based approaches face challenges due to the high dimensionality and nonlinearities such as hysteresis effects. In contrast, learning-based approaches provide nonlinear models of different soft robots based only on measured data. In this paper, recurrent neural networks (RNNs) predict the behavior of an articulated soft robot (ASR) with five degrees of freedom (DoF). RNNs based on gated recurrent units (GRUs) are compared to the more commonly used long short-term memory (LSTM) networks and show better accuracy. The recurrence enables to capture hysteresis effects that are inherent in soft robots due to viscoelasticity or friction but cannot be captured by simple feedforward networks. The data-driven model is used within a nonlinear model predictive control (NMPC), whereby the correct handling of the RNN's hidden states is focused. A training approach is presented that allows measured values to be utilized in each control cycle. This enables accurate predictions of short horizons based on sensor data, which is crucial for closed-loop NMPC. The proposed learning-based NMPC enables trajectory tracking with an average error of 1.2 deg in experiments with the pneumatic five-DoF ASR.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt18">
             <b>
              WeDT18
             </b>
             Regular Session, 406
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1458" name="modifyWeDT18" onclick="modsession(577,1458)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt18" title="Click to go to the Program at a Glance">
             <b>
              Surgical Robotics: Steerable Catheters/Needles 1
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#179020" title="Click to go to the Author Index">
             Khadem, Mohsen
            </a>
           </td>
           <td class="r">
            University of Edinburgh
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#211411" title="Click to go to the Author Index">
             Chitalia, Yash
            </a>
           </td>
           <td class="r">
            University of Louisville
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt18_01">
             15:15-15:20, Paper WeDT18.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1459" name="modify1" onclick="modify(1,1459)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Towards a Tendon-Assisted Magnetically Steered (TAMS) Robotic Stylet for Brachytherapy
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#275424" title="Click to go to the Author Index">
             Kheradmand, Pejman
            </a>
           </td>
           <td class="r">
            University of Louisville
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#358857" title="Click to go to the Author Index">
             Moradkhani, Behnam
            </a>
           </td>
           <td class="r">
            University of Louisville
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#380069" title="Click to go to the Author Index">
             Jella, Harshith
            </a>
           </td>
           <td class="r">
            University of Louisville
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378048" title="Click to go to the Author Index">
             Sowards, Keith
            </a>
           </td>
           <td class="r">
            Department of Radiation Oncology, University of Louisville
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#377879" title="Click to go to the Author Index">
             Silva, Scott
            </a>
           </td>
           <td class="r">
            University of Louisville
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#211411" title="Click to go to the Author Index">
             Chitalia, Yash
            </a>
           </td>
           <td class="r">
            University of Louisville
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Interstitial brachytherapy requires up to 20 straight needles to surround and irradiate deep-seated tumors, but may offer sub-optimal radiation dosage in cases of advanced cancers. A steerable stylet can be used to guide the needle within the tissue, improving procedure accuracy and reducing the number of needles required for each operation. This work introduces the design of a novel tendon-assisted magnetically steered (TAMS) robotic stylet to steer commercially available brachytherapy needles. The dual-actuation modality (magnetic and tendon-driven) allows for increased bending compliance while retaining axial rigidity at extremely small diameters (OD: 1.4 mm), key properties for steering hollow needles from within their lumen. We also develop a two-tube Cosserat rod model that estimates the behavior of the TAMS robot and needle assembly under actuation from tendons, external magnetic fields, and finally combined magnet+tendon forces. We validate our model in free space and demonstrate the capability of the TAMS robot and dual-actuation modalities to steer brachytherapy needles to high curvatures inside phantom tissue.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt18_02">
             15:20-15:25, Paper WeDT18.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1460" name="modify580" onclick="modify(580,1460)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('580'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              VascularPilot3D: Toward a 3D Fully Autonomous Navigation for Endovascular Robotics
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#293703" title="Click to go to the Author Index">
             Song, Jingwei
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#362978" title="Click to go to the Author Index">
             Yang, Keke
            </a>
           </td>
           <td class="r">
            United Imaging
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418046" title="Click to go to the Author Index">
             Chen, Han
            </a>
           </td>
           <td class="r">
            Shanghai United Imaging Medical High-Tech Research Institute Co
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418018" title="Click to go to the Author Index">
             Liu, Jiayi
            </a>
           </td>
           <td class="r">
            United Imaging
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418008" title="Click to go to the Author Index">
             Gu, Yinan
            </a>
           </td>
           <td class="r">
            Shanghai United Imaging Healthcare High Tech Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418024" title="Click to go to the Author Index">
             Hui, Qianxin
            </a>
           </td>
           <td class="r">
            Shanghai United Imaging Healthcare Advance Technology Research I
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418072" title="Click to go to the Author Index">
             Huang, Yanqi
            </a>
           </td>
           <td class="r">
            Shanghai United Imaging Healthcare Co., LTD
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#362989" title="Click to go to the Author Index">
             Li, Meng
            </a>
           </td>
           <td class="r">
            Shanghai United Imaging Healthcare Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#362991" title="Click to go to the Author Index">
             Zhang, Zheng
            </a>
           </td>
           <td class="r">
            1. the Institute of Medical Imaging Technology, School of Biomed
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#363083" title="Click to go to the Author Index">
             Cao, Tuoyu
            </a>
           </td>
           <td class="r">
            United Imaging Healthcare
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#131371" title="Click to go to the Author Index">
             Ghaffari, Maani
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab580" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This research reports VascularPilot3D, the first 3D fully autonomous endovascular robot navigation system. As an exploration toward autonomous guidewire navigation, VascularPilot3D is developed as a complete navigation system based on intra-operative imaging systems (fluoroscopic X-ray in this study) and typical endovascular robots. VascularPilot3D adopts previously researched fast 3D-2D vessel registration algorithms and guidewire segmentation methods as its perception modules. We additionally propose three modules: a topology-constrained 2D-3D instrument end-point lifting method, a tree-based fast path planning algorithm, and a prior-free endovascular navigation strategy. VascularPilot3D is compatible with most mainstream endovascular robots. Ex-vivo experiments validate that VascularPilot3D achieves 100% success rate among 25 trials. It reduces the human surgeon's overall control loops by 18.38%. VascularPilot3D is promising for general clinical autonomous endovascular navigation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt18_03">
             15:25-15:30, Paper WeDT18.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1461" name="modify1554" onclick="modify(1554,1461)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1554'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Weakly-Supervised Learning Via Multi-Lateral Decoder Branching for Tool Segmentation in Robot-Assisted Cardiovascular Catheterization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#200378" title="Click to go to the Author Index">
             Omisore, Olatunji Mumini
            </a>
           </td>
           <td class="r">
            Shenzhen Institute of Advanced Technology, Chinese Academy of Sc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#342377" title="Click to go to the Author Index">
             Akinyemi, Toluwanimi
            </a>
           </td>
           <td class="r">
            Shenzhen Institute of Advanced Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#171078" title="Click to go to the Author Index">
             Nguyen, Anh
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#220193" title="Click to go to the Author Index">
             Wang, Lei
            </a>
           </td>
           <td class="r">
            Shenzhen Institutes of Advanced Technology, Chinese Academy of S
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1554" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robot-assisted catheterization has garnered a good attention for its potentials in treating cardiovascular diseases. However, advancing surgeon-robot collaboration still requires further research, particularly on task-specific automation. For instance, automated tool segmentation can assist surgeons in visualizing and tracking endovascular tools during procedures. While learning-based models have demonstrated state-of-the- art segmentation performances, generating ground-truth labels for fully-supervised methods is labor-intensive, time consuming, and costly. In this study, we developed a weakly-supervised learning method that is based on multi-lateral pseudo labeling for tool segmentation in cardiovascular angiogram datasets. The method utilizes a modified U-Net architecture featuring one encoder and multiple laterally branched decoders. The decoders generate diverse pseudo labels under different perturbations to augment the available partial annotation for model training. A mixed loss function with shared consistency was adapted for this purpose. The weakly-supervised model was trained end-to-end and validated using partially annotated angiogram data from three cardiovascular catheterization procedures. Validation results show that the weakly-supervised model could perform closer to fully-supervised models. Furthermore, the proposed multi-lateral approach outperforms three well known weakly- supervised learning methods, offering the highest segmentation performance across the three angiogram datasets. Numerous ablation studies confirmed the model’s consistent performance under different settings. Finally, the model was applied for tool segmentation in a robot-assisted catheterization experiments. The model enhanced visualization with high connectivity indices for guidewire and catheter, and a mean segmentation time of 35.26ms per frame. This study provides a fast, stable, and less expensive method for tool segmentation and visualization in robotic catheterization.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt18_04">
             15:30-15:35, Paper WeDT18.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1462" name="modify3603" onclick="modify(3603,1462)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3603'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Towards Evaluating the User Comfort and Experience of a Novel Steerable Drilling Robotic System in Pedicle Screw Fixation Procedures: A User Study
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309709" title="Click to go to the Author Index">
             Sharma, Susheela
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#325082" title="Click to go to the Author Index">
             Racz, Frigyes Samuel
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#345756" title="Click to go to the Author Index">
             Go, Sarah
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#345778" title="Click to go to the Author Index">
             Kapuria, Siddhartha
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#380635" title="Click to go to the Author Index">
             Rezayof, Omid
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#310690" title="Click to go to the Author Index">
             Amadio, Jordan P.
            </a>
           </td>
           <td class="r">
            University of Texas Dell Medical School
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#179020" title="Click to go to the Author Index">
             Khadem, Mohsen
            </a>
           </td>
           <td class="r">
            University of Edinburgh
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105019" title="Click to go to the Author Index">
             Millán, José del R.
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#190490" title="Click to go to the Author Index">
             Alambeigi, Farshid
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3603" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Aiming at developing a safe, intuitive, and collaborative steerable drilling robotic system for pedicle screw fixation procedures, in this paper, we leverage our recently developed steerable drilling robotic framework, and developed a collaborative drilling mode to control this system. In this control mode, first a user positions a concentric tube steerable drilling robot (CT-SDR) in the workspace and aligns it based on a pre-planned trajectory. Next, the CT-SDR is directly controlled by the user through an admittance mode to perform a drilling procedure and creating a J-shape tunnel. To evaluate the user comfort and intuitiveness of the drilling procedure using this system and the proposed control interface, we performed a user study with 11 subjects, who had no prior experience in using this system. The results of this study were analyzed using various qualitative and quantitative metrics.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt18_05">
             15:35-15:40, Paper WeDT18.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1463" name="modify4406" onclick="modify(4406,1463)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4406'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Minimally Invasive Endotracheal Inside-Out Flexible Needle Driving System towards Microendoscope-Guided Robotic Tracheostomy
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426645" title="Click to go to the Author Index">
             Lin, Botao
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#246849" title="Click to go to the Author Index">
             Yuan, Sishen
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351235" title="Click to go to the Author Index">
             Zhang, Tinghua
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#370759" title="Click to go to the Author Index">
             Zhang, Tao
            </a>
           </td>
           <td class="r">
            Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#376122" title="Click to go to the Author Index">
             Hao, Ruoyi
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#345751" title="Click to go to the Author Index">
             Yuan, Wu
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#179144" title="Click to go to the Author Index">
             Lim, Chwee Ming
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106795" title="Click to go to the Author Index">
             Ren, Hongliang
            </a>
           </td>
           <td class="r">
            Chinese Univ Hong Kong (CUHK) &amp; National Univ Singapore(NUS)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4406" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Open tracheostomy (OT) is considered the traditional way and golden standard for treating airway obstruction patients. However, OT has many unavoidable drawbacks, including strict performing scenarios, significant scarring, and the risk of surgeon infection. Percutaneous dilation tracheostomy (PDT) emerges, with advantages including a lower cost, smaller scarring, and better protection of surgeons from inflecting by aerosol. However, the outside-in puncture manner of PDT has a risk of piercing the post-tracheal wall and the esophagus with uncontrolled force. Additionally, locating tracheal rings and determining the puncture site externally can be challenging for certain patients, such as those who are obese or have undergone neck surgery, while this procedure typically relies on palpation and the surgeon's expertise. Hence, to improve the safety and simplicity of tracheostomy, a minimally-invasive endotracheal inside-out flexible needle-driving system towards microendoscope-guided robotic tracheostomy (MERT) has been proposed in this paper. Guided by an optical coherence tomography (OCT) probe and a microendoscope, the robot inserts into the trachea and performs an inside-out puncture using a flexible needle. The robot can work through a standard endotracheal tube (ETT), and the puncture direction of the flexible needle is variable. Kinematics and statics models of the flexible needle have been derived, and the minimum position errors generated in the kinematics and statics validation experiments are 0.57 pm 0.21 mm and 0.27 pm 0.21 mm. Finally, a porcine trachea puncture experiment is carried out, and the feasibility of the proposed system is verified.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt18_06">
             15:40-15:45, Paper WeDT18.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1464" name="modify4926" onclick="modify(4926,1464)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4926'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Comparison of Classical, Neural Network and Hybrid Models for Hysteretic Single-Tendon Catheter Kinematics
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#384715" title="Click to go to the Author Index">
             Wang, Yuan
            </a>
           </td>
           <td class="r">
            Boston Children's Hospital, Harvard Medical School
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101790" title="Click to go to the Author Index">
             Dupont, Pierre
            </a>
           </td>
           <td class="r">
            Children's Hospital Boston, Harvard Medical School
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4926" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             While robotic control of catheter motion can improve tip positioning accuracy, hysteresis arising from tendon friction and flexural deformation degrades kinematic modeling accuracy. In this paper, we compare the capabilities of three types of models for representing the forward and inverse kinematic maps of a clinical single-tendon cardiac catheter. Classical hysteresis models, neural networks and hybrid combinations of the two are included. Our results show that modeling accuracy is best when models are trained using motions corresponding to the anticipated clinical motions. For sinusoidal motions, recurrent neural network models provide the best performance. For point-to-point motions, however, a simple backlash model can provide comparable performance to a recurrent neural network.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt19">
             <b>
              WeDT19
             </b>
             Regular Session, 407
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1465" name="modifyWeDT19" onclick="modsession(383,1465)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt19" title="Click to go to the Program at a Glance">
             <b>
              Novel Methods for Mapping and Localization
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#107504" title="Click to go to the Author Index">
             Paley, Derek
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#126962" title="Click to go to the Author Index">
             Kim, Ayoung
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt19_01">
             15:15-15:20, Paper WeDT19.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1466" name="modify11" onclick="modify(11,1466)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('11'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Fieldscale: Locality-Aware Field-Based Adaptive Rescaling for Thermal Infrared Image
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#257470" title="Click to go to the Author Index">
             Gil, Hyeonjae
            </a>
           </td>
           <td class="r">
            SNU
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#226880" title="Click to go to the Author Index">
             Jeon, Myung-Hwan
            </a>
           </td>
           <td class="r">
            UIUC
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#126962" title="Click to go to the Author Index">
             Kim, Ayoung
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab11" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Thermal infrared (TIR) cameras are emerging as promising sensors in safety-related fields due to their robustness against external illumination. However, RAW TIR image has 14 bits of pixel depth and needs to be rescaled into 8 bits for general applications. Previous works utilize a global 1D look-up table to compute pixel-wise gain solely based on its intensity, which degrades image quality by failing to consider the local nature of the heat. We propose Fieldscale, a rescaling based on locality-aware 2D fields where both the intensity value and spatial context of each pixel within an image are embedded. It can adaptively determine the pixel gain for each region and produce spatially consistent 8-bit rescaled images with minimal information loss and high visibility. Consistent performance improvement on image quality assessment and two other downstream tasks support the effectiveness and usability of Fieldscale. All the codes are publicly opened to facilitate research advancements in this field. https://github.com/hyeonjaegil/fieldscale
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt19_02">
             15:20-15:25, Paper WeDT19.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1467" name="modify393" onclick="modify(393,1467)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('393'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Evaluating Global Geo-Alignment for Precision Learned Autonomous Vehicle Localization Using Aerial Data
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#196827" title="Click to go to the Author Index">
             Yang, Yi
            </a>
           </td>
           <td class="r">
            Nuro Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#257371" title="Click to go to the Author Index">
             Zhao, Xuran
            </a>
           </td>
           <td class="r">
            Nuro
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#383431" title="Click to go to the Author Index">
             Zhao, Haicheng Charles
            </a>
           </td>
           <td class="r">
            Nuro
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416580" title="Click to go to the Author Index">
             Yuan, Shumin
            </a>
           </td>
           <td class="r">
            Nuro AI
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#278471" title="Click to go to the Author Index">
             Bateman, Samuel
            </a>
           </td>
           <td class="r">
            Nuro
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#179401" title="Click to go to the Author Index">
             Huang, Tiffany A.
            </a>
           </td>
           <td class="r">
            Mercedes-Benz Research &amp; Development North America
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#135568" title="Click to go to the Author Index">
             Beall, Chris
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#130517" title="Click to go to the Author Index">
             Maddern, Will
            </a>
           </td>
           <td class="r">
            Nuro
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab393" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recently there has been growing interest in the use of aerial and satellite map data for autonomous vehicles, primarily due to its potential for significant cost reduction and enhanced scalability. Despite the advantages, aerial data also comes with challenges such as a sensor-modality gap and a viewpoint difference gap. Learned localization methods have shown promise for overcoming these challenges to provide precise metric localization for autonomous vehicles. Most learned localization methods rely on coarsely aligned ground truth, or implicit consistency-based methods to learn the localization task – however, in this paper we find that improving the alignment between aerial data and autonomous vehicle sensor data at training time is critical to the performance of a learning-based localization system. We compare two data alignment methods using a factor graph framework and, using these methods, we then evaluate the effects of closely aligned ground truth on learned localization accuracy through ablation studies. Finally, we evaluate a learned localization system using the data alignment methods on a comprehensive (1600km) autonomous vehicle dataset and demonstrate localization error below 0.3m and 0.5◦ sufficient for autonomous vehicle applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt19_03">
             15:25-15:30, Paper WeDT19.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1468" name="modify2928" onclick="modify(2928,1468)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2928'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Under Pressure: Altimeter-Aided ICP for 3D Maps Consistency
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339072" title="Click to go to the Author Index">
             Dubois, William
            </a>
           </td>
           <td class="r">
            Université Laval
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424624" title="Click to go to the Author Index">
             Samson, Nicolas
            </a>
           </td>
           <td class="r">
            Université Laval
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#355181" title="Click to go to the Author Index">
             Daum, Effie
            </a>
           </td>
           <td class="r">
            Université Laval
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#236390" title="Click to go to the Author Index">
             Laconte, Johann
            </a>
           </td>
           <td class="r">
            French National Research Institute for Agriculture, Food and The
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#123399" title="Click to go to the Author Index">
             Pomerleau, Francois
            </a>
           </td>
           <td class="r">
            Université Laval
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2928" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose a novel method to enhance the accuracy of the Iterative Closest Point (ICP) algorithm by integrating altitude constraints from a barometric pressure sensor. While ICP is widely used in mobile robotics for Simultaneous Localization and Mapping (SLAM), it is susceptible to drift, especially in underconstrained environments such as vertical shafts. To address this issue, we propose to augment ICP with altimeter measurements, reliably constraining drifts along the gravity vector. To demonstrate the potential of altimetry in SLAM, we offer an analysis of calibration procedures and noise sensitivity of various pressure sensors, improving measurements to centimeter-level accuracy. Leveraging this accuracy, we propose a novel ICP formulation that integrates altitude measurements along the gravity vector, thus simplifying the optimization problem to 3-Degree Of Freedom (DOF). Experimental results from real-world deployments demonstrate that our method reduces vertical drift by 84% and improves overall localization accuracy compared to state-of-the-art methods in non-planar environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt19_04">
             15:30-15:35, Paper WeDT19.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1469" name="modify3856" onclick="modify(3856,1469)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3856'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Neural Ranging Inertial Odometry
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#353971" title="Click to go to the Author Index">
             Wang, Si
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#313340" title="Click to go to the Author Index">
             Shen, Bingqi
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423283" title="Click to go to the Author Index">
             Wang, Fei
            </a>
           </td>
           <td class="r">
            Beijing Institute of Electronic System Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#178926" title="Click to go to the Author Index">
             Cao, Yanjun
            </a>
           </td>
           <td class="r">
            Zhejiang University, Huzhou Institute of Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#113216" title="Click to go to the Author Index">
             Xiong, Rong
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#156231" title="Click to go to the Author Index">
             Wang, Yue
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3856" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Ultra-wideband (UWB) has shown promising potential in GPS-denied localization thanks to its lightweight and drift-free characteristics, while the accuracy is limited in real scenarios due to its sensitivity to sensor arrangement and non-Gaussian pattern induced by multi-path or multi-signal interference, which commonly occurs in many typical applications like long tunnels. We introduce a novel neural fusion framework for ranging inertial odometry which involves a graph attention UWB network and a recurrent neural inertial network. Our graph net learns scene-relevant ranging patterns and adapts to any number of anchors or tags, realizing accurate positioning without calibration. Additionally, the integration of least squares and the incorporation of nominal frame enhance overall performance and scalability. The effectiveness and robustness of our methods are validated through extensive experiments on both public and self-collected datasets, spanning indoor, outdoor, and tunnel environments. The results demonstrate the superiority of our proposed IR-ULSG in handling challenging conditions, including scenarios outside the convex envelope and cases where only a single anchor is available.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt19_05">
             15:35-15:40, Paper WeDT19.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1470" name="modify4904" onclick="modify(4904,1470)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4904'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robust Preintegrated Wheel Odometry for Off-Road Autonomous Ground Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#295646" title="Click to go to the Author Index">
             Potokar, Easton
            </a>
           </td>
           <td class="r">
            Carnegie Mellon Uiversity
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#310642" title="Click to go to the Author Index">
             McGann, Daniel
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104298" title="Click to go to the Author Index">
             Kaess, Michael
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4904" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Wheel odometry is not often used in state estimation for off-road vehicles due to frequent wheel slippage, varying wheel radii, and the 3D motion of the vehicle not fitting with the 2D nature of integrated wheel odometry. This paper attempts to overcome these issues by proposing a novel 3D preintegration of wheel encoder measurements on manifold. Our method additionally estimates wheel slip, radii, and baseline online to improve accuracy and robustness. Further, due to the preintegration, many measurements can be summarized into a single motion constraint using first-order updates for wheel slippage and intrinsics, allowing for efficient usage in an optimization-based state estimation framework. While our method can be used with any sensors in a factor graph framework, we validate its effectiveness and observability of parameters in a vision-wheel-odometry system (VWO) in a Monte Carlo simulation. Additionally, we illustrate its accuracy and demonstrate it can be used to overcome other sensor failures in real-world off-road scenarios in both a VWO and visual-inertial-wheel odometry (VIWO) system.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt19_06">
             15:40-15:45, Paper WeDT19.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1471" name="modify4979" onclick="modify(4979,1471)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4979'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Air-Ground Collaboration with SPOMP: Semantic Panoramic Online Mapping and Planning (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#233233" title="Click to go to the Author Index">
             Miller, Ian
            </a>
           </td>
           <td class="r">
            Burro
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#257289" title="Click to go to the Author Index">
             Cladera, Fernando
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106900" title="Click to go to the Author Index">
             Smith, Trey
            </a>
           </td>
           <td class="r">
            NASA Ames Research Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106877" title="Click to go to the Author Index">
             Taylor, Camillo Jose
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104342" title="Click to go to the Author Index">
             Kumar, Vijay
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4979" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Mapping and navigation have gone hand-in-hand since long before robots existed. Maps are a key form of communication, allowing someone who has never been somewhere to nonetheless navigate that area successfully. In the context of multirobot systems, the maps and information that flow between robots are necessary for effective collaboration, whether those robots are operating concurrently, sequentially, or completely asynchronously. In this article, we argue that maps must go beyond encoding purely geometric or visual information to enable increasingly complex autonomy, particularly between robots. We propose a framework for multirobot autonomy, focusing in particular on air and ground robots operating in outdoor 2.5-D environments. We show that semantic maps can enable the specification, planning, and execution of complex collaborative missions, including localization in Global Positioning System (GPS)-denied settings. A distinguishing characteristic of this work is that we strongly emphasize field experiments and testing, and by doing so demonstrate that these ideas can work at scale in the real world. We also perform extensive simulation experiments to validate our ideas at even larger scales. We believe that these experiments and the experimental results constitute a significant step forward toward advancing the state of the art of large-scale, collaborative multirobot systems operating with real communication, navigation, and perception constraints.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt19_07">
             15:45-15:50, Paper WeDT19.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1472" name="modify4990" onclick="modify(4990,1472)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4990'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Visual-Inertial Localization Leveraging Skylight Polarization Pattern Constraints
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#382796" title="Click to go to the Author Index">
             Wan, Zhenhua
            </a>
           </td>
           <td class="r">
            Guangxi University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#401975" title="Click to go to the Author Index">
             Fu, Peng
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#352913" title="Click to go to the Author Index">
             Wang, Kunfeng
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#353599" title="Click to go to the Author Index">
             Zhao, Kaichun
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4990" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_inertial_slam" title="Click to go to the Keyword Index">
               Visual-Inertial SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this letter, we develop a tightly coupled polarization-visual-inertial localization system that utilizes naturally-attributed polarized skylight to provide a global heading. We introduce a focal plane polarization camera with negligible instantaneous field-of-view error to collect polarized skylight. Then, we design a robust heading determination method from polarized skylight and construct a global stable heading constraint. In particular, this constraint compensates for the heading unobservability present in standard VINS. In addition to the standard sparse visual feature measurements used in VINS, polarization heading residuals are constructed and co-optimized in a tightly-coupled VINS update. An adaptive fusion strategy is designed to correct the cumulative drift. Outdoor real-world experiments show that the proposed method outperforms state-of-the-art VINS-Fusion in terms of localization accuracy, and improves 22% over VINS-Fusion in a wooded campus environment.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt20">
             <b>
              WeDT20
             </b>
             Regular Session, 408
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1473" name="modifyWeDT20" onclick="modsession(175,1473)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt20" title="Click to go to the Program at a Glance">
             <b>
              Human-Robot Interaction: Physiological Sensing
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#105066" title="Click to go to the Author Index">
             Mombaur, Katja
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#274216" title="Click to go to the Author Index">
             Lagomarsino, Marta
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt20_01">
             15:15-15:20, Paper WeDT20.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1474" name="modify288" onclick="modify(288,1474)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('288'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Promoting Trust in Industrial Human-Robot Collaboration through Preference-Based Optimization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#310229" title="Click to go to the Author Index">
             Campagna, Giulio
            </a>
           </td>
           <td class="r">
            Aalborg University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#274216" title="Click to go to the Author Index">
             Lagomarsino, Marta
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#218363" title="Click to go to the Author Index">
             Lorenzini, Marta
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#108136" title="Click to go to the Author Index">
             Chrysostomou, Dimitrios
            </a>
           </td>
           <td class="r">
            Aalborg University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#158245" title="Click to go to the Author Index">
             Rehm, Matthias
            </a>
           </td>
           <td class="r">
            Aalborg University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#150752" title="Click to go to the Author Index">
             Ajoudani, Arash
            </a>
           </td>
           <td class="r">
            Istituto Italiano Di Tecnologia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab288" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_factors_and_human_in_the_loop" title="Click to go to the Keyword Index">
               Human Factors and Human-in-the-Loop
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#acceptability_and_trust" title="Click to go to the Keyword Index">
               Acceptability and Trust
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes a novel theoretical framework for promoting trust in human-robot collaboration (HRC). The framework exploits Preference-Based Optimization (PBO) and focuses on three key interaction parameters: robot velocity profile, human-robot separation distance, and vertical proximity to the user’s head. By iteratively refining these parameters based on qualitative feedback from human collaborators, the system dynamically adapts robot trajectories. This personalization aims to enhance users’ confidence in the robot’s actions and foster a more trusting collaborative environment. In our user study with fourteen participants, we simulated a chemical industrial scenario for the HRC task. Results suggest that the framework effectively promotes human operator confidence in the robot assistant, particularly for individuals with limited prior experience in robotics.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt20_02">
             15:20-15:25, Paper WeDT20.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1475" name="modify1022" onclick="modify(1022,1475)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1022'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GazeHTA: End-To-End Gaze Target Detection with Head-Target Association
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#414372" title="Click to go to the Author Index">
             Lin, Zhi-Yi
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#164508" title="Click to go to the Author Index">
             Chew, Jouh Yeong
            </a>
           </td>
           <td class="r">
            Honda Research Institute Japan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#357105" title="Click to go to the Author Index">
             van Gemert, Jan C.
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#380409" title="Click to go to the Author Index">
             Zhang, Xucong
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1022" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#intention_recognition" title="Click to go to the Keyword Index">
               Intention Recognition
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#gesture__posture_and_facial_expressions" title="Click to go to the Keyword Index">
               Gesture, Posture and Facial Expressions
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Precisely detecting which object a person is paying attention to is critical for human-robot interaction since it provides important cues for the next action from the human user. We propose an end-to-end approach for gaze target detection: predicting a head-target connection between individuals and the target image regions they are looking at. Most of the existing methods use independent components such as off-the-shelf head detectors or have problems in establishing associations between heads and gaze targets. In contrast, we investigate an end-to-end multi-person Gaze target detection framework with Heads and Targets Association (GazeHTA), which predicts multiple head-target instances based solely on input scene image. GazeHTA addresses challenges in gaze target detection by (1) leveraging a pre-trained diffusion model to extract scene features for rich semantic understanding, (2) re-injecting a head feature to enhance the head priors for improved head understanding, and (3) learning a connection map as the explicit visual associations between heads and gaze targets. Our extensive experimental results demonstrate that GazeHTA outperforms state-of-the-art gaze target detection methods and two adapted diffusion-based baselines on two standard datasets.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt20_03">
             15:25-15:30, Paper WeDT20.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1476" name="modify1358" onclick="modify(1358,1476)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1358'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Gaze and Go: Harnessing Visual Attention Valence in Upper-Limb Robotic Rehabilitation with Tailored Gamification and Eye Tracking for Neuroplasticity
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416714" title="Click to go to the Author Index">
             Wang, Daomiao
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#274552" title="Click to go to the Author Index">
             He, Peidong
            </a>
           </td>
           <td class="r">
            University of Shanghai for Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417712" title="Click to go to the Author Index">
             Wang, Yixi
            </a>
           </td>
           <td class="r">
            Shanghai ZD MedTech Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#384314" title="Click to go to the Author Index">
             Jian, Zhuo
            </a>
           </td>
           <td class="r">
            Shanghai ZD MEDTECH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417709" title="Click to go to the Author Index">
             Song, Zilong
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421133" title="Click to go to the Author Index">
             Hu, Qihan
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#384315" title="Click to go to the Author Index">
             Fang, Fanfu
            </a>
           </td>
           <td class="r">
            Changhai Hospital
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421126" title="Click to go to the Author Index">
             Yang, Cuiwei
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418546" title="Click to go to the Author Index">
             Wang, Daoyu
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#251630" title="Click to go to the Author Index">
             Yu, Hongliu
            </a>
           </td>
           <td class="r">
            University of Shanghai for Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1358" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_detection_and_tracking" title="Click to go to the Keyword Index">
               Human Detection and Tracking
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#rehabilitation_robotics" title="Click to go to the Keyword Index">
               Rehabilitation Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Therapeutic robotic systems have emerged as reliable tools for physical rehabilitation, providing variable-intensity movement assistance to patients with motor impairments. Robot-assisted rehabilitation facilitates the restoration mobility and dexterity, promotes functional neuroplasticity and potentially enables workforce reentry through training-induced cognitive and motor learning. To boost participant engagement and visuomotor coordination, we propose ArmGuider Pro, an advanced upper-limb training system that integrates hand-eye collaboration and gaze-triggered assistance within rehabilitation-tailored serious games. The system implements intuitive eye-tracking and visual-triggering strategies to align therapeutic interventions with participants' intentional focus, incorporating immersive gaming elements and adaptive control algorithms. Experimental validation demonstrates significant activation in motor and cognitive cerebral cortex regions, enhanced visual attention concentration in desired target areas (25.92% improvement), and improved trajectory adherence across sequential sessions (27.27% improvement). By harnessing visual attention valence, our proposed system could encourage neuroplasticity, supporting its viability for clinical application and widespread adaption in rehabilitation regimens.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt20_04">
             15:30-15:35, Paper WeDT20.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1477" name="modify1584" onclick="modify(1584,1477)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1584'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Teleoperating a 6 DoF Robotic Manipulator from Head Movements
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#290960" title="Click to go to the Author Index">
             Poignant, Alexis
            </a>
           </td>
           <td class="r">
            Sorbonne Université, ISIR UMR 7222 CNRS
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106021" title="Click to go to the Author Index">
             Jarrassé, Nathanael
            </a>
           </td>
           <td class="r">
            Sorbonne Université, ISIR UMR 7222 CNRS
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104642" title="Click to go to the Author Index">
             Morel, Guillaume
            </a>
           </td>
           <td class="r">
            Sorbonne Université, CNRS, INSERM
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1584" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_detection_and_tracking" title="Click to go to the Keyword Index">
               Human Detection and Tracking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This article presents an interactive control approach allowing a human user to teleoperate a robotic manipulator located nearby. With this approach, the user keeps his/her hands free, as only head movements are exploited to control the robot. The controller maps the 6 Degrees of Freedom (DoF) user's head position and orientation into the 6~DoF robot end-effector position and orientation.
             <p>
              The robot can reach a large workspace thanks to the combination of two features. Firstly, a virtual wand between the user's head and the robot end-effector converts user's head pan-tilt rotations into large displacements of the robot end-effector center perpendicularly to the wand axis (2 DoF). Secondly, for the remaining 4 DoF (robot end-effector center displacement along the wand axis and robot en-effector orientation), real-time deformation of the virtual wand is triggered when the user reaches uncomfortable configurations due to his/her head workspace limitations. Additionally, the user gets, through an Augmented Reality (AR) Headset, a non-delayed visual feedback of the current virtual wand geometry and location.
              <p>
               The paper includes a description of the setup and the proposed controller, detailing how the robot position/orientation is coupled to the user's head position/orientation. A set of elementary experiments with a constant-geometry wand is first presented, showing workspace limitations for some DoF. Then the wand reconfiguration is introduced in the experiments, leading to full control of 6 DoF manipulation tasks throughout a large workspace.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt20_05">
             15:35-15:40, Paper WeDT20.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1478" name="modify1889" onclick="modify(1889,1478)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1889'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Wearable Soft Sensing Band with Stretchable Sensors for Torque Estimation and Hand Gesture Recognition
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256668" title="Click to go to the Author Index">
             Choi, Junhwan
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology, (KAIST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#227329" title="Click to go to the Author Index">
             Feng, Jirou
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#115549" title="Click to go to the Author Index">
             Kim, Jung
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1889" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_detection_and_tracking" title="Click to go to the Keyword Index">
               Human Detection and Tracking
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intention_recognition" title="Click to go to the Keyword Index">
               Intention Recognition
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#wearable_robotics" title="Click to go to the Keyword Index">
               Wearable Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a wearable soft sensing band with stretchable sensors for monitoring muscle activity by estimating muscle volume changes. Unlike conventional surface electromyography (sEMG) sensing techniques, which require excessive pressure or adhesive electrodes, the proposed sensing method allows muscle volume variations to be detected simply by placing the device on the skin without additional pressure or adhesives. The band was evaluated in isometric-static and isometric-varying torque estimation tasks, demonstrating superior accuracy to sEMG, with a relative torque to maximum torque estimation error of less than 11.5%. In isometric-varying conditions, relative torque was estimated with an average error of 10.1% at frequencies of 0.1 Hz, 0.2 Hz, and 0.5 Hz. Furthermore, the band achieved a classification accuracy of 92.9% in recognizing ten distinct hand gestures, highlighting its capability to differentiate between multiple muscle activations. The lightweight and flexible design addresses limitations of sEMG, such as signal noise, skin irritation, and complex calibration. Experimental results validate the potential of the proposed sensing method for applications in muscle activity monitoring across healthcare, rehabilitation, and sports, and it also offers potential for use in robot teaching for reference motion generation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt20_06">
             15:40-15:45, Paper WeDT20.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1479" name="modify4418" onclick="modify(4418,1479)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4418'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Plug-And-Play Multi-Domain Fusion Adaptation for Cross-Subject EEG-Based Motor Imagery Classification
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#266944" title="Click to go to the Author Index">
             Shi, Kecheng
            </a>
           </td>
           <td class="r">
            The School of Automation Engineering, University of Electronic S
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#183121" title="Click to go to the Author Index">
             Huang, Rui
            </a>
           </td>
           <td class="r">
            University of Electronic Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#336747" title="Click to go to the Author Index">
             Li, Zhe
            </a>
           </td>
           <td class="r">
            University of Electronic Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#244145" title="Click to go to the Author Index">
             Lyu, Jianzhi
            </a>
           </td>
           <td class="r">
            University of Hamburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#246600" title="Click to go to the Author Index">
             Zhao, Yang
            </a>
           </td>
           <td class="r">
            University of Electronic Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#225105" title="Click to go to the Author Index">
             Song, Guangkui
            </a>
           </td>
           <td class="r">
            University of Electronic Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#159479" title="Click to go to the Author Index">
             Cheng, Hong
            </a>
           </td>
           <td class="r">
            University of Electronic Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106951" title="Click to go to the Author Index">
             Zhang, Jianwei
            </a>
           </td>
           <td class="r">
            University of Hamburg
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4418" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#brain_machine_interfaces" title="Click to go to the Keyword Index">
               Brain-Machine Interfaces
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intention_recognition" title="Click to go to the Keyword Index">
               Intention Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Motor imagery (MI) classification in rehabilitation brain-computer interfaces (RBCIs) faces significant challenges due to the variability of electroencephalography (EEG) signals across subjects. Existing methods typically require extensive EEG data collection from each new subject, which is time-consuming and results in poor user experience. To address this issue, this paper decompose MI EEG into subject-specific private components and shared components common across all subjects, and propose a plug-and-play domain fusion adaptive method (PPMDFA) to handle variability between subjects. In the training phase, PPMDFA introduces a Multi-Domain Fusion Graph Convolutional Network (MDFGCN) module to extract shared and private features from the MI processes of source domain subjects. In the calibration phase, the method constructs private classifiers for the target new subject using the extracted shared features combined with a small amount of labeled data. During testing, PPMDFA leverages the similarity of private components to utilize knowledge from source subjects, thereby enhancing classification accuracy for target subjects' MI. We validated the proposed method on the PhysioNet and LLMBCImotion datasets. Experimental results show that PPMDFA achieves state-of-the-art classification accuracy on both datasets, with rapid adaptation to new subjects using only 20% of the data, reaching accuracies of 73.33% and 61.62%, demonstrating strong generalization ability and robustness.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt20_07">
             15:45-15:50, Paper WeDT20.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1480" name="modify4611" onclick="modify(4611,1480)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4611'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning to Communicate Functional States with Nonverbal Expressions for Improved Human-Robot Collaboration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#358671" title="Click to go to the Author Index">
             Roy, Liam
            </a>
           </td>
           <td class="r">
            Monash University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100067" title="Click to go to the Author Index">
             Croft, Elizabeth
            </a>
           </td>
           <td class="r">
            University of Victoria
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#108781" title="Click to go to the Author Index">
             Kulic, Dana
            </a>
           </td>
           <td class="r">
            Monash University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4611" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_modal_perception_for_hri" title="Click to go to the Keyword Index">
               Multi-Modal Perception for HRI
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Collaborative robots must effectively communicate their internal state to humans to enable a smooth interaction. Nonverbal communication is widely used to communicate information during human-robot interaction, however, such methods may also be misunderstood, leading to communication errors. In this work, we explore modulating the acoustic parameter values (pitch bend, beats per minute, beats per loop) of nonverbal auditory expressions to convey functional robot states (accomplished, progressing, stuck). We propose a reinforcement learning (RL) algorithm based on noisy human feedback to produce accurately interpreted nonverbal auditory expressions. The proposed approach was evaluated through a user study with 24 participants. The results demonstrate that: (i) Our proposed RL-based approach is able to learn suitable acoustic parameter values which improve the users’ ability to correctly identify the state of the robot. (ii) Algorithm initialization informed by previous user data can be used to significantly speed up the learning process. (iii) The method used for algorithm initialization strongly influences whether participants converge to similar sounds for each robot state. (iv) Modulation of pitch bend has the largest influence on user association between sounds and robotic states.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt21">
             <b>
              WeDT21
             </b>
             Regular Session, 410
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1481" name="modifyWeDT21" onclick="modsession(619,1481)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt21" title="Click to go to the Program at a Glance">
             <b>
              Vision-Language-Action Models
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#123972" title="Click to go to the Author Index">
             Guy, Stephen J.
            </a>
           </td>
           <td class="r">
            University of Minnesota - Twin Cities
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#196806" title="Click to go to the Author Index">
             Arkin, Jacob
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt21_01">
             15:15-15:20, Paper WeDT21.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1482" name="modify457" onclick="modify(457,1482)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('457'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SpatialBot: Precise Spatial Understanding with Vision Language Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#413712" title="Click to go to the Author Index">
             Cai, Wenxiao
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372860" title="Click to go to the Author Index">
             Ponomarenko, Iaroslav
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#348482" title="Click to go to the Author Index">
             Yuan, Jianhao
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372289" title="Click to go to the Author Index">
             Li, Xiaoqi
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#269636" title="Click to go to the Author Index">
             Yang, Wankou
            </a>
           </td>
           <td class="r">
            Southeast University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#280114" title="Click to go to the Author Index">
             Dong, Hao
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#413715" title="Click to go to the Author Index">
             Zhao, Bo
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab457" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Vision Language Models (VLMs) have achieved impressive performance in 2D image understanding; however, they still struggle with spatial understanding, which is fundamental to embodied AI. In this paper, we propose SpatialBot, a model designed to enhance spatial understanding by utilizing both RGB and depth images. To train VLMs for depth perception, we introduce the SpatialQA and SpatialQA-E datasets, which include multi-level depth-related questions spanning various scenarios and embodiment tasks. SpatialBench is also developed to comprehensively evaluate VLMs' spatial understanding capabilities across different levels. Extensive experiments on our spatial-understanding benchmark, general VLM benchmarks, and embodied AI tasks demonstrate the remarkable improvements offered by SpatialBot. The model, code, and datasets are available at https://github.com/BAAI-DCAI/SpatialBot.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt21_02">
             15:20-15:25, Paper WeDT21.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1483" name="modify3270" onclick="modify(3270,1483)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3270'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Run-Time Observation Interventions Make Vision-Language-Action Models More Visually Robust
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#348298" title="Click to go to the Author Index">
             Hancock, Asher
            </a>
           </td>
           <td class="r">
            Princeton University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309518" title="Click to go to the Author Index">
             Ren, Allen Z.
            </a>
           </td>
           <td class="r">
            Princeton University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#148191" title="Click to go to the Author Index">
             Majumdar, Anirudha
            </a>
           </td>
           <td class="r">
            Princeton University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3270" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Vision-language-action (VLA) models trained on large-scale internet data and robot demonstrations have the potential to serve as generalist robot policies. However, despite their large-scale training, VLAs are often brittle to task-irrelevant visual details such as distractor objects or background colors. We introduce Bring Your Own VLA (BYOVLA): a run-time intervention scheme that (1) dynamically identifies regions of the input image that the model is sensitive to, and (2) minimally alters task-irrelevant regions to reduce the model’s sensitivity using automated image editing tools. Our approach is compatible with any off the shelf VLA without model finetuning or access to the model’s weights. Hardware experiments on language-instructed manipulation tasks demonstrate that BYOVLA enables state-of-the-art VLA models to nearly retain their nominal performance in the presence of distractor objects and backgrounds, which otherwise degrade task success rates by up to 60%.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt21_03">
             15:25-15:30, Paper WeDT21.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1484" name="modify3536" onclick="modify(3536,1484)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3536'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              KALIE: Fine-Tuning Vision-Language Models for Open-World Manipulation without Robot Data
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425415" title="Click to go to the Author Index">
             Tang, Grace
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425394" title="Click to go to the Author Index">
             Rajkumar, Swetha
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425645" title="Click to go to the Author Index">
             Zhou, Yifei
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#350194" title="Click to go to the Author Index">
             Walke, Homer
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#156706" title="Click to go to the Author Index">
             Levine, Sergey
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#217568" title="Click to go to the Author Index">
             Fang, Kuan
            </a>
           </td>
           <td class="r">
            Cornell University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3536" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#big_data_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Big Data in Robotics and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Building generalist robotic systems involves effectively endowing robots with the capabilities to handle novel objects in an open-world setting. Inspired by the advances of large pre-trained models, we propose Keypoint Affordance Learning from Imagined Environments (KALIE), which adapts pre-trained Vision Language Models (VLMs) for robotic control in a scalable manner. Instead of directly producing motor commands, KALIE controls the robot by predicting point-based affordance representations based on natural language instructions and visual observations of the scene. The VLM is trained on 2D images with affordances labeled by humans, bypassing the need for training data collected on robotic systems. Through an affordance-aware data synthesis pipeline, KALIE automatically creates massive high-quality training data based on limited example data manually collected by humans. We demonstrate that KALIE can learn to robustly solve new manipulation tasks with unseen objects given only 50 example data points. Compared to baselines using pre-trained VLMs, our approach consistently achieves superior performance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt21_04">
             15:30-15:35, Paper WeDT21.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1485" name="modify3978" onclick="modify(3978,1485)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3978'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GHIL-Glue: Hierarchical Control with Filtered Subgoal Images
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#298591" title="Click to go to the Author Index">
             Hatch, Kyle Beltran
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#238319" title="Click to go to the Author Index">
             Balakrishna, Ashwin
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#191594" title="Click to go to the Author Index">
             Mees, Oier
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#237226" title="Click to go to the Author Index">
             Nair, Suraj
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#403217" title="Click to go to the Author Index">
             Park, Seohong
            </a>
           </td>
           <td class="r">
            Seohong@berkeley.edu
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#176036" title="Click to go to the Author Index">
             Wulfe, Blake
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#286255" title="Click to go to the Author Index">
             Itkina, Masha
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#270274" title="Click to go to the Author Index">
             Eysenbach, Benjamin
            </a>
           </td>
           <td class="r">
            CMU
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#156706" title="Click to go to the Author Index">
             Levine, Sergey
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107892" title="Click to go to the Author Index">
             Kollar, Thomas
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#186298" title="Click to go to the Author Index">
             Burchfiel, Benjamin
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3978" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Image and video generative models that are pre-trained on Internet-scale data can greatly increase the generalization capacity of robot learning systems. These models can function as high-level planners, generating intermediate subgoals for low-level goal-conditioned policies to reach. However, the performance of these systems can be greatly bottlenecked by the interface between generative models and low-level controllers. For example, generative models may predict photo-realistic yet physically infeasible frames that confuse low-level policies. Low-level policies may also be sensitive to subtle visual artifacts in generated goal images. This paper addresses these two facets of generalization, providing an interface to effectively “glue together” language-conditioned image or video prediction models with low-level goal-conditioned policies. Our method, Generative Hierarchical Imitation Learning-Glue (GHIL-Glue), filters out subgoals that do not lead to task progress and improves the robustness of goal-conditioned policies to generated subgoals with harmful visual artifacts. We find in extensive experiments in both simulated and real environments that GHIL-Glue achieves a 25% improvement across several hierarchical models that leverage generative subgoals, achieving a new state-of-the-art on the CALVIN simulation benchmark for policies using observations from a single RGB camera. GHIL-Glue also outperforms other generalist robot policies across 3/4 language-conditioned manipulation tasks testing zero-shot generalization in physical experiments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt21_05">
             15:35-15:40, Paper WeDT21.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1486" name="modify4211" onclick="modify(4211,1486)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4211'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Simultaneous Localization and Affordance Prediction of Tasks from Egocentric Video
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#280077" title="Click to go to the Author Index">
             Chavis, Zachary
            </a>
           </td>
           <td class="r">
            University of Minnesota
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#117877" title="Click to go to the Author Index">
             Park, Hyun Soo
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#123972" title="Click to go to the Author Index">
             Guy, Stephen J.
            </a>
           </td>
           <td class="r">
            University of Minnesota - Twin Cities
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4211" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Vision-Language Models (VLMs) have shown great success as foundational models for downstream vision and natural language applications in a variety of domains. However, these models are limited to reasoning over objects and actions currently visible on the image plane. We present a spatial extension to the VLM, which leverages spatially-localized egocentric video demonstrations to augment VLMs in two ways --- through understanding spatial task-affordances, i.e. where an agent must be for the task to physically take place, and the localization of that task relative to the egocentric viewer. We show our approach outperforms the baseline of using a VLM to map similarity of a task's description over a set of location-tagged images. Our approach has less error both on predicting where a task may take place and on predicting what tasks are likely to happen at the current location. The resulting representation will enable robots to use egocentric sensing to navigate to, or around, physical regions of interest for novel tasks specified in natural language.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt21_06">
             15:40-15:45, Paper WeDT21.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1487" name="modify4332" onclick="modify(4332,1487)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4332'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              QUART-Online: Latency-Free Multimodal Large Language Model for Quadruped Robot Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425565" title="Click to go to the Author Index">
             Tong, Xinyang
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#391285" title="Click to go to the Author Index">
             Ding, Pengxiang
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426256" title="Click to go to the Author Index">
             Fan, Yiguo
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267934" title="Click to go to the Author Index">
             Wang, Donglin
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426274" title="Click to go to the Author Index">
             Zhang, Wenjie
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#391284" title="Click to go to the Author Index">
             Cui, Can
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421976" title="Click to go to the Author Index">
             Sun, Mingyang
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#334849" title="Click to go to the Author Index">
             Zhao, Han
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#284933" title="Click to go to the Author Index">
             Zhang, Hongyin
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405521" title="Click to go to the Author Index">
             Dang, Yonghao
            </a>
           </td>
           <td class="r">
            Beijing University of Posts and Telecommunications
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426273" title="Click to go to the Author Index">
             Huang, Siteng
            </a>
           </td>
           <td class="r">
            Westlake Univerisity
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#192153" title="Click to go to the Author Index">
             Lyu, Shangke
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4332" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#perception_action_coupling" title="Click to go to the Keyword Index">
               Perception-Action Coupling
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper addresses the inherent inference latency challenges associated with deploying multimodal large language models (MLLM) in quadruped vision-language-action (QUAR-VLA) tasks. Our investigation reveals that conventional parameter reduction techniques ultimately impair the performance of the language foundation model during the action instruction tuning phase, making them unsuitable for this purpose. We introduce a novel latency-free quadruped MLLM model, dubbed QUART-Online, designed to enhance inference efficiency without degrading the performance of the language foundation model. By incorporating Action Chunk Discretization (ACD), we compress the original action representation space, mapping continuous action values onto a smaller set of discrete representative vectors while preserving critical information. Subsequently, we fine-tune the MLLM to integrate vision, language, and compressed actions into a unified semantic space. Experimental results demonstrate that QUART-Online operates in tandem with the existing MLLM system, achieving real-time inference at 50Hz in sync with the underlying controller frequency, significantly boosting the success rate across various tasks by 65%. Our project page is https://quart-online.github.io.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt21_07">
             15:45-15:50, Paper WeDT21.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1488" name="modify4457" onclick="modify(4457,1488)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4457'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              IntelliRMS: A Robotic Manipulation System for Domain-Specific Tasks Using Vision and Language Foundational Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#219606" title="Click to go to the Author Index">
             Singh, Chandan Kumar
            </a>
           </td>
           <td class="r">
            Tata Consultancy Services
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#394641" title="Click to go to the Author Index">
             Kumar, Devesh
            </a>
           </td>
           <td class="r">
            Tata Consultancy Services Limited
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#300040" title="Click to go to the Author Index">
             Sanap, Vipul
            </a>
           </td>
           <td class="r">
            TCS
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#394639" title="Click to go to the Author Index">
             Khandelwal, Mayank
            </a>
           </td>
           <td class="r">
            Tata Consultancy Services Limited
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#226116" title="Click to go to the Author Index">
             Sinha, Rajesh
            </a>
           </td>
           <td class="r">
            TCS-Noida
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4457" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#software_architecture_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Software Architecture for Robotic and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#software_hardware_integration_for_robot_systems" title="Click to go to the Keyword Index">
               Software-Hardware Integration for Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recent advancements in large language models (LLMs) have significantly enhanced machines’ ability to understand and follow human instructions. In many tasks, LLMs have demonstrated performance that rivals human-level common sense. However, directly applying LLMs to domain-specific use cases, such as robotic pick-and-place, remains a challenge. Tasks that are intuitive for humans, who rely on prior knowledge and skills, become complex for robots. Industrial robotic applications like pick-and-place require a high degree of accuracy, often exceeding 90%. In response to these challenges in domain-specific applications, we propose IntelliRMS, a novel system-oriented architecture for instruction-following robotic manipulation. The IntelliRMS synergizes the linguistic and open-vocabulary visual capabilities of foundational models to arrive at an accurate, robust and scalable system. Further, we demonstrate the effectiveness of IntelliRMS in a real-world industrial Bin-picking scenario within the retail sector, validating its performance with a comprehensive dataset.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt22">
             <b>
              WeDT22
             </b>
             Regular Session, 411
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1489" name="modifyWeDT22" onclick="modsession(113,1489)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt22" title="Click to go to the Program at a Glance">
             <b>
              Deep Learning for Visual Perception 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#266445" title="Click to go to the Author Index">
             Ding, Mingyu
            </a>
           </td>
           <td class="r">
            University of North Carolina at Chapel Hill
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#106116" title="Click to go to the Author Index">
             Roumeliotis, Stergios
            </a>
           </td>
           <td class="r">
            Apple Inc
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt22_01">
             15:15-15:20, Paper WeDT22.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1490" name="modify740" onclick="modify(740,1490)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('740'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SCA3D: Enhancing Cross-Modal 3D Retrieval Via 3D Shape and Caption Paired Data Augmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418944" title="Click to go to the Author Index">
             Ren, Junlong
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420473" title="Click to go to the Author Index">
             Wu, Hao
            </a>
           </td>
           <td class="r">
            HKUST
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425627" title="Click to go to the Author Index">
             Xiong, Hui
            </a>
           </td>
           <td class="r">
            HKUST(GZ)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423920" title="Click to go to the Author Index">
             Wang, Hao
            </a>
           </td>
           <td class="r">
            HKUST(GZ)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab740" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The cross-modal 3D retrieval task aims to achieve mutual matching between text descriptions and 3D shapes. This has the potential to enhance the interaction between natural language and the 3D environment, especially within the realms of robotics and embodied artificial intelligence (AI) applications. However, the scarcity and expensiveness of 3D data constrain the performance of existing cross-modal 3D retrieval methods. These methods heavily rely on features derived from the limited number of 3D shapes, resulting in poor generalization ability across diverse scenarios. To address this challenge, we introduce SCA3D, a novel 3D shape and caption online data augmentation method for cross-modal 3D retrieval. Our approach uses the LLaVA model to create a component library, captioning each segmented part of every 3D shape within the dataset. Notably, it facilitates the generation of extensive new 3D-text pairs containing new semantic features. We employ both inter and intra distances to align various components into a new 3D shape, ensuring that the components do not overlap and are closely fitted. Further, text templates are utilized to process the captions of each component and generate new text descriptions. Besides, we use unimodal encoders to extract embeddings for 3D shapes and texts based on the enriched dataset. We then calculate fine-grained cross-modal similarity using Earth Mover’s Distance (EMD) and enhance cross-modal matching with contrastive learning, enabling bidirectional retrieval between texts and 3D shapes. Extensive experiments show our SCA3D outperforms previous works on the Text2Shape dataset, raising the Shape-to-Text RR@1 score from 20.03 to 27.22 and the Text-to-Shape RR@1 score from 13.12 to 16.67. Codes can be found in https://github.com/3DAgentWorld/SCA3D.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt22_02">
             15:20-15:25, Paper WeDT22.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1491" name="modify761" onclick="modify(761,1491)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('761'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              TrajSSL: Trajectory-Enhanced Semi-Supervised 3D Object Detection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#342059" title="Click to go to the Author Index">
             Jacobson, Philip
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#341928" title="Click to go to the Author Index">
             Xie, Yichen
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#266445" title="Click to go to the Author Index">
             Ding, Mingyu
            </a>
           </td>
           <td class="r">
            UC Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#295784" title="Click to go to the Author Index">
             Xu, Chenfeng
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100071" title="Click to go to the Author Index">
             Tomizuka, Masayoshi
            </a>
           </td>
           <td class="r">
            University of California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#170266" title="Click to go to the Author Index">
             Zhan, Wei
            </a>
           </td>
           <td class="r">
            Univeristy of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#342079" title="Click to go to the Author Index">
             Wu, Ming
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab761" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Semi-supervised 3D object detection is a common strategy employed to circumvent the challenge of manually labeling large-scale autonomous driving perception datasets. Pseudo-labeling approaches to semi-supervised learning adopt a teacher-student framework in which machine-generated pseudo-labels on a large unlabeled dataset are used in combination with a small manually-labeled dataset for training. In this work, we address the problem of improving pseudo-label quality through leveraging long-term temporal information captured in driving scenes. More specifically, we leverage pre-trained motion-forecasting models to generate object trajectories on pseudo-labeled data to further enhance the student model training. Our approach improves pseudo-label quality in two distinct manners: first, we suppress false positive pseudo-labels through establishing consistency across multiple frames of motion forecasting outputs. Second, we compensate for false negative detections by directly inserting predicted object tracks into the pseudo-labeled scene. Experiments on the nuScenes dataset demonstrate the effectiveness of our approach, improving the performance of standard semi-supervised approaches in a variety of settings.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt22_03">
             15:25-15:30, Paper WeDT22.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1492" name="modify813" onclick="modify(813,1492)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('813'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Single-Shot Metric Depth from Focused Plenoptic Cameras
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419442" title="Click to go to the Author Index">
             Lasheras-Hernandez, Blanca
            </a>
           </td>
           <td class="r">
            German Aerospace Center (DLR)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103847" title="Click to go to the Author Index">
             Strobl, Klaus H.
            </a>
           </td>
           <td class="r">
            German Aerospace Center (DLR)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#293268" title="Click to go to the Author Index">
             Izquierdo, Sergio
            </a>
           </td>
           <td class="r">
            University of Zaragoza
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106050" title="Click to go to the Author Index">
             Bodenmueller, Tim
            </a>
           </td>
           <td class="r">
            German Aerospace Center (DLR)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102317" title="Click to go to the Author Index">
             Triebel, Rudolph
            </a>
           </td>
           <td class="r">
            German Aerospace Center (DLR)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105562" title="Click to go to the Author Index">
             Civera, Javier
            </a>
           </td>
           <td class="r">
            Universidad De Zaragoza
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab813" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Metric depth estimation from visual sensors is crucial for robots to perceive, navigate, and interact with their environment. Traditional range imaging setups, such as stereo or structured light cameras, face hassles including calibration, occlusions, and hardware demands, with accuracy limited by the baseline between cameras. Single- and multiview monocular depth offers a more compact alternative, but is constrained by the unobservability of the metric scale. Light field imaging provides a promising solution for estimating metric depth by using a unique lens configuration through a single device. However, its application to single-view dense metric depth is under-addressed mainly due to the technology’s high cost, the lack of public benchmarks, and proprietary geometrical models and software.
             <p>
              Our work explores the potential of focused plenoptic cameras for dense metric depth. We propose a novel pipeline that predicts metric depth from a single plenoptic camera shot by first generating a sparse metric point cloud using a neural network, which is then used to scale and align a dense relative depth map regressed by a foundation depth model, resulting in a dense metric depth. To validate it, we curated the Light Field &amp; Stereo Image Dataset (LFS) of real-world light field images with stereo depth labels, filling a current gap in existing resources. Experimental results show that our pipeline produces accurate metric depth predictions, laying a solid groundwork for future research in this field.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt22_04">
             15:30-15:35, Paper WeDT22.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1493" name="modify890" onclick="modify(890,1493)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('890'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              TREND: Tri-Teaching for Robust Preference-Based Reinforcement Learning with Demonstrations
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#391483" title="Click to go to the Author Index">
             Huang, Shuaiyi
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#289666" title="Click to go to the Author Index">
             Levy, Mara
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419673" title="Click to go to the Author Index">
             Gupta, Anubhav
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#413642" title="Click to go to the Author Index">
             Ekpo, Daniel
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419753" title="Click to go to the Author Index">
             Zheng, Ruijie
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#176399" title="Click to go to the Author Index">
             Shrivastava, Abhinav
            </a>
           </td>
           <td class="r">
            University of Maryland, College Park
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab890" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Preference feedback collected by human or VLM annotators is often noisy, presenting a significant challenge for preference-based reinforcement learning that relies on accurate preference labels. To address this challenge, we propose TREND, a novel framework that integrates few-shot expert demonstrations with a tri-teaching strategy for effective noise mitigation. Our method trains three reward models simultaneously, where each model views its small-loss preference pairs as useful knowledge and teaches such useful pairs to its peer network for updating the parameters. Remarkably, our approach requires as few as one to three expert demonstrations to achieve high performance. We evaluate TREND on various robotic manipulation tasks, achieving up to 90% success rates even with noise levels as high as 40%, highlighting its effective robustness in handling noisy preference feedback.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt22_05">
             15:35-15:40, Paper WeDT22.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1494" name="modify1316" onclick="modify(1316,1494)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1316'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SYNERGUARD: A Robust Framework for Point Cloud Classification Via Local Geometry and Spatial Topology
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415551" title="Click to go to the Author Index">
             Zhong, Haonan
            </a>
           </td>
           <td class="r">
            The University of New South Wales
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420935" title="Click to go to the Author Index">
             Song, Wei
            </a>
           </td>
           <td class="r">
            UNSW
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#132771" title="Click to go to the Author Index">
             Pagnucco, Maurice
            </a>
           </td>
           <td class="r">
            University of New South Wales
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339638" title="Click to go to the Author Index">
             Song, Yang
            </a>
           </td>
           <td class="r">
            University of New South Wales
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1316" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#acceptability_and_trust" title="Click to go to the Keyword Index">
               Acceptability and Trust
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Point cloud recognition models are known to be vulnerable to adversarial attacks. The state-of-the-art defense solutions either focus on partial features of the point cloud, limiting their effectiveness, or rely heavily on known adversarial examples, reducing their generalizability, while others, like point cloud reconstruction, will degrade the classifier’s accuracy on clean examples. To address this, we introduce SYNERGUARD, a novel robust point cloud classification framework mitigating adversarial attacks by considering comprehensive geometric and topological attributes of the point cloud, without relying on known adversarial examples while attaining classification accuracies on clean examples. We comprehensively test SYNERGUARD against seven attack types from three leading adversarial attack approaches on two widely used datasets, ModelNet40 and ShapeNetPart. The results demonstrate SYNERGUARD’s superiority against existing defenses in mitigating adversarial attacks, as well as managing clean examples.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt22_06">
             15:40-15:45, Paper WeDT22.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1495" name="modify1395" onclick="modify(1395,1495)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1395'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Is Discretization Fusion All You Need for Collaborative Perception?
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#399461" title="Click to go to the Author Index">
             Yang, Kang
            </a>
           </td>
           <td class="r">
            Renmin University of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420067" title="Click to go to the Author Index">
             Bu, Tianci
            </a>
           </td>
           <td class="r">
            National University of Defense and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417696" title="Click to go to the Author Index">
             Li, Lantao
            </a>
           </td>
           <td class="r">
            Sony (China) Limited
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420346" title="Click to go to the Author Index">
             Li, Chunxu
            </a>
           </td>
           <td class="r">
            School of Information Renmin University of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#157092" title="Click to go to the Author Index">
             Wang, Yongcai
            </a>
           </td>
           <td class="r">
            Renmin University of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#336800" title="Click to go to the Author Index">
             Li, Deying
            </a>
           </td>
           <td class="r">
            Renmin University of China
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1395" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Collaborative perception in multi-agent system enhances overall perceptual capabilities by facilitating the exchange of complementary information among agents. Current mainstream collaborative perception methods rely on discretized feature maps to conduct fusion, which however, lacks flexibility in extracting and transmitting the informative features and can hardly focus on the informative features during fusion. To address these problems, this paper proposes a novel Anchor-Centric paradigm for Collaborative Object detection (ACCO). It avoids grid precision issues and allows more flexible and efficient anchor-centric communication and fusion. ACCO is composed by three main components: (1) Anchor featuring block (AFB) that targets to generate anchor proposals and projects prepared anchor queries to image features. (2) Anchor confidence generator (ACG) is designed to minimize communication by selecting only the features in the confident anchors to transmit. (3) A local-global fusion module, in which local fusion is anchor alignment-based fusion (LAAF) and global fusion is conducted by spatial-aware cross-attention (SACA). LAAF and SACA run in multi-layers, so agents conduct anchor-centric fusion iteratively to adjust the anchor proposals. Comprehensive experiments are conducted to evaluate ACCO on OPV2V and Dair-V2X datasets, which demonstrate ACCO's superiority in reducing the communication volume, and in improving the perception range and detection performances. We will make our code available.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt22_07">
             15:45-15:50, Paper WeDT22.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1496" name="modify1515" onclick="modify(1515,1496)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1515'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Tri-AutoAug: Single Domain Generalization for Bird's-Eye-View 3D Object Detection through Pixel-2D-3D Features
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#403404" title="Click to go to the Author Index">
             Zhao, Xue
            </a>
           </td>
           <td class="r">
            SJTU
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415433" title="Click to go to the Author Index">
             Peng, Pai
            </a>
           </td>
           <td class="r">
            Cowarobot
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415451" title="Click to go to the Author Index">
             Li, Xianfei
            </a>
           </td>
           <td class="r">
            Cowarobot
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#363143" title="Click to go to the Author Index">
             Wang, Xinbing
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#363144" title="Click to go to the Author Index">
             Zhou, Chenghu
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#363104" title="Click to go to the Author Index">
             Ye, Nanyang
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1515" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             With the increasing popularity of autonomous driving based on the Bird’s-Eye-View (BEV) representation, improving the generalization of such detection models is key for safe real-world applications. However, a realistic yet challenging scenario: Single Domain Generalization (SDG) for BEV, is still under-explored. A key ingredient for SDG is to increase data diversity via common image augmentation or adversarial data generation first. However, common image-level augmentation is not sufficient enough to ensure domain diversity in most part of latent space. The adversarial generation has the problem of unstable training or mode collapsing as well. To address these limitations, we present Tri-level Automatic Augmentation (Tri-AutoAug), a simple yet effective method to enlarge the diversity and quantity of data from image and 2D features and facilitate the model to learn more domain-invariant features in BEV space. Besides, Tri-AutoAug can automatically learn augmentation strategies to avoid spending too much time manually adjusting hyperparameters and maximize the benefit of Tri-level Augmentation. To the best of our knowledge, this is the first study to explore automatic augmentation for SDG BEV. Extensive experiments on NuScenes-C including eight testing domains have demonstrated that our approach can achieve the best performance across various domain generalization methods. More importantly, we evaluate the proposed method in real-world autonomous driving scenarios. Tri-AutoAug improves the out-of-distribution (ood) performance by 8.54% (mAP), which demonstrates that Tri-AutoAug provides a practical and feasible solution for the applications of 3D detectors in the real world.The code is available at https://github.com/ClaireTun/Tri-AutoAug.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="wedt23">
             <b>
              WeDT23
             </b>
             Regular Session, 412
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1497" name="modifyWeDT23" onclick="modsession(221,1497)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#wedt23" title="Click to go to the Program at a Glance">
             <b>
              Learning Based Planning and Control
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#130305" title="Click to go to the Author Index">
             Faigl, Jan
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#131647" title="Click to go to the Author Index">
             Zarrouk, David
            </a>
           </td>
           <td class="r">
            Ben Gurion University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt23_01">
             15:15-15:20, Paper WeDT23.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1498" name="modify192" onclick="modify(192,1498)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('192'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Motion Planning for Minimally-Actuated Serial Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#275472" title="Click to go to the Author Index">
             Cohen, Avi
            </a>
           </td>
           <td class="r">
            Ben Gurion University of the Negev
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#149815" title="Click to go to the Author Index">
             Sintov, Avishai
            </a>
           </td>
           <td class="r">
            Tel-Aviv University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#131647" title="Click to go to the Author Index">
             Zarrouk, David
            </a>
           </td>
           <td class="r">
            Ben Gurion University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab192" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#redundant_robots" title="Click to go to the Keyword Index">
               Redundant Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Modern manipulators are acclaimed for their precision but often struggle to operate in confined spaces. This limitation has driven the development of hyper-redundant and continuum robots. While these present unique advantages, they face challenges in, for instance, weight, mechanical complexity, modeling and costs. The Minimally Actuated Serial Robot (MASR) has been proposed as a light-weight, low-cost and simpler alternative where passive joints are actuated with a Mobile Actuator (MA) moving along the arm. Yet, Inverse Kinematics (IK) and a general motion planning algorithm for the MASR have not be addressed. In this letter, we propose the MASR-RRT* motion planning algorithm specifically developed for the unique kinematics of MASR. The main component of the algorithm is a data-based model for solving the IK problem while considering minimal traverse of the MA. The model is trained solely using the forward kinematics of the MASR and does not require real data. With the model as a local-connection mechanism, MASR-RRT* minimizes a cost function expressing the action time. In a comprehensive analysis, we show that MASR-RRT* is superior in performance to the straight-forward implementation of the standard RRT*. Experiments on a real robot in different environments with obstacles validate the proposed algorithm.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt23_02">
             15:20-15:25, Paper WeDT23.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1499" name="modify374" onclick="modify(374,1499)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('374'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Using Implicit Behavior Cloning and Dynamic Movement Primitive to Facilitate Reinforcement Learning for Robot Motion Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#209818" title="Click to go to the Author Index">
             Zhang, Zengjie
            </a>
           </td>
           <td class="r">
            Eindhoven University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339484" title="Click to go to the Author Index">
             Hong, Jayden
            </a>
           </td>
           <td class="r">
            Uvic ACIS Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#311700" title="Click to go to the Author Index">
             Soufi Enayati, Amir Mehdi
            </a>
           </td>
           <td class="r">
            University of Victoria
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103596" title="Click to go to the Author Index">
             Najjaran, Homayoun
            </a>
           </td>
           <td class="r">
            University of Victoria
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab374" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#efficient_reinforcement_learning" title="Click to go to the Keyword Index">
               Efficient Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_and_adaptive_systems" title="Click to go to the Keyword Index">
               Learning and Adaptive Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Reinforcement learning (RL) for motion planning of multi-degree-of-freedom robots still suffers from low efficiency in terms of slow training speed and poor generalizability. In this paper, we propose a novel RL-based robot motion planning framework that uses implicit behavior cloning (IBC) and dynamic movement primitive (DMP) to improve the training speed and generalizability of an off-policy RL agent. IBC utilizes human demonstration data to leverage the training speed of RL, and DMP serves as a heuristic model that transfers motion planning into a simpler planning space. To support this, we also create a human demonstration dataset using a pick-and-place experiment that can be used for similar studies. Comparison studies reveal the advantage of the proposed method over the conventional RL agents with faster training speed and higher scores. A real-robot experiment indicates the applicability of the proposed method to a simple assembly task. Our work provides a novel perspective on using motion primitives and human demonstration to leverage the performance of RL for robot applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt23_03">
             15:25-15:30, Paper WeDT23.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1500" name="modify541" onclick="modify(541,1500)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('541'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Interpretable Active Inference Gait Control Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#278261" title="Click to go to the Author Index">
             Szadkowski, Rudolf
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#130305" title="Click to go to the Author Index">
             Faigl, Jan
            </a>
           </td>
           <td class="r">
            Czech Technical University in Prague
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab541" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#bioinspired_robot_learning" title="Click to go to the Keyword Index">
               Bioinspired Robot Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#probabilistic_inference" title="Click to go to the Keyword Index">
               Probabilistic Inference
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_experience" title="Click to go to the Keyword Index">
               Learning from Experience
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Sustaining the gait locomotion in an adversarial environment requires the robot to react to novel experiences adaptively. In Free Energy Principle (FEP), the behavioral reaction is driven by the discrepancy between observation and prediction. Although, for legged robot gait locomotion, the prediction of gait dynamics is challenging as the consequences non-linearly depend on the activity history, the animal gait is robust, adapting to severe motion disruptions seemingly instantly. In biomimetic robotics, the Central Pattern Generator (CPG) relaxes the general dynamics of body-environment interaction to the stable and repetitive dynamics of gait. Based on these observations, we propose self-learning of the gait dynamics model and FEP framework that infers state estimation and gait control. The proposed method is experimentally evaluated on a real hexapod walking robot with 18 controllable degrees of freedom. The robot learns the gait dynamics model indoors and then deploys it in outdoor navigation under various adversarial scenarios. Results show that the developed interpretable gait controller exhibits complex and real-time adaptive behavior when it encounters unknown situations.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt23_04">
             15:30-15:35, Paper WeDT23.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1501" name="modify683" onclick="modify(683,1501)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('683'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DOPT: D-Learning with Off-Policy Target Toward Sample Efficiency and Fast Convergence Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#412136" title="Click to go to the Author Index">
             Shen, Zhaolong
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#194601" title="Click to go to the Author Index">
             Quan, Quan
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab683" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_categories_and_concepts" title="Click to go to the Keyword Index">
               Learning Categories and Concepts
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In recent times, Lyapunov theory has been incorporated into learning-based control methods to provide a stability guarantee. However, merely satisfying the Lyapunov conditions does not fully leverage the capabilities of the Neural Network (NN) controller. Furthermore, training an effective Lyapunov candidate requires substantial data, which inherently results in sample inefficiency. To address these limitations, we propose an off-policy variant of the vanilla D-learning method that uses current and historical data to iteratively enhance the NN controller within the framework of Lyapunov theory. Our method outperforms the Deep Deterministic Policy Gradient (DDPG) and D-learning in terms of stability, sample efficiency, and the quality of the trained controllers and Lyapunov candidates.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt23_05">
             15:35-15:40, Paper WeDT23.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1502" name="modify702" onclick="modify(702,1502)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('702'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DFM: Deep Fourier Mimic for Expressive Dance Motion Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#359765" title="Click to go to the Author Index">
             Watanabe, Ryo
            </a>
           </td>
           <td class="r">
            SONY Group
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#337985" title="Click to go to the Author Index">
             Li, Chenhao
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#114045" title="Click to go to the Author Index">
             Hutter, Marco
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab702" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#art_and_entertainment_robotics" title="Click to go to the Keyword Index">
               Art and Entertainment Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             As entertainment robots gain popularity, the demand for natural and expressive motion, particularly in dancing, continues to rise. Traditionally, dancing motions have been manually designed by artists, a process that is both labor-intensive and restricted to simple motion playback,lacking the flexibility to incorporate additional tasks such as locomotion or gaze control during dancing. To overcome these challenges, we introduce Deep Fourier Mimic (DFM), a novel method that combines advanced motion representation with Reinforcement Learning (RL) to enable smooth transitions between motions while concurrently managing auxiliary tasks during dance sequences. While previous frequency domain based motion representations have successfully encoded dance motions into latent parameters, they often impose overly rigid periodic assumptions at the local level, resulting in reduced tracking accuracy and motion expressiveness, which is a critical aspect for entertainment robots. By relaxing these locally periodic constraints, our approach not only enhances tracking precision but also facilitates smooth transitions between different motions. Furthermore, the learned RL policy that supports simultaneous base activities, such as locomotion and gaze control, allows entertainment robots to engage more dynamically and interactively with users rather than merely replaying static, pre-designed dance routines.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt23_06">
             15:40-15:45, Paper WeDT23.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1503" name="modify856" onclick="modify(856,1503)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('856'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Uncertainty-Aware Deep Reinforcement Learning with Calibrated Quantile Regression and Evidential Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#355273" title="Click to go to the Author Index">
             Stutts, Alex Christopher
            </a>
           </td>
           <td class="r">
            University of Illinois Chicago
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#214796" title="Click to go to the Author Index">
             Erricolo, Danilo
            </a>
           </td>
           <td class="r">
            University of Illinois at Chicago
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#355276" title="Click to go to the Author Index">
             Tulabandhula, Theja
            </a>
           </td>
           <td class="r">
            University of Illinois Chicago
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419648" title="Click to go to the Author Index">
             Mittal, Mohit
            </a>
           </td>
           <td class="r">
            Meta Reality Labs
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#355268" title="Click to go to the Author Index">
             Trivedi, Amit Ranjan
            </a>
           </td>
           <td class="r">
            University of Illinois at Chicago (UIC), Chicago, USA
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab856" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning_under_uncertainty" title="Click to go to the Keyword Index">
               Planning under Uncertainty
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a novel statistical approach to incorporate uncertainty awareness in model-free distributional deep reinforcement learning for mission and safety-critical robotics. Deep learning predictions are influenced by uncertainties in the data, termed as aleatoric uncertainties, as well as uncertainties in the learning process and model structure, known as epistemic uncertainties. The proposed algorithm, called as Calibrated Evidential Quantile Regression in Deep-Q Networks (CEQR-DQN), addresses key challenges associated with separately estimating aleatoric and epistemic uncertainty in stochastic robotic environments. It combines deep evidential learning with quantile calibration based on the principles of conformal inference to provide explicit, sample-free computations of global uncertainty as opposed to local estimates based on simple variance. Thereby, the proposed approach overcomes limitations of traditional methods in computational and statistical efficiency and handling of out-of-distribution (OOD) observations. Tested on a suite of representative miniaturized Atari games (i.e., MinAtar), CEQR-DQN is shown to surpass similar existing frameworks in scores and learning speed. Its ability to rigorously evaluate uncertainties improves exploration strategies and can serve as a blueprint for other uncertainty-aware robotic algorithms.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="wedt23_07">
             15:45-15:50, Paper WeDT23.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1504" name="modify5008" onclick="modify(5008,1504)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5008'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Teaching Periodic Stable Robot Motions Generation Via Sketch
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#238613" title="Click to go to the Author Index">
             Zhi, Weiming
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#404812" title="Click to go to the Author Index">
             Tang, Haozhan
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#266906" title="Click to go to the Author Index">
             Zhang, Tianyi
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#118789" title="Click to go to the Author Index">
             Johnson-Roberson, Matthew
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5008" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Contemporary robots are complex systems. Teaching novel motion patterns to robots requires specialised expertise, often entailing the careful specification of robot motion or the cumbersome design of optimisation problems. In this paper, we seek to simplify the process of generating periodic motions, by teaching robots with user sketches. In particular, we tackle the problem of teaching a robot to approach a surface and then follow cyclic motion on the surface. The limit cycle of the motion can be arbitrarily specified by a single user-provided sketch over an image from the robot’s camera, and the sketched limit cycle is then projected into the scene. To generate motion that converges to the limit cycle, we contribute the Stable Periodic Diagrammatic Teaching (SPDT) framework. SPDT models the robot’s motion as an Orbitally Asymptotically Stable (O.A.S.) dynamical system that learns to stabilise based on the diagrammatic sketch provided by the user. This is achieved by applying a differentiable and invertible function, known as a diffeomorphism, to shape a known O.A.S. system. The parameterised diffeomorphism is then optimised with respect to the Hausdorff distance between the limit cycle of our modelled system and the sketch, to produce the desired robot motion. We provide insight into the behaviour of the optimised system and empirically evaluate SPDT. Results show that we can diagrammatically teach complex cyclic motion patterns with accuracy.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet1">
             <b>
              WeET1
             </b>
             Regular Session, 302
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1505" name="modifyWeET1" onclick="modsession(79,1505)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet1" title="Click to go to the Program at a Glance">
             <b>
              Autonomous Vehicles 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#100760" title="Click to go to the Author Index">
             Ang Jr, Marcelo H
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#291510" title="Click to go to the Author Index">
             Shi, Weisong
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet1_01">
             16:35-16:40, Paper WeET1.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1506" name="modify40" onclick="modify(40,1506)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('40'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DriveSceneGen: Generating Diverse and Realistic Driving Scenarios from Scratch
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#302076" title="Click to go to the Author Index">
             Sun, Shuo
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#375120" title="Click to go to the Author Index">
             Gu, Zekai
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#375121" title="Click to go to the Author Index">
             Sun, Tianchen
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#355145" title="Click to go to the Author Index">
             Sun, Jiawei
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#355146" title="Click to go to the Author Index">
             Yuan, Chengran
            </a>
           </td>
           <td class="r">
            National Universtiy of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#367117" title="Click to go to the Author Index">
             Han, Yuhang
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#367116" title="Click to go to the Author Index">
             Li, Dongen
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100760" title="Click to go to the Author Index">
             Ang Jr, Marcelo H
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab40" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#big_data_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Big Data in Robotics and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Realistic and diverse traffic scenarios in large quantities are crucial for the development and validation of autonomous driving systems. However, owing to numerous difficulties in the data collection process and the reliance on intensive annotations, real-world datasets lack sufficient quantity and diversity to support the increasing demand for data. This work introduces DriveSceneGen, a data-driven driving scenario generation method that learns from the real-world driving dataset and generates entire dynamic driving scenarios from scratch. Experimental results on 5k generated scenarios highlight that DriveSceneGen is able to generate novel driving scenarios that align with real-world data distributions with high fidelity and diversity. To the best of our knowledge, DriveSceneGen is the first method that generates novel driving scenarios involving both static map elements and dynamic traffic participants from scratch. Extensive experiments demonstrate that our two-stage method outperforms existing state-of-the-art map generation methods and trajectory simulation methods on their respective tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet1_02">
             16:40-16:45, Paper WeET1.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1507" name="modify110" onclick="modify(110,1507)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('110'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              AMVP: Adaptive Multi-Volume Primitives for Auto-Driving Novel View Synthesis
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#284001" title="Click to go to the Author Index">
             Qi, Dexin
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#282772" title="Click to go to the Author Index">
             Tao, Tao
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#305066" title="Click to go to the Author Index">
             Zhang, Zhihong
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#133888" title="Click to go to the Author Index">
             Mei, Xuesong
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab110" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Synthesizing high-quality novel views is critical to extending training data for auto-driving scenes. However, existing novel view synthesis techniques rely on a single-volume radiance field with uniform spatial resolution, constraining their model capacity and resulting in artifacts in synthesized auto-driving views. This paper introduces AMVP, a novel neural representation that models auto-driving scenes using multiple local primitives with adaptive spatial resolution. AMVP addresses the lack of representation capability of detail-rich regions by adaptively subdividing the scene into multiple local volumes. Each local volume is assigned a tailored resolution based on its geometric complexity, as determined by a density prior. Subsequently, multi-volume primitives are introduced to enable sharing a global feature table among local volumes, addressing the GPU memory inefficiency caused by the duplicated allocation. In addition, the paper proposes resolution-aware confidence, a mechanism that suppresses artifacts arising from frequency ambiguity. This mechanism adaptively reduces high-frequency components based on the spatial resolution of each local volume and the distance of the sampling point from the optical center. Experimental results on benchmark auto-driving datasets demonstrate that the proposed AMVP achieves superior rendering quality while using a similar number of parameters compared to existing methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet1_03">
             16:45-16:50, Paper WeET1.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1508" name="modify886" onclick="modify(886,1508)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('886'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              EMATO: Energy-Model-Aware Trajectory Optimization for Autonomous Driving
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#337319" title="Click to go to the Author Index">
             Tian, Zhaofeng
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419739" title="Click to go to the Author Index">
             Xia, Lichen
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#291510" title="Click to go to the Author Index">
             Shi, Weisong
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab886" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#energy_and_environment_aware_automation" title="Click to go to the Keyword Index">
               Energy and Environment-Aware Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous driving currently lacks robust evidence of energy efficiency when using energy-model-agnostic trajectory planning. To address this, we explore how differential energy models can be effectively utilized under varying driving conditions to enhance energy efficiency. Furthermore, we propose an online nonlinear programming approach that optimizes polynomial trajectories generated by the Frenet polynomial method while incorporating traffic trajectory data and road slope predictions. Through case studies, quantitative analyses, and ablation studies conducted on both sedan and truck models, we demonstrate the effectiveness of the proposed method.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet1_04">
             16:50-16:55, Paper WeET1.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1509" name="modify1939" onclick="modify(1939,1509)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1939'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Task-Oriented Pre-Training for Drivable Area Detection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#276186" title="Click to go to the Author Index">
             Ma, Fulong
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#365001" title="Click to go to the Author Index">
             Zhao, Guoyang
            </a>
           </td>
           <td class="r">
            HKUST(GZ)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#367558" title="Click to go to the Author Index">
             Qi, Weiqing
            </a>
           </td>
           <td class="r">
            HKUST
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#125556" title="Click to go to the Author Index">
             Liu, Ming
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#182083" title="Click to go to the Author Index">
             Ma, Jun
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1939" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Pre-training techniques play a crucial role in deep learning, enhancing models' performance across a variety of tasks. By initially training on large datasets and subsequently fine-tuning on task-specific data, pre-training provides a solid foundation for models, improving generalization abilities and accelerating convergence rates. This approach has seen significant success in the fields of natural language processing and computer vision. However, traditional pre-training methods necessitate large datasets and substantial computational resources, and they can only learn shared features through prolonged training and struggle to capture deeper, task-specific features. In this paper, we propose a task-oriented pre-training method that begins with generating redundant segmentation proposals using the Segment Anything (SAM) model. We then introduce a Specific Category Enhancement Fine-tuning (SCEF) strategy for fine-tuning the Contrastive Language-Image Pre-training (CLIP) model to select proposals most closely related to the drivable area from those generated by SAM. This approach can generate a lot of coarse training data for pre-training models, which are further fine-tuned using manually annotated data, thereby improving model's performance. Comprehensive experiments conducted on the KITTI road dataset demonstrate that our task-oriented pre-training method achieves an all-around performance improvement compared to models without pre-training. Moreover, our pre-training method not only surpasses traditional pre-training approach but also achieves the best performance compared to state-of-the-art self-training methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet1_05">
             16:55-17:00, Paper WeET1.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1510" name="modify2031" onclick="modify(2031,1510)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2031'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              UA-PnP: Uncertainty-Aware End-To-End Bird's Eye View Visual Perception and Prediction for Autonomous Driving
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423065" title="Click to go to the Author Index">
             Huang, Zijian
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#156378" title="Click to go to the Author Index">
             Li, Dachuan
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338830" title="Click to go to the Author Index">
             Hao, Qi
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2031" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robust and accurate perception and prediction of the driving scenarios are crucial for autonomous driving vehicles (ADV). State-of-the-art ADV frameworks have evolved from conventional modular design to an end-to-end (E2E) pipeline that enables joint feature learning and optimization. However, the evaluation of uncertainties in the intermediate features propagated between perception and prediction units is missing in current E2E pipelines. Consequently, adverse and extreme environment factors may incur highly untrustworthy features that ultimately result in degraded perception and prediction. In this work, we propose a novel uncertainty-aware E2E visual perception and prediction framework that utilized Bird's Eye View (BEV) representations. A feature distribution estimation network is introduced to explicitly quantify the uncertainties in the intermediate BEV features extracted from the images. To better exploit	temporal information and generate more robust features for scene prediction, an uncertainty-aware transformer is designed to utilize the guidance of the quantified feature uncertainty via the attention mechanism. In addition, an evidential decoder generates accurate future instance segmentations along with the associated uncertainties. Comprehensive experiments conducted on real-world dataset validate the superiority of our proposed framework over conventional pipelines. Codes are available at: https://github.com/Huang121381/UA-PnP.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet1_06">
             17:00-17:05, Paper WeET1.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1511" name="modify2140" onclick="modify(2140,1511)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2140'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              HGAT-CP: Heterogeneous Graph Attention Network for Collision Prediction in Autonomous Driving
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#407149" title="Click to go to the Author Index">
             Jiang, Yongzhi
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421282" title="Click to go to the Author Index">
             Zhou, Bin
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#307327" title="Click to go to the Author Index">
             Li, Yongwei
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#307333" title="Click to go to the Author Index">
             Wu, Xinkai
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#410836" title="Click to go to the Author Index">
             Xiong, Zhongxia
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2140" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Predicting potential collision events is beneficial to ensure the driving safety of autonomous vehicles. Existing graph-based collision prediction methods rely heavily on domain knowledge and predefined semantic relations, limiting their flexibility and adaptability in complex driving scenarios. To overcome these challenges, this paper introduces a novel collision prediction framework named HGAT-CP, which integrates a Heterogeneous Graph Attention Network (HGAT) with a Long Short-Term Memory network (LSTM) to model the spatial-temporal interactions in scenes. First, the proposed method employs a data-driven scene graph embedding module to autonomously learn relationships between vehicles and lanes and construct flexible scene graphs. Then, the HGAT module utilizes a dual-level attention mechanism, operating at both the node level and type level, to capture spatial interactions without relying on predefined semantic rules. The LSTM module models temporal dependencies of the scene graph embeddings to improve the prediction of collision events over time. Experimental evaluations on public datasets demonstrate that our proposed method achieves state-of-the-art performance, outperforming existing methods across all metrics.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet1_07">
             17:05-17:10, Paper WeET1.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1512" name="modify2319" onclick="modify(2319,1512)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2319'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SE-STDGNN: A Self-Evolving Spatial-Temporal Directed Graph Neural Network for Multi-Vehicle Trajectory Prediction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#343258" title="Click to go to the Author Index">
             Guo, Zixuan
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#377537" title="Click to go to the Author Index">
             Han, Bingxin
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#375342" title="Click to go to the Author Index">
             Huang, Yijun
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351227" title="Click to go to the Author Index">
             Chen, Xi
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#171587" title="Click to go to the Author Index">
             Chen, Ben M.
            </a>
           </td>
           <td class="r">
            Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2319" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#automation_technologies_for_smart_cities" title="Click to go to the Keyword Index">
               Automation Technologies for Smart Cities
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Vehicle trajectory prediction (VTP) is essential for microscopic traffic risk assessment, autonomous vehicle navigation, and traffic behavior analysis. Related research leveraging learning-based methodologies has yielded notable success on various benchmark trajectory datasets. However, these models often experience performance degradation when faced with dynamic changes in traffic conditions such as vehicle density, road types, and weather conditions, as they have not been exposed to these variations during the training process. To effectively address the need for real-time adaptation in dynamic traffic scenarios, we propose a novel framework titled self-evolving spatial-temporal directed graph neural network (SE-STDGNN). This model utilizes evolving graph convolution networks (EvolveGCNs) to aggregate spatial-temporal features of vehicles and their neighbors, which are then utilized by a trajectory prediction module to forecast future trajectories. Further, a self-evolving mechanism is introduced to adjust model parameters dynamically in the real-time operation. The efficacy of SE STDGNN is validated using the public vehicle trajectory dataset AD4CHE.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet1_08">
             17:10-17:15, Paper WeET1.8
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1513" name="modify3302" onclick="modify(3302,1513)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3302'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Generalized Control Revision Method for Autonomous Driving Safety
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423628" title="Click to go to the Author Index">
             Zhu, Zehang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420408" title="Click to go to the Author Index">
             Wang, Yuning
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423782" title="Click to go to the Author Index">
             Ke, Tianqi
            </a>
           </td>
           <td class="r">
            School of Vehicle and Mobility, Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#370805" title="Click to go to the Author Index">
             Han, Zeyu
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#283152" title="Click to go to the Author Index">
             Xu, Shaobing
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#216342" title="Click to go to the Author Index">
             Xu, Qing
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104857" title="Click to go to the Author Index">
             Dolan, John M.
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#216343" title="Click to go to the Author Index">
             Wang, Jianqiang
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3302" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Safety is one of the most crucial challenges of autonomous driving vehicles, and one solution to guarantee safety is to employ an additional control revision module after the planning backbone. Control Barrier Function (CBF) has been widely used because of its strong mathematical foundation on safety. However, the incompatibility with heterogeneous perception data and incomplete consideration of traffic scene elements make existing systems hard to be applied in dynamic and complex real-world scenarios. In this study, we introduce a generalized control revision method for autonomous driving safety, which adopts both vectorized perception and occupancy grid map as inputs and comprehensively models multiple types of traffic scene constraints based on a new proposed barrier function. Traffic elements are integrated into one unified framework, decoupled from specific scenario settings or rules. Experiments on CARLA, SUMO, and OnSite simulator prove that the proposed algorithm could realize safe control revision under complicated scenes, adapting to various planning backbones, road topologies, and risk types. Physical platform validation also verifies the real-world application feasibility.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet2">
             <b>
              WeET2
             </b>
             Regular Session, 301
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1514" name="modifyWeET2" onclick="modsession(243,1514)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet2" title="Click to go to the Program at a Glance">
             <b>
              Learning-Based SLAM 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#168080" title="Click to go to the Author Index">
             Kim, Donghyun
            </a>
           </td>
           <td class="r">
            University of Massachusetts Amherst
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#211530" title="Click to go to the Author Index">
             Biggie, Harel
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet2_01">
             16:35-16:40, Paper WeET2.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1515" name="modify87" onclick="modify(87,1515)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('87'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              H3-Mapping: Quasi-Heterogeneous Feature Grids for Real-Time Dense Mapping Using Hierarchical Hybrid Representation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#319946" title="Click to go to the Author Index">
             Jiang, Chenxing
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#371295" title="Click to go to the Author Index">
             Luo, Yiming
            </a>
           </td>
           <td class="r">
            The University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#225160" title="Click to go to the Author Index">
             Zhou, Boyu
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#142354" title="Click to go to the Author Index">
             Shen, Shaojie
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab87" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In recent years, implicit online dense mapping methods have achieved high-quality reconstruction results, showcasing great potential in robotics, AR/VR, and digital twins applications. However, existing methods struggle with slow texture modeling which limits their real-time performance. To address these limitations, we propose a NeRF-based dense mapping method that enables faster and higher-quality reconstruction. To improve texture modeling, we introduce quasi-heterogeneous feature grids, which inherit the fast querying ability of uniform feature grids while adapting to varying levels of texture complexity. Besides, we present a gradient-aided coverage-maximizing strategy for keyframe selection that enables the selected keyframes to exhibit a closer focus on rich-textured regions and a broader scope for weak-textured areas. Experimental results demonstrate that our method surpasses existing NeRF-based approaches in
             <p>
              texture fidelity, geometry accuracy, and time consumption. The code for
              <p>
               our method will be available at: https://github.com/SYSU-STAR/H3-Mapping.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet2_02">
             16:40-16:45, Paper WeET2.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1516" name="modify482" onclick="modify(482,1516)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('482'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CEAR: Comprehensive Event Camera Dataset for Rapid Perception of Agile Quadruped Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#286851" title="Click to go to the Author Index">
             Zhu, Shifan
            </a>
           </td>
           <td class="r">
            University of Massachusetts Amherst
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398602" title="Click to go to the Author Index">
             Xiong, Zixun
            </a>
           </td>
           <td class="r">
            University of Massachusetts Amherst
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#168080" title="Click to go to the Author Index">
             Kim, Donghyun
            </a>
           </td>
           <td class="r">
            University of Massachusetts Amherst
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab482" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_slam" title="Click to go to the Keyword Index">
               Data Sets for SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             When legged robots perform agile movements, traditional RGB cameras often produce blurred images, posing a challenge for rapid perception. Event cameras have emerged as a promising solution for capturing rapid perception and coping with challenging lighting conditions thanks to their low latency, high temporal resolution, and high dynamic range. However, integrating event cameras into agile-legged robots is still largely unexplored. Notably, no dataset including event cameras has yet been developed for the context of agile quadruped robots. To bridge this gap, we introduce CEAR, a dataset comprising data from an event camera, an RGB-D camera, an IMU, a LiDAR, and joint encoders, all mounted on a dynamic quadruped, Mini Cheetah robot. This comprehensive dataset features more than 100 sequences from real-world environments, encompassing various indoor and outdoor environments, different lighting conditions, a range of robot gaits (e.g., trotting, bounding, pronking), as well as acrobatic movements like backflip. To our knowledge, this is the first event camera dataset capturing the dynamic and diverse quadruped robot motions under various setups, developed to advance research in rapid perception for quadruped robots.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet2_03">
             16:45-16:50, Paper WeET2.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1517" name="modify941" onclick="modify(941,1517)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('941'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DVLO4D: Deep Visual-Lidar Odometry with Sparse Spatial-Temporal Fusion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#337009" title="Click to go to the Author Index">
             Liu, Mengmeng
            </a>
           </td>
           <td class="r">
            University of Twente
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#191165" title="Click to go to the Author Index">
             Yang, Michael Ying
            </a>
           </td>
           <td class="r">
            University of Bath
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419665" title="Click to go to the Author Index">
             Liu, Jiuming
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417291" title="Click to go to the Author Index">
             Zhang, Yunpeng
            </a>
           </td>
           <td class="r">
            PhiGent Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417705" title="Click to go to the Author Index">
             Li, Jiangtao
            </a>
           </td>
           <td class="r">
            Phigent Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#193591" title="Click to go to the Author Index">
             Sander, Oude Elberink
            </a>
           </td>
           <td class="r">
            University of Twente
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#236371" title="Click to go to the Author Index">
             Vosselman, George
            </a>
           </td>
           <td class="r">
            University of Twente
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#287309" title="Click to go to the Author Index">
             Cheng, Hao
            </a>
           </td>
           <td class="r">
            University of Twente
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab941" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visual-LiDAR odometry is a critical component for autonomous system localization, yet achieving high accuracy and strong robustness remains a challenge. Traditional approaches commonly struggle with sensor misalignment, fail to fully leverage temporal information, and require extensive manual tuning to handle diverse sensor configurations. To address these problems, we introduce DVLO4D, a novel visual-LiDAR odometry framework that leverages sparse spatial-temporal fusion to enhance accuracy and robustness.
             <p>
              Our approach proposes three key innovations: (1) Sparse Query Fusion, which utilizes sparse LiDAR queries for effective multi-modal data fusion; (2) a Temporal Interaction and Update module that integrates temporally-predicted positions with current frame data, providing better initialization values for pose estimation and enhancing model's robustness against accumulative errors; and (3) a Temporal Clip Training strategy combined with a Collective Average Loss mechanism that aggregates losses across multiple frames, enabling global optimization and reducing the scale drift over long sequences.
              <p>
               Extensive experiments on the KITTI and Argoverse Odometry dataset demonstrate the superiority of our proposed DVLO4D, which achieves state-of-the-art performance in terms of both pose accuracy and robustness. Additionally, our method has high efficiency, with an inference time of 82 ms, possessing the potential for the real-time deployment.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet2_04">
             16:50-16:55, Paper WeET2.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1518" name="modify2255" onclick="modify(2255,1518)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2255'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hier-SLAM: Scaling-Up Semantics in SLAM with a Hierarchically Categorical Gaussian Splatting
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#269225" title="Click to go to the Author Index">
             Li, Boying
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419888" title="Click to go to the Author Index">
             Cai, Zhixi
            </a>
           </td>
           <td class="r">
            Monash University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422363" title="Click to go to the Author Index">
             Li, Yuan-Fang
            </a>
           </td>
           <td class="r">
            Monash University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106056" title="Click to go to the Author Index">
             Reid, Ian
            </a>
           </td>
           <td class="r">
            University of Adelaide
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#212097" title="Click to go to the Author Index">
             Rezatofighi, Hamid
            </a>
           </td>
           <td class="r">
            Monash University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2255" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose Hier-SLAM, a semantic 3D Gaussian Splatting SLAM method featuring a novel hierarchical categorical representation, which enables accurate global 3D semantic mapping, scaling-up capability, and explicit semantic label prediction in the 3D world. The parameter usage in semantic SLAM systems increases significantly with the growing complexity of the environment, making it particularly challenging and costly for scene understanding. To address this problem, we introduce a novel hierarchical representation that encodes semantic information in a compact form into 3D Gaussian Splatting, leveraging the capabilities of large language models (LLMs). We further introduce a novel semantic loss designed to optimize hierarchical semantic information through both inter-level and cross-level optimization. Furthermore, we enhance the whole SLAM system, resulting in improved tracking and mapping performance. Our Hier-SLAM outperforms existing dense SLAM methods in both mapping and tracking accuracy, while achieving a 2x operation speed-up. Additionally, it achieves on-par semantic rendering performance compared to existing methods while significantly reducing storage and training time requirements. Rendering FPS impressively reaches 2,000 with semantic information and 3,000 without it. Most notably, it showcases the capability of handling the complex real-world scene with more than 500 semantic classes, highlighting its valuable scaling-up capability. The open-source code is available at https://github.com/LeeBY68/Hier-SLAM.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet2_05">
             16:55-17:00, Paper WeET2.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1519" name="modify4784" onclick="modify(4784,1519)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4784'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CLIP-Clique: Graph-Based Correspondence Matching Augmented by Vision Language Models for Object-Based Global Localization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#293680" title="Click to go to the Author Index">
             Matsuzaki, Shigemichi
            </a>
           </td>
           <td class="r">
            Toyota Motor Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#371572" title="Click to go to the Author Index">
             Tanaka, Kazuhito
            </a>
           </td>
           <td class="r">
            Toyota Motor Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#374936" title="Click to go to the Author Index">
             Shintani, Kazuhiro
            </a>
           </td>
           <td class="r">
            Toyota Motor Corporation
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4784" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper proposes a method of global localization on a map with semantic object landmarks. One of the most promising approaches for localization on object maps is to use semantic graph matching using landmark descriptors calculated from the distribution of surrounding objects. These descriptors are vulnerable to misclassification and partial observations. Moreover, many existing methods rely on inlier extraction using RANSAC, which is stochastic and prone to a high outlier rate. To address the former issue, we augment the correspondence matching using Vision Language Models (VLMs). Landmark discriminability is improved by VLM embeddings, which are independent of surrounding objects. In addition, inliers are estimated deterministically using a graph-theoretic approach. We also incorporate
             <p>
              pose calculation using the weighted least squares considering correspondence similarity and observation completeness to improve the robustness. We confirmed improvements in matching and pose estimation accuracy through experiments on ScanNet and TUM datasets.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet2_06">
             17:00-17:05, Paper WeET2.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1520" name="modify4804" onclick="modify(4804,1520)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4804'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CLOi-Mapper: Consistent, Lightweight, Robust, and Incremental Mapper with Embedded Systems for Commercial Robot Services
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#151640" title="Click to go to the Author Index">
             Noh, DongKi
            </a>
           </td>
           <td class="r">
            LG Electronics Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#227869" title="Click to go to the Author Index">
             Lim, Hyungtae
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#135538" title="Click to go to the Author Index">
             Eoh, Gyuho
            </a>
           </td>
           <td class="r">
            Tech University of Korea
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#195944" title="Click to go to the Author Index">
             Choi, Duckyu
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104629" title="Click to go to the Author Index">
             Choi, Jeong-Sik
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#242598" title="Click to go to the Author Index">
             Lim, Hyunjun
            </a>
           </td>
           <td class="r">
            Electronics and Telecommunication Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104112" title="Click to go to the Author Index">
             Baek, Seung-Min
            </a>
           </td>
           <td class="r">
            LG Electronics
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104490" title="Click to go to the Author Index">
             Myung, Hyun
            </a>
           </td>
           <td class="r">
            KAIST (Korea Advanced Institute of Science and Technology)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4804" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#service_robotics" title="Click to go to the Keyword Index">
               Service Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#embedded_systems_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Embedded Systems for Robotic and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In commercial autonomous service robots with several form factors, simultaneous localization and mapping (SLAM) is an essential technology
             <p>
              for providing proper services such as cleaning and guidance. Such robots require SLAM algorithms suitable for specific applications and environments. Hence, several SLAM frameworks have been proposed to address various requirements in the past decade. However, we have encountered challenges in implementing recent innovative frameworks when handling service robots with low-end processors and insufficient sensor data, such as low-resolution 2D LiDAR sensors. Specifically, regarding commercial robots, consistent performance in different hardware configurations and environments is more crucial than the performance dedicated to specific sensors or environments. Therefore, we propose a) a multi-stage approach for global pose estimation in embedded systems; b) a graph generation method with zero constraints for synchronized sensors; and c) a robust and memory-efficient method for long-term pose-graph optimization. As verified in in-home and large-scale indoor environments, the proposed method yields consistent global pose estimation for services in commercial fields. Furthermore, the proposed method exhibits potential commercial viability considering
              <p>
               the consistent performance verified via mass production and long-term (&gt; 5 years) operation.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet2_07">
             17:05-17:10, Paper WeET2.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1521" name="modify4867" onclick="modify(4867,1521)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4867'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              D2S: Representing Sparse Descriptors and 3D Coordinates for Camera Relocalization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#330184" title="Click to go to the Author Index">
             Bui, Bach-Thuan
            </a>
           </td>
           <td class="r">
            Ritsumeikan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#387509" title="Click to go to the Author Index">
             Bui, Huy Hoang
            </a>
           </td>
           <td class="r">
            Ritsumeikan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#184289" title="Click to go to the Author Index">
             Tran, Dinh Tuan
            </a>
           </td>
           <td class="r">
            College of Information Science and Engineering, Ritsumeikan Univ
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100204" title="Click to go to the Author Index">
             Lee, Joo-Ho
            </a>
           </td>
           <td class="r">
            Ritsumeikan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4867" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             State-of-the-art visual localization methods mostly rely on complex procedures to match local descriptors and 3D point clouds. However, these procedures can incur significant costs in terms of inference, storage, and updates over time. In this study, we propose a direct learning-based approach that utilizes a simple network named D2S to represent complex local descriptors and their scene coordinates. Our method is characterized by its simplicity and cost-effectiveness. It solely leverages a single RGB image for localization during the testing phase and only requires a lightweight model to encode a complex sparse scene. The proposed D2S employs a combination of a simple loss function and graph attention to selectively focus on robust descriptors while disregarding areas such as clouds, trees, and several dynamic objects. This selective attention enables D2S to effectively perform a binary-semantic classification for sparse descriptors. Additionally, we propose a simple outdoor dataset to evaluate the capabilities of visual localization methods in scene-specific generalization and self-updating from unlabeled observations. Our approach outperforms the previous regression-based methods in both indoor and outdoor environments. It demonstrates the ability to generalize beyond training data, including scenarios involving transitions from day to night and adapting to domain shifts. The source code, trained models, dataset, and demo videos are available at the following link: https://thpjp.github.io/d2s
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet3">
             <b>
              WeET3
             </b>
             Regular Session, 303
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1522" name="modifyWeET3" onclick="modsession(391,1522)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet3" title="Click to go to the Program at a Glance">
             <b>
              Offroad Navigation
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#101682" title="Click to go to the Author Index">
             Roy, Nicholas
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#119747" title="Click to go to the Author Index">
             Manderson, Travis
            </a>
           </td>
           <td class="r">
            McGill University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet3_01">
             16:35-16:40, Paper WeET3.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1523" name="modify462" onclick="modify(462,1523)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('462'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CAHSOR: Competence-Aware High-Speed Off-Road Ground Navigation in SE(3)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#399211" title="Click to go to the Author Index">
             Pokhrel, Anuj
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#349198" title="Click to go to the Author Index">
             Nazeri, Mohammad
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354757" title="Click to go to the Author Index">
             Datar, Aniket
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#177144" title="Click to go to the Author Index">
             Xiao, Xuesu
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab462" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             While the workspace of traditional ground vehi- cles is usually assumed to be in a 2D plane, i.e., SE(2), such an assumption may not hold when they drive at high speeds on unstructured off-road terrain: High-speed sharp turns on high- friction surfaces may lead to vehicle rollover; Turning aggres- sively on loose gravel or grass may violate the non-holonomic constraint and cause significant lateral sliding; Driving quickly on rugged terrain will produce extensive vibration along the vertical axis. Therefore, most offroad vehicles are currently limited to driving only at low speeds to assure vehicle stability and safety. In this work, we aim at empowering high-speed off-road vehicles with competence awareness in SE(3) so that they can reason about the consequences of taking aggressive maneuvers on different terrain with a 6-DoF forward kino- dynamic model. The kinodynamic model is learned from visual, speed, and
             <p>
              inertial Terrain Representation for Off-road Navigation ( TRON ) using multimodal, self-supervised vehicle-terrain interactions. We demonstrate the efficacy of our Competence-Aware High- Speed Off-Road ( CAHSOR ) navigation approach on a physical ground robot in both autonomous navigation and a human shared-control setup and show that CAHSOR can efficiently reduce vehicle instability by 62% while only compromising 8.6% average speed with the help of TRON .
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet3_02">
             16:40-16:45, Paper WeET3.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1524" name="modify1374" onclick="modify(1374,1524)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1374'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ROD: RGB-Only Fast and Efficient Off-Road Freespace Detection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#392927" title="Click to go to the Author Index">
             Sun, Tong
            </a>
           </td>
           <td class="r">
            University of Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395596" title="Click to go to the Author Index">
             Ye, Hongliang
            </a>
           </td>
           <td class="r">
            Zhejiang Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#234105" title="Click to go to the Author Index">
             Mei, Jilin
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395603" title="Click to go to the Author Index">
             Chen, Liang
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology: Beijing, CN
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#216058" title="Click to go to the Author Index">
             Zhao, Fangzhou
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#393318" title="Click to go to the Author Index">
             Zong, Leiqiang
            </a>
           </td>
           <td class="r">
            Beijing Special Vehicle Academy
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#207125" title="Click to go to the Author Index">
             Hu, Yu
            </a>
           </td>
           <td class="r">
            Institute of Computing Technology Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1374" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Off-road freespace detection is more challenging than on-road scenarios because of the blurred boundaries of traversable areas. Previous state-of-the-art (SOTA) methods employ multi-modal fusion of RGB images and LiDAR data. However, due to the significant increase in inference time when calculating surface normal maps from LiDAR data, multi-modal methods are not suitable for real-time applications, particularly in real-world scenarios where higher FPS is required compared to slow navigation. This paper presents a novel RGB-only approach for off-road freespace detection, named ROD, eliminating the reliance on LiDAR data and its computational demands. Specifically, we utilize a pre-trained Vision Transformer (ViT) to extract rich features from RGB images. Additionally, we design a lightweight yet efficient decoder, which together improve both precision and inference speed. ROD establishes a new SOTA on ORFD and RELLIS-3D datasets, as well as an inference speed of 50 FPS, significantly outperforming prior models. Our code will be available at https://github.com/STLIFE97/offroad_roadseg.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet3_03">
             16:45-16:50, Paper WeET3.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1525" name="modify1528" onclick="modify(1528,1525)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1528'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              JORD: A Benchmark Dataset for Off-Road LiDAR Place Recognition and SLAM
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372599" title="Click to go to the Author Index">
             Zhou, Wei
            </a>
           </td>
           <td class="r">
            Jilin University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#363572" title="Click to go to the Author Index">
             Zhang, Tongzhou
            </a>
           </td>
           <td class="r">
            Jilin University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418288" title="Click to go to the Author Index">
             Xu, Qian
            </a>
           </td>
           <td class="r">
            China North Vehicle Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#363575" title="Click to go to the Author Index">
             Chen, Yu
            </a>
           </td>
           <td class="r">
            Jilin University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#370282" title="Click to go to the Author Index">
             Hou, Minghui
            </a>
           </td>
           <td class="r">
            Jilin University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#363662" title="Click to go to the Author Index">
             Wang, Gang
            </a>
           </td>
           <td class="r">
            Jilin University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1528" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_slam" title="Click to go to the Keyword Index">
               Data Sets for SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mapping" title="Click to go to the Keyword Index">
               Mapping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Simultaneous localization and mapping (SLAM) is a crucial component of unmanned systems, playing a key role in autonomous navigation. Currently, most LiDAR SLAM methods are focused on structured environments. However, highly irregular off-road terrain poses more challenges for LiDAR SLAM tasks, but these environments are not fully represented in existing datasets. To address this issue, we introduce the first dedicated LiDAR SLAM benchmark dataset for off-road environments, named Jlurobot Off-Road Dadaset (JORD). This dataset is collected using a custom avenger data collection platform in large-scale forest off-road scenes, consisting of 8 LiDAR sequences with a total length of approximately 6.07 kilometers, containing 49,144 point cloud frames along with accurate 6DoF ground truth. The dataset includes multiple revisit information within the sequences, making it suitable for LiDAR place recognition and SLAM tasks. Furthermore, we employe several state-of-the-art methods for benchmarking to validate the dataset's challenges. The release of JORD aims to provide researchers with valuable resources to develop new approaches and explore novel directions for unmanned systems in off-road environments. The complete dataset and code is available at https://github.com/jiurobots/JORD.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet3_04">
             16:50-16:55, Paper WeET3.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1526" name="modify1856" onclick="modify(1856,1526)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1856'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Self-Reflective Perceptual Adaptation for Robust Ground Navigation in Unstructured Off-Road Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#201241" title="Click to go to the Author Index">
             Siva, Sriram
            </a>
           </td>
           <td class="r">
            US Army DEVCOM Army Research Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#329987" title="Click to go to the Author Index">
             Youngquist, Oscar
            </a>
           </td>
           <td class="r">
            University of Massachusetts Amherst
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#192056" title="Click to go to the Author Index">
             Wigness, Maggie
            </a>
           </td>
           <td class="r">
            U.S. Army Research Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102697" title="Click to go to the Author Index">
             Rogers III, John G.
            </a>
           </td>
           <td class="r">
            US Army Research Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#138554" title="Click to go to the Author Index">
             Zhang, Hao
            </a>
           </td>
           <td class="r">
            University of Massachusetts Amherst
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1856" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous ground robots navigating unstructured off-road environments face perceptual challenges, such as sensor obscuration or failure, which can lead to inaccurate perception or navigation failures. While robot adaptation has recently gained increasing attention, self-reflective robot adaptation, where robots understand and adjust to their own sensor limitations, remains under-explored. This paper proposes a novel approach for self-reflective perceptual adaptation in order to enhance robust off-road navigation. Our approach enables a robot to identify its own perceptual difficulties and dynamically adapt in challenging environments. The key novelty is learning a modality-invariant perceptual representation that encodes shared sensor data into a compact feature space. Within this representation space, the robot's dynamics model is also learned, which enables accurate prediction of future navigation paths. Extensive experiments in off-road environments with sensor obstructions and failures demonstrate that our method significantly improves adaptive capabilities and outperforms baseline and state-of-the-art approaches.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet3_05">
             16:55-17:00, Paper WeET3.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1527" name="modify3746" onclick="modify(3746,1527)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3746'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Dynamics Modeling Using Visual Terrain Features for High-Speed Autonomous Off-Road Driving
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#252690" title="Click to go to the Author Index">
             Gibson, Jason
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378751" title="Click to go to the Author Index">
             Alavilli, Anoushka
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#404181" title="Click to go to the Author Index">
             Tevere, Erica
            </a>
           </td>
           <td class="r">
            Jet Propulsion Laboratory, California Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#110087" title="Click to go to the Author Index">
             Theodorou, Evangelos
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256947" title="Click to go to the Author Index">
             Spieler, Patrick
            </a>
           </td>
           <td class="r">
            JPL
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3746" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Rapid autonomous traversal of unstructured ter- rain is essential for scenarios such as disaster response, search and rescue, or planetary exploration. As a vehicle navigates at the limit of its capabilities over extreme terrain, its dynamics can change suddenly and dramatically. For example, high-speed and varying terrain can affect parameters such as traction, tire slip, and rolling resistance. To achieve effective planning in such environments, it is crucial to have a dynamics model that can accurately anticipate these conditions. In this work, we present a hybrid model that predicts the changing dynamics induced by the terrain as a function of visual inputs. We leverage a pre- trained visual foundation model (VFM) such as DINOv2, which provides rich features that encode fine-grained semantic infor- mation. To use this dynamics model for planning, we propose an end-to-end training architecture for a projection distance independent feature encoder that compresses the information from the VFM, enabling the creation of a lightweight map of the environment at runtime. We validate our architecture on an extensive dataset (hundreds of kilometers of aggressive off-road driving) collected across multiple locations as part of the DARPA Robotic Autonomy in Complex Environments with Resiliency (RACER) program.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet3_06">
             17:00-17:05, Paper WeET3.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1528" name="modify3996" onclick="modify(3996,1528)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3996'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Digital Twins Meet the Koopman Operator: Data-Driven Learning for Robust Autonomy
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#249554" title="Click to go to the Author Index">
             Samak, Chinmay
            </a>
           </td>
           <td class="r">
            Clemson University International Center for Automotive Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#249560" title="Click to go to the Author Index">
             Samak, Tanmay
            </a>
           </td>
           <td class="r">
            Clemson University International Center for Automotive Research
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351323" title="Click to go to the Author Index">
             Joglekar, Ajinkya
            </a>
           </td>
           <td class="r">
            Clemson University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#330763" title="Click to go to the Author Index">
             Vaidya, Umesh
            </a>
           </td>
           <td class="r">
            Clemson University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101679" title="Click to go to the Author Index">
             Krovi, Venkat
            </a>
           </td>
           <td class="r">
            Clemson University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3996" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Contrary to on-road autonomous navigation, off-road autonomy is complicated by various factors ranging from sensing challenges to terrain variability. In such a milieu, data-driven approaches have been commonly employed to capture intricate vehicle-environment interactions effectively. However, the success of data-driven methods depends crucially on the quality and quantity of data, which can be compromised by large variability in off-road environments. To address these concerns, we present a novel methodology to recreate the exact vehicle and its target operating conditions digitally for domain-specific data generation. This enables us to effectively model off-road vehicle dynamics from simulation data using the Koopman operator theory, and employ the obtained models for local motion planning and optimal vehicle control. The capabilities of the proposed methodology are demonstrated through an autonomous navigation problem of a 1:5 scale vehicle, where a terrain-informed planner is employed for global mission planning. Results indicate a substantial improvement in off-road navigation performance with the proposed algorithm (5.84x) and underscore the efficacy of digital twinning in terms of improving the sample efficiency (3.2x) and reducing the sim2real gap (5.2%).
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet3_07">
             17:05-17:10, Paper WeET3.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1529" name="modify4555" onclick="modify(4555,1529)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4555'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Off-Road Freespace Detection with LiDAR-Camera Fusion and Self-Distillation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#227080" title="Click to go to the Author Index">
             Gu, Shuo
            </a>
           </td>
           <td class="r">
            Nanjing University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423601" title="Click to go to the Author Index">
             Gao, Ming
            </a>
           </td>
           <td class="r">
            Nanjing University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4555" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             LiDAR-camera fusion has gradually become the mainstream for the freespace detection in unstructured off-road environments. However, existing methods mainly use the traditional method to densify the sparse LiDAR data in the perspective view, which introduces noise and limits the representation ability. In this paper, we propose a lightweight end-to-end freespace detection network with cascaded LiDAR-camera fusion and multi-scale self-distillation. It first performs sparse freespace detection in the range view, and then projects the range-view features onto the perspective view and densifies them. The dense features obtained are fused with camera images to get the final freespace detection results. In our method, the cascaded fusion strategy reduces the impact of resolution differences between LiDAR point clouds and camera images, and the introduction of noise during the data densification process. The multi-scale self-distillation strategy distills knowledge from the LiDAR-camera fusion module to the perspective-view module to further improve the freespace detection performance using LiDAR data only. Experiments on the off-road ORFD datasets demonstrate the effectiveness of the proposed cascaded fusion and multi-scale self-distillation strategies, our method obtains 93.4% IoU at speeds of more than 50 Hz. It also achieves state-of-the-art performance among all LiDAR-based freespace detection methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet3_08">
             17:10-17:15, Paper WeET3.8
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1530" name="modify5029" onclick="modify(5029,1530)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5029'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning to Model and Plan for Wheeled Mobility on Vertically Challenging Terrain
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354757" title="Click to go to the Author Index">
             Datar, Aniket
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#349237" title="Click to go to the Author Index">
             Pan, Chenhui
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#177144" title="Click to go to the Author Index">
             Xiao, Xuesu
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5029" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Most autonomous navigation systems assume wheeled robots are rigid bodies and their 2D planar workspaces can be divided into free spaces and obstacles. However, recent wheeled mobility research, showing that wheeled platforms have the potential of moving over vertically challenging terrain (e.g., rocky outcroppings, rugged boulders, and fallen tree trunks), invalidate both assumptions. Navigating off-road vehicle chassis with long suspension travel and low tire pressure in places where the boundary between obstacles and free spaces is blurry requires precise 3D modeling of the interaction between the chassis and
             <p>
              the terrain, which is complicated by suspension and tire deformation, varying tire-terrain friction, vehicle weight distribution and momentum, etc. In this paper, we present a learning approach to model wheeled mobility, i.e., in terms of vehicle-terrain forward dynamics, and plan feasible, stable, and efficient motion to drive over vertically challenging terrain without rolling over or getting stuck. We present physical experiments on two wheeled robots and show that planning using our learned model can achieve up to 60% improvement in navigation success rate and 46% reduction in unstable chassis roll and pitch angles.
             </p>
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet4">
             <b>
              WeET4
             </b>
             Regular Session, 304
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1531" name="modifyWeET4" onclick="modsession(535,1531)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet4" title="Click to go to the Program at a Glance">
             <b>
              Sensor Fusion 4
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#102438" title="Click to go to the Author Index">
             Choi, Hyouk Ryeol
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#114431" title="Click to go to the Author Index">
             Huang, Guoquan (Paul)
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet4_01">
             16:35-16:40, Paper WeET4.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1532" name="modify16" onclick="modify(16,1532)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('16'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Dynamic Importance-Weighted Fusion Network Based on Dynamic Convolutions for Hand Posture Recognition: A Technique Based on Red, Green, Blue Plus Depth Cameras
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309360" title="Click to go to the Author Index">
             Qi, Jing
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#370427" title="Click to go to the Author Index">
             Ma, Li
            </a>
           </td>
           <td class="r">
            Hebei University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#140228" title="Click to go to the Author Index">
             Yu, Yushu
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab16" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Hand posture recognition enhances human-computer interaction, with existing algorithms mainly using RGB images or depth data. However, RGB images are affected by lighting and background, while depth data struggles to capture details, reducing accuracy. To address these issues, fusing RGB images and depth data has gained attention. Traditional fusion methods use fixed modal weights, which struggle to adapt to complex modal relationships, causing performance degradation. To resolve this, we propose a Fusion module incorporating Multi-Scale Gated Extraction (MSGE) for multi-scale feature extraction and gating, Context Sensitive Dynamic Filtering (CSDF) for dynamic weight adjustment based on modal importance, and Importance Weighted Fusion (IWF) for adaptive weighting. Based on this, this paper proposes a network that fuses RGB information and depth data, named Dynamic Importance-Weighted Fusion Network (DIWFNet). This network utilizes a dual-branch YOLOv5 framework integrated with four Fusion modules, fully leveraging the complementary nature of RGB images and depth data. Through dynamic weight distribution and adaptive feature convolution, it precisely captures and models the complex interactions between different modalities, enhancing the accuracy and robustness of hand posture recognition. Our method has shown excellent performance on the CUG dataset, NTU dataset, and self-built dataset, and has been successfully applied to robots in real operational environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet4_02">
             16:40-16:45, Paper WeET4.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1533" name="modify525" onclick="modify(525,1533)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('525'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robust 4D Radar-Aided Inertial Navigation for Aerial Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415424" title="Click to go to the Author Index">
             Zhu, Jinwen
            </a>
           </td>
           <td class="r">
            Meituan Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#219988" title="Click to go to the Author Index">
             Hu, Jun
            </a>
           </td>
           <td class="r">
            Meituan Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415429" title="Click to go to the Author Index">
             Zhao, Xudong
            </a>
           </td>
           <td class="r">
            Meituan Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#271337" title="Click to go to the Author Index">
             Lang, Xiaoming
            </a>
           </td>
           <td class="r">
            Meituan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267538" title="Click to go to the Author Index">
             Mao, Yinian
            </a>
           </td>
           <td class="r">
            Meituan-Dianping Group
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#114431" title="Click to go to the Author Index">
             Huang, Guoquan (Paul)
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab525" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             While LiDAR and cameras are becoming ubiquitous for unmanned aerial vehicles (UAVs) but can be ineffective in challenging environments, 4D millimeter-wave (MMW)radars that can provide robust 3D ranging and Doppler velocity measurements are less exploited for aerial navigation. In this paper, we develop an efficient and robust error-state Kalman filter (ESKF)-based radar-inertial navigation for UAVs. The key idea of the proposed approach is the point-to-distribution radar scan matching to provide motion constraints with proper uncertainty qualification, which are used to update the navigation states in a tightly coupled manner, along with the Doppler velocity measurements. Moreover, we propose a robust keyframe-based matching scheme against the prior map to bound the cumulative navigation errors and provide a radar-based global localization solution with high accuracy. Extensive real-world experimental validations have demonstrated that the proposed radar-aided inertial navigation outperforms state-of-the-art methods in both accuracy and robustness.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet4_03">
             16:45-16:50, Paper WeET4.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1534" name="modify1369" onclick="modify(1369,1534)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1369'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Semi-Elastic LiDAR-Inertial Odometry
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#307947" title="Click to go to the Author Index">
             Yuan, Zikang
            </a>
           </td>
           <td class="r">
            Huazhong University, Wuhan, 430073, China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#344165" title="Click to go to the Author Index">
             Lang, Fengtian
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#308417" title="Click to go to the Author Index">
             Xu, Tianle
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#385638" title="Click to go to the Author Index">
             Ming, Ruiye
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#376671" title="Click to go to the Author Index">
             Zhao, Chengwei
            </a>
           </td>
           <td class="r">
            Hangzhou Guochen Robot Technology Company Limited
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#201893" title="Click to go to the Author Index">
             Yang, Xin
            </a>
           </td>
           <td class="r">
            Huazhong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1369" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work proposes a semi-elastic optimization-based LiDAR-inertial state estimation method, which balances the constraints from LiDAR, IMU and consistency according to their unique characteristics, thereby imparts appropriate elasticity for current state to be optimized to the correct value, and ensure the accuracy, consistency, and robustness of state estimation. We incorporate the proposed LiDAR-inertial state estimation method into a self-developed optimization-based LiDAR-inertial odometry (LIO) framework. Experimental results on four public datasets demonstrate that the proposed method enhances the performance of optimization-based LiDAR-inertial state estimation. We have released the source code of this work for the development of the community.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet4_04">
             16:50-16:55, Paper WeET4.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1535" name="modify1798" onclick="modify(1798,1535)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1798'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DOGE: An Extrinsic Orientation and Gyroscope Bias Estimation for Visual-Inertial Odometry Initialization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#304558" title="Click to go to the Author Index">
             Xu, Zewen
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Science
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#201400" title="Click to go to the Author Index">
             He, Yijia
            </a>
           </td>
           <td class="r">
            TCL RayNeo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#231587" title="Click to go to the Author Index">
             Wei, Hao
            </a>
           </td>
           <td class="r">
            University of Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#120553" title="Click to go to the Author Index">
             Wu, Yihong
            </a>
           </td>
           <td class="r">
            National Laboratory of Pattern Recognition, InstituteofAutomatio
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1798" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#visual_inertial_slam" title="Click to go to the Keyword Index">
               Visual-Inertial SLAM
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Most existing visual-inertial odometry (VIO) initialization methods rely on accurate pre-calibrated extrinsic parameters. However, during long-term use, irreversible structural deformation caused by temperature changes, mechanical squeezing, etc. will cause changes in extrinsic parameters, especially in the rotational part. Existing initialization methods that simultaneously estimate extrinsic parameters suffer from poor robustness, low precision, and long initialization latency due to the need for sufficient translational motion. To address these problems, we propose a novel VIO initialization method, which jointly considers extrinsic orientation and gyroscope bias within the normal epipolar constraints, achieving higher precision and better robustness without delayed rotational calibration. First, a rotation-only constraint is designed for extrinsic orientation and gyroscope bias estimation, which tightly couples gyroscope measurements and visual observations and can be solved in pure-rotation cases. Second, we propose a weighting strategy together with a failure detection strategy to enhance the precision and robustness of the estimator. Finally, we leverage Maximum A Posteriori to refine the results before enough translation parallax comes. Extensive experiments have demonstrated that our method outperforms the state-of-the-art methods in both accuracy and robustness while maintaining competitive efficiency.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet4_05">
             16:55-17:00, Paper WeET4.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1536" name="modify2958" onclick="modify(2958,1536)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2958'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GaRLIO: Gravity Enhanced Radar-LiDAR-Inertial Odometry
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#381697" title="Click to go to the Author Index">
             Noh, Chiyun
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#342598" title="Click to go to the Author Index">
             Yang, Wooseong
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#311476" title="Click to go to the Author Index">
             Jung, Minwoo
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#311328" title="Click to go to the Author Index">
             Jung, Sangwoo
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#126962" title="Click to go to the Author Index">
             Kim, Ayoung
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2958" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#range_sensing" title="Click to go to the Keyword Index">
               Range Sensing
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Recently, gravity has been highlighted as a crucial constraint for state estimation to alleviate potential vertical drift. Existing online gravity estimation methods rely on pose estimation combined with IMU measurements, which is considered best practice when direct velocity measurements are unavailable. However, with radar sensors providing direct velocity data—a measurement not yet utilized for gravity estimation—we found a significant opportunity to improve gravity estimation accuracy substantially. GaRLIO, the proposed gravity- enhanced Radar-LiDAR-Inertial Odometry, can robustly predict gravity to reduce vertical drift while simultaneously enhancing state estimation performance using pointwise velocity measurements. Furthermore, GaRLIO ensures robustness in dynamic environments by utilizing radar to remove dynamic objects from LiDAR point clouds. Our method is validated through experiments in various environments prone to vertical drift, demonstrating superior performance compared to traditional LiDAR-Inertial Odometry methods. We make our source code publicly available to encourage further research and development. https://github.com/ChiyunNoh/GaRLIO
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet4_06">
             17:00-17:05, Paper WeET4.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1537" name="modify4048" onclick="modify(4048,1537)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4048'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              AF-RLIO: Adaptive Fusion of Radar-LiDAR-Inertial Information for Robust Odometry in Challenging Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426224" title="Click to go to the Author Index">
             Qian, Chenglong
            </a>
           </td>
           <td class="r">
            Zhejiang University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#294245" title="Click to go to the Author Index">
             Xu, Yang
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#355541" title="Click to go to the Author Index">
             Shi, Xiufang
            </a>
           </td>
           <td class="r">
            Zhejiang University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#163844" title="Click to go to the Author Index">
             Chen, Jiming
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#191287" title="Click to go to the Author Index">
             Li, Liang
            </a>
           </td>
           <td class="r">
            Zhejiang Univerisity
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4048" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In robotic navigation, maintaining precise pose estimation and navigation in complex and dynamic environments is crucial. However, environmental challenges such as smoke, tunnels, and adverse weather can significantly degrade the performance of single-sensor systems like LiDAR or GPS, compromising the overall stability and safety of autonomous robots. To address these challenges, we propose AF-RLIO: an adaptive fusion approach that integrates 4D millimeter-wave radar, LiDAR, inertial measurement unit (IMU), and GPS to leverage the complementary strengths of these sensors for robust odometry estimation in complex environments. Our method consists of three key modules. Firstly, the pre-processing module utilizes radar data to assist LiDAR in removing dynamic points and determining when environmental conditions are degraded for LiDAR. Secondly, the dynamic-aware multimodal odometry selects appropriate point cloud data for scan-to-map matching and tightly couples it with the IMU using the Iterative Error State Kalman Filter. Lastly, the factor graph optimization module balances weights between odometry and GPS data, constructing a pose graph for optimization. The proposed approach has been evaluated on datasets and tested in real-world robotic environments, demonstrating its effectiveness and advantages over existing methods in challenging conditions such as smoke and tunnels. Furthermore, we open source our code at https://github.com/NeSC-IV/AF-RLIO.git to benefit the research community.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet4_07">
             17:05-17:10, Paper WeET4.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1538" name="modify5035" onclick="modify(5035,1538)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5035'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Adaptive Measurement Model-Based Fusion of Capacitive Proximity Sensor and LiDAR for Improved Mobile Robot Perception
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#383632" title="Click to go to the Author Index">
             Kang, Hyunchang
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#268073" title="Click to go to the Author Index">
             Yim, Hongsik
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#412677" title="Click to go to the Author Index">
             Sung, HyukJae
            </a>
           </td>
           <td class="r">
            SUNGKYUNKWAN UNIVERSITY
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102438" title="Click to go to the Author Index">
             Choi, Hyouk Ryeol
            </a>
           </td>
           <td class="r">
            Sungkyunkwan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5035" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_collaboration" title="Click to go to the Keyword Index">
               Human-Robot Collaboration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This study introduces a novel algorithm that combines a custom-developed capacitive proximity sensor with LiDAR. This integration targets the limitations of using single-sensor systems for mobile robot perception. Our approach deals with the non-Gaussian distribution that arises during the nonlinear transformation of capacitive sensor data into distance measurements. The non-Gaussian distribution resulting from this nonlinear transformation is linearized using a first-order Taylor approximation, creating a measurement model unique to our sensor. This method helps establish a linear relationship between capacitance values and their corresponding distance measurements. Assuming that the capacitance’s standard deviation remains constant, it is modeled as a distance function. By linearizing the capacitance data and synthesizing it with LiDAR data using Gaussian methods, we fuse the sensor information to enhance integration. This results in more precise and robust distance measurements than those obtained through traditional Extended Kalman Filter (EKF) and Adaptive Extended Kalman Filter (AEKF) methods. The proposed algorithm is designed for real-time data processing, significantly improving the robot’s state estimation accuracy and stability in various environments. This study offers a reliable method for positional estimation of mobile robots, showcasing outstanding fusion performance in complex settings.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet5">
             <b>
              WeET5
             </b>
             Regular Session, 305
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1539" name="modifyWeET5" onclick="modsession(21,1539)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet5" title="Click to go to the Program at a Glance">
             <b>
              Aerial Robots 3
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#124265" title="Click to go to the Author Index">
             Schoellig, Angela P.
            </a>
           </td>
           <td class="r">
            TU Munich
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#204392" title="Click to go to the Author Index">
             Jagannatha Sanket, Nitin
            </a>
           </td>
           <td class="r">
            Worcester Polytechnic Institute
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet5_01">
             16:35-16:40, Paper WeET5.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1540" name="modify657" onclick="modify(657,1540)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('657'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robust Attitude Control with Fixed Exponential Rate of Convergence and Consideration of Motor Dynamics for Tilt Quadrotor Using Quaternions (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395959" title="Click to go to the Author Index">
             Seshasayanan, Sathyanarayanan
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology Kanpur
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418501" title="Click to go to the Author Index">
             De, Souradip
            </a>
           </td>
           <td class="r">
            Assistant Professor, Mnnit Allahabad
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#257267" title="Click to go to the Author Index">
             Sahoo, Soumya Ranjan
            </a>
           </td>
           <td class="r">
            Indian Institute of Technology Kanpur
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab657" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the existing literature on the robust control design of UAV systems, the controllers are designed without considering motor dynamics. Hence, if these controller gains are not correctly tuned, the system undergoes oscillation and may even go unstable. We have demonstrated this through an experiment in this work. Here, we propose a novel control strategy that considers actuator parameter uncertainties, including motor dynamics for a tilt quadrotor. This strategy is based on the traditional two-loop control scheme where the inner loop controls the angular velocity, and the outer loop controls the vehicle’s attitude based on quaternions. In the quaternion-based controller, usually, the convergence rate increases when the quaternion starts closer to its equilibrium point, thus making it challenging to design a linear controller for the inner loop. To overcome this, we propose a nonlinear control with a varying gain for the outer loop that ensures the quaternion has a fixed convergence rate. We propose the control design of the inner loop, which consists of a disturbance observer (DOB) and a linear controller. The DOB is optimally designed to minimize external disturbances in the presence of model uncertainties. With the DOB, a linear controller is designed for the inner loop, guaranteeing robust stability and performance against the model and actuator parameter uncertainties. The results of experimental flights are reported in this paper.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet5_02">
             16:40-16:45, Paper WeET5.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1541" name="modify684" onclick="modify(684,1541)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('684'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Flying through Moving Gates without Full State Estimation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#362565" title="Click to go to the Author Index">
             Römer, Ralf
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416567" title="Click to go to the Author Index">
             Emmert, Tim
            </a>
           </td>
           <td class="r">
            TU Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#124265" title="Click to go to the Author Index">
             Schoellig, Angela P.
            </a>
           </td>
           <td class="r">
            TU Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab684" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous drone racing requires powerful perception, planning, and control and has become a benchmark and test field for autonomous, agile flight. Existing work usually assumes static race tracks with known maps, which enables offline planning of time-optimal trajectories, performing localization to the gates to reduce the drift in visual-inertial odometry (VIO) for state estimation or training learning-based methods for the particular race track and operating environment. In contrast, many real-world tasks like disaster response or delivery need to be performed in unknown and dynamic environments. To make drone racing more robust against unseen environments and moving gates, we propose a control algorithm that operates without a race track map or VIO, relying solely on monocular measurements of the line of sight to the gates. For this purpose, we adopt the law of proportional navigation (PN) to accurately fly through the gates despite gate motions or wind. We formulate the PN-informed vision-based control problem for drone racing as a constrained optimization problem and derive a closed-form optimal solution. Through simulations and real-world experiments, we demonstrate that our algorithm can navigate through moving gates at high speeds while being robust to different gate movements, model errors, wind, and delays.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet5_03">
             16:45-16:50, Paper WeET5.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1542" name="modify1049" onclick="modify(1049,1542)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1049'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Collapsible Airfoil Single Actuator ROtor-Craft (CASARO) - Construction and Analysis of a Soft Rotary Wing Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#224063" title="Click to go to the Author Index">
             Ang, Wei Jun
            </a>
           </td>
           <td class="r">
            Singapore University of Technology &amp; Design
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#236742" title="Click to go to the Author Index">
             Tang, Emmanuel
            </a>
           </td>
           <td class="r">
            Singapore University of Technology &amp; Design
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#223470" title="Click to go to the Author Index">
             Ng, Matthew
            </a>
           </td>
           <td class="r">
            Singapore University of Technology and Design
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107237" title="Click to go to the Author Index">
             Foong, Shaohui
            </a>
           </td>
           <td class="r">
            Singapore University of Technology and Design
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1049" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_materials_and_design" title="Click to go to the Keyword Index">
               Soft Robot Materials and Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, a soft rotary wing robot capable of flight and control is presented. The Collapsible Airfoil Single Actuator ROtor-craft (CASARO) is a single actuator monocopter that derives its geometric properties from the Samara seed. CASARO achieves better flight efficiency, lift, and handling ergonomics by reducing its overall volume by 91.7% when collapsed and stowed. Unlike conventional rotorcraft, CASARO uses a non-rigid fabric wing to produce lift in flight. It utilizes the robot’s rotational velocity to maintain tension within its fabric and airframe, providing adequate lift during its hover state. The conception, design, construction, and control of the soft monowing are demonstrated, including its capability to reduce its footprint with its soft fabric construction. To analyze the flight dynamics of CASARO, the craft is flown indoors autonomously, tracking its wing surface, craft body attitude, and position with various step inputs to observe different wing dynamics. CASARO is also capable of being deployed outdoors for real-life human-operated flight.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet5_04">
             16:50-16:55, Paper WeET5.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1543" name="modify2616" onclick="modify(2616,1543)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2616'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              VizFlyt: Perception-Centric Pedagogical Framework for Autonomous Aerial Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#388249" title="Click to go to the Author Index">
             Srivastava, Kushagra
            </a>
           </td>
           <td class="r">
            Worcester Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424513" title="Click to go to the Author Index">
             Kulkarni, Rutwik Sudhakar
            </a>
           </td>
           <td class="r">
            Worcester Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#388243" title="Click to go to the Author Index">
             Velmurugan, Manoj
            </a>
           </td>
           <td class="r">
            Worcester Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#204392" title="Click to go to the Author Index">
             Jagannatha Sanket, Nitin
            </a>
           </td>
           <td class="r">
            Worcester Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2616" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#education_robotics" title="Click to go to the Keyword Index">
               Education Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous aerial robots are becoming commonplace in our lives. Hands-on aerial robotics courses are pivotal in training the next-generation workforce to meet the growing market demands. Such an efficient and compelling course depends on a reliable testbed. In this paper, we present VizFlyt, an open-source perception-centric Hardware-In-The-Loop (HITL) photorealistic testing framework for aerial robotics courses. We utilize pose from an external localization system to hallucinate real-time and photorealistic visual sensors using 3D Gaussian Splatting. This enables stress-free testing of autonomy algorithms on aerial robots without the risk of crashing into obstacles. We achieve over 100Hz of system update rate. Lastly, we build upon our past experiences of offering hands-on aerial robotics courses and propose a new open-source and open-hardware curriculum based on VizFlyt for the future. We test our framework on various course projects in real-world HITL experiments and present the results showing the efficacy of such a system and its large potential use cases. Code, datasets, hardware guides and demo videos are available at https://pear.wpi.edu/research/vizflyt.html
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet5_05">
             16:55-17:00, Paper WeET5.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1544" name="modify2949" onclick="modify(2949,1544)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2949'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Distributed Loitering Synchronization with Fixed-Wing UAVs
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379722" title="Click to go to the Author Index">
             AlKatheeri, Ahmed
            </a>
           </td>
           <td class="r">
            NA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#365742" title="Click to go to the Author Index">
             Barcis, Agata
            </a>
           </td>
           <td class="r">
            Technology Innovation Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#147435" title="Click to go to the Author Index">
             Ferrante, Eliseo
            </a>
           </td>
           <td class="r">
            Vrije Universiteit Amsterdam
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2949" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#distributed_robot_systems" title="Click to go to the Keyword Index">
               Distributed Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Distributed loitering synchronization is the process whereby a group of fixed-wing Unmanned Aerial Vehicles (UAVs) align with each other while they follow a circular path in the air. This process is essential to establish proper initial conditions for missions in the real world. We evaluate the performance of three synchronization algorithms using a setup of continuously moving fixed-wing drones randomly placed around a loitering circle. We consider the algorithm based on distributed consensus as a baseline. We propose two methods: the Minimum Of Shortest Arc (MOSA) algorithm that outperforms the baseline in this setup and Firefly multi-Pulse Synchronization (FPS), which is inspired by firefly synchronization. The latter method requires 10 times less communication while maintaining a performance comparable to the baseline. These algorithms were first tested in a simple simulation, then a more realistic simulation environment using Gazebo in which fixed-wing dynamics are considered. The proposed algorithms are rigorously tested in simulation through multiple trials involving a group of 10 UAVs, confirming the effectiveness of our approaches. The results were then validated in real flights using 3 fixed-wing drones. Index Terms— Fixed-Wing UAVs, Distributed Synchronization, Multi-Robot Systems, Pulse-Coupled Oscillators
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet5_06">
             17:00-17:05, Paper WeET5.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1545" name="modify3255" onclick="modify(3255,1545)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3255'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Map-Free Deep Learning-Based Framework for Gate-To-Gate Monocular Visual Navigation Aboard Miniaturized Aerial Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419656" title="Click to go to the Author Index">
             Scarciglia, Lorenzo
            </a>
           </td>
           <td class="r">
            SUPSI, IDSIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#141042" title="Click to go to the Author Index">
             Paolillo, Antonio
            </a>
           </td>
           <td class="r">
            IDSIA USI-SUPSI
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#270112" title="Click to go to the Author Index">
             Palossi, Daniele
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3255" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#micro_nano_robots" title="Click to go to the Keyword Index">
               Micro/Nano Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Palm-sized autonomous nano-drones, i.e., sub-50 g in weight, recently entered the drone racing scenario, where they are tasked to avoid obstacles and navigate as fast as possible through gates. However, in contrast with their bigger counterparts, i.e., kg-scale drones, nano-drones expose three orders of magnitude less onboard memory and compute power, demanding more efficient and lightweight vision-based pipelines to win the race. This work presents a map-free vision-based (using only a monocular camera) autonomous nano-drone that combines a real-time deep learning gate detection front-end with a classic yet elegant and effective visual servoing control back-end, only relying on onboard resources. Starting from two state-of-the-art tiny deep learning models, we adapt them for our specific task, and after a mixed simulator-real-world training, we integrate and deploy them aboard our nano-drone. Our best-performing pipeline costs of only 24 M multiply- accumulate operations per frame, resulting in a closed-loop control performance of 30 Hz, while achieving a gate detection root mean square error of 1.4 pixels, on our∼20 k real-world image dataset. In-field experiments highlight the capability of our nano-drone to successfully navigate through 15 gates in 4 min, never crashing and covering a total travel distance of ∼100 m, with a peak flight speed of 1.9 m/s. Finally, to stress the generalization capability of our system, we also test it in a never-seen-before environment, where it navigates through gates for more than 4 min.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet5_07">
             17:05-17:10, Paper WeET5.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1546" name="modify4935" onclick="modify(4935,1546)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4935'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Agile Fixed-Wing UAVs for Urban Swarm Operations (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267276" title="Click to go to the Author Index">
             Basescu, Max
            </a>
           </td>
           <td class="r">
            Johns Hopkins University Applied Physics Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#289508" title="Click to go to the Author Index">
             Polevoy, Adam
            </a>
           </td>
           <td class="r">
            Johns Hopkins University Applied Physics Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#225533" title="Click to go to the Author Index">
             Yeh, Bryanna
            </a>
           </td>
           <td class="r">
            The Johns Hopkins University Applied Physics Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309950" title="Click to go to the Author Index">
             Scheuer, Luca
            </a>
           </td>
           <td class="r">
            Johns Hopkins University Applied Physics Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#431302" title="Click to go to the Author Index">
             Sutton, Erin
            </a>
           </td>
           <td class="r">
            Johns Hopkins University Applied Physics Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#148235" title="Click to go to the Author Index">
             Moore, Joseph
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4935" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Fixed-wing uncrewed aerial vehicles (UAVs) offer significant performance advantages over rotary-wing UAVs in terms of speed, endurance, and efficiency. Such attributes make these vehicles ideally suited for long-range or high-speed reconnaissance operations and position them as valuable complementary members of a heterogeneous multi-robot team. However, these vehicles have traditionally been severely limited with regards to both vertical take-off and landing (VTOL) as well as maneuverability, which greatly restricts their utility in environments characterized by complex obstacle fields (e.g., forests or urban centers).
             <p>
              This paper describes a set of algorithms and hardware advancements that enable agile fixed-wing UAVs to operate as members of a swarm in complex urban environments. At the core of our approach is a direct nonlinear model predictive control (NMPC) algorithm that is capable of controlling fixed-wing UAVs through aggressive post-stall maneuvers. We demonstrate in hardware how our online planning and control technique can enable navigation through tight corridors and in close proximity to obstacles. We also demonstrate how our approach can be combined with onboard stereo vision to enable high speed flight in unknown environments. Finally, we describe our method for achieving swarm system integration; this includes a gimballed propeller design to facilitate automatic take-off, a precision deep-stall landing capability, and multi-vehicle collision avoidance.
             </p>
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet6">
             <b>
              WeET6
             </b>
             Regular Session, 307
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1547" name="modifyWeET6" onclick="modsession(229,1547)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet6" title="Click to go to the Program at a Glance">
             <b>
              Learning for Legged Locomotion 1
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#149893" title="Click to go to the Author Index">
             Atanasov, Nikolay
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#280419" title="Click to go to the Author Index">
             Wang, Xiaolong
            </a>
           </td>
           <td class="r">
            UC San Diego
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet6_01">
             16:35-16:40, Paper WeET6.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1548" name="modify2771" onclick="modify(2771,1548)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2771'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Offline Adaptation of Quadrupeds Using Diffusion Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424644" title="Click to go to the Author Index">
             O'Mahoney, Reece
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#257119" title="Click to go to the Author Index">
             Mitchell, Alexander Luis
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#271349" title="Click to go to the Author Index">
             Yu, Wanming
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106689" title="Click to go to the Author Index">
             Posner, Ingmar
            </a>
           </td>
           <td class="r">
            Oxford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#123323" title="Click to go to the Author Index">
             Havoutis, Ioannis
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2771" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a diffusion-based approach to quadrupedal locomotion that simultaneously addresses the limitations of learning and interpolating between multiple skills (modes) and of offline adapting to new locomotion behaviours after training. This is the first framework to apply classifier-guided diffusion to quadruped locomotion and demonstrate its efficacy by extracting goal-conditioned behaviour from an originally unlabelled dataset. We show that these capabilities are compatible with a multi-skill policy and can be applied with little modification. We verify the validity of our approach with hardware experiments on the ANYmal quadruped platform.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet6_02">
             16:40-16:45, Paper WeET6.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1549" name="modify3028" onclick="modify(3028,1549)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3028'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              High-Performance Reinforcement Learning on Spot: Optimizing Simulation Parameters with Distributional Measures
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#278953" title="Click to go to the Author Index">
             Miller, A.J.
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#333831" title="Click to go to the Author Index">
             Yu, Fangzhou
            </a>
           </td>
           <td class="r">
            Robotics and AI Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424824" title="Click to go to the Author Index">
             Brauckmann, Michael
            </a>
           </td>
           <td class="r">
            AI Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#166522" title="Click to go to the Author Index">
             Farshidian, Farbod
            </a>
           </td>
           <td class="r">
            Robotics and AI Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3028" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work presents an overview of the technical details behind a high-performance reinforcement learning policy deployment with the Spot RL Researcher Development Kit for low-level motor access on Boston Dynamic’s Spot. This represents the first public demonstration of an end-to-end reinforcement learning policy deployed on Spot hardware with training code publicly available through Nvidia IsaacLab and deployment code available through Boston Dynamics. We utilize Wasserstein Distance and Maximum Mean Discrepancy to quantify the distributional dissimilarity of data collected on hardware and in simulation to measure our sim-to-real gap. We use these measures as a scoring function for the Covariance Matrix Adaptation Evolution Strategy to optimize simulated parameters that are unknown or difficult to measure from Spot. Our procedure for modeling and training produces high-quality reinforcement learning policies capable of multiple gaits, including a flight phase. We deploy policies capable of over 5.2m/s locomotion, more than triple Spot’s default controller maximum speed, robustness to slippery surfaces, disturbance rejection, and overall agility previously unseen on Spot. We detail our method and release our code to support future work on Spot with the low-level API.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet6_03">
             16:45-16:50, Paper WeET6.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1550" name="modify3338" onclick="modify(3338,1550)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3338'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              HOVER: Versatile Neural Whole-Body Controller for Humanoid Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379756" title="Click to go to the Author Index">
             He, Tairan
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379763" title="Click to go to the Author Index">
             Xiao, Wenli
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395586" title="Click to go to the Author Index">
             Lin, Toru
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#278518" title="Click to go to the Author Index">
             Luo, Zhengyi
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#241233" title="Click to go to the Author Index">
             Xu, Zhenjia
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#342351" title="Click to go to the Author Index">
             Jiang, Zhenyu
            </a>
           </td>
           <td class="r">
            The Unversity of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#219045" title="Click to go to the Author Index">
             Kautz, Jan
            </a>
           </td>
           <td class="r">
            NVIDIA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#171352" title="Click to go to the Author Index">
             Liu, Changliu
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#236627" title="Click to go to the Author Index">
             Shi, Guanya
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#280419" title="Click to go to the Author Index">
             Wang, Xiaolong
            </a>
           </td>
           <td class="r">
            UC San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#280356" title="Click to go to the Author Index">
             Fan, Linxi
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203352" title="Click to go to the Author Index">
             Zhu, Yuke
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3338" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#whole_body_motion_planning_and_control" title="Click to go to the Keyword Index">
               Whole-Body Motion Planning and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Humanoid whole-body control requires adapting to diverse tasks such as navigation, loco-manipulation, and tabletop manipulation, each demanding a different mode of control. For example, navigation relies on root velocity or position tracking, while tabletop manipulation prioritizes upper-body joint angle tracking. Existing approaches typically train individual policies tailored to a specific command space, limiting their transferability across modes. We present the key insight that full-body kinematic motion imitation can serve as a common abstraction for all these tasks and provide general-purpose motor skills for learning multiple modes of whole-body control. Building on this, we propose HOVER (Humanoid Versatile Controller), a multi-mode policy distillation framework that consolidates diverse control modes into a unified policy. HOVER enables seamless transitions between control modes while preserving the distinct advantages of each, offering a robust and scalable solution for humanoid control across a wide range of modes. By eliminating the need for policy retraining for each control mode, our approach improves efficiency and flexibility for future humanoid applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet6_04">
             16:50-16:55, Paper WeET6.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1551" name="modify3833" onclick="modify(3833,1551)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3833'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Humanoid Locomotion with Perceptive Internal Model
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#403048" title="Click to go to the Author Index">
             Long, Junfeng
            </a>
           </td>
           <td class="r">
            Shanghai AI Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309185" title="Click to go to the Author Index">
             Ren, Junli
            </a>
           </td>
           <td class="r">
            Hong Kong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#331836" title="Click to go to the Author Index">
             Shi, Moji
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424556" title="Click to go to the Author Index">
             Wong, Ziseoi
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339383" title="Click to go to the Author Index">
             Huang, Tao
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#343034" title="Click to go to the Author Index">
             Luo, Ping
            </a>
           </td>
           <td class="r">
            The University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#359992" title="Click to go to the Author Index">
             Pang, Jiangmiao
            </a>
           </td>
           <td class="r">
            Shanghai AI Laboratory
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3833" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#humanoid_robot_systems" title="Click to go to the Keyword Index">
               Humanoid Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In contrast to quadruped robots that can navigate diverse terrains using a "blind" policy, humanoid robots require accurate perception for stable locomotion due to their high degrees of freedom and inherently unstable morphology. However, incorporating perceptual signals often introduces additional disturbances to the system, potentially reducing its robustness, generalizability, and efficiency. This paper presents the Perceptive Internal Model (PIM), which relies on onboard, continuously updated elevation maps centered around the robot to perceive its surroundings. We train the policy using ground-truth obstacle heights surrounding the robot in simulation, optimizing it based on the Hybrid Internal Model (HIM), and perform inference with heights sampled from the constructed elevation map. Unlike previous methods that directly encode depth maps or raw point clouds, our approach allows the robot to perceive the terrain beneath its feet clearly and is less affected by camera movement or noise. Furthermore, since depth map rendering is not required in simulation, our method introduces minimal additional computational costs and can train the policy in 3 hours on an RTX 4090 GPU. We verify the effectiveness of our method across various humanoid robots, various indoor and outdoor terrains, stairs, and various sensor configurations. Our method can enable a humanoid robot to continuously climb stairs and has the potential to serve as a foundational algorithm for the development of future humanoid control methods.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet6_05">
             16:55-17:00, Paper WeET6.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1552" name="modify4278" onclick="modify(4278,1552)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4278'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Learning Framework for Diverse Legged Robot Locomotion Using Barrier-Based Style Rewards
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#313945" title="Click to go to the Author Index">
             Kim, Gijeong
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology, KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416503" title="Click to go to the Author Index">
             Lee, Yonghoon
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology, KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#138298" title="Click to go to the Author Index">
             Park, Hae-Won
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4278" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work introduces a model-free reinforcement learning framework that enables various modes of motion (quadruped, tripod, or biped) and diverse tasks for legged robot locomotion. We employ a motion-style reward based on a relaxed logarithmic barrier function as a soft constraint, to bias the learning process toward the desired motion style, such as gait, foot clearance, joint position, or body height. The predefined gait cycle is encoded in a flexible manner, facilitating gait adjustments throughout the learning process. Extensive experiments demonstrate that KAIST HOUND, a 45 kg robotic system, can achieve biped, tripod, and quadruped locomotion using the proposed framework; quadrupedal capabilities include traversing uneven terrain, galloping at 4.67 m/s, and overcoming obstacles up to 58 cm (67 cm for HOUND2); bipedal capabilities include running at 3.6 m/s, carrying a 7.5 kg object, and ascending stairs-all performed without exteroceptive input.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet6_06">
             17:00-17:05, Paper WeET6.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1553" name="modify4379" onclick="modify(4379,1553)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4379'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              WildLMa: Long Horizon Loco-Manipulation in the Wild
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#313611" title="Click to go to the Author Index">
             Qiu, Ri-Zhao
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416217" title="Click to go to the Author Index">
             Song, Yuchen
            </a>
           </td>
           <td class="r">
            UC San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#370870" title="Click to go to the Author Index">
             Peng, Xuanbin
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#361575" title="Click to go to the Author Index">
             Suryadevara, Sai Aneesh
            </a>
           </td>
           <td class="r">
            University of California San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354897" title="Click to go to the Author Index">
             Yang, Ge
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338828" title="Click to go to the Author Index">
             Liu, Minghuan
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#386085" title="Click to go to the Author Index">
             Ji, Mazeyu
            </a>
           </td>
           <td class="r">
            UCSD
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#376445" title="Click to go to the Author Index">
             Jia, Chengzhe
            </a>
           </td>
           <td class="r">
            University of California SanDiego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#308775" title="Click to go to the Author Index">
             Yang, Ruihan
            </a>
           </td>
           <td class="r">
            UC San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424340" title="Click to go to the Author Index">
             Xueyan Zou, Zou
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#280419" title="Click to go to the Author Index">
             Wang, Xiaolong
            </a>
           </td>
           <td class="r">
            UC San Diego
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4379" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             `In-the-wild' mobile manipulation aims at deploying robots in diverse real-world environments, which requires the robot to (1) have skills that generalize across object configurations; (2) be capable of long-horizon task execution in diverse environments; and (3) perform complex manipulation beyond pick-and-place. Quadruped robots with manipulators hold promise for such an ability for the extended workspace and robust locomotion, but existing results do not investigate such a capability. This paper proposes WildLMa with three components to address these issues: (1) a learned low-level controller for VR-enabled whole-body tele-operation and traversability; (2) WildLMa-Skill -- a library of generalizable visuomotor skills acquired via imitation learning or analytical planner and (3) WildLMa-Planner -- an LLM planner that interfaces and coordinates these skills. WildLMa exploits CLIP for language-conditioned imitation learning that empirically generalizes to objects unseen in training demonstrations. We then show these skills can be effectively interfaced with an LLM planner for autonomous long-horizon execution. Besides extensive quantitative evaluation, we qualitatively demonstrate practical robot applications, such as cleaning up trash in university hallways or outdoor terrains, operating articulated objects, and rearranging items on a bookshelf.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet6_07">
             17:05-17:10, Paper WeET6.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1554" name="modify5005" onclick="modify(5005,1554)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5005'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Variable-Frequency Model Learning and Predictive Control for Jumping Maneuvers on Legged Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#312921" title="Click to go to the Author Index">
             Nguyen, Chuong
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378598" title="Click to go to the Author Index">
             Altawaitan, Abdullah
            </a>
           </td>
           <td class="r">
            University of California San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#255787" title="Click to go to the Author Index">
             Duong, Thai
            </a>
           </td>
           <td class="r">
            Rice University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#149893" title="Click to go to the Author Index">
             Atanasov, Nikolay
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203386" title="Click to go to the Author Index">
             Nguyen, Quan
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5005" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Achieving both target accuracy and robustness in dynamic maneuvers with long flight phases, such as high or long jumps, has been a significant challenge for legged robots. To address this challenge, we propose a novel learning-based control approach consisting of model learning and model predictive control (MPC) utilizing a variable-frequency scheme. Compared to existing MPC techniques, we learn a model directly from experiments, accounting not only for leg dynamics but also for modeling errors and unknown dynamics mismatch in hardware and during contact. Additionally, learning the model with variable-frequency allows us to cover the entire flight phase and final jumping target, enhancing the prediction accuracy of the jumping trajectory. Using the learned model, we also design variable-frequency to effectively leverage different jumping phases and track the target accurately. In a total of 92 jumps on Unitree A1 robot hardware, we verify that our approach outperforms other MPCs using fixed-frequency or nominal model, reducing the jumping distance error 2 to 8 times. We also achieve jumping distance errors of less than 3 percent during continuous jumping on uneven terrain with randomly-placed perturbations of random heights (up to 4 cm or 27 percent of the robot’s standing height). Our approach obtains distance errors of 1cm to 2cm on 34 single and continuous jumps with different jumping targets and model uncertainties. Code is available at https://github.com/DRCL-USC/Learning_MPC_Jumping.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet7">
             <b>
              WeET7
             </b>
             Regular Session, 309
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1555" name="modifyWeET7" onclick="modsession(401,1555)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet7" title="Click to go to the Program at a Glance">
             <b>
              Perception 3
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#163828" title="Click to go to the Author Index">
             Redwan Newaz, Abdullah Al
            </a>
           </td>
           <td class="r">
            University of New Orleans
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#101723" title="Click to go to the Author Index">
             Araujo, Helder
            </a>
           </td>
           <td class="r">
            University of Coimbra
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet7_01">
             16:35-16:40, Paper WeET7.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1556" name="modify334" onclick="modify(334,1556)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('334'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Drive with the Flow
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415589" title="Click to go to the Author Index">
             Mannocci, Enrico
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#223499" title="Click to go to the Author Index">
             Poggi, Matteo
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#224965" title="Click to go to the Author Index">
             Mattoccia, Stefano
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab334" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             End-to-end autonomous driving systems have recently made rapid progress, thanks to simulators such as CARLA. They can drive without infraction of common driving rules on uncongested roads but are still struggling with dense traffic scenarios. We conjecture that this occurs because it lacks understanding of the dynamics of the surrounding vehicles, caused by the absence of explicit short-term memory within the perception path of end-to-end models. To address this challenge, we revise the perception module to explicitly model temporal information, by extending it with an auxiliary task that is well-known in computer vision research: optical flow. We generate a novel benchmark using the CARLA simulator to train our model, FlowFuser, and prove its superior ability to avoid collisions with other agents on the road.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet7_02">
             16:40-16:45, Paper WeET7.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1557" name="modify2851" onclick="modify(2851,1557)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2851'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Potential Fields As Scene Affordance for Behavior Change-Based Visual Risk Object Identification
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#371868" title="Click to go to the Author Index">
             Pao, Pang-Yuan
            </a>
           </td>
           <td class="r">
            National Yang Ming Chiao Tung University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#371896" title="Click to go to the Author Index">
             Lu, Shu-Wei
            </a>
           </td>
           <td class="r">
            National Yang Ming Chiao Tung University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#391107" title="Click to go to the Author Index">
             Lu, Zeyan
            </a>
           </td>
           <td class="r">
            National Yang Ming Chiao Tung University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#237152" title="Click to go to the Author Index">
             Chen, Yi-Ting
            </a>
           </td>
           <td class="r">
            National Yang Ming Chiao Tung University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2851" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We study behavior change-based visual risk object identification (Visual-ROI), a crucial formulation for Visual-ROI that aims to detect potential hazards for intelligent driving systems. Existing methods often show significant limitations in spatial accuracy and temporal consistency, stemming from an incomplete understanding of scene affordance. For example, these methods frequently misidentify vehicles that do not impact the ego vehicle as risk objects. Furthermore, existing behavior change-based methods are inefficient because they implement causal inference in the perspective image space. We propose a new framework with a Bird’s Eye View (BEV) representation to overcome the above challenges. Specifically, we utilize potential fields as scene affordance, involving repulsive forces derived from road infrastructure and traffic participants, along with attractive forces sourced from target destinations. In this work, we compute potential fields from perspective images by assigning different energy levels based on the semantic labels acquired through BEV semantic segmentation. We conduct comprehensive experiments and ablation studies, comparing the proposed method with various state-of-the-art algorithms on both synthetic and real-world datasets. Our results show a notable increase in spatial accuracy and temporal consistency, with enhancements of 20.3% and 11.6% on the RiskBench dataset, respectively. Additionally, we can improve computational efficiency by 88%. Similarly, on the nuScenes dataset, we achieve improvements of 5.4% and 7.2% in spatial and temporal consistency.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet7_03">
             16:45-16:50, Paper WeET7.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1558" name="modify3303" onclick="modify(3303,1558)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3303'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SCAM-P: Spatial Channel Attention Module for Panoptic Driving Perception
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#366867" title="Click to go to the Author Index">
             Erabati, Gopi Krishna
            </a>
           </td>
           <td class="r">
            University of Coimbra
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101723" title="Click to go to the Author Index">
             Araujo, Helder
            </a>
           </td>
           <td class="r">
            University of Coimbra
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3303" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             A high-precision, high-efficiency, and lightweight panoptic driving perception system is an essential part of autonomous driving for optimal maneuver planning of the autonomous vehicle. We propose a simple, lightweight, and ef- ficient SCAM-P multi-task learning network that accomplishes three crucial tasks simultaneously for panoptic driving: vehicle detection, drivable area segmentation, and lane segmentation. To increase the representation power of the shared backbone of our multi-task network, we designed a novel SCAM module with spatially localized channel attention and channel localized spatial attention blocks. SCAM is a lightweight module that can be plugged into any CNN architecture to enhance the semantic features with negligible computational overhead. We integrate our SCAM module and design the SCAM-P network, which has a shared backbone for feature extraction and three independent heads to handle three tasks at the same time. We also designed a nano variant of our SCAM-P network to make it deployment-friendly on edge devices. Our SCAM-P network obtains competitive results on the BDD100K dataset with 81.1 % mAP50 for object detection, 91.6 % mIoU for drivable area segmentation, and 28.8 % IoU for lane segmentation. Our model is robust in various adverse weather conditions, such as rainy, snowy, and at night. Our SCAM-P network not only achieves improved performance but also runs efficiently in real-time at 230.5 FPS on the RTX 4090 GPU and 112.1 FPS on the Jetson Orin edge device.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet7_04">
             16:50-16:55, Paper WeET7.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1559" name="modify3634" onclick="modify(3634,1559)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3634'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              IROAM: Improving Roadside Monocular 3D Object Detection Learning from Autonomous Vehicle Data Domain
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#311771" title="Click to go to the Author Index">
             Wang, Zhe
            </a>
           </td>
           <td class="r">
            Institute for AI Industry Research, Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351537" title="Click to go to the Author Index">
             Huo, Xiaoliang
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351526" title="Click to go to the Author Index">
             Fan, Siqi
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351533" title="Click to go to the Author Index">
             Wang, Yan
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#341336" title="Click to go to the Author Index">
             Liu, Jingjing
            </a>
           </td>
           <td class="r">
            Institute for AI Industry Research (AIR), Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309553" title="Click to go to the Author Index">
             Zhang, Ya-Qin
            </a>
           </td>
           <td class="r">
            Institute for AI Industry Research(AIR), Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3634" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In autonomous driving, The perception capabilities of the ego-vehicle can be improved with roadside sensors, which can provide a holistic view of the environment. However, existing monocular detection methods designed for vehicle cameras are not suitable for roadside cameras due to viewpoint domain gaps. To bridge this gap and Improve ROAdside Monocular 3D object detection, we propose IROAM, a semantic-geometry decoupled contrastive learning framework, which takes vehicle-side and roadside data as input simultaneously. IROAM has two significant modules. In-Domain Query Interaction module utilizes a transformer to learn content and depth information for each domain and outputs object queries. Cross-Domain Query Enhancement To learn better feature representations from two domains, Cross-Domain Query Enhancement decouples queries into semantic and geometry parts and only the former is used for contrastive learning. Experiments demonstrate the effectiveness of IROAM in improving roadside detector’s performance. The results validate that IROAM has the capability to learn cross-domain information.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet7_05">
             16:55-17:00, Paper WeET7.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1560" name="modify4010" onclick="modify(4010,1560)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4010'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Fast LiDAR Data Generation with Rectified Flows
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#202611" title="Click to go to the Author Index">
             Nakashima, Kazuto
            </a>
           </td>
           <td class="r">
            Kyushu University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425040" title="Click to go to the Author Index">
             Liu, Xiaowen
            </a>
           </td>
           <td class="r">
            Kyushu University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425031" title="Click to go to the Author Index">
             Miyawaki, Tomoya
            </a>
           </td>
           <td class="r">
            Kyushu University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103233" title="Click to go to the Author Index">
             Iwashita, Yumi
            </a>
           </td>
           <td class="r">
            NASA / Caltech Jet Propulsion Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103231" title="Click to go to the Author Index">
             Kurazume, Ryo
            </a>
           </td>
           <td class="r">
            Kyushu University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4010" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Building LiDAR generative models holds promise as powerful data priors for restoration, scene manipulation, and scalable simulation in autonomous mobile robots. In recent years, approaches using diffusion models have emerged, significantly improving training stability and generation quality. Despite their success, diffusion models require numerous iterations of running neural networks to generate high-quality samples, making the increasing computational cost a potential barrier for robotics applications. To address this challenge, this paper presents R2Flow, a fast and high-fidelity generative model for LiDAR data. Our method is based on rectified flows that learn straight trajectories, simulating data generation with significantly fewer sampling steps compared to diffusion models. We also propose an efficient Transformer-based model architecture for processing the image representation of LiDAR range and reflectance measurements. Our experiments on unconditional LiDAR data generation using the KITTI-360 dataset demonstrate the effectiveness of our approach in terms of both efficiency and quality.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet7_06">
             17:00-17:05, Paper WeET7.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1561" name="modify4805" onclick="modify(4805,1561)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4805'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              AmodalSynthDrive: A Synthetic Amodal Perception Dataset for Autonomous Driving
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256075" title="Click to go to the Author Index">
             Sekkat, Ahmed Rida
            </a>
           </td>
           <td class="r">
            IAV GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#243678" title="Click to go to the Author Index">
             Mohan, Rohit
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#182255" title="Click to go to the Author Index">
             Sawade, Oliver
            </a>
           </td>
           <td class="r">
            IAV GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#374459" title="Click to go to the Author Index">
             Matthes, Elmar
            </a>
           </td>
           <td class="r">
            IAV GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#160427" title="Click to go to the Author Index">
             Valada, Abhinav
            </a>
           </td>
           <td class="r">
            University of Freiburg
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4805" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Unlike humans, who can effortlessly estimate the entirety of objects even when partially occluded, modern computer vision algorithms still find this aspect extremely challenging. Leveraging this amodal perception for autonomous driving remains largely untapped due to the lack of suitable datasets. The curation of these datasets is primarily hindered by significant annotation costs and mitigating annotator subjectivity in accurately labeling occluded regions. To address these limitations, we introduce AmodalSynthDrive, a synthetic multi-task multi-modal amodal perception dataset. The dataset provides multi-view camera images, 3D bounding boxes, LiDAR data, and odometry for 150 driving sequences with over 1M object annotations in diverse traffic, weather, and lighting conditions. AmodalSynthDrive supports multiple amodal scene understanding tasks including the introduced amodal depth estimation for enhanced spatial understanding. We evaluate several baselines for each of these tasks to illustrate the challenges and set up public benchmarking servers. The dataset is available at http://amodalsynthdrive.cs.uni-freiburg.de.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet8">
             <b>
              WeET8
             </b>
             Regular Session, 311
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1562" name="modifyWeET8" onclick="modsession(485,1562)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet8" title="Click to go to the Program at a Glance">
             <b>
              Representation Learning 4
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#130054" title="Click to go to the Author Index">
             Ben Amor, Heni
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#219131" title="Click to go to the Author Index">
             Gan, Lu
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet8_01">
             16:35-16:40, Paper WeET8.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1563" name="modify428" onclick="modify(428,1563)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('428'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              FedEFM: Federated Endovascular Foundation Model with Unseen Data
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#285288" title="Click to go to the Author Index">
             Do, Tuong
            </a>
           </td>
           <td class="r">
            AIOZ
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416558" title="Click to go to the Author Index">
             Vu Huu, Nghia
            </a>
           </td>
           <td class="r">
            AIOZ
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#310280" title="Click to go to the Author Index">
             Jianu, Tudor
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#234039" title="Click to go to the Author Index">
             Huang, Baoru
            </a>
           </td>
           <td class="r">
            Imperial College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#196876" title="Click to go to the Author Index">
             Vu, Minh Nhat
            </a>
           </td>
           <td class="r">
            TU Wien, Austria
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#289870" title="Click to go to the Author Index">
             Su, Jionglong
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong-Liverpool University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267805" title="Click to go to the Author Index">
             Tjiputra, Erman
            </a>
           </td>
           <td class="r">
            AIOZ
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#266963" title="Click to go to the Author Index">
             Tran, Quang
            </a>
           </td>
           <td class="r">
            AIOZ
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372811" title="Click to go to the Author Index">
             Chiu, Te-Chuan
            </a>
           </td>
           <td class="r">
            National Tsing Hua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#171078" title="Click to go to the Author Index">
             Nguyen, Anh
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab428" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In endovascular surgery, the precise identification of catheters and guidewires in X-ray images is essential for reducing intervention risks. However, accurately segmenting catheter and guidewire structures is challenging due to the limited availability of labeled data. Foundation models offer a promising solution by enabling the collection of similar-domain data to train models whose weights can be fine-tuned for downstream tasks. Nonetheless, large-scale data collection for training is constrained by the necessity of maintaining patient privacy. This paper proposes a new method to train a foundation model in a decentralized federated learning setting for endovascular intervention. To ensure the feasibility of the training, we tackle the unseen data issue using differentiable Earth Mover's Distance within a knowledge distillation framework. Once trained, our foundation model's weights provide valuable initialization for downstream tasks, thereby enhancing task-specific performance. Intensive experiments show that our approach achieves new state-of-the-art results, contributing to advancements in endovascular intervention and robotic-assisted endovascular surgery, while addressing the critical issue of data sharing in the medical domain.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet8_02">
             16:40-16:45, Paper WeET8.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1564" name="modify774" onclick="modify(774,1564)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('774'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LamPro: Multi-Prototype Representation Learning for Enhanced Visual Pattern Recognition
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419041" title="Click to go to the Author Index">
             Qi, Ji
            </a>
           </td>
           <td class="r">
            China Mobile (Suzhou) Software Technology Co., Ltd, China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419044" title="Click to go to the Author Index">
             Sun, Wei
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419051" title="Click to go to the Author Index">
             Huang, Qihe
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419025" title="Click to go to the Author Index">
             Zhou, Zhengyang
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#278350" title="Click to go to the Author Index">
             Wang, Yang
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab774" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Visual pattern recognition usually plays important roles in robotics and automation society where the pattern recognition relies on representation learning. Existing representation learning often neglects two important issues, the diversity of intra-class representation and under-exploited label utilization, especially the negative feedback during training process. Fortunately, prototype learning potentially raises label utilization and encourages intra-class diversity. In this paper, we investigate the intra-class diversity and effective updates in prototype learning for enhanced visual pattern recognition. Specifically, we propose a Label-aware multi-Prototype learning, LamPro, by incorporating the label awareness into both prototype formation and update to improve the representation quality. Firstly, we design a supervised contrastive learning to achieve class-discriminative representations. Secondly, we randomly initialize multiple prototypes and update the nearest prototype upon the arrival of instance, to preserve intra-class diversity. Thirdly, we propose a novel Label-guided Adaptive Updating. We separate the prototype updates from the representation optimization and exploit the label indexes to directly implement the prediction feedback. To correct the model optimization directions, we identify the negative feedback, and correct the prototype updates via queries of labels. Finally, we design a memory-based counter to alternately update these deviated prototypes. Experiments verify the effectiveness of our label-aware and joint multi-prototype updating strategies.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet8_03">
             16:45-16:50, Paper WeET8.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1565" name="modify1902" onclick="modify(1902,1565)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1902'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SAS-Prompt: Large Language Models As Numerical Optimizers for Robot Self-Improvement
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#130054" title="Click to go to the Author Index">
             Ben Amor, Heni
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#278048" title="Click to go to the Author Index">
             Graesser, Laura
            </a>
           </td>
           <td class="r">
            Google
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#219951" title="Click to go to the Author Index">
             Iscen, Atil
            </a>
           </td>
           <td class="r">
            Google
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#145247" title="Click to go to the Author Index">
             D'Ambrosio, David
            </a>
           </td>
           <td class="r">
            Google
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#313435" title="Click to go to the Author Index">
             Abeyruwan, Saminda Wishwajith
            </a>
           </td>
           <td class="r">
            Google Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#141816" title="Click to go to the Author Index">
             Bewley, Alex
            </a>
           </td>
           <td class="r">
            Google
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#324106" title="Click to go to the Author Index">
             Zhou, Yifan
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#321063" title="Click to go to the Author Index">
             Kalirathinam, Kamalesh
            </a>
           </td>
           <td class="r">
            Arizona State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418491" title="Click to go to the Author Index">
             Mishra, Swaroop
            </a>
           </td>
           <td class="r">
            Google DeepMind
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#278053" title="Click to go to the Author Index">
             Sanketi, Pannag
            </a>
           </td>
           <td class="r">
            Google
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1902" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_experience" title="Click to go to the Keyword Index">
               Learning from Experience
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#incremental_learning" title="Click to go to the Keyword Index">
               Incremental Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We demonstrate the ability of large language models (LLMs) to perform iterative self-improvement of robot policies. An important insight of this paper is that LLMs have a built-in ability to perform (stochastic) numerical optimization and that this property can be leveraged for explainable robot policy search. Based on this insight, we introduce the SAS Prompt (Summarize, Analyze, Synthesize) – a single prompt that enables iterative learning and adaptation of robot behavior by combining the LLM’s ability to retrieve, reason and optimize over previous robot traces in order to synthesize new, unseen behavior. Our approach can be regarded as an early example of a new family of explainable policy search methods that are entirely implemented within an LLM. We evaluate our approach both in simulation and on a real-robot table tennis task. Project website: sites.google.com/asu.edu/sas-llm/
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet8_04">
             16:50-16:55, Paper WeET8.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1566" name="modify2046" onclick="modify(2046,1566)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2046'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Cohere3D: Exploiting Temporal Coherence for Unsupervised Representation Learning of Vision-Based Autonomous Driving
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#341928" title="Click to go to the Author Index">
             Xie, Yichen
            </a>
           </td>
           <td class="r">
            University of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#319623" title="Click to go to the Author Index">
             Chen, Hongge
            </a>
           </td>
           <td class="r">
            Waymo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#269226" title="Click to go to the Author Index">
             Meyer, Gregory P.
            </a>
           </td>
           <td class="r">
            Motional
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#170579" title="Click to go to the Author Index">
             Lee, Yong Jae
            </a>
           </td>
           <td class="r">
            UW-Madison
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#160760" title="Click to go to the Author Index">
             Wolff, Eric
            </a>
           </td>
           <td class="r">
            Cruise
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100071" title="Click to go to the Author Index">
             Tomizuka, Masayoshi
            </a>
           </td>
           <td class="r">
            University of California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#170266" title="Click to go to the Author Index">
             Zhan, Wei
            </a>
           </td>
           <td class="r">
            Univeristy of California, Berkeley
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#280302" title="Click to go to the Author Index">
             Chai, Yuning
            </a>
           </td>
           <td class="r">
            Waymo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#218924" title="Click to go to the Author Index">
             Huang, Xin
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2046" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#representation_learning" title="Click to go to the Keyword Index">
               Representation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-frame temporal inputs are important for vision-based autonomous driving. Observations from different angles enable the recovery of 3D object states from 2D images as long as we can identify the same instance from different input frames. However, the dynamic nature of driving scenes leads to significant variance in the instance appearance and shape captured by the cameras at different time steps. To this end, we propose a novel contrastive learning algorithm, Cohere3D, to learn coherent instance representations robust to the changes of distance and perspective in a long-term temporal sequence without any human annotations. In the pretraining stage, raw point clouds from LiDAR sensors are utilized to construct the instance-wise long-term temporal correspondence, which serves as guidance for the extraction of instance-level representation from the vision-based bird's-eye-view (BEV) feature map. Cohere3D encourages consistent representation for the same instance at different frames but distinguishes between different instances. We validate the effectiveness and generalizability of our algorithm by finetuning the pretrained model across key downstream autonomous driving tasks: perception, mapping, prediction, and planning. Results show a notable improvement in both data efficiency and final performance in all these tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet8_05">
             16:55-17:00, Paper WeET8.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1567" name="modify2575" onclick="modify(2575,1567)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2575'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Towards Open-Ended Robotic Exploration Using Vision-Inspired Similarity and Foundation Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#211612" title="Click to go to the Author Index">
             Filntisis, Panagiotis Paraskevas
            </a>
           </td>
           <td class="r">
            National Technical University of Athens
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397593" title="Click to go to the Author Index">
             Tsaprazlis, Efthymios
            </a>
           </td>
           <td class="r">
            Athena Research and Innovation Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#266887" title="Click to go to the Author Index">
             Oikonomou, Paris
            </a>
           </td>
           <td class="r">
            National Technical University of Athens (NTUA)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397606" title="Click to go to the Author Index">
             Mattioli, Francesco
            </a>
           </td>
           <td class="r">
            AI2Life
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#176330" title="Click to go to the Author Index">
             Santucci, Vieri Giuliano
            </a>
           </td>
           <td class="r">
            Consiglio Nazionale Delle Ricerche
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#377064" title="Click to go to the Author Index">
             Retsinas, George
            </a>
           </td>
           <td class="r">
            National Technical University of Athens
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#114414" title="Click to go to the Author Index">
             Maragos, Petros
            </a>
           </td>
           <td class="r">
            National Technical University of Athens
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2575" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#continual_learning" title="Click to go to the Keyword Index">
               Continual Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#incremental_learning" title="Click to go to the Keyword Index">
               Incremental Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the domain of robotics, achieving Lifelong Open-ended Learning Autonomy (LOLA) represents a significant milestone, especially in contexts where autonomous agents must adapt to unforeseen environmental variations and evolving objectives. This paper introduces VISOR (Vision-Inspired Similarity for Open-ended Robotic exploration), a vision-based framework designed to assist robotic agents in autonomously exploring and learning from new environments and objects, whether through guided or random exploration, without reliance on predefined design considerations. In that direction, VISOR acts as a perception mediator, classifying everything a robot encounters in a scene as either known or unknown. It further identifies potential distractors (e.g., background elements), known categories, or objects specified through text seeds. By leveraging recent advancements in vision foundation models, VISOR operates in a training-free manner. It begins by segmenting a scene into its constituent entities, regardless of familiarity, and then extracts robust visual representations for each one. These representations are compared against an adaptive memory system that evolves over time; unknown objects are assigned unique IDs and added to this memory as new classes, enriching the robot's understanding of its environment. We argue that this evolving memory can facilitate guided exploration through prior knowledge, enhancing the efficiency of robotic exploration, and validate this by designing two exploration scenarios and running both simulated and real-world experiments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet8_06">
             17:00-17:05, Paper WeET8.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1568" name="modify3121" onclick="modify(3121,1568)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3121'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MI-HGNN: Morphology-Informed Heterogeneous Graph Neural Network for Legged Robot Contact Perception
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354750" title="Click to go to the Author Index">
             Butterfield, Daniel Chase
            </a>
           </td>
           <td class="r">
            Georgia Institute of Tehcnology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411857" title="Click to go to the Author Index">
             Garimella, Sandilya Sai
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#346465" title="Click to go to the Author Index">
             Cheng, NaiJen
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#219131" title="Click to go to the Author Index">
             Gan, Lu
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3121" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a Morphology-Informed Heterogeneous Graph Neural Network (MI-HGNN) for learning-based contact perception. The architecture and connectivity of the MI-HGNN are constructed from the robot morphology, in which nodes and edges are robot joints and links, respectively. By incorporating the morphology-informed constraints into a neural network, we improve a learning-based approach using model-based knowledge. We apply the proposed MI-HGNN to two contact perception problems, and conduct extensive experiments using both real-world and simulated data collected using two quadruped robots. Our experiments demonstrate the superiority of our method in terms of effectiveness, generalization ability, model efficiency, and sample efficiency. Our MI-HGNN improved the performance of a state-of-the-art model that leverages robot morphological symmetry by 8.4% with only 0.21% of its parameters. Although MI-HGNN is applied to contact perception problems for legged robots in this work, it can be seamlessly applied to other types of multi-body dynamical systems and has the potential to improve other robot learning frameworks. Our code is made publicly available at https://github.com/lunarlab-gatech/Morphology-Informed-HGNN.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet8_07">
             17:05-17:10, Paper WeET8.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1569" name="modify5040" onclick="modify(5040,1569)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5040'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Data-Driven Dynamics Modeling of Miniature Robotic Blimps Using Neural ODEs with Parameter Auto-Tuning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#319520" title="Click to go to the Author Index">
             Zhu, Yongjian
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#326479" title="Click to go to the Author Index">
             Cheng, Hao
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#148116" title="Click to go to the Author Index">
             Zhang, Feitian
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5040" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#calibration_and_identification" title="Click to go to the Keyword Index">
               Calibration and Identification
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Miniature robotic blimps, as one type of lighter-than-air aerial vehicles, have attracted increasing attention in the science and engineering community for their enhanced safety, extended endurance, and quieter operation compared to quadrotors. Accurately modeling the dynamics of these robotic blimps poses a significant challenge due to the complex aerodynamics stemming from their large lifting bodies. Traditional first-principle models have difficulty obtaining accurate aerodynamic parameters and often overlook high-order nonlinearities, thus coming to their limit in modeling the motion dynamics of miniature robotic blimps. To tackle this challenge, this letter proposes the Auto-tuning Blimp-oriented Neural Ordinary Differential Equation method (ABNODE), a data-driven approach that integrates first-principle and neural network modeling. Spiraling motion experiments of robotic blimps are conducted, comparing the ABNODE with first-principle and other data-driven benchmark models, the results of which demonstrate the effectiveness of the proposed method.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet9">
             <b>
              WeET9
             </b>
             Regular Session, 312
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1570" name="modifyWeET9" onclick="modsession(341,1570)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet9" title="Click to go to the Program at a Glance">
             <b>
              Motion Planning and Control
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#219469" title="Click to go to the Author Index">
             Geng, Junyi
            </a>
           </td>
           <td class="r">
            Pennsylvania State University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#101767" title="Click to go to the Author Index">
             Brock, Oliver
            </a>
           </td>
           <td class="r">
            Technische Universität Berlin
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet9_01">
             16:35-16:40, Paper WeET9.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1571" name="modify38" onclick="modify(38,1571)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('38'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Improving the Performance of Learned Controllers in Behavior Trees Using Value Function Estimates at Switching Boundaries
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#318056" title="Click to go to the Author Index">
             Kartašev, Mart
            </a>
           </td>
           <td class="r">
            KTH Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104031" title="Click to go to the Author Index">
             Ogren, Petter
            </a>
           </td>
           <td class="r">
            Royal Institute of Technology (KTH)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab38" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#behavior_based_systems" title="Click to go to the Keyword Index">
               Behavior-Based Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#control_architectures_and_programming" title="Click to go to the Keyword Index">
               Control Architectures and Programming
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Behavior trees represent a modular way to create an overall controller from a set of sub-controllers solving different sub-problems. These sub-controllers can be created using various methods, such as classical
             <p>
              model based control or reinforcement learning (RL). If each sub-controller satisfies the preconditions of the next sub-controller, the overall controller will achieve the overall goal. However, even if all sub-controllers are locally optimal in achieving the preconditions of the next, with respect to some performance metric such as completion
              <p>
               time, the overall controller might still be far from optimal with respect to the same performance metric. In this paper we show how the performance
               <p>
                of the overall controller can be improved if we use approximations of value functions to inform the design of a sub-controller of the needs of the next one. We also show how, under certain assumptions, this leads to a globally optimal controller when the process is executed on all sub-controllers. Finally, this result also holds when some of the sub-controllers are already given, i.e., if we are constrained to use some existing sub-controllers the overall controller will be globally optimal given this constraint.
               </p>
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet9_02">
             16:40-16:45, Paper WeET9.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1572" name="modify1201" onclick="modify(1201,1572)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1201'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Deliberative Control-Aware Motion Planning for Kinematic-Constrained UAVs in a Dynamic Environment
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338179" title="Click to go to the Author Index">
             Freitas, Elias José de Rezende
            </a>
           </td>
           <td class="r">
            Universidade Federal De Minas Gerais
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#337667" title="Click to go to the Author Index">
             Vangasse, Arthur
            </a>
           </td>
           <td class="r">
            Universidade Federal De Minas Gerais
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411422" title="Click to go to the Author Index">
             Cohen, Miri Weiss
            </a>
           </td>
           <td class="r">
            Braude College of Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411423" title="Click to go to the Author Index">
             Guimarães, Frederico Gadelha
            </a>
           </td>
           <td class="r">
            UFMG
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105840" title="Click to go to the Author Index">
             Pimenta, Luciano
            </a>
           </td>
           <td class="r">
            Universidade Federal De Minas Gerais
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1201" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#constrained_motion_planning" title="Click to go to the Keyword Index">
               Constrained Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a motion planning approach for navigating in a dynamic environment. The path is represented using a Non-Uniform Rational B-Spline (NURBS) to ensure smoothness, curvature continuity, and proper orientation by adjusting its parameters. A Differential Evolution algorithm optimizes the curve parameters and traversal speed at each re-planning interval, taking into account speed limits, maximum curvature, and obstacles in the environment. A constraint-based on Velocity Obstacle (VO) ensures collision-free motion, considering bounds provided by lower-level controllers. The feasibility of the approach is validated through simulations and real-world experiments with the Crazyflie 2.1 micro quadcopter.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet9_03">
             16:45-16:50, Paper WeET9.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1573" name="modify1918" onclick="modify(1918,1573)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1918'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robot Navigation in Unknown and Cluttered Workspace with Dynamical System Modulation in Starshaped Roadmap
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#285922" title="Click to go to the Author Index">
             Chen, Kai
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#352797" title="Click to go to the Author Index">
             Liu, Haichao
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339738" title="Click to go to the Author Index">
             Li, Yulin
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology(HKUST)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#220330" title="Click to go to the Author Index">
             Duan, Jianghua
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#341869" title="Click to go to the Author Index">
             Zhu, Lei
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#182083" title="Click to go to the Author Index">
             Ma, Jun
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1918" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_control" title="Click to go to the Keyword Index">
               Integrated Planning and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_based_control" title="Click to go to the Keyword Index">
               Sensor-based Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Compared to conventional decomposition methods that use ellipses or polygons to represent free space, starshaped representation can better capture the natural distribution of sensor data, thereby exploiting a larger portion of traversable space. This paper introduces a novel motion planning and control framework for navigating robots in unknown and cluttered environments using a dynamically constructed starshaped roadmap. Our approach generates a starshaped representation of the surrounding free space from real-time sensor data using piece-wise polynomials. Additionally, an incremental roadmap maintaining the connectivity information is constructed, and a searching algorithm efficiently selects short-term goals on this roadmap. Importantly, this framework addresses deadend situations with a graph updating mechanism. To ensure safe and efficient movement within the starshaped roadmap, we propose a reactive controller based on Dynamic System Modulation (DSM). This controller facilitates smooth motion within starshaped regions and their intersections, avoiding conservative and short-sighted behaviors and allowing the system to handle intricate obstacle configurations in unknown and cluttered environments. Comprehensive evaluations in both simulations and real-world experiments show that the proposed method achieves higher success rates and reduced travel times compared to other methods. It effectively manages intricate obstacle configurations, avoiding conservative and myopic behaviors.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet9_04">
             16:50-16:55, Paper WeET9.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1574" name="modify2978" onclick="modify(2978,1574)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2978'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robust Planning for Autonomous Driving Via Mixed Adversarial Diffusion Predictions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419098" title="Click to go to the Author Index">
             Zhao, Albert
            </a>
           </td>
           <td class="r">
            University of California Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#113021" title="Click to go to the Author Index">
             Soatto, Stefano
            </a>
           </td>
           <td class="r">
            UCLA
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2978" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#planning_under_uncertainty" title="Click to go to the Keyword Index">
               Planning under Uncertainty
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We describe a robust planning method for autonomous driving that mixes normal and adversarial agent predictions output by a diffusion model trained for motion prediction. We first train a diffusion model to learn an unbiased distribution of normal agent behaviors. We then generate a distribution of adversarial predictions by biasing the diffusion model at test time to generate predictions that are likely to collide with a candidate plan. We score plans using expected cost with respect to a mixture distribution of normal and adversarial predictions, leading to a planner that is robust against adversarial behaviors but not overly conservative when agents behave normally. Unlike current approaches, we do not use risk measures that over-weight adversarial behaviors while placing little to no weight on low-cost normal behaviors or use hard safety constraints that may not be appropriate for all driving scenarios. We show the effectiveness of our method on single-agent and multi-agent jaywalking scenarios as well as a red light violation scenario.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet9_05">
             16:55-17:00, Paper WeET9.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1575" name="modify3511" onclick="modify(3511,1575)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3511'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Autonomous Navigation in Ice-Covered Waters with Learned Predictions on Ship-Ice Interactions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#322404" title="Click to go to the Author Index">
             Zhong, Ninghan
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425545" title="Click to go to the Author Index">
             Potenza, Alessandro
            </a>
           </td>
           <td class="r">
            University of Manitoba
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#116598" title="Click to go to the Author Index">
             Smith, Stephen L.
            </a>
           </td>
           <td class="r">
            University of Waterloo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3511" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Autonomous navigation in ice-covered waters poses significant challenges due to the frequent lack of viable collision-free trajectories. When complete obstacle avoidance is infeasible, it becomes imperative for the navigation strategy to minimize collisions. Additionally, the dynamic nature of ice, which moves in response to ship maneuvers, complicates the path planning process. To address these challenges, we propose a novel deep learning model to estimate the coarse dynamics of ice movements triggered by ship actions through occupancy estimation. To ensure real-time applicability, we propose a novel approach that caches intermediate prediction results and seamlessly integrates the predictive model into a graph search planner. We evaluate the proposed planner in both simulation and in a physical testbed against existing approaches and show that our planner significantly reduces collisions with ice when compared to the state-of-the-art. Codes and demos of this work are available at https://github.com/IvanIZ/predictive-asv-planner.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet9_06">
             17:00-17:05, Paper WeET9.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1576" name="modify4505" onclick="modify(4505,1576)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4505'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              IKap: Kinematics-Aware Planning with Imperative Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#388281" title="Click to go to the Author Index">
             Li, Qihang
            </a>
           </td>
           <td class="r">
            University at Buffalo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372668" title="Click to go to the Author Index">
             Chen, Zhuoqun
            </a>
           </td>
           <td class="r">
            University of California San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426386" title="Click to go to the Author Index">
             Zheng, Haoze
            </a>
           </td>
           <td class="r">
            University at Buffalo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#340574" title="Click to go to the Author Index">
             He, Haonan
            </a>
           </td>
           <td class="r">
            Department of Mechanical Engineering, College of Engineering, Ca
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351065" title="Click to go to the Author Index">
             Zhan, Zitong
            </a>
           </td>
           <td class="r">
            University at Buffalo, SUNY
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#310547" title="Click to go to the Author Index">
             Su, Shaoshu
            </a>
           </td>
           <td class="r">
            State University of New York at Buffalo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#219469" title="Click to go to the Author Index">
             Geng, Junyi
            </a>
           </td>
           <td class="r">
            Pennsylvania State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#200000" title="Click to go to the Author Index">
             Wang, Chen
            </a>
           </td>
           <td class="r">
            University at Buffalo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4505" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Trajectory planning in robotics aims to generate collision-free pose sequences that can be reliably executed. Recently, vision-to-planning systems have gained increasing attention for their efficiency and ability to interpret and adapt to surrounding environments. However, traditional modular systems suffer from increased latency and error propagation, while purely data-driven approaches often overlook the robot's kinematic constraints. This oversight leads to discrepancies between planned trajectories and those that are executable. To address these challenges, we propose iKap, a novel vision-to-planning system that integrates the robot's kinematic model directly into the learning pipeline. iKap employs a self-supervised learning approach and incorporates the state transition model within a differentiable bi-level optimization framework. This integration ensures the network learns collision-free waypoints while satisfying kinematic constraints, enabling gradient back-propagation for end-to-end training. Our experimental results demonstrate that iKap achieves higher success rates and reduced latency compared to the state-of-the-art methods. Besides the complete system, iKap offers a visual-to-planning network that seamlessly works with various controllers, providing a robust solution for robots navigating complex environments.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet9_07">
             17:05-17:10, Paper WeET9.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1577" name="modify5014" onclick="modify(5014,1577)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5014'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Differentiable-Optimization Based Neural Policy for Occlusion-Aware Target Tracking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#277741" title="Click to go to the Author Index">
             Masnavi, Houman
            </a>
           </td>
           <td class="r">
            Toronto Metropolitan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#123110" title="Click to go to the Author Index">
             Singh, Arun Kumar
            </a>
           </td>
           <td class="r">
            University of Tartu
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100725" title="Click to go to the Author Index">
             Janabi-Sharifi, Farrokh
            </a>
           </td>
           <td class="r">
            Ryerson University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5014" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose a learned probabilistic neural policy for safe, occlusion-free target tracking. The core novelty of our work stems from the structure of our policy network that combines generative modeling based on Conditional Variational Autoencoder (CVAE) with differentiable optimization layers. The weights of the CVAE network and the parameters of the differentiable optimization can be learned in an end-to-end fashion through demonstration trajectories. We improve the state-of-the-art (SOTA) in the following respects. We show that our learned policy outperforms existing SOTA in terms of occlusion/collision avoidance capabilities and computation time. Second, we present an extensive ablation showing how different components of our learning pipeline contribute to the overall tracking task. We also demonstrate the real-time performance of our approach on resource-constrained hardware such as NVIDIA Jetson TX2. Finally, our learned policy can also be viewed as a reactive planner for navigation in highly cluttered environments.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet10">
             <b>
              WeET10
             </b>
             Regular Session, 313
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1578" name="modifyWeET10" onclick="modsession(357,1578)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet10" title="Click to go to the Program at a Glance">
             <b>
              Multi-Robot Planning
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#270001" title="Click to go to the Author Index">
             Li, Jiaoyang
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#179159" title="Click to go to the Author Index">
             Seiler, Konstantin M
            </a>
           </td>
           <td class="r">
            University of Technology Sydney
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet10_01">
             16:35-16:40, Paper WeET10.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1579" name="modify140" onclick="modify(140,1579)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('140'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Horizon Multi-Agent Planning Using Decentralised Monte Carlo Tree Search
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#179159" title="Click to go to the Author Index">
             Seiler, Konstantin M
            </a>
           </td>
           <td class="r">
            University of Technology Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#217476" title="Click to go to the Author Index">
             Kong, Felix Honglim
            </a>
           </td>
           <td class="r">
            The University of Technology Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104600" title="Click to go to the Author Index">
             Fitch, Robert
            </a>
           </td>
           <td class="r">
            University of Technology Sydney
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab140" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose multi-horizon Monte Carlo tree search (MH-MCTS), the first framework for integrated hierarchical multi-horizon, multi-agent planning based on Monte Carlo tree search (MCTS). The method employs multiple simultaneous MCTS optimisations for each planning level within each agent, which are designed to optimise a joint objective function. Using concepts from decentralised Monte Carlo tree search (Dec-MCTS), the individual optimisations continuously exchange information about their current plans. This breaks the common top-down only information flow within the planning hierarchy and allows higher level optimisers to consider progress made by lower level planners. The method is implemented for survey missions using a fleet of ground robots. Simulation results with different mission profiles show substantial performance improvements of the new method of up to 59% compared to traditional MCTS and Dec-MCTS.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet10_02">
             16:40-16:45, Paper WeET10.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1580" name="modify1936" onclick="modify(1936,1580)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1936'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Generalized Mission Planning for Heterogeneous Multi-Robot Teams Via LLM-Constructed Hierarchical Trees
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#336179" title="Click to go to the Author Index">
             Gupta, Piyush
            </a>
           </td>
           <td class="r">
            Honda Research Institute, US
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#165476" title="Click to go to the Author Index">
             Isele, David
            </a>
           </td>
           <td class="r">
            University of Pennsylvania, Honda Research Institute USA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#208540" title="Click to go to the Author Index">
             Sachdeva, Enna
            </a>
           </td>
           <td class="r">
            Honda Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420732" title="Click to go to the Author Index">
             Huang, Pin-Hao
            </a>
           </td>
           <td class="r">
            Honda Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#111942" title="Click to go to the Author Index">
             Dariush, Behzad
            </a>
           </td>
           <td class="r">
            Honda Research Institute USA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420725" title="Click to go to the Author Index">
             Lee, Kwonjoon
            </a>
           </td>
           <td class="r">
            Honda Research Institute USA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#268381" title="Click to go to the Author Index">
             Bae, Sangjae
            </a>
           </td>
           <td class="r">
            Honda Research Institute, USA
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1936" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We present a novel mission-planning strategy for heterogeneous multi-robot teams, taking into account the specific constraints and capabilities of each robot. Our approach employs hierarchical trees to systematically break down complex missions into manageable sub-tasks. We develop specialized APIs and tools, which are utilized by Large Language Models (LLMs) to efficiently construct these hierarchical trees. Once the hierarchical tree is generated, it is further decomposed to create optimized schedules for each robot, ensuring adherence to their individual constraints and capabilities. We demonstrate the effectiveness of our framework through detailed examples covering a wide range of missions, showcasing its flexibility and scalability.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet10_03">
             16:45-16:50, Paper WeET10.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1581" name="modify2220" onclick="modify(2220,1581)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2220'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Efficient Coordination and Synchronization of Multi-Robot Systems under Recurring Linear Temporal Logic
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421653" title="Click to go to the Author Index">
             Peron, Davide
            </a>
           </td>
           <td class="r">
            Università Degli Studi Di Padova
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#340152" title="Click to go to the Author Index">
             Nan Fernandez-Ayala, Victor
            </a>
           </td>
           <td class="r">
            KTH Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421624" title="Click to go to the Author Index">
             Vlahakis, Eleftherios E.
            </a>
           </td>
           <td class="r">
            KTH Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103919" title="Click to go to the Author Index">
             Dimarogonas, Dimos V.
            </a>
           </td>
           <td class="r">
            KTH Royal Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2220" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We consider multi-robot systems under recurring tasks formalized as linear temporal logic (LTL) specifications. To solve the planning problem efficiently, we propose a bottom-up approach combining offline plan synthesis with online coordination, dynamically adjusting plans via real-time communication. To address action delays, we introduce a synchronization mechanism ensuring coordinated task execution, leading to a multi-agent coordination and synchronization framework that is adaptable to a wide range of multi-robot applications. The software package is developed in Python and ROS2 for broad deployment. We validate our findings through lab experiments involving nine robots showing enhanced adaptability compared to previous methods. Additionally, we conduct simulations with up to ninety agents to demonstrate the reduced computational complexity and the scalability features of our work.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet10_04">
             16:50-16:55, Paper WeET10.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1582" name="modify2410" onclick="modify(2410,1582)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2410'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              HULK: Large-Scale Hierarchical Coordination under Continual and Uncertain Temporal Tasks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424221" title="Click to go to the Author Index">
             Luo, Qingyuan
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#185553" title="Click to go to the Author Index">
             Li, Jie
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#151683" title="Click to go to the Author Index">
             Guo, Meng
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2410" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#formal_methods_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Formal Methods in Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-agent systems can be extremely efficient when working concurrently and collaboratively, e.g., for delivery, surveillance, search and rescue. Coordination of such teams often involves two aspects: (i) selecting appropriate subteams for different tasks in various areas; (ii) coordinating agents in the subteams to execute the associated subtasks. Existing work often assumes that the tasks are static and known beforehand, where an integer program can be formulated and solved offline.However, in many applications, the team-wise tasks are generated online continually by external requests; and the amount of subtasks within each task is uncertain (e.g., the number of packages to deliver, and victims to rescue). The aforementioned offline solution becomes inadequate as it would require constant re-computation for the whole team and global communication to broadcast the results. Thus, this work tackles the large-scale coordination problem under continual and uncertain temporal tasks, specified as temporal logic formulas over collaborative actions. The proposed hierarchical framework (HULK) consists of two interleaved layers: the rolling assignment of currently-known tasks to sub-teams within a certain horizon, and the dynamic coordination within a sub-team given the detected subtasks during online execution. Thus, the coordination is performed hierarchically at different granularities and triggering conditions, to improve the computational efficiency and robustness. It is validated rigorously over large-scale heterogeneous systems under various temporal tasks and environment uncertainties.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet10_05">
             16:55-17:00, Paper WeET10.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1583" name="modify2576" onclick="modify(2576,1583)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2576'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              COHERENT: Collaboration of Heterogeneous Multi-Robot System with Large Language Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395945" title="Click to go to the Author Index">
             Liu, Kehui
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#332308" title="Click to go to the Author Index">
             Tang, Zixin
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#345464" title="Click to go to the Author Index">
             Wang, Dong
            </a>
           </td>
           <td class="r">
            Shanghai Artificial Intelligence Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#376465" title="Click to go to the Author Index">
             Wang, Zhigang
            </a>
           </td>
           <td class="r">
            Shanghai AI Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372120" title="Click to go to the Author Index">
             Li, Xuelong
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372118" title="Click to go to the Author Index">
             Zhao, Bin
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2576" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Leveraging the powerful reasoning capabilities of large language models (LLMs), recent LLM-based robot task planning methods yield promising results. However, they mainly focus on single or multiple homogeneous robots on simple tasks. Practically, complex long-horizon tasks always require collaboration among multiple heterogeneous robots especially with more complex action spaces, which makes these tasks more challenging. To this end, we propose COHERENT, a novel LLM-based task planning framework for collaboration of heterogeneous multi-robot systems including quadrotors, robotic dogs, and robotic arms. Specifically, a Proposal-Execution-Feedback-Adjustment (PEFA) mechanism is designed to decompose and assign actions for individual robots, where a centralized task assigner makes a task planning proposal to decompose the complex task into subtasks, and then assigns subtasks to robot executors. Each robot executor selects a feasible action to implement the assigned subtask and reports self-reflection feedback to the task assigner for plan adjustment. The PEFA loops until the task is completed. Moreover, we create a challenging heterogeneous multi-robot task planning benchmark encompassing 100 complex long-horizon tasks. The experimental results show that our work surpasses the previous methods by a large margin in terms of success rate and execution efficiency. The experimental videos, code, and benchmark are released at https://github.com/MrKeee/COHERENT.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet10_06">
             17:00-17:05, Paper WeET10.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1584" name="modify3583" onclick="modify(3583,1584)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3583'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              LaMMA-P: Generalizable Multi-Agent Long-Horizon Task Allocation and Planning with LM-Driven PDDL Planner
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#376343" title="Click to go to the Author Index">
             Zhang, Xiaopan
            </a>
           </td>
           <td class="r">
            University of California - Riverside
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420848" title="Click to go to the Author Index">
             Qin, Hao
            </a>
           </td>
           <td class="r">
            Pennsylvania State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420847" title="Click to go to the Author Index">
             Wang, Fuquan
            </a>
           </td>
           <td class="r">
            University of California Riverside
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425400" title="Click to go to the Author Index">
             Dong, Yue
            </a>
           </td>
           <td class="r">
            University of California Riverside
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#233337" title="Click to go to the Author Index">
             Li, Jiachen
            </a>
           </td>
           <td class="r">
            University of California, Riverside
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3583" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#cooperating_robots" title="Click to go to the Keyword Index">
               Cooperating Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Language models (LMs) possess a strong capability to comprehend natural language, making them effective in translating human instructions into detailed plans for simple robot tasks. Nevertheless, it remains a significant challenge to handle long-horizon tasks, especially in subtask identification and allocation for cooperative heterogeneous robot teams. To address this issue, we propose a Language Model-Driven Multi-Agent PDDL Planner (LaMMA-P), a novel multi-agent task planning framework that achieves state-of-the-art performance on long-horizon tasks. LaMMA-P integrates the strengths of the LMs’ reasoning capability and the traditional heuristic search planner to achieve a high success rate and efficiency while demonstrating strong generalization across tasks. Additionally, we create MAT-THOR, a comprehensive benchmark that features household tasks with two different levels of complexity based on the AI2-THOR environment. The experimental results demonstrate that LaMMA-P achieves a 105% higher success rate and 36% higher efficiency than existing LM-based multi-agent planners. The experimental videos, code, datasets, and detailed prompts used in each module can be found on the project website: https://lamma-p.github.io.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet10_07">
             17:05-17:10, Paper WeET10.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1585" name="modify3639" onclick="modify(3639,1585)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3639'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              FlyKites: Human-Centric Interactive Exploration and Assistance under Limited Communication
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424284" title="Click to go to the Author Index">
             Zhang, Yuyang
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424240" title="Click to go to the Author Index">
             Tian, Zhuoli
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424264" title="Click to go to the Author Index">
             Wei, Jinsheng
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#151683" title="Click to go to the Author Index">
             Guo, Meng
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3639" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_robot_teaming" title="Click to go to the Keyword Index">
               Human-Robot Teaming
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Fleets of autonomous robots have been deployed for exploration of unknown scenes for features of interest, e.g., subterranean exploration, reconnaissance, search and rescue missions. During exploration, the robots may encounter un-identified targets, blocked passages, interactive objects, temporary failure, or other unexpected events, all of which require consistent human assistance with reliable communication for a time period. This however can be particularly challenging if the communication among the robots is severely restricted to only close-range exchange via ad-hoc networks, especially in extreme environments like caves and underground tunnels. This paper presents a novel human-centric interactive exploration and assistance framework called FlyKites, for multi-robot systems under limited communication. It consists of three interleaved components: (I) the distributed exploration and intermittent communication (called the ``spread mode"), where the robots collaboratively explore the environment and exchange local data among the fleet and with the operator; (II) the simultaneous optimization of the relay topology, the operator path, and the assignment of robots to relay roles (called the ``relay mode"), such that all requested assistance can be provided with minimum delay; (III) the human-in-the-loop online execution, where the robots switch between different roles and interact with the operator adaptively. Extensive human-in-the-loop simulations and hardware experiments are performed over numerous challenging scenes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet10_08">
             17:10-17:15, Paper WeET10.8
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1586" name="modify2970" onclick="modify(2970,1586)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2970'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Work Smarter Not Harder: Simple Imitation Learning with CS-PIBT Outperforms Large-Scale Imitation Learning for MAPF
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#343289" title="Click to go to the Author Index">
             Veerapaneni, Rishi
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424231" title="Click to go to the Author Index">
             Jakobsson, Arthur
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424718" title="Click to go to the Author Index">
             Ren, Kevin
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424194" title="Click to go to the Author Index">
             Kim, Samuel
            </a>
           </td>
           <td class="r">
            Solon High School
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#270001" title="Click to go to the Author Index">
             Li, Jiaoyang
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106468" title="Click to go to the Author Index">
             Likhachev, Maxim
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2970" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-Agent Path Finding (MAPF) is the problem of effectively finding efficient collision-free paths for a group of agents in a shared workspace. The MAPF community has largely focused on developing high-performance heuristic search methods. Recently, several works have applied various machine learning (ML) techniques to solve MAPF, usually involving sophisticated architectures, reinforcement learning techniques, and set-ups, but none using large amounts of high-quality supervised data. Our initial objective in this work was to show how simple large-scale imitation learning of high-quality heuristic search methods can lead to state-of-the-art ML MAPF performance. However, we find that, at least with our model architecture, simple large-scale (700k examples with hundreds of agents per example) imitation learning does not produce impressive results. Instead, we find that by using prior work that post-processes MAPF model predictions to resolve 1-step collisions (CS-PIBT), we can train a simple ML MAPF policy in minutes that dramatically outperforms existing ML MAPF policies. This has serious implications for all future ML MAPF policies (with local communication) which currently struggle to scale. In particular, this finding implies that future learnt policies should always (1) use smart 1-step collision shields (e.g. CS-PIBT) and (2) include the collision shield with greedy actions as a baseline (e.g. PIBT), as well as (3) motivates future models to focus on longer horizon / more complex planning as 1-step collisions can be efficiently resolved.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet11">
             <b>
              WeET11
             </b>
             Regular Session, 314
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1587" name="modifyWeET11" onclick="modsession(39,1587)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet11" title="Click to go to the Program at a Glance">
             <b>
              Agile Legged Locomotion
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#104389" title="Click to go to the Author Index">
             Clark, Jonathan
            </a>
           </td>
           <td class="r">
            Florida State University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#101950" title="Click to go to the Author Index">
             Cutkosky, Mark
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet11_01">
             16:35-16:40, Paper WeET11.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1588" name="modify759" onclick="modify(759,1588)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('759'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Mastering Agile Jumping Skills from Simple Practices with Iterative Learning Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#312921" title="Click to go to the Author Index">
             Nguyen, Chuong
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#402089" title="Click to go to the Author Index">
             Bao, Lingfan
            </a>
           </td>
           <td class="r">
            University College London
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203386" title="Click to go to the Author Index">
             Nguyen, Quan
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab759" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_experience" title="Click to go to the Keyword Index">
               Learning from Experience
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Achieving precise target jumping with legged robots poses a significant challenge due to the long flight phase and the uncertainties inherent in contact dynamics and hardware. Forcefully attempting these agile motions on hardware could result in severe failures and potential damage. Motivated by this challenge, we propose an Iterative Learning Control (ILC) approach to learn and refine jumping skills from easy to difficult, instead of directly learning these challenging tasks. We verify that learning from simplicity can enhance safety and target jumping accuracy over trials. Compared to other ILC approaches for legged locomotion, our method can tackle the problem of a long flight phase where control input is not available. In addition, our approach allows the robot to apply what it learns from a simple jumping task to accomplish more challenging tasks within a few trials directly in hardware, instead of learning from scratch. We validate the method through extensive experiments on the A1 model and hardware for various tasks. Starting from a small jump (e.g., a forward jump 40cm), our learning approach empowers the robot to accomplish a variety of challenging targets, including jumping onto a 20cm high box, leaping to a greater distance of up to 60cm, as well as performing jumps while carrying an unknown payload of 2kg. Our framework allows the robot to reach the desired position and orientation targets with approximate errors of 1cm and 1 degree within a few trials.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet11_02">
             16:40-16:45, Paper WeET11.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1589" name="modify904" onclick="modify(904,1589)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('904'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Agile Continuous Jumping in Discontinuous Terrains
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#220165" title="Click to go to the Author Index">
             Yang, Yuxiang
            </a>
           </td>
           <td class="r">
            Google Deepmind
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#236627" title="Click to go to the Author Index">
             Shi, Guanya
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#336562" title="Click to go to the Author Index">
             Lin, Changyi
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#238087" title="Click to go to the Author Index">
             Meng, Xiangyun
            </a>
           </td>
           <td class="r">
            University of Washington
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#198077" title="Click to go to the Author Index">
             Scalise, Rosario
            </a>
           </td>
           <td class="r">
            University of Washington
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#242700" title="Click to go to the Author Index">
             Guaman Castro, Mateo
            </a>
           </td>
           <td class="r">
            University of Washington
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#198071" title="Click to go to the Author Index">
             Yu, Wenhao
            </a>
           </td>
           <td class="r">
            Google
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#173944" title="Click to go to the Author Index">
             Zhang, Tingnan
            </a>
           </td>
           <td class="r">
            Google
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203949" title="Click to go to the Author Index">
             Zhao, Ding
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#219934" title="Click to go to the Author Index">
             Tan, Jie
            </a>
           </td>
           <td class="r">
            Google
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#151779" title="Click to go to the Author Index">
             Boots, Byron
            </a>
           </td>
           <td class="r">
            University of Washington
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab904" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We focus on advancing the agility of quadrupedal robots with continuous, precise, and terrain-adaptive jumping in discontinuous terrains such as stairs and stepping stones. To accomplish this task, we design a hierarchical learning and control framework, which consists of a learned heightmap predictor for robust terrain perception, a reinforcement-learning-based centroidal-level motion policy for versatile and terrain-adaptive planning, and a low-level model-based leg controller for accurate motion tracking. In addition, we minimize the sim-to-real gap by accurately modeling the hardware characteristics. Such a hierarchical and hybrid framework effectively combines the advantages of model-free learning and model-based control, therefore enabling a Unitree Go1 robot to perform agile and continuous jumps on human-sized stairs and sparse stepping stones, for the first time to the best of our knowledge. In particular, the robot can cross two stair steps in each jump and completes a 3.5m long, 2.8m high, 14-step stair in 4.5 seconds. Moreover, the same policy outperforms baselines in various other parkour tasks, such as jumping over single horizontal or vertical discontinuities.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet11_03">
             16:45-16:50, Paper WeET11.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1590" name="modify1989" onclick="modify(1989,1590)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1989'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              High Accuracy Aerial Maneuvers on Legged Robots Using Variational Integrator Discretized Trajectory Optimization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422050" title="Click to go to the Author Index">
             Beck, Scott
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#312921" title="Click to go to the Author Index">
             Nguyen, Chuong
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#255787" title="Click to go to the Author Index">
             Duong, Thai
            </a>
           </td>
           <td class="r">
            Rice University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#149893" title="Click to go to the Author Index">
             Atanasov, Nikolay
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203386" title="Click to go to the Author Index">
             Nguyen, Quan
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1989" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Performing acrobatic maneuvers involving long aerial phases, such as precise dives or multiple backflips from significant heights, remains an open challenge in legged robot autonomy. Such aggressive motions often require accurate state predictions over long horizons with multiple contacts and extended flight phases. Most existing trajectory optimization (TO) methods rely on Euler or Runge-Kutta integration, which can accumulate significant prediction errors over long planning horizons. In this work, we propose a novel whole-body TO method using variational integration (VI) and full-body nonlinear dynamics for long-flight aggressive maneuvers. Compared to traditional Euler-based TO, our approach using VI preserves energy and momentum properties of the continuous time system and reduces error between predicted and executed trajectories by factors of between 2 − 10 while achieving similar planning time. We successfully demonstrate long-flight triple backflips on a quadruped A1 robot model and backflips on a bipedal HECTOR robot model for various heights and distances, achieving landing angle errors of only a few degrees. In contrast, TO with Euler integration fails to achieve accurate landings in equivalent circumstances, e.g., with landing angle errors greater than 90◦ for triple backflips. We provide an open-source implementation of our VI-discretized TO to support further research on accurate dynamic maneuvers for multi-rigid-body robot systems with contact: https://github.com/DRCL-USC/VI_discretized_TO
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet11_04">
             16:50-16:55, Paper WeET11.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1591" name="modify2092" onclick="modify(2092,1591)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2092'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learn to Swim: Data-Driven LSTM Hydrodynamic Model for Quadruped Robot Gait Optimization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#313294" title="Click to go to the Author Index">
             Han, Fei
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422660" title="Click to go to the Author Index">
             Guo, Pengming
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422721" title="Click to go to the Author Index">
             Chen, Hao
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422442" title="Click to go to the Author Index">
             Li, Weikun
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421529" title="Click to go to the Author Index">
             Ren, Jingbo
            </a>
           </td>
           <td class="r">
            Xinyang Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#223479" title="Click to go to the Author Index">
             Liu, Naijun
            </a>
           </td>
           <td class="r">
            Institute of Automation Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422374" title="Click to go to the Author Index">
             Yang, Ning
            </a>
           </td>
           <td class="r">
            Institute of Automation, Chinese Academy of Sciences
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#292383" title="Click to go to the Author Index">
             Fan, Dixia
            </a>
           </td>
           <td class="r">
            Westlake University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2092" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#whole_body_motion_planning_and_control" title="Click to go to the Keyword Index">
               Whole-Body Motion Planning and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents a Long Short-Term Memory network-based Fluid Experiment Data-Driven model (FED-LSTM) for predicting unsteady, nonlinear hydrodynamic forces on the underwater quadruped robot we constructed. Trained on experimental data from leg force and body drag tests conducted in both a recirculating water tank and a towing tank, FED-LSTM outperforms traditional empirical formulas (EF) commonly used for flow prediction over flat surfaces. The model demonstrates superior accuracy and adaptability in capturing complex fluid dynamics, particularly in straight-line and turning-gait optimizations via the NSGA-II algorithm. FED-LSTM reduces deflection errors during straight-line swimming and improves turn times without increasing the turning radius. Hardware experiments further validate the model's precision and stability over EF. This approach provides a robust framework for enhancing the swimming performance of legged robots, laying the groundwork for future advances in underwater robotic locomotion.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet11_05">
             16:55-17:00, Paper WeET11.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1592" name="modify2546" onclick="modify(2546,1592)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2546'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Stage-Wise Reward Shaping for Acrobatic Robots: A Constrained Multi-Objective Reinforcement Learning Approach
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267981" title="Click to go to the Author Index">
             Kim, Dohyeong
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#396916" title="Click to go to the Author Index">
             Kwon, Hyeokjin
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#325779" title="Click to go to the Author Index">
             Kim, Junseok
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#246764" title="Click to go to the Author Index">
             Lee, Gunmin
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#119971" title="Click to go to the Author Index">
             Oh, Songhwai
            </a>
           </td>
           <td class="r">
            Seoul National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2546" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robot_safety" title="Click to go to the Keyword Index">
               Robot Safety
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             As the complexity of tasks addressed through reinforcement learning (RL) increases, the definition of reward functions also has become highly complicated. We introduce an RL method aimed at simplifying the reward-shaping process through intuitive strategies. Initially, instead of a single reward function composed of various terms, we define multiple reward and cost functions within a constrained multi-objective RL (CMORL) framework. For tasks involving sequential complex movements, we segment the task into distinct stages and define multiple rewards and costs for each stage. Finally, we introduce a practical CMORL algorithm that maximizes objectives based on these rewards while satisfying constraints defined by the costs. The proposed method has been successfully demonstrated across a variety of acrobatic tasks in both simulation and real-world environments. Additionally, it has been shown to successfully perform tasks compared to existing RL and constrained RL algorithms. Our code is available at https://github.com/rllab-snu/Stage-Wise-CMORL.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet11_06">
             17:00-17:05, Paper WeET11.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1593" name="modify3247" onclick="modify(3247,1593)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3247'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design and Implementation of a Swimming and Walking Quadruped for Seafloor Exploration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267405" title="Click to go to the Author Index">
             Chase, Ashley
            </a>
           </td>
           <td class="r">
            Florida State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424414" title="Click to go to the Author Index">
             Labiner, Benjamin
            </a>
           </td>
           <td class="r">
            North Carolina State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424186" title="Click to go to the Author Index">
             Boylan, Jonathan
            </a>
           </td>
           <td class="r">
            FAMU-FSU College of Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425175" title="Click to go to the Author Index">
             Ryals, Cameron
            </a>
           </td>
           <td class="r">
            Florida State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422306" title="Click to go to the Author Index">
             Vranicar, Jack
            </a>
           </td>
           <td class="r">
            Florida State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354820" title="Click to go to the Author Index">
             Dina, Michael
            </a>
           </td>
           <td class="r">
            Florida State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354816" title="Click to go to the Author Index">
             Vasquez, Derek A.
            </a>
           </td>
           <td class="r">
            Florida State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425174" title="Click to go to the Author Index">
             Seal, Dane
            </a>
           </td>
           <td class="r">
            Florida State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#211918" title="Click to go to the Author Index">
             Young, Charles
            </a>
           </td>
           <td class="r">
            Florida State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424296" title="Click to go to the Author Index">
             St Laurent, Louis
            </a>
           </td>
           <td class="r">
            University of Washington
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#113634" title="Click to go to the Author Index">
             Ordonez, Camilo
            </a>
           </td>
           <td class="r">
            Florida State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104389" title="Click to go to the Author Index">
             Clark, Jonathan
            </a>
           </td>
           <td class="r">
            Florida State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3247" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#marine_robotics" title="Click to go to the Keyword Index">
               Marine Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The seafloor is a complex environment and it is challenging to conduct detailed mapping, soil composition sampling, and habitat characterization missions in this benthic region. As a step toward overcoming these challenges, we present a quadruped robot capable of walking on the seafloor and maneuvering via midfluid swimming. SELQIE, the Seafloor Environment Legged Quadruped Intelligent Explorer, is capable of walking underwater at speeds up to 0.2 m/s, swimming at over 0.16 m/s, and transitioning between modes. We also introduce a path planning algorithm that can account for both swimming and walking gaits to efficiently navigate around or over obstacles, and demonstrate the robot executing such a multi-modal trajectory.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet11_07">
             17:05-17:10, Paper WeET11.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1594" name="modify4491" onclick="modify(4491,1594)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4491'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Beyond Robustness: Learning Unknown Dynamic Load Adaptation for Quadruped Locomotion on Rough Terrain
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#358613" title="Click to go to the Author Index">
             Chang, Leixin
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425900" title="Click to go to the Author Index">
             Nai, Yuxuan
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#251380" title="Click to go to the Author Index">
             Chen, Hua
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#150329" title="Click to go to the Author Index">
             Yang, Liangjing
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4491" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Unknown dynamic load carrying is one important practical application for quadruped robots. Such a problem is non-trivial, posing three major challenges in quadruped loco- motion control. First, how to model or represent the dynamics of the load in a generic manner. Second, how to make the robot capture the dynamics without any external sensing. Third, how to enable the robot to interact with load handling the mutual effect and stabilizing the load. In this work, we propose a general load modeling approach called load characteristics modeling to capture the dynamics of the load. We integrate this proposed modeling technique and leverage recent advances in Reinforcement Learning (RL) based locomotion control to enable the robot to infer the dynamics of load movement and interact with the load indirectly to stabilize it and realize the sim-to-real deployment to verify its effectiveness in real scenarios. We conduct extensive comparative simulation experiments to validate the effectiveness and superiority of our proposed method. Results show that our method outperforms other methods in sudden load resistance, load stabilizing and locomotion with heavy load on rough terrain.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet11_08">
             17:10-17:15, Paper WeET11.8
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1595" name="modify4779" onclick="modify(4779,1595)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4779'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              PIE: Parkour with Implicit-Explicit Learning Framework for Legged Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#394003" title="Click to go to the Author Index">
             Luo, Shixin
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405183" title="Click to go to the Author Index">
             Li, Songbo
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#392868" title="Click to go to the Author Index">
             Yu, Ruiqi
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#290016" title="Click to go to the Author Index">
             Wang, Zhicheng
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#113218" title="Click to go to the Author Index">
             Wu, Jun
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#232612" title="Click to go to the Author Index">
             Zhu, Qiuguo
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4779" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Parkour presents a highly challenging task for legged robots, requiring them to traverse various terrains with agile and smooth locomotion. This necessitates comprehensive understanding of both the robot's own state and the surrounding terrain, despite the inherent unreliability of robot perception and actuation. Current state-of-the-art methods either rely on complex pre-trained high-level terrain reconstruction modules or limit the maximum potential of robot parkour to avoid failure due to inaccurate perception. In this paper, we propose a one-stage end-to-end learning-based parkour framework: Parkour with Implicit-Explicit learning framework for legged robots (PIE) that leverages dual-level implicit-explicit estimation. With this mechanism, even a low-cost quadruped robot equipped with an unreliable egocentric depth camera can achieve exceptional performance on challenging parkour terrains using a relatively simple training process and reward function. While the training process is conducted entirely in simulation, our real-world validation demonstrates successful zero-shot deployment of our framework, showcasing superior parkour performance on harsh terrains.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet12">
             <b>
              WeET12
             </b>
             Regular Session, 315
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1596" name="modifyWeET12" onclick="modsession(633,1596)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet12" title="Click to go to the Program at a Glance">
             <b>
              Visual Servoing and Tracking
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#101831" title="Click to go to the Author Index">
             Chaumette, Francois
            </a>
           </td>
           <td class="r">
            Inria Center at University of Rennes
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#231782" title="Click to go to the Author Index">
             Cheng, Sheng
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet12_01">
             16:35-16:40, Paper WeET12.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1597" name="modify56" onclick="modify(56,1597)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('56'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Determination of All Stable and Unstable Equilibria for Image-Point-Based Visual Servoing
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#365117" title="Click to go to the Author Index">
             Colotti, Alessandro
            </a>
           </td>
           <td class="r">
            Centre Inria De l'Université De Rennes
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#365118" title="Click to go to the Author Index">
             García Fontán, Jorge
            </a>
           </td>
           <td class="r">
            Sorbonne Université
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#186371" title="Click to go to the Author Index">
             Goldsztejn, Alexandre
            </a>
           </td>
           <td class="r">
            CNRS IRCCyN
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102880" title="Click to go to the Author Index">
             Briot, Sébastien
            </a>
           </td>
           <td class="r">
            LS2N
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101831" title="Click to go to the Author Index">
             Chaumette, Francois
            </a>
           </td>
           <td class="r">
            Inria Center at University of Rennes
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#132132" title="Click to go to the Author Index">
             Kermorgant, Olivier
            </a>
           </td>
           <td class="r">
            École Centrale Nantes, Laboratoire Des Sciences Du Numérique De
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#268010" title="Click to go to the Author Index">
             Safey El Din, Mohab
            </a>
           </td>
           <td class="r">
            Sorbonne Univ
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab56" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#visual_servoing" title="Click to go to the Keyword Index">
               Visual Servoing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#formal_methods_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Formal Methods in Robotics and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_based_control" title="Click to go to the Keyword Index">
               Sensor-based Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#stability_analysis" title="Click to go to the Keyword Index">
               Stability Analysis
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Local minima are a well-known drawback of image-based visual servoing systems. Up to now, there were no formal guarantees on their number, or even their existence, according to the considered configuration. In this work, a formal approach is presented for the exhaustive computation of all minima and unstable equilibria for a class of six well-known image- based visual servoing controllers. This approach relies on a new polynomial formulation of the equilibrium condition that avoids using the camera pose. By using modern computational algebraic geometry methods and an ad hoc symmetry breaking strategy, the formal resolution of this new equilibrium condition is rendered computationally feasible. The proposed methodology is applied to compute the equilibria of several classical visual servoing tasks, with planar and non-planar configurations of four and five points. The effects of local minima and saddle points on the dynamics of the system are finally illustrated through intensive simulation results, as well as the effects of image noise and uncertainties on depths.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet12_02">
             16:40-16:45, Paper WeET12.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1598" name="modify102" onclick="modify(102,1598)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('102'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DiffTune: Auto-Tuning through Auto-Differentiation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#231782" title="Click to go to the Author Index">
             Cheng, Sheng
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#341345" title="Click to go to the Author Index">
             Kim, Minkyung
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#341320" title="Click to go to the Author Index">
             Song, Lin
            </a>
           </td>
           <td class="r">
            UIUC
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#349202" title="Click to go to the Author Index">
             Yang, Chengyu
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#366824" title="Click to go to the Author Index">
             Jin, Yiquan
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#193952" title="Click to go to the Author Index">
             Wang, Shenlong
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#151876" title="Click to go to the Author Index">
             Hovakimyan, Naira
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab102" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#control_architectures_and_programming" title="Click to go to the Keyword Index">
               Control Architectures and Programming
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_and_adaptive_systems" title="Click to go to the Keyword Index">
               Learning and Adaptive Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#auto_tuning" title="Click to go to the Keyword Index">
               auto-tuning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The performance of robots in high-level tasks depends on the quality of their lower-level controller, which requires fine-tuning. However, the intrinsically nonlinear dynamics and controllers make tuning a challenging task when it is done by hand. We present DiffTune, a novel, gradient-based automatic tuning framework. We formulate the controller tuning as a parameter optimization problem and update the controller parameters through gradient-based optimization. The gradient is obtained using sensitivity propagation, which is the only method for gradient computation when tuning for a physical system instead of its simulated counterpart. Furthermore, we use L1 adaptive control to compensate for the uncertainties so that the gradient is not biased by the unmodelled uncertainties. We validate the DiffTune in simulation and compare it with state-of-the-art auto-tuning methods, where DiffTune achieves the best performance in a more efficient manner. Experiments on auto-tuning a nonlinear controller for quadrotor show promising results, where DiffTune achieves 3.5x tracking error reduction on an aggressive trajectory in only 10 trials over a 12-dimensional controller par
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet12_03">
             16:45-16:50, Paper WeET12.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1599" name="modify103" onclick="modify(103,1599)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('103'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Output Feedback with Feedforward Robust Control for Motion Systems Driven by Nonlinear Position-Dependent Actuators (I)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#234351" title="Click to go to the Author Index">
             Al Saaideh, Mohammad
            </a>
           </td>
           <td class="r">
            Memorial University of Newfoundland
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#321712" title="Click to go to the Author Index">
             Boker, Almuatazbellah
            </a>
           </td>
           <td class="r">
            Virginia Tech
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#132899" title="Click to go to the Author Index">
             Al Janaideh, Mohammad
            </a>
           </td>
           <td class="r">
            University of Guelph
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab103" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper introduces a control approach for a motion system driven by a class of actuators with multiple nonlinearities. The proposed approach presents a combination of a feedforward controller and an output feedback controller to enhance the tracking performance of the motion system. The feedforward controller is mainly proposed to address the actuator dynamics and provide a linearization of the actuator without requiring measurements from the actuator. Subsequently, the output feedback controller is designed using the measured position to achieve a tracking objective for a desired reference signal, considering the unknown nonlinearities in the system and the error due to the open-loop compensation using feedforward control. The efficacy of the proposed control approach is validated through three applications: reluctance actuator, electrostatic microactuator, and magnetic levitation system. Both simulation and experimental results demonstrate the effectiveness of the proposed control approach in achieving the desired reference signal with minimal tracking error, considering that the actuator and system nonlinearities are unknown.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet12_04">
             16:50-16:55, Paper WeET12.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1600" name="modify313" onclick="modify(313,1600)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('313'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              QP-Based Visual Servoing under Motion Blur-Free Constraint
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#321666" title="Click to go to the Author Index">
             Robic, Maxime
            </a>
           </td>
           <td class="r">
            University of Picardy Jules Verne
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#323185" title="Click to go to the Author Index">
             Fraisse, Renaud
            </a>
           </td>
           <td class="r">
            Airbus Defence &amp; Space
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101938" title="Click to go to the Author Index">
             Marchand, Eric
            </a>
           </td>
           <td class="r">
            Univ Rennes, Inria, CNRS, IRISA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101831" title="Click to go to the Author Index">
             Chaumette, Francois
            </a>
           </td>
           <td class="r">
            Inria Center at University of Rennes
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab313" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#visual_servoing" title="Click to go to the Keyword Index">
               Visual Servoing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This work proposes a QP-based visual servoing scheme for limiting motion blur during the achievement of a visual task. Unlike traditional image restoration approaches, we want to avoid any deconvolution step by keeping the image sequence acquired by the camera as sharp as possible. To do so, we select the norm of the image gradient as sharpness metric, from which we design a velocity constraint that is injected in a QP controller. Our system is evaluated for an Earth observation satellite. Simulation and experimental results show the effectiveness of our approach.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet12_05">
             16:55-17:00, Paper WeET12.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1601" name="modify2589" onclick="modify(2589,1601)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2589'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              FACET: Fast and Accurate Event-Based Eye Tracking Using Ellipse Modeling for Extended Reality
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423999" title="Click to go to the Author Index">
             Ding, Junyuan
            </a>
           </td>
           <td class="r">
            Beihang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424046" title="Click to go to the Author Index">
             Wang, Ziteng
            </a>
           </td>
           <td class="r">
            DVSense (Beijing) Technology Co., Ltd., China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395400" title="Click to go to the Author Index">
             Gao, Chang
            </a>
           </td>
           <td class="r">
            Delft University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424067" title="Click to go to the Author Index">
             Liu, Min
            </a>
           </td>
           <td class="r">
            DVSense
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423964" title="Click to go to the Author Index">
             Chen, Qinyu
            </a>
           </td>
           <td class="r">
            Leiden University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2589" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#gesture__posture_and_facial_expressions" title="Click to go to the Keyword Index">
               Gesture, Posture and Facial Expressions
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_based_control" title="Click to go to the Keyword Index">
               Sensor-based Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Eye tracking is a key technology for gaze-based interactions in Extended Reality (XR), but traditional frame-based systems struggle to meet XR's demands for high accuracy, low latency, and power efficiency. Event cameras offer a promising alternative due to their high temporal resolution and low power consumption. In this paper, we present FACET (Fast and Accurate Event-based Eye Tracking), an end-to-end neural network that directly outputs pupil ellipse parameters from event data, optimized for real-time XR applications. The ellipse output can be directly used in subsequent ellipse-based pupil trackers. We enhance the EV-Eye dataset by expanding annotated data and converting original mask labels to ellipse-based annotations to train the model. Besides, a novel trigonometric loss is adopted to address angle discontinuities and a fast causal event volume event representation method is put forward. On the enhanced EV-Eye test set, FACET achieves an average pupil center error of 0.20 pixels and an inference time of 0.53 ms, reducing pixel error and inference time by 1.6x and 1.8x compared to the prior art, EV-Eye, with 4.4x and 11.7x less parameters and arithmetic operations. The code is available at https://github.com/DeanJY/FACET.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet12_06">
             17:00-17:05, Paper WeET12.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1602" name="modify4848" onclick="modify(4848,1602)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4848'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              EMoE-Tracker: Environmental MoE-Based Transformer for Robust Event-Guided Object Tracking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#406077" title="Click to go to the Author Index">
             Chen, Yucheng
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology (GZ)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256235" title="Click to go to the Author Index">
             Wang, Lin
            </a>
           </td>
           <td class="r">
            Nanyang Technological University (NTU)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4848" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The unique complementarity of frame-based and event cameras for high frame rate object tracking has recently inspired some research attempts to develop multi-modal fusion approaches. However, these methods directly fuse both modalities and thus ignore the environmental attributes, e.g., motion blur, illumination variance, occlusion, scale variation, etc. Meanwhile, no interaction between search and template features makes distinguishing target objects and backgrounds difficult. As a result, performance degradation is induced especially in challenging conditions. This paper proposes a novel and effective Transformer-based event-guided tracking framework, called eMoE-Tracker, which achieves new SOTA performance under various conditions. Our key idea is to disentangle the environment into several learnable attributes to dynamically learn the attribute-specific features for better interaction and discriminability between the target information and background. To achieve the goal, we first propose an environmental Mix-of-Experts (eMoE) module that is built upon the environmental Attributes Disentanglement to learn attribute-specific features and environmental Attributes Gating to assemble the attribute-specific features by the learnable attribute scores dynamically. The eMoE module is a subtle router that fine-tunes the transformer backbone more efficiently. We then introduce a contrastive relation modeling (CRM) module to improve interaction and discriminability between the target information and background. Extensive experiments on diverse event-based benchmark datasets showcase the superior performance of our eMoE-Tracker compared to the prior arts.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet13">
             <b>
              WeET13
             </b>
             Regular Session, 316
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1603" name="modifyWeET13" onclick="modsession(267,1603)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet13" title="Click to go to the Program at a Glance">
             <b>
              Manipulating Challenging Objects
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#413929" title="Click to go to the Author Index">
             Khan, Shiraz
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#176232" title="Click to go to the Author Index">
             Kuppuswamy, Naveen
            </a>
           </td>
           <td class="r">
            Toyota Research Institute
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet13_01">
             16:35-16:40, Paper WeET13.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1604" name="modify149" onclick="modify(149,1604)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('149'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Keypoints for Robotic Cloth Manipulation Using Synthetic Data
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#374467" title="Click to go to the Author Index">
             Lips, Thomas
            </a>
           </td>
           <td class="r">
            Ghent University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#374426" title="Click to go to the Author Index">
             De Gusseme, Victor-Louis
            </a>
           </td>
           <td class="r">
            Ghent University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#131145" title="Click to go to the Author Index">
             Wyffels, Francis
            </a>
           </td>
           <td class="r">
            Ghent University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab149" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Assistive robots should be able to wash, fold or iron clothes. However, due to the variety, deformability and self-occlusions of clothes, creating robot systems for cloth manipulation is challenging. Synthetic data is a promising direction to improve generalization, but the sim-to-real gap limits its effectiveness. To advance the use of synthetic data for cloth manipulation tasks such as robotic folding, we present a synthetic data pipeline to train keypoint detectors for almost- flattened cloth items. To evaluate its performance, we have also collected a real-world dataset. We train detectors for both T-shirts, towels and shorts and obtain an average precision of 64% and an average keypoint distance of 18 pixels. Fine-tuning on real-world data improves performance to 74% mAP and an average distance of only 9 pixels. Furthermore, we describe failure modes of the keypoint detectors and compare different approaches to obtain cloth meshes and materials. We also quantify the remaining sim- to-real gap and argue that further improvements to the fidelity of cloth assets will be required to further reduce this gap. The code, dataset and trained models are available online.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet13_02">
             16:40-16:45, Paper WeET13.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1605" name="modify907" onclick="modify(907,1605)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('907'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RaggeDi: Diffusion-Based State Estimation of Disordered Rags, Sheets, Towels and Blankets
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#320305" title="Click to go to the Author Index">
             Ye, Jikai
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338255" title="Click to go to the Author Index">
             Li, Wanze
            </a>
           </td>
           <td class="r">
            Nation University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#413929" title="Click to go to the Author Index">
             Khan, Shiraz
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#303554" title="Click to go to the Author Index">
             Chirikjian, Gregory
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab907" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Cloth state estimation is an important problem in robotics. It is essential for the robot to know the accurate state to manipulate cloth and execute tasks such as robotic dressing, stitching, and covering/uncovering human beings. However, estimating cloth state accurately remains challenging due to its high flexibility and self-occlusion. This paper proposes a diffusion model-based pipeline that formulates the cloth state estimation as an image generation problem by representing the cloth state as an RGB image that describes the point-wise translation (translation map) between a pre-defined flattened mesh and the deformed mesh in a canonical space. Then we train a conditional diffusion-based image generation model to predict the translation map based on an observation. Experiments are conducted in both simulation and the real world to validate the performance of our method. Results indicate that our method outperforms two recent methods in both accuracy and speed.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet13_03">
             16:45-16:50, Paper WeET13.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1606" name="modify1373" onclick="modify(1373,1606)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1373'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Excavating in the Wild: The GOOSE-Ex Dataset for Semantic Segmentation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#328035" title="Click to go to the Author Index">
             Hagmanns, Raphael
            </a>
           </td>
           <td class="r">
            Karlsruhe Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#327716" title="Click to go to the Author Index">
             Mortimer, Peter
            </a>
           </td>
           <td class="r">
            Universität Der Bundeswehr München
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#377846" title="Click to go to the Author Index">
             Granero, Miguel
            </a>
           </td>
           <td class="r">
            Fraunhofer IOSB
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#127926" title="Click to go to the Author Index">
             Luettel, Thorsten
            </a>
           </td>
           <td class="r">
            Universität Der Bundeswehr München
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#157298" title="Click to go to the Author Index">
             Petereit, Janko
            </a>
           </td>
           <td class="r">
            Fraunhofer IOSB
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1373" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The successful deployment of deep learning-based techniques for autonomous systems is highly dependent on the data availability for the respective system in its deployment environment. Especially for unstructured outdoor environments, very few datasets exist for even fewer robotic platforms and scenarios. In an earlier work, we presented the German Outdoor and Offroad Dataset (GOOSE) framework along with 10000 multimodal frames from an offroad vehicle to enhance the perception capabilities in unstructured environments. In this work, we address the generalizability of the GOOSE framework. To accomplish this, we open-source the GOOSE-Ex dataset, which contains additional 5000 labeled multimodal frames from various completely different environments, recorded on a robotic excavator and a quadruped platform. We perform a comprehensive analysis of the semantic segmentation performance on different platforms and sensor modalities in unseen environments. In addition, we demonstrate how the combined datasets can be utilized for different downstream applications or competitions such as offroad navigation, object manipulation or scene completion. The dataset, its platform documentation and pre-trained state-of-the-art models for offroad perception will be made available on https://goose-dataset.de/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet13_04">
             16:50-16:55, Paper WeET13.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1607" name="modify2807" onclick="modify(2807,1607)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2807'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robotic Framework for Iterative and Adaptive Profile Grading of Sand
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424678" title="Click to go to the Author Index">
             Hanut, Louis
            </a>
           </td>
           <td class="r">
            KU Leuven
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424687" title="Click to go to the Author Index">
             Du, Yurui
            </a>
           </td>
           <td class="r">
            KU Leuven
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424697" title="Click to go to the Author Index">
             Vande Moere, Andrew
            </a>
           </td>
           <td class="r">
            KU Leuven
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#128174" title="Click to go to the Author Index">
             Detry, Renaud
            </a>
           </td>
           <td class="r">
            KU Leuven
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100187" title="Click to go to the Author Index">
             Bruyninckx, Herman
            </a>
           </td>
           <td class="r">
            KU Leuven
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2807" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robotics_and_automation_in_construction" title="Click to go to the Keyword Index">
               Robotics and Automation in Construction
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper studies sand profile grading, a manipulation task to obtain a desired geometric curve in sand. Manipulating sand is challenging because like other amorphous materials, its properties are difficult to estimate and emergent effects such as collapses may occur which both influence the manipulation outcome. To tackle these challenges, humans iterate and adapt their manual actions to the observed material states. In this paper, we propose to replicate this adaptive and iterative approach on a robotic profile grading task. Our results demonstrate that (1) tool insertion adaptation reduces force limit violations during tool-material interactions, (2) grading angle adaptation ensures no undercutting or collisions while allowing for cutting or smoothing the sand profile, and (3) adapting progress speed to task evolution provides a balance between grading precision and execution time. This paper’s findings pave the way for generalized and transferable robotic systems manipulating various amorphous materials and automating a larger set of construction tasks and beyond.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet13_05">
             16:55-17:00, Paper WeET13.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1608" name="modify3353" onclick="modify(3353,1608)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3353'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Autonomous Excavation of Challenging Terrain Using Oscillatory Primitives and Adaptive Impedance Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425004" title="Click to go to the Author Index">
             Franceschini, Noah
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#326312" title="Click to go to the Author Index">
             Thangeda, Pranay
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#217244" title="Click to go to the Author Index">
             Ornik, Melkior
            </a>
           </td>
           <td class="r">
            University of Illinois Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#123478" title="Click to go to the Author Index">
             Hauser, Kris
            </a>
           </td>
           <td class="r">
            University of Illinois at Urbana-Champaign
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3353" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robotics_and_automation_in_construction" title="Click to go to the Keyword Index">
               Robotics and Automation in Construction
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#compliance_and_impedance_control" title="Click to go to the Keyword Index">
               Compliance and Impedance Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mining_robotics" title="Click to go to the Keyword Index">
               Mining Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper addresses the challenge of autonomous excavation of challenging terrains, in particular those that are prone to jamming and inter-particle adhesion when tackled by a standard penetrate-drag-scoop motion pattern. Inspired by human excavation strategies, our approach incorporates oscillatory rotation elements -- including swivel, twist, and dive motions -- to break up compacted, tangled grains and reduce jamming. We also present an adaptive impedance control method, the Reactive Attractor Impedance Controller (RAIC), that adapts a motion trajectory to unexpected forces during loading in a manner that tracks a trajectory closely when loads are low, but avoids excessive loads when significant resistance is met. Our method is evaluated on four terrains using a robotic arm, demonstrating improved excavation performance across multiple metrics, including volume scooped, protective stop rate, and trajectory completion percentage.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet13_06">
             17:00-17:05, Paper WeET13.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1609" name="modify3628" onclick="modify(3628,1609)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3628'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Diffusion-Based Self-Supervised Imitation Learning from Imperfect Visual Servoing Demonstrations for Robotic Glass Installation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425157" title="Click to go to the Author Index">
             Xiao, Canran
            </a>
           </td>
           <td class="r">
            Central South University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#281394" title="Click to go to the Author Index">
             Hou, Liwei
            </a>
           </td>
           <td class="r">
            Central South University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425178" title="Click to go to the Author Index">
             Fu, Ling
            </a>
           </td>
           <td class="r">
            Zoomlion
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#166682" title="Click to go to the Author Index">
             Chen, Wenrui
            </a>
           </td>
           <td class="r">
            Hunan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3628" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robotics_and_automation_in_construction" title="Click to go to the Keyword Index">
               Robotics and Automation in Construction
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Heavy-duty glass installation is a high-risk, precision-critical task in modern construction, traditionally performed through labor-intensive and error-prone manual methods. This paper presents a novel robotic framework that leverages diffusion-based self-supervised imitation learning from imperfect visual servoing demonstrations to achieve safe and precise glass installation. Specifically, our approach employs noisy and suboptimal demonstration data obtained via visual servoing to train a Denoising Diffusion Probabilistic Model (DDPM). This model iteratively refines installation trajectories, transforming them into smooth, precise, and collision-free movements. Extensive experiments demonstrate that our method significantly surpasses conventional visual servoing and standard imitation learning baselines in terms of success rate, precision, and installation efficiency, while markedly improving operational safety. Our results establish a new benchmark for automating complex, high-risk tasks in construction robotics.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet13_07">
             17:05-17:10, Paper WeET13.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1610" name="modify4796" onclick="modify(4796,1610)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4796'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Global-Local Graph Attention Network for Deformable Linear Objects Dynamic Interaction with Environment
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#407880" title="Click to go to the Author Index">
             Chu, Jian
            </a>
           </td>
           <td class="r">
            Hefei University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#407904" title="Click to go to the Author Index">
             Zhang, Wenkang
            </a>
           </td>
           <td class="r">
            Anhui Agricultural University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#170902" title="Click to go to the Author Index">
             Ouyang, Bo
            </a>
           </td>
           <td class="r">
            Hefei University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#407905" title="Click to go to the Author Index">
             Tian, Kunmiao
            </a>
           </td>
           <td class="r">
            Hefei University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#322088" title="Click to go to the Author Index">
             Zhang, Shuai
            </a>
           </td>
           <td class="r">
            Hefei University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#407909" title="Click to go to the Author Index">
             Zhai, Kai
            </a>
           </td>
           <td class="r">
            Hefei University of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4796" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurately modeling the interactions between deformable linear objects (DLOs) and their environments is crucial for active deformation control by robot manipulators. Graph Neural Networks (GNNs) have shown immense potential in particle-based simulation of DLOs. However, most existing studies propagate particle information in sequence, ignoring that particle motions, including the distal particle, correlate strongly with each other and the interaction state. In this paper, a global and local attention dynamic simulation model named GladSim is designed based on GNNs and the attention mechanism to aggregate information among particles and focus on the interaction particles for DLO interaction with the environment. Specifically, a global virtual node is proposed to deliver particle information and shorten the propagation path for the first time, which connects all the particles and aggregates global information. When the DLOs and the obstacle boundary particles are close, an edge is established between them to capture the interaction state. Moreover, we group all the particles by k-hop neighbors and design a HopSA module that combines hop attention and self-attention to discover the correlates among adjacent particles. Experimental results on simulation and real-world data show that the proposed GladSim network's predictive accuracy significantly outperforms baseline models, especially in long-term prediction.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet14">
             <b>
              WeET14
             </b>
             Regular Session, 402
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1611" name="modifyWeET14" onclick="modsession(543,1611)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet14" title="Click to go to the Program at a Glance">
             <b>
              Social Navigation 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#107243" title="Click to go to the Author Index">
             Kosecka, Jana
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#104036" title="Click to go to the Author Index">
             Lilienthal, Achim J.
            </a>
           </td>
           <td class="r">
            Orebro University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet14_01">
             16:35-16:40, Paper WeET14.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1612" name="modify1252" onclick="modify(1252,1612)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1252'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Generating Causal Explanations of Vehicular Agent Behavioural Interactions with Learnt Reward Profiles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#283837" title="Click to go to the Author Index">
             Howard, Rhys Peter Matthew
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#116406" title="Click to go to the Author Index">
             Hawes, Nick
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#132636" title="Click to go to the Author Index">
             Kunze, Lars
            </a>
           </td>
           <td class="r">
            University of Oxford
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1252" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#agent_based_systems" title="Click to go to the Keyword Index">
               Agent-Based Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Transparency and explainability are important features that responsible autonomous vehicles should possess, particularly when interacting with humans, and causal reasoning offers a strong basis to provide these qualities. However, even if one assumes agents act to maximise some concept of reward, it is difficult to make accurate causal inferences of agent planning without capturing what is of importance to the agent. Thus our work aims to learn a weighting of reward metrics for agents such that explanations for agent interactions can be causally inferred. We validate our approach quantitatively and qualitatively across three real-world driving datasets, demonstrating a functional improvement over previous methods and competitive performance across evaluation metrics.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet14_02">
             16:40-16:45, Paper WeET14.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1613" name="modify1404" onclick="modify(1404,1613)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1404'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Fast Online Learning of CLiFF-Maps in Changing Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339836" title="Click to go to the Author Index">
             Zhu, Yufei
            </a>
           </td>
           <td class="r">
            Örebro University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#190205" title="Click to go to the Author Index">
             Rudenko, Andrey
            </a>
           </td>
           <td class="r">
            Robert Bosch GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#155650" title="Click to go to the Author Index">
             Palmieri, Luigi
            </a>
           </td>
           <td class="r">
            Robert Bosch GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309913" title="Click to go to the Author Index">
             Heuer, Lukas
            </a>
           </td>
           <td class="r">
            Örebro University, Robert Bosch GmbH
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104036" title="Click to go to the Author Index">
             Lilienthal, Achim J.
            </a>
           </td>
           <td class="r">
            Orebro University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101909" title="Click to go to the Author Index">
             Magnusson, Martin
            </a>
           </td>
           <td class="r">
            Örebro University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1404" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_detection_and_tracking" title="Click to go to the Keyword Index">
               Human Detection and Tracking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Maps of dynamics are effective representations of motion patterns learned from prior observations, with recent research demonstrating their ability to enhance various downstream tasks such as human-aware robot navigation, long-term human motion prediction, and robot localization. Current advancements have primarily concentrated on methods for learning maps of human flow in environments where the flow is static, i.e., not assumed to change over time. In this paper we propose an online update method of the CLiFF-map (an advanced map of dynamics type that models motion patterns as velocity and orientation mixtures) to actively detect and adapt to human flow changes. As new observations are collected, our goal is to update a CLiFF-map to effectively and accurately integrate them, while retaining relevant historic motion patterns. The proposed online update method maintains a probabilistic representation in each observed location, updating parameters by continuously tracking sufficient statistics. In experiments using both synthetic and real-world datasets, we show that our method is able to maintain accurate representations of human motion dynamics, contributing to high performance flow-compliant planning downstream tasks, while being orders of magnitude faster than the comparable baselines.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet14_03">
             16:45-16:50, Paper WeET14.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1614" name="modify2559" onclick="modify(2559,1614)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2559'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Hybrid Approach to Indoor Social Navigation: Integrating Reactive Local Planning and Proactive Global Planning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#337404" title="Click to go to the Author Index">
             Debnath, Arnab
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#205862" title="Click to go to the Author Index">
             Stein, Gregory
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107243" title="Click to go to the Author Index">
             Kosecka, Jana
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2559" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We consider the problem of indoor building-scale social navigation, where the robot must reach a point goal as quickly as possible without colliding with humans who are freely moving around. Factors such as varying crowd densities, unpredictable human behavior, and the constraints of indoor spaces add significant complexity to the navigation task, necessitating a more advanced approach. We propose a modular navigation framework that leverages the strengths of both classical methods and deep reinforcement learning (DRL). Our approach employs a global planner to generate waypoints, assigning soft costs around anticipated pedestrian locations, encouraging caution around potential future positions of humans. Simultaneously, the local planner, powered by DRL, follows these waypoints while avoiding collisions. The combination of these planners enables the agent to perform complex maneuvers and effectively navigate crowded and constrained environments while improving reliability. Many existing studies on social navigation are conducted in simplistic or open environments, limiting the ability of trained models to perform well in complex, real-world settings. To advance research in this area, we introduce a new 2D benchmark designed to facilitate development and testing of social navigation strategies in indoor environments. We benchmark our method against traditional and RL-based navigation strategies, demonstrating that our approach outperforms both.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet14_04">
             16:50-16:55, Paper WeET14.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1615" name="modify2777" onclick="modify(2777,1615)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2777'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Overlapping Social Navigation Principles: A Framework for Social Robot Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#314831" title="Click to go to the Author Index">
             Ikeda, Bryce
            </a>
           </td>
           <td class="r">
            University of North Carolina Chapel Hill
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#399595" title="Click to go to the Author Index">
             Higger, Mark
            </a>
           </td>
           <td class="r">
            Colorado School of Mines
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#360978" title="Click to go to the Author Index">
             Song, Christina Soyoung
            </a>
           </td>
           <td class="r">
            Illinois State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#113407" title="Click to go to the Author Index">
             Trafton, Greg
            </a>
           </td>
           <td class="r">
            Naval Research Laboratory
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2777" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             As autonomous robots become integrated into society, they must socially navigate around humans. We propose that effective social robot navigation relies on three key principles: social norms, perceived safety, and legibility. Our framework, Overlapping Social Navigation Principles, suggests that the strength of each principle is influenced by the presence of other principles. To test our framework, we implemented SRN behaviors on an autonomous robot in a passing scenario and conducted an online study where participants ranked videos of different SRN behavior combinations. Our findings show that incorporating all three principles enhances SRN, with social norms having the greatest impact.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet14_05">
             16:55-17:00, Paper WeET14.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1616" name="modify4057" onclick="modify(4057,1616)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4057'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Relative Velocity-Based Reward Model for Socially-Aware Navigation with Deep Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424301" title="Click to go to the Author Index">
             Maddumage, Vinu Vihan
            </a>
           </td>
           <td class="r">
            University of Technology Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106883" title="Click to go to the Author Index">
             Kodagoda, Sarath
            </a>
           </td>
           <td class="r">
            University of Technology, Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#137844" title="Click to go to the Author Index">
             Carmichael, Marc
            </a>
           </td>
           <td class="r">
            Centre for Autonomous Systems
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#292320" title="Click to go to the Author Index">
             Gunatilake, Amal
            </a>
           </td>
           <td class="r">
            University of Technology Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#248368" title="Click to go to the Author Index">
             Thiyagarajan, Karthick
            </a>
           </td>
           <td class="r">
            University of Technology Sydney
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425513" title="Click to go to the Author Index">
             Martin, Jodi
            </a>
           </td>
           <td class="r">
            Guide Dogs NSW/ACT
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4057" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#human_aware_motion_planning" title="Click to go to the Keyword Index">
               Human-Aware Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#social_hri" title="Click to go to the Keyword Index">
               Social HRI
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Mobile robots are increasingly deployed in shared environments where they must learn to navigate alongside humans. Deep Reinforcement Learning (DRL) techniques have shown promise in developing navigation policies that account for interactions within crowds, fostering socially acceptable movement. However, these techniques often depend heavily on collision avoidance rewards to ensure safe navigation. In this study, we introduce a novel reward component based on relative velocity for collision avoidance, which integrates both the robot’s and humans’ kinematics within personal distance constraints. We conducted a thorough evaluation comparing this new reward model against a conventional one in simulated environments using advanced DRL methods. Our findings indicate that the proposed reward model improves the robots’ ability to avoid collisions and navigate towards their goals while being socially acceptable.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet14_06">
             17:00-17:05, Paper WeET14.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1617" name="modify4782" onclick="modify(4782,1617)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4782'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SICNav: Safe and Interactive Crowd Navigation Using Model Predictive Control and Bilevel Optimization
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#238017" title="Click to go to the Author Index">
             Samavi, Sepehr
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#358119" title="Click to go to the Author Index">
             Han, James
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#142623" title="Click to go to the Author Index">
             Shkurti, Florian
            </a>
           </td>
           <td class="r">
            University of Toronto
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#124265" title="Click to go to the Author Index">
             Schoellig, Angela P.
            </a>
           </td>
           <td class="r">
            TU Munich
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4782" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#social_navigation" title="Click to go to the Keyword Index">
               Social Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#optimization_and_optimal_control" title="Click to go to the Keyword Index">
               Optimization and Optimal Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robots need to predict and react to human motions to navigate through a crowd without collisions. Many existing methods decouple prediction from planning, which does not account for the interaction between robot and human motions and can lead to the robot getting stuck. We propose SICNav, a Model Predictive Control (MPC) method that jointly solves for robot motion and predicted crowd motion in closed-loop. We model each human in the crowd to be following an Optimal Reciprocal Collision Avoidance (ORCA) scheme and embed that model as a constraint in the robot’s local planner, resulting in a bilevel nonlinear MPC optimization problem. We use a KKT- reformulation to cast the bilevel problem as a single level and use a nonlinear solver to optimize. Our MPC method can influence pedestrian motion while explicitly satisfying safety constraints in a single-robot multi-human environment. We analyze the performance of SICNav in two simulation environments and indoor experiments with a real robot to demonstrate safe robot motion that can influence the surrounding humans. We also validate the trajectory forecasting performance of ORCA on a human trajectory dataset.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet15">
             <b>
              WeET15
             </b>
             Regular Session, 403
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1618" name="modifyWeET15" onclick="modsession(581,1618)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet15" title="Click to go to the Program at a Glance">
             <b>
              Surgical Robotics: Systems
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#100111" title="Click to go to the Author Index">
             Arai, Fumihito
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#106216" title="Click to go to the Author Index">
             Zefran, Milos
            </a>
           </td>
           <td class="r">
            University of Illinois at Chicago
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet15_01">
             16:35-16:40, Paper WeET15.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1619" name="modify475" onclick="modify(475,1619)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('475'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Autonomous Continuous Capsulorhexis Based on a Force-Vision-Guided Robot System
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335423" title="Click to go to the Author Index">
             Liang, Hongli
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395014" title="Click to go to the Author Index">
             Liu, Jiali
            </a>
           </td>
           <td class="r">
            Zhongshan Ophthalmic Center, Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#160079" title="Click to go to the Author Index">
             Nasseri, M. Ali
            </a>
           </td>
           <td class="r">
            Technische Universitaet Muenchen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#244766" title="Click to go to the Author Index">
             Lin, Haotian
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University, Zhongshan Ophthalmic Center
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#193739" title="Click to go to the Author Index">
             Huang, Kai
            </a>
           </td>
           <td class="r">
            Sun Yat-Sen University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab475" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Capsulorhexis is challenging in cataract surgery, since the size, centering, and circularity of the capsule are important. Those indicators are closely related to the subsequent step of phacoemulsification and the postoperative position of the intraocular lens. It takes 3-5 years for a resident to practice, while the occurrence of deficient capsulorhexis is still inevitable. This paper proposes a robotic system to automate Continuous Curvilinear Capsulorhexis(CCC) in cataract surgery. A typical ophthalmic microscope system and a triaxial force sensor are utilized to guide the robot system with a force-vision method. The constraint of a Remote Center of Motion (RCM) is designed to perform the surgery route. The experimental results on ex-vivo porcine eyes show our autonomous method can achieve a satisfactory 6mm capsule. With an average centering deviation below 76% and circularity of 0.993, the consistency of the capsulorhexis is comparable to a surgeon-made one.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet15_02">
             16:40-16:45, Paper WeET15.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1620" name="modify675" onclick="modify(675,1620)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('675'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Ultrasound-Guided Robotic Blood Drawing and in Vivo Studies on Submillimetre Vessels of Rats
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416185" title="Click to go to the Author Index">
             Jing, Shuaiqi
            </a>
           </td>
           <td class="r">
            Chengdu Aixam Medical Technology Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#360412" title="Click to go to the Author Index">
             Yao, Tianliang
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416187" title="Click to go to the Author Index">
             Zhang, Ke
            </a>
           </td>
           <td class="r">
            Chengdu Aixam Medical Technology Co. Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256953" title="Click to go to the Author Index">
             Wu, Di
            </a>
           </td>
           <td class="r">
            University of Southern Denmark
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416188" title="Click to go to the Author Index">
             Wang, Qiulin
            </a>
           </td>
           <td class="r">
            Chengdu Aixam Medical Technology Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#326569" title="Click to go to the Author Index">
             Chen, Zixi
            </a>
           </td>
           <td class="r">
            Scuola Superiore Sant'Anna
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419867" title="Click to go to the Author Index">
             Chen, Ke
            </a>
           </td>
           <td class="r">
            Chengdu Aixam Medical Technology Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#165194" title="Click to go to the Author Index">
             Qi, Peng
            </a>
           </td>
           <td class="r">
            Tongji University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab675" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#service_robotics" title="Click to go to the Keyword Index">
               Service Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Billions of vascular access procedures are performed annually worldwide, serving as a crucial first step in various clinical diagnostic and therapeutic procedures. For pediatric or elderly individuals, whose vessels are small in size (typically 2 to 3 mm in diameter for adults and &lt;1 mm in children), vascular access can be highly challenging. This study presents an image-guided robotic system aimed at enhancing the accuracy of difficult vascular access procedures. The system integrates a 6-DoF (Degrees of Freedom) robotic arm with a 3-DoF end-effector, ensuring precise navigation and needle insertion. Multi-modal imaging and sensing technologies have been utilized to endow the medical robot with precision and safety, while ultrasound (US) imaging guidance is specifically evaluated in this study. To evaluate in vivo vascular access in submillimeter vessels, we conducted ultrasound-guided robotic blood drawing on the tail veins (with a diameter of 0.7 ± 0.2 mm) of 40 rats. The results demonstrate that the system achieved a first-attempt success rate of 95%. The high first-attempt success rate in intravenous vascular access, even with small blood vessels, demonstrates the system’s effectiveness in performing these procedures. This capability reduces the risk of failed attempts, minimizes patient discomfort, and enhances clinical efficiency.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet15_03">
             16:45-16:50, Paper WeET15.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1621" name="modify1200" onclick="modify(1200,1621)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1200'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Sensory Glove-Based Surgical Robot User Interface
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#376125" title="Click to go to the Author Index">
             Borgioli, Leonardo
            </a>
           </td>
           <td class="r">
            University of Illinois Chicago
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#298431" title="Click to go to the Author Index">
             Oh, Ki-Hwan
            </a>
           </td>
           <td class="r">
            University of Illinois at Chicago
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#384726" title="Click to go to the Author Index">
             Valle, Valentina
            </a>
           </td>
           <td class="r">
            Surgical Innovation and Training Lab, Department of Surgery, Col
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#384731" title="Click to go to the Author Index">
             Ducas, Alvaro
            </a>
           </td>
           <td class="r">
            Surgical Innovation and Training Lab, Department of Surgery, Col
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420581" title="Click to go to the Author Index">
             Mohammad Halloum, Mohammad Halloum
            </a>
           </td>
           <td class="r">
            Surgical Innovation and Training Lab, Department of Surgery, Col
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420587" title="Click to go to the Author Index">
             Diego Federico Mendoza Medina, Diego Federico Mendoza Medina
            </a>
           </td>
           <td class="r">
            Surgical Innovation and Training Lab, Department of Surgery, Col
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398278" title="Click to go to the Author Index">
             Lopez, Paula
            </a>
           </td>
           <td class="r">
            Surgical Innovation and Training Lab, Department of Surgery, Col
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420585" title="Click to go to the Author Index">
             Arman Sharifi, Arman Sharifi
            </a>
           </td>
           <td class="r">
            Surgical Innovation and Training Lab, Department of Surgery, Col
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398280" title="Click to go to the Author Index">
             Cassiani, Jessica
            </a>
           </td>
           <td class="r">
            Surgical Innovation and Training Lab, Department of Surgery, Col
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106216" title="Click to go to the Author Index">
             Zefran, Milos
            </a>
           </td>
           <td class="r">
            University of Illinois at Chicago
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378869" title="Click to go to the Author Index">
             Chen, Liaohai
            </a>
           </td>
           <td class="r">
            Surgical Innovation and Training Lab, Department of Surgery, Col
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378882" title="Click to go to the Author Index">
             Giulianotti, Pier Cristoforo
            </a>
           </td>
           <td class="r">
            Surgical Innovation and Training Lab, Department of Surgery, Col
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1200" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic surgery has reached a high level of maturity and has become an integral part of standard surgical care. However, existing surgeon consoles are bulky and take up valuable space in the operating room, present challenges for surgical team coordination, and their proprietary nature makes it difficult to take advantage of recent technological advances, especially in virtual and augmented reality. One potential area for further improvement is the integration of modern sensory gloves into robotic platforms, allowing surgeons to control robotic arms intuitively with their hand movements. We propose one such system that combines an HTC Vive tracker, a Manus Meta Prime 3 XR sensory glove, and SCOPEYE wireless smart glasses. The system controls one arm of a da Vinci surgical robot. In addition to moving the arm, the surgeon can use fingers to control the end-effector of the surgical instrument. Hand gestures are used to implement clutching and similar functions. In particular, we introduce clutching of the instrument orientation, a functionality unavailable in the da Vinci system. The vibrotactile elements of the glove are used to provide feedback to the user when gesture commands are invoked. A qualitative and quantitative evaluation has been conducted comparing the current device to the dVRK console; the system shows that it has excellent tracking accuracy and allows surgeons to efficiently perform common surgical training tasks with minimal practice with the new interface.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet15_04">
             16:50-16:55, Paper WeET15.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1622" name="modify2145" onclick="modify(2145,1622)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2145'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Self-Deformable Magnetic Miniature Robot for Traction Assistance in Endoscopic Submucosal Dissection
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423476" title="Click to go to the Author Index">
             Zhang, Bolan
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#217061" title="Click to go to the Author Index">
             Yamanaka, Toshiro
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#413022" title="Click to go to the Author Index">
             Shu, Tengo
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419938" title="Click to go to the Author Index">
             Liu, Yuxuan
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100111" title="Click to go to the Author Index">
             Arai, Fumihito
            </a>
           </td>
           <td class="r">
            The University of Tokyo
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2145" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Between 1999 and 2020, gastrointestinal cancers were responsible for over three million deaths, emphasizing the critical role of minimally invasive surgical techniques like Endoscopic Submucosal Dissection (ESD) in managing such life-threatening conditions. ESD, which dissects the connective tissue between the mucosal and muscular layers using an electrosurgical knife connected to an endoscope, requires a constant traction force to stabilize tissues and expose underlying anatomical structures. This paper introduces a miniature magnetic flexible robot, actuated by a permanent magnet on a robotic manipulator, designed to enhance ESD by providing traction forces consistently on lesions. The robot was fabricated by casting magnetic silicone composites, and its safe deployment through the endoscope instrument channel was successfully demonstrated, avoiding tissue contact. Experiments in a rubber intestine model validated the feasibility of providing constant traction and 2 DOF orientation control via the robot, allowing real-time fine-tuning of the force direction. This reduces the difficulty and improves the precision and safety of ESD. This research presents a practical method for achieving stable force output in medical miniature robots, particularly in gastrointestinal procedures.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet15_05">
             16:55-17:00, Paper WeET15.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1623" name="modify3007" onclick="modify(3007,1623)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3007'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Variable-Stiffness Nasotracheal Intubation Robot with Passive Buffering: A Modular Platform in Mannequin Studies
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#376122" title="Click to go to the Author Index">
             Hao, Ruoyi
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#223899" title="Click to go to the Author Index">
             Lai, Jiewen
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378307" title="Click to go to the Author Index">
             Zhong, Wenqi
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423848" title="Click to go to the Author Index">
             Xie, Dihong
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#285217" title="Click to go to the Author Index">
             Tian, Yu
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#370759" title="Click to go to the Author Index">
             Zhang, Tao
            </a>
           </td>
           <td class="r">
            Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#344164" title="Click to go to the Author Index">
             Zhang, Yang
            </a>
           </td>
           <td class="r">
            Hubei University of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354005" title="Click to go to the Author Index">
             Chan, Catherine Po Ling
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#257621" title="Click to go to the Author Index">
             Chan, Jason Ying-Kuen
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106795" title="Click to go to the Author Index">
             Ren, Hongliang
            </a>
           </td>
           <td class="r">
            Chinese Univ Hong Kong (CUHK) &amp; National Univ Singapore(NUS)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3007" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Intubation is a critical medical procedure for securing airway patency in patients, but the inconsistent skill levels among medical practitioners necessitate the advancement of better robotic solutions. While orotracheal intubation robots have been widely developed, nasotracheal intubation remains essential in specific clinical scenarios. However, nasotracheal intubation robots are still underdeveloped and lack buffer protection mechanisms to ensure safety. This study presents a novel variable-stiffness nasotracheal intubation robot (NIR) with passive buffering. The proposed NIR is a modular platform capable of performing the main steps of nasotracheal intubation, validated through mannequin studies via teleoperation. We proposed a variable-stiffness fiberoptic bronchoscope (FOB) control module for the FOB distal end control, and validated its dual functionality in experiments: low-stiffness mode provides passive buffering during nasal cavity navigation, with a frontal peak force of 2.8 N and a lateral peak force of 0.12 N; high-stiffness mode enhances load-bearing capacity for near-glottis navigation, with a frontal bearing force of 4.9 N and a lateral bearing force of 0.42 N. Additionally, a compact (74 × 64 × 53 mm, 150 g) FOB feeding module with passive failure protection was designed to limit the max frontal impact force to 2.3 N.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet15_06">
             17:00-17:05, Paper WeET15.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1624" name="modify3992" onclick="modify(3992,1624)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3992'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SurgPose: A Dataset for Articulated Robotic Surgical Tool Pose Estimation and Tracking
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426059" title="Click to go to the Author Index">
             Wu, Zijian
            </a>
           </td>
           <td class="r">
            The University of British Columbia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#310895" title="Click to go to the Author Index">
             Schmidt, Adam
            </a>
           </td>
           <td class="r">
            Intuitive Surgical
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426082" title="Click to go to the Author Index">
             Moore, Randy
            </a>
           </td>
           <td class="r">
            The University of British Columbia
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#298819" title="Click to go to the Author Index">
             Zhou, Haoying
            </a>
           </td>
           <td class="r">
            Worcester Polytechnic Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#319940" title="Click to go to the Author Index">
             Banks, Alexandre
            </a>
           </td>
           <td class="r">
            University of New Brunswick
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106071" title="Click to go to the Author Index">
             Kazanzides, Peter
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106462" title="Click to go to the Author Index">
             Salcudean, Septimiu E.
            </a>
           </td>
           <td class="r">
            University of British Columbia
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3992" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Accurate and efficient surgical robotic tool pose estimation is of fundamental significance to downstream applications such as augmented reality (AR) in surgical training and learning-based autonomous manipulation. While significant advancements have been made in pose estimation for humans and animals, it is still a challenge in surgical robotics due to the scarcity of published data. The relatively large absolute error of the da Vinci end effector kinematics and arduous calibration procedure make calibrated kinematics data collection expensive. Driven by this limitation, we collected a dataset, dubbed SurgPose, providing instance-aware semantic keypoints for visual surgical tool pose estimation and tracking. By marking keypoints using ultraviolet (UV) reactive paint, which is invisible under white light and fluorescent under UV light, we execute the same trajectory under different lighting conditions to collect raw videos and keypoint annotations, respectively. The SurgPose dataset consists of approximately 120K surgical instrument instances of 6 categories as shown in Fig. 1. Since the videos are collected in stereo pairs, the 2D pose can be lifted to 3D based on stereo-matching depth. In addition to releasing the dataset, we tested a few baseline approaches to surgical instrument tracking to demonstrate the utility of SurgPose. More details can be found at surgpose.github.io.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet15_07">
             17:05-17:10, Paper WeET15.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1625" name="modify4971" onclick="modify(4971,1625)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4971'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              On High Performance Control of Concentric Tube Continuum Robots through Parsimonious Calibration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#316721" title="Click to go to the Author Index">
             Boyer, Quentin
            </a>
           </td>
           <td class="r">
            UBFC
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#114742" title="Click to go to the Author Index">
             Voros, Sandrine
            </a>
           </td>
           <td class="r">
            TIMC-IMAG Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405833" title="Click to go to the Author Index">
             Roux, Pierre
            </a>
           </td>
           <td class="r">
            FEMTO-ST Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405834" title="Click to go to the Author Index">
             Marionnet, François
            </a>
           </td>
           <td class="r">
            FEMTO-ST Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#122197" title="Click to go to the Author Index">
             Rabenorosoa, Kanty
            </a>
           </td>
           <td class="r">
            Univ. Bourgogne Franche-Comté, CNRS
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#196280" title="Click to go to the Author Index">
             Chikhaoui, M. Taha
            </a>
           </td>
           <td class="r">
            CNRS - Univ. Grenoble Alpes
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4971" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#calibration_and_identification" title="Click to go to the Keyword Index">
               Calibration and Identification
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Continuum robots deform continuously, compared to conventional robots composed of rigid links and joints, and require dedicated calibration methods. Indeed, calibration is an essential step to obtain high performance control, as it directly influences robot accuracy. In this paper, we investigate how model parameters influence both model accuracy and model-based closed-loop control accuracy of Concentric Tube Continuum Robots (CTCR). A fast, robust, and real-time implementation of the Cosserat rod model is first introduced. Then, a model-based Jacobian control scheme is presented. A parsimonious calibration procedure focused on control accuracy is finally proposed to achieve submillimetric tracking errors along a 3D trajectory at velocity reaching 5 mm/s in complex scenarios including actuation constraints, obstacle avoidance, and external forces. Results are demonstrated both in simulation and on an experimental setup of a 3-tube CTCR.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet16">
             <b>
              WeET16
             </b>
             Regular Session, 404
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1626" name="modifyWeET16" onclick="modsession(121,1626)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet16" title="Click to go to the Program at a Glance">
             <b>
              Deformable Objects
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#237816" title="Click to go to the Author Index">
             Li, Yunzhu
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#108549" title="Click to go to the Author Index">
             Iordachita, Ioan Iulian
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet16_01">
             16:35-16:40, Paper WeET16.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1627" name="modify32" onclick="modify(32,1627)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('32'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Deformation Control of a 3D Soft Object Using RGB-D Visual Servoing and FEM-Based Dynamic Model
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#296465" title="Click to go to the Author Index">
             Ouafo Fonkoua, Mandela
            </a>
           </td>
           <td class="r">
            Inria Centre at Rennes University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101831" title="Click to go to the Author Index">
             Chaumette, Francois
            </a>
           </td>
           <td class="r">
            Inria Center at University of Rennes
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104061" title="Click to go to the Author Index">
             Krupa, Alexandre
            </a>
           </td>
           <td class="r">
            Centre Inria De l'Université De Rennes
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab32" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#visual_servoing" title="Click to go to the Keyword Index">
               Visual Servoing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this letter, we present a visual control framework for accurately positioning feature points belonging to the surface of a 3D deformable object to desired 3D positions, by acting on a set of manipulated points using a robotic manipulator. Notably, our framework considers the dynamic behavior of the object deformation, that is, we do not assume that the object is in its static equilibrium during the manipulation. By relying on a coarse dynamic Finite Element Model (FEM), we have successfully formulated the analytical relationship expressing the motion of the feature points to the six degrees of freedom (6~DOF) motion of a robot gripper. From this modeling step, a novel closed-loop deformation controller is designed. To be robust against model approximations, the whole shape of the object is tracked in real-time using an RGB-D camera, thus allowing to correct any drift between the object and its model on-the-fly. Our model-based and vision-based controller has been validated in real experiments. The results highlight the effectiveness of the proposed methodology.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet16_02">
             16:40-16:45, Paper WeET16.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1628" name="modify1161" onclick="modify(1161,1628)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1161'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Real-Time Deformation-Aware Control for Autonomous Robotic Subretinal Injection Based on OCT Guidance
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420614" title="Click to go to the Author Index">
             Arikan, Demir
            </a>
           </td>
           <td class="r">
            Technical University Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#312928" title="Click to go to the Author Index">
             Zhang, Peiyao
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309994" title="Click to go to the Author Index">
             Sommersperger, Michael
            </a>
           </td>
           <td class="r">
            Technical University of Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#309456" title="Click to go to the Author Index">
             Dehghani, Shervin
            </a>
           </td>
           <td class="r">
            TUM
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#291427" title="Click to go to the Author Index">
             Esfandiari, Mojtaba
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105851" title="Click to go to the Author Index">
             Taylor, Russell H.
            </a>
           </td>
           <td class="r">
            The Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#160079" title="Click to go to the Author Index">
             Nasseri, M. Ali
            </a>
           </td>
           <td class="r">
            Technische Universitaet Muenchen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#139397" title="Click to go to the Author Index">
             Gehlbach, Peter
            </a>
           </td>
           <td class="r">
            Johns Hopkins Medical Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107647" title="Click to go to the Author Index">
             Navab, Nassir
            </a>
           </td>
           <td class="r">
            TU Munich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#108549" title="Click to go to the Author Index">
             Iordachita, Ioan Iulian
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1161" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic platforms provide consistent and precise tool positioning that significantly enhances retinal microsurgery. Integrating such systems with intraoperative optical coherence tomography (iOCT) enables image-guided robotic interventions, allowing autonomous performance of advanced treatments, such as injecting therapeutic agents into the subretinal space. However, tissue deformations due to tool-tissue interactions constitute a significant challenge in autonomous iOCT-guided robotic subretinal injections. Such interactions impact correct needle positioning and procedure outcomes. This paper presents a novel method for autonomous subretinal injection under iOCT guidance that considers tissue deformations during the insertion procedure. The technique is achieved through real-time segmentation and 3D reconstruction of the surgical scene from densely sampled iOCT B-scans, which we refer to as B
             <sup>
              5
             </sup>
             -scans. Using B
             <sup>
              5
             </sup>
             -scans we monitor the position of the instrument relative to a virtual target layer between the ILM and RPE. Our experiments on ex-vivo porcine eyes demonstrate dynamic adjustment of the insertion depth and overall improved accuracy in needle positioning compared to prior autonomous insertion approaches. Compared to a 35% success rate in subretinal bleb generation with previous approaches, our method reliably created subretinal blebs in 90% our experiments. The source code and data used in this study are publicly available on GitHub
             <sup>
              1
             </sup>
             .
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet16_03">
             16:45-16:50, Paper WeET16.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1629" name="modify1328" onclick="modify(1328,1629)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1328'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              6-DoF Shape Servoing of Deformable Objects in Co-Rotated Space of Modal Graph
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#195722" title="Click to go to the Author Index">
             Yang, Bohan
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#333989" title="Click to go to the Author Index">
             Huang, Tianyu
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#191020" title="Click to go to the Author Index">
             Zhong, Fangxun
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100055" title="Click to go to the Author Index">
             Liu, Yunhui
            </a>
           </td>
           <td class="r">
            Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1328" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#visual_servoing" title="Click to go to the Keyword Index">
               Visual Servoing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Shape control of deformable objects under both rotational and translational deformations is important for versatile robotic applications. However, deformation control with full 6-degree-of-freedom (DoF) manipulation is an open problem, since modeling and describing rotational deformations lead to significant challenges. To tackle the problem, this paper proposes a novel method by introducing a co-rotated space for the modal graph representation of objects with unknown physical and geometric models. In this space, we design new deformation features that can encode local rotations while preserving a compact and low-frequency shape representation. Moreover, these features can be mapped analytically to the robot manipulation, enabling the design of adaptive control laws with guaranteed stability for unmodeled objects. Experiments on complex volumetric objects demonstrate the effectiveness and advantages of our method with raw, noisy, and unregistered point clouds. The results highlight the importance of integrating the co-rotated features to address rotational deformations.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet16_04">
             16:50-16:55, Paper WeET16.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1630" name="modify1495" onclick="modify(1495,1630)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1495'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Deformable Gaussian Splatting for Efficient and High-Fidelity Reconstruction of Surgical Scenes
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379522" title="Click to go to the Author Index">
             Shan, Jiwei
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420287" title="Click to go to the Author Index">
             Cai, Zeyu
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420316" title="Click to go to the Author Index">
             Hsieh, Cheng-Tai
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256999" title="Click to go to the Author Index">
             Han, Lijun
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#178362" title="Click to go to the Author Index">
             Cheng, Shing Shin
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103003" title="Click to go to the Author Index">
             Wang, Hesheng
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1495" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_medical_robotics" title="Click to go to the Keyword Index">
               Computer Vision for Medical Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Efficient and high-fidelity reconstruction of deformable surgical scenes is a critical yet challenging task. Building on recent advancements in 3D Gaussian splatting, current methods have seen significant improvements in both reconstruction quality and rendering speed. However, two major limitations remain: (1) difficulty in handling irreversible dynamic changes, such as tissue shearing, which are common in surgical scenes; and (2) the lack of hierarchical modeling for surgical scene deformation, which reduces rendering speed. To address these challenges, we introduce EH-SurGS, an efficient and high-fidelity reconstruction algorithm for deformable surgical scenes. We propose a deformation modeling approach that incorporates the life cycle of 3D Gaussians, effectively capturing both regular and irreversible deformations, thus enhancing reconstruction quality. Additionally, we present an adaptive motion hierarchy strategy that distinguishes between static and deformable regions within the surgical scene. This strategy reduces the number of 3D Gaussians passing through the deformation field, thereby improving rendering speed. Extensive experiments on public datasets captured with static endoscopes demonstrate that our method surpasses existing state-of-the-art approaches in both reconstruction quality and rendering speed. Ablation studies further validate the effectiveness and necessity of our proposed components. We will open-source our code upon acceptance of the paper.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet16_05">
             16:55-17:00, Paper WeET16.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1631" name="modify3817" onclick="modify(3817,1631)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3817'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              One-Shot Video Imitation Via Parameterized Symbolic Abstraction Graphs
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#277454" title="Click to go to the Author Index">
             Wang, Jianren
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378246" title="Click to go to the Author Index">
             Liu, Kangni
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#305022" title="Click to go to the Author Index">
             Guo, Dingkun
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#293274" title="Click to go to the Author Index">
             Xian, Zhou
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101843" title="Click to go to the Author Index">
             Atkeson, Christopher
            </a>
           </td>
           <td class="r">
            CMU
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3817" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Learning to manipulate dynamic and deformable objects from a single demonstration video holds great promise in terms of scalability. Previous approaches have predominantly focused on either replaying object relationships or actor trajectories. The former often struggles to generalize across diverse tasks, while the latter suffers from data inefficiency. Moreover, both methodologies encounter challenges in capturing invisible physical attributes, such as forces. In this paper, we propose to interpret video demonstrations through a series of Parameterized Symbolic Abstraction Graphs (PSAGs), where nodes represent objects and edges denote relationships between objects. We further ground geometric constraints through simulation to estimate non-geometric, visually imperceptible attributes. The augmented PSAGs are then applied in real robot experiments. Our approach has been validated across a range of tasks, such as Cutting Avocado, Cutting Vegetable, Pouring Liquid, Rolling Dough, and Slicing Pizza. We demonstrate successful generalization to novel objects with distinct visual and physical properties. For visualizations of the learned policies please check: https://jianrenw.com/PSAG/
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet16_06">
             17:00-17:05, Paper WeET16.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1632" name="modify4426" onclick="modify(4426,1632)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4426'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              KUDA: Keypoints to Unify Dynamics Learning and Visual Prompting for Open-Vocabulary Robotic Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419683" title="Click to go to the Author Index">
             Liu, Zixian
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378728" title="Click to go to the Author Index">
             Zhang, Mingtong
            </a>
           </td>
           <td class="r">
            UIUC
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#237816" title="Click to go to the Author Index">
             Li, Yunzhu
            </a>
           </td>
           <td class="r">
            Columbia University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4426" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             With the rapid advancement of large language models (LLMs) and vision-language models (VLMs), significant progress has been made in developing open-vocabulary robotic manipulation systems. However, many existing approaches overlook the importance of object dynamics, limiting their applicability to more complex, dynamic tasks. In this work, we introduce KUDA, an open-vocabulary manipulation system that integrates dynamics learning and visual prompting through keypoints, leveraging both VLMs and learning-based neural dynamics models. Our key insight is that a textit{keypoint-based target specification} is simultaneously interpretable by VLMs and can be efficiently translated into cost functions for model-based planning. Given language instructions and visual observations, KUDA first assigns keypoints to the RGB image and queries the VLM to generate target specifications. These abstract keypoint-based representations are then converted into cost functions, which are optimized using a learned dynamics model to produce robotic trajectories. We evaluate KUDA on a range of manipulation tasks, including free-form language instructions across diverse object categories, multi-object interactions, and deformable or granular objects, demonstrating the effectiveness of our framework. The project page is available at url{http://kuda-dynamics.github.io/}.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet16_07">
             17:05-17:10, Paper WeET16.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1633" name="modify5061" onclick="modify(5061,1633)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5061'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DLO Perceiver: Grounding Large Language Model for Deformable Linear Objects Perception
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#275384" title="Click to go to the Author Index">
             Caporali, Alessio
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#297357" title="Click to go to the Author Index">
             Galassi, Kevin
            </a>
           </td>
           <td class="r">
            Università Di Bologna
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103582" title="Click to go to the Author Index">
             Palli, Gianluca
            </a>
           </td>
           <td class="r">
            University of Bologna
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5061" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_manufacturing" title="Click to go to the Keyword Index">
               Computer Vision for Manufacturing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#recognition" title="Click to go to the Keyword Index">
               Recognition
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The perception of Deformable Linear Objects (DLOs) is a challenging task due to their complex and ambiguous appearance, lack of discernible features, typically small sizes, and deformability. Despite these challenges, achieving a robust and effective segmentation of DLOs is crucial to introduce robots into environments where they are currently underrepresented, such as domestic and complex industrial settings. In this context, the integration of language-based inputs can simplify the perception task while also enabling the possibility of introducing robots as human companions. Therefore, this paper proposes a novel architecture for the perception of DLOs, wherein the input image is augmented with a text-based prompt guiding the segmentation of the target DLO. After encoding the image and text separately, a Perceiver-inspired structure is exploited to compress the concatenated data into transformer layers and generate the output mask from a latent vector representation. The method is experimentally evaluated on real-world images of DLOs like electrical cables and ropes, validating its efficacy and efficiency in real practical scenarios.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet17">
             <b>
              WeET17
             </b>
             Regular Session, 405
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1634" name="modifyWeET17" onclick="modsession(217,1634)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet17" title="Click to go to the Program at a Glance">
             <b>
              Large Models for Autonomous Vehicles
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#398669" title="Click to go to the Author Index">
             Billah, Syed
            </a>
           </td>
           <td class="r">
            Pennsylvania State University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#118282" title="Click to go to the Author Index">
             Chung, Soon-Jo
            </a>
           </td>
           <td class="r">
            Caltech
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet17_01">
             16:35-16:40, Paper WeET17.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1635" name="modify359" onclick="modify(359,1635)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('359'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Label Anything: An Interpretable, High-Fidelity and Prompt-Free Annotator
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339729" title="Click to go to the Author Index">
             Kou, Wei-Bin
            </a>
           </td>
           <td class="r">
            The University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339830" title="Click to go to the Author Index">
             Zhu, Guangxu
            </a>
           </td>
           <td class="r">
            Shenzhen Research Institute of Big Data
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#409671" title="Click to go to the Author Index">
             Ye, Rongguang
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#288452" title="Click to go to the Author Index">
             Wang, Shuai
            </a>
           </td>
           <td class="r">
            Shenzhen Institute of Advanced Technology, Chinese Academy of Sc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#392509" title="Click to go to the Author Index">
             Tang, Ming
            </a>
           </td>
           <td class="r">
            Southern University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#340053" title="Click to go to the Author Index">
             Wu, Yik-Chung
            </a>
           </td>
           <td class="r">
            The University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab359" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Learning-based street scene semantic understanding in autonomous driving (AD) has advanced significantly recently, but the performance of the AD model is heavily dependent on the quantity and quality of the annotated training data. However, traditional manual labeling involves high cost to annotate the vast amount of required data for training robust model. To mitigate this cost of manual labeling, we propose a Label Anything Model (denoted as LAM), serving as an interpretable, high-fidelity, and prompt-free data annotator. Specifically, we firstly incorporate a pretrained Vision Transformer (ViT) to extract the latent features. On top of ViT, we propose a semantic class adapter (SCA) and an optimization-oriented unrolling algorithm (OptOU), both with a quite small number of trainable parameters. SCA is proposed to fuse ViT-extracted features to consolidate the basis of the subsequent automatic annotation. OptOU consists of multiple cascading layers and each layer contains an optimization formulation to align its output with the ground truth as closely as possible, though which OptOU acts as being interpretable rather than learning-based blackbox nature. In addition, training SCA and OptOU requires only a single pre-annotated RGB seed image, owing to their small volume of learnable parameters. Extensive experiments clearly demonstrate that the proposed LAM can generate high-fidelity annotations (almost 100% in mIoU) for multiple real-world datasets (i.e., Camvid, Cityscapes, and Apolloscapes) and CARLA simulation dataset.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet17_02">
             16:40-16:45, Paper WeET17.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1636" name="modify371" onclick="modify(371,1636)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('371'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Logic-RAG: Augmenting Large Multimodal Models with Visual-Spatial Knowledge for Road Scene Understanding
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#322471" title="Click to go to the Author Index">
             Kabir, Imran
            </a>
           </td>
           <td class="r">
            Pennsylvania State University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#195921" title="Click to go to the Author Index">
             Reza, Md Alimoor
            </a>
           </td>
           <td class="r">
            Drake University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398669" title="Click to go to the Author Index">
             Billah, Syed
            </a>
           </td>
           <td class="r">
            Pennsylvania State University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab371" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#semantic_scene_understanding" title="Click to go to the Keyword Index">
               Semantic Scene Understanding
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_modal_perception_for_hri" title="Click to go to the Keyword Index">
               Multi-Modal Perception for HRI
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#formal_methods_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Formal Methods in Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Large multimodal models (LMMs) are increasingly integrated into autonomous driving systems for user interaction. However, their limitations in fine-grained spatial reasoning pose challenges for system interpretability and user trust. We introduce Logic-RAG, a novel Retrieval-Augmented Generation (RAG) framework that improves LMMs' spatial understanding in driving scenarios. Logic-RAG constructs a dynamic knowledge base (KB) about object-object relationships in first-order logic (FOL) using a perception module, a query-to-logic embedder, and a logical inference engine. We evaluated Logic-RAG on visual-spatial queries using both synthetic and real-world driving videos. When using popular LMMs (GPT-4V, Claude 3.5) as proxies for an autonomous driving system, these models achieved only 50% accuracy on synthetic driving scenes and under 75% on real-world driving scenes. Augmenting them with Logic-RAG increased their accuracies to over 80% and 90%, respectively. An ablation study showed that even without logical inference, the fact-based context constructed by Logic-RAG alone improved accuracy by 15%. Logic-RAG is extensible: it allows seamless replacement of individual components with improved versions and enables domain experts to compose new knowledge in both FOL and natural language. In sum, Logic-RAG addresses critical spatial reasoning deficiencies in LMMs for autonomous driving applications. Code and data are available at: https://github.com/Imran2205/LogicRAG.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet17_03">
             16:45-16:50, Paper WeET17.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1637" name="modify2201" onclick="modify(2201,1637)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2201'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Discrete Contrastive Learning for Diffusion Policies in Autonomous Driving
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419065" title="Click to go to the Author Index">
             Kujanpää, Kalle
            </a>
           </td>
           <td class="r">
            Aalto University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#227480" title="Click to go to the Author Index">
             Baimukashev, Daulet
            </a>
           </td>
           <td class="r">
            Aalto University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#296735" title="Click to go to the Author Index">
             Munir, Farzeen
            </a>
           </td>
           <td class="r">
            Aalto University, Finnish Center for Artificial Intelligence
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#296615" title="Click to go to the Author Index">
             Azam, Shoaib
            </a>
           </td>
           <td class="r">
            Aalto University, Finnish Center for Artificial Intelligence (FC
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#166253" title="Click to go to the Author Index">
             Kucner, Tomasz Piotr
            </a>
           </td>
           <td class="r">
            Aalto University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#168113" title="Click to go to the Author Index">
             Pajarinen, Joni
            </a>
           </td>
           <td class="r">
            Aalto University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105044" title="Click to go to the Author Index">
             Kyrki, Ville
            </a>
           </td>
           <td class="r">
            Aalto University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2201" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#modeling_and_simulating_humans" title="Click to go to the Keyword Index">
               Modeling and Simulating Humans
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Learning to perform accurate and rich simulations of human driving behaviors from data for autonomous vehicle testing remains challenging due to human driving styles' high diversity and variance. We address this challenge by proposing a novel approach that leverages contrastive learning to extract a dictionary of driving styles from pre-existing human driving data. We discretize these styles with quantization, and the styles are used to learn a conditional diffusion policy for simulating human drivers. Our empirical evaluation confirms that the behaviors generated by our approach are both safer and more human-like than those of the machine-learning-based baseline methods. We believe this has the potential to enable higher realism and more effective techniques for evaluating and improving the performance of autonomous vehicles.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet17_04">
             16:50-16:55, Paper WeET17.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1638" name="modify2328" onclick="modify(2328,1638)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2328'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Intelligence Evaluation Methods for Autonomous Vehicles
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419424" title="Click to go to the Author Index">
             Zhou, Junjie
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#141767" title="Click to go to the Author Index">
             Wang, Lin
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424008" title="Click to go to the Author Index">
             Meng, Qiang
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#296116" title="Click to go to the Author Index">
             Wang, Xiaofan
            </a>
           </td>
           <td class="r">
            Shanghai University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2328" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#performance_evaluation_and_benchmarking" title="Click to go to the Keyword Index">
               Performance Evaluation and Benchmarking
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The rapid advancement of artificial intelligence has significantly enhanced the intelligence of autonomous vehicles (AVs). However, owing to the complexity of AV behavior and the high dimensionality of driving environments, the objective and practical quantitative evaluation of AV intelligence remains a significant and unresolved challenge. This paper proposes a robust training-based comprehensive evaluation (RTCE) system specifically designed to assess the intelligence of AVs in the time dimension. Beginning with a foundation model, the first generation of AVs is developed by training in the initial naturalistic traffic scenarios. To effectively test the intelligence of the AVs, we propose an adversarial trajectory optimization technique to generate challenging, critical test scenarios that evaluate the learning capabilities of AVs in complex environments. Through robust training in these complex scenarios, the second generation of AVs is obtained. To objectively and effectively quantify the intelligence of AVs, we further propose a comprehensive evaluation metric system encompassing five dimensions and 14 evaluation metrics. The intelligence score of each AV is computed using the objective multi-criteria decision-making approach. The proposed intelligence evaluation method is validated using various self-evolution autonomous driving algorithms. The results demonstrate that the RTCE method can quantitatively and effectively test the intelligence of AVs in a multi-dimensional and automated manner. Furthermore, the proposed method is flexible and generalizable, making it adaptable to different testing platforms and autonomous driving algorithms.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet17_05">
             16:55-17:00, Paper WeET17.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1639" name="modify2480" onclick="modify(2480,1639)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2480'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              NaVid-4D: Unleashing Spatial Intelligence in Egocentric RGB-D Videos for Vision-And-Language Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#382083" title="Click to go to the Author Index">
             Liu, Haoran
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#319728" title="Click to go to the Author Index">
             Wan, Weikang
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#414281" title="Click to go to the Author Index">
             Yu, Xiqian
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424094" title="Click to go to the Author Index">
             Li, Minghan
            </a>
           </td>
           <td class="r">
            Galbot
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#331922" title="Click to go to the Author Index">
             Zhang, Jiazhao
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#413715" title="Click to go to the Author Index">
             Zhao, Bo
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#211144" title="Click to go to the Author Index">
             Chen, Zhibo
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421276" title="Click to go to the Author Index">
             Wang, Zhongyuan
            </a>
           </td>
           <td class="r">
            BAAI
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#209075" title="Click to go to the Author Index">
             Zhang, Zhizheng
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#155911" title="Click to go to the Author Index">
             Wang, He
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2480" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_agents" title="Click to go to the Keyword Index">
               Autonomous Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Understanding and reasoning about the 4D space-time is crucial for Vision-and-Language Navigation (VLN). However, previous works lack in-depth exploration in this aspect, resulting in bottlenecked spatial perception and action precision of VLN agents. In this work, we introduce NaVid-4D, a Vision Language Model (VLM) based navigation agent taking the lead in explicitly showcasing the capabilities of spatial intelligence in the real world. Given natural language instructions, NaVid-4D requires only egocentric RGB-D video streams as observations to perform spatial understanding and reasoning for generating precise instruction-following robotic actions. NaVid-4D learns navigation policies using the data from simulation environments and is endowed with precise spatial understanding and reasoning capabilities using web data. Without the need to pre-train an RGB-D foundation model, we propose a method capable of directly injecting the depth features into the visual encoder of a VLM. We further compare the use of factually captured depth information with the monocularly estimated one and find NaVid-4D works well with both while using estimated depth offers greater generalization capability and better mitigates the sim-to-real gap. Extensive experiments demonstrate that NaVid-4D achieves state-of-the-art performance in simulation environment and makes impressive VLN performance with spatial intelligence happen in the real world.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet17_06">
             17:00-17:05, Paper WeET17.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1640" name="modify3841" onclick="modify(3841,1640)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3841'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Generating Out-Of-Distribution Scenarios Using Language Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#299628" title="Click to go to the Author Index">
             Aasi, Erfan
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398926" title="Click to go to the Author Index">
             Nguyen, Phat
            </a>
           </td>
           <td class="r">
            University of Massachusetts Amherst
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#340539" title="Click to go to the Author Index">
             Sreeram, Shiva
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#173551" title="Click to go to the Author Index">
             Rosman, Guy
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#124153" title="Click to go to the Author Index">
             Karaman, Sertac
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101388" title="Click to go to the Author Index">
             Rus, Daniela
            </a>
           </td>
           <td class="r">
            MIT
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3841" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The deployment of autonomous vehicles controlled by machine learning techniques requires extensive testing in diverse real-world environments, robust handling of edge cases and out-of-distribution scenarios, and comprehensive safety validation to ensure that these systems can navigate safely and effectively under unpredictable conditions. Addressing Out-Of-Distribution (OOD) driving scenarios is essential for enhancing safety, as OOD scenarios help validate the reliability of the models within the vehicle’s autonomy stack. However, generating OOD scenarios is challenging due to their long-tailed distribution and rarity in urban driving datasets. Recently, Large Language Models (LLMs) have shown promise in autonomous driving, particularly for their zero-shot generalization and common-sense reasoning capabilities. In this paper, we leverage these LLM strengths to introduce a framework for generating diverse OOD driving scenarios. Our approach uses LLMs to construct a branching tree, where each branch represents a unique OOD scenario. These scenarios are then simulated in the CARLA simulator using an automated framework that aligns scene augmentation with the corresponding textual descriptions. We evaluate our framework through extensive simulations, and assess its performance via a diversity metric that measures the richness of the scenarios. Additionally, we introduce a new "OOD-ness" metric, which quantifies how much the generated scenarios deviate from typical urban driving conditions. Furthermore, we explore the capacity of modern Vision-Language Models (VLMs) to interpret and safely navigate through the simulated OOD scenarios. Our findings offer valuable insights into the reliability of language models in addressing OOD scenarios within the context of urban driving.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet17_07">
             17:05-17:10, Paper WeET17.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1641" name="modify4603" onclick="modify(4603,1641)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4603'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MAGIC-VFM - Meta-Learning Adaptation for Ground Interaction Control with Visual Foundation Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#269234" title="Click to go to the Author Index">
             Lupu, Elena-Sorina
            </a>
           </td>
           <td class="r">
            California Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#378736" title="Click to go to the Author Index">
             Xie, Fengze
            </a>
           </td>
           <td class="r">
            California Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#199492" title="Click to go to the Author Index">
             Preiss, James
            </a>
           </td>
           <td class="r">
            Caltech
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#386764" title="Click to go to the Author Index">
             Alindogan, Jedidiah
            </a>
           </td>
           <td class="r">
            California Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267936" title="Click to go to the Author Index">
             Anderson, Matthew
            </a>
           </td>
           <td class="r">
            Caltech
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#118282" title="Click to go to the Author Index">
             Chung, Soon-Jo
            </a>
           </td>
           <td class="r">
            Caltech
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4603" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_and_adaptive_systems" title="Click to go to the Keyword Index">
               Learning and Adaptive Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_foundation_models" title="Click to go to the Keyword Index">
               Visual Foundation Models
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Control of off-road vehicles is challenging due to the complex dynamic interactions with the terrain. Accurate modeling of these interactions is important to optimize driving performance, but the relevant physical phenomena are too complex to model from first principles. Therefore, we present an offline meta-learning algorithm to construct a rapidly-tunable model of residual dynamics and disturbances. Our model processes terrain images into features using a visual foundation model (VFM), then maps these features and the vehicle state to an estimate of the current actuation matrix using a deep neural network (DNN). We then combine this model with composite adaptive control to modify the last layer of the DNN in real time, accounting for the remaining terrain interactions not captured during offline training. We provide mathematical guarantees of stability and robustness for our controller, and demonstrate the effectiveness of our method through simulations and hardware experiments with a tracked vehicle and a car-like robot. We evaluate our method outdoors on different slopes with varying slippage and actuator degradation disturbances, and compare against an adaptive controller that
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet17_08">
             17:10-17:15, Paper WeET17.8
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1642" name="modify4943" onclick="modify(4943,1642)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4943'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              DINO-MOT: 3D Multi-Object Tracking with Visual Foundation Model for Pedestrian Re-Identification Using Visual Memory Mechanism
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#347777" title="Click to go to the Author Index">
             Lee, Min Young
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#289473" title="Click to go to the Author Index">
             Lee, Christina Dao Wen
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#367042" title="Click to go to the Author Index">
             Jianghao, Li
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100760" title="Click to go to the Author Index">
             Ang Jr, Marcelo H
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4943" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_detection_and_tracking" title="Click to go to the Keyword Index">
               Human Detection and Tracking
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In the advancing domain of autonomous driving, this research focuses on enhancing 3D Multi-Object Tracking (3D-MOT). Pedestrians are particularly vulnerable in urban environments, and robust tracking methodologies are required to understand their movements. Prevalent Tracking-By-Detection (TBD) frameworks often underutilize the rich visual data from sensors such as cameras. This study leverages the advanced visual foundation model, DINOv2, to refine the TBD framework by incorporating camera modality, thereby improving pedestrian tracking consistency and overall 3D-MOT performance. The proposed DINO-MOT framework is the first application of DINOv2 for enhancing 3D-MOT through pedestrian Re-Identification (Re-ID), and Score Filter Ceiling is implemented to prevent premature exclusion of low-confidence 3D detections during tracking association. Furthermore, utilization of DINOv2 as a feature extractor within the DINO-MOT framework reduces pedestrian ID switches by up to 12.3%. Achieving AMOTA of 76.3% on the nuScenes test dataset, DINO-MOT has set a new benchmark in the 3D MOT literature with an improvement of 0.5%, securing the top rank on the leaderboard. Furthermore, this research paves the potential of applying a visual foundation model to improve the existing TBD framework, to enhance 3D-MOT in autonomous driving.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet18">
             <b>
              WeET18
             </b>
             Regular Session, 406
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1643" name="modifyWeET18" onclick="modsession(579,1643)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet18" title="Click to go to the Program at a Glance">
             <b>
              Surgical Robotics: Steerable Catheters/Needles 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#182418" title="Click to go to the Author Index">
             Hoelscher, Janine
            </a>
           </td>
           <td class="r">
            Clemson
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#119227" title="Click to go to the Author Index">
             Krieger, Axel
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet18_01">
             16:35-16:40, Paper WeET18.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1644" name="modify195" onclick="modify(195,1644)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('195'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hysteresis Compensation of Tendon-Sheath Mechanism Using Nonlinear Programming Based on Preisach Model
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#180768" title="Click to go to the Author Index">
             Kim, Hongmin
            </a>
           </td>
           <td class="r">
            Massachusetts Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#308360" title="Click to go to the Author Index">
             Kim, Dongchan
            </a>
           </td>
           <td class="r">
            KAIST (Korea Advanced Institute of Science and Technology)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#349798" title="Click to go to the Author Index">
             Park, Su Hyeon
            </a>
           </td>
           <td class="r">
            Pusan National University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#145436" title="Click to go to the Author Index">
             Jin, Sangrok
            </a>
           </td>
           <td class="r">
            Pusan National University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab195" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#tendon_wire_mechanism" title="Click to go to the Keyword Index">
               Tendon/Wire Mechanism
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Tendon sheath mechanism (TSM) is an essential mechanical element for the implementation of flexible endoscopic systems owing to its small volume and simple structure. However, nonlinear characteristics, such as backlash, hysteresis and friction occur when employing such a component. In this study, we formulate a Preisach hysteresis model consisting of elementary hysteresis operators. Subsequently, we propose a compensation algorithm that repeatedly and sequentially solves a nonlinear optimization problem online, producing an inverse control signal for the desired output at every time step, compensating the nonlinear effects of TSM. The results indicate that the presented model and control scheme are promising for motion control in any application utilizing TSM.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet18_02">
             16:40-16:45, Paper WeET18.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1645" name="modify1129" onclick="modify(1129,1645)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1129'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Resolution Optimal Motion Planning for Medical Needle Steering from Airway Walls in the Lung
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#182418" title="Click to go to the Author Index">
             Hoelscher, Janine
            </a>
           </td>
           <td class="r">
            Clemson
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#280295" title="Click to go to the Author Index">
             Fried, Inbar
            </a>
           </td>
           <td class="r">
            University of North Carolina at Chapel Hill
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#159588" title="Click to go to the Author Index">
             Salzman, Oren
            </a>
           </td>
           <td class="r">
            Technion
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#107129" title="Click to go to the Author Index">
             Alterovitz, Ron
            </a>
           </td>
           <td class="r">
            University of North Carolina at Chapel Hill
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1129" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__planning" title="Click to go to the Keyword Index">
               Surgical Robotics: Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#nonholonomic_motion_planning" title="Click to go to the Keyword Index">
               Nonholonomic Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Steerable needles are novel medical devices capable of following curved paths through tissue, enabling them to avoid anatomical obstacles and steer to hard-to-reach sites in tissue, including targets in the lung for lung cancer diagnosis. Steerable needles are typically deployed into tissue from an insertion surface, and selecting the insertion site is critical for procedure success as it determines which paths the needle can take to its target. Prior motion planners for steerable needles typically only plan from a specific start pose to the target. We introduce a new resolution-optimal steerable needle motion planner that efficiently finds plans from an insertion surface to a target position, handling additional degrees of freedom at both the start and the target. Our algorithm systematically builds a search tree consisting of needle motion primitives backward from the target towards the insertion surface, which allows it to provide an optimality guarantee up to the resolution of the primitives. The algorithm finds higher-quality plans faster than prior state-of-the-art motion planners, as demonstrated in anatomical scenario simulations in the lung.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet18_03">
             16:45-16:50, Paper WeET18.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1646" name="modify1400" onclick="modify(1400,1646)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1400'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Self-Sufficient 5-DoF Discrete Global Localization for Magnetically-Actuated Endoscope in Bronchoscopy
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#304796" title="Click to go to the Author Index">
             Tan, Jiewen
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#312461" title="Click to go to the Author Index">
             Zhao, Da
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420931" title="Click to go to the Author Index">
             Zhou, Rui
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#406336" title="Click to go to the Author Index">
             Xie, Wenxuan
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#178362" title="Click to go to the Author Index">
             Cheng, Shing Shin
            </a>
           </td>
           <td class="r">
            The Chinese University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1400" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Existing sensor-based global localization methods limit the miniaturization potential of magnetically-actuated endoscopes (MAE) while localization based on external medical imaging demands accurate registration and imposes a variety of modality-specific challenges during continuous image acquisition. This work proposes a novel self-sufficient method for discrete (one-time) global localization of an MAE based solely on inherent endoscopic images without any prior MAE pose information. More specifically, it adopts a model-free control approach to determine five different external magnet (EM) poses (corresponding to five independent nonlinear equations) that can align the MAE image center with the lumen center while the MAE maintains the same pose. The five degree-of freedom (DoF) global pose of the MAE can then be estimated by minimizing the root mean square of MAE's torque balance residuals under these EM poses. Our proposed method achieves similar accuracy as other sensor-based methods for permanent magnet-driven MAE with 6.7 ± 2.1 mm position error and 9.5 ± 2.9° orientation error in the experiments. Compared to existing methods, our approach does not require physical sensor integration, enabling a more compact endoscope design for exploration in narrower respiratory tracts. It also offers a critical step toward achieving sensorless and continuous global localization of the permanent magnet-driven MAE during its autonomous navigation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet18_04">
             16:50-16:55, Paper WeET18.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1647" name="modify1868" onclick="modify(1868,1647)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1868'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Intraoperative 3D Shape Estimation of Magnetic Soft Guidewire
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421702" title="Click to go to the Author Index">
             Zhao, Yiting
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#122976" title="Click to go to the Author Index">
             Shi, Liwei
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#183539" title="Click to go to the Author Index">
             Xiao, Nan
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1868" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__planning" title="Click to go to the Keyword Index">
               Surgical Robotics: Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             本文介绍了一种 3D 形状重建技术 用于血管内手术中的介入装置， 利用灵活的磁性尖端导丝，保持 标准导丝的基本属性。我们 开发了一个将磁头形状相关联的模型 周围磁场分布为 通过磁场估计形状。这 磁性 磁场分布和磁导丝的形状 为直接形状估计带来了挑战。要解决 为此，我们将图像和物理约束合并到 简化估算过程。此方法显示高 形状估计的准确性和稳定性，带均值根 平方误差 （RMSE） 和豪斯多夫距离 （HD） 均在下方 1 毫米，这比其他现有的估计要好 方法。值得注意的是，介入导丝不需要 嵌入式传感器或布线，以及透视图像 使用的是临床实践中的标准。重建 过程不ߩ
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet18_05">
             16:55-17:00, Paper WeET18.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1648" name="modify3791" onclick="modify(3791,1648)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3791'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Semi-Autonomous 2.5D Control of Untethered Magnetic Suture Needle
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425874" title="Click to go to the Author Index">
             Wang, Qinhan
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#238055" title="Click to go to the Author Index">
             Bhattacharjee, Anuruddha
            </a>
           </td>
           <td class="r">
            The Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#368142" title="Click to go to the Author Index">
             Chen, Xinhao
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#278708" title="Click to go to the Author Index">
             Mair, Lamar
            </a>
           </td>
           <td class="r">
            Weinberg Medical Physics, Inc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#166158" title="Click to go to the Author Index">
             Diaz-Mercado, Yancy
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#119227" title="Click to go to the Author Index">
             Krieger, Axel
            </a>
           </td>
           <td class="r">
            Johns Hopkins University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3791" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Untethered miniature surgical tools could significantly reduce invasiveness and enhance patient outcomes in robot-assisted laparoscopic surgical procedures. This paper demonstrates the feasibility of performing semi-autonomous suturing tasks using an untethered magnetic needle controlled by an external electromagnetic manipulator. The electromagnetic manipulator can generate magnetic torques and gradient-based pulling forces to actuate the magnetic needle. Here, we develop and implement a semi-autonomous 2.5D control method for controlling the in-plane position and both in-plane and out-of-plane orientations of a magnetic needle for suturing on tissue-mimicking agar gel phantoms. The method includes recognizing needles and incisions, planning trajectory, and performing suturing with visual feedback control. We conduct two mock suturing tasks using both continuous and interrupted techniques on 1% agar gel phantoms with 2 cm and 3 cm incision sizes. The results demonstrate precise needle control, with an average root-mean-square position error of 1.01 mm and 1.12 mm across tasks. The system also achieved submillimeter-level suture spacing accuracy, comparable to surgeons using state-of-the-art surgical robots. These findings highlight the feasibility of using untethered magnetic suture needles for minimally invasive suturing procedures.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet18_06">
             17:00-17:05, Paper WeET18.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1649" name="modify4223" onclick="modify(4223,1649)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4223'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Steerable Tape-Spring Needle for Autonomous Sharp Turns through Tissue
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398964" title="Click to go to the Author Index">
             Abdoun, Omar
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426457" title="Click to go to the Author Index">
             Tjandra, Davin
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426434" title="Click to go to the Author Index">
             Yin, Katie
            </a>
           </td>
           <td class="r">
            University of California, Riverside
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426450" title="Click to go to the Author Index">
             Kurzan, Pablo
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#219913" title="Click to go to the Author Index">
             Yin, Jessica
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101787" title="Click to go to the Author Index">
             Yim, Mark
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4223" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__planning" title="Click to go to the Keyword Index">
               Surgical Robotics: Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__laparoscopy" title="Click to go to the Keyword Index">
               Surgical Robotics: Laparoscopy
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Steerable needles offer a minimally invasive method to deliver treatment to hard-to-reach tissue regions. We introduce a new class of textit{tape-spring} steerable needles, capable of sharp turns ranging from 15 to 150 degrees with a turn radius of as low as 3mm, which minimize surrounding tissue damage. In this work, we derive and experimentally validate a geometric model for our steerable needle design. We evaluate both manual and robotic steering of the needle along a Dubins path in 7 kPa and 13 kPa tissue phantoms, simulating our target clinical application in healthy and unhealthy liver tissue. We conduct experiments to measure needle robustness to stiffness transitions between non-homogeneous tissues. We demonstrate progress towards clinical use with needle tip tracking via ultrasound imaging, navigation around anatomical obstacles, and integration with a robotic autonomous steering system.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet18_07">
             17:05-17:10, Paper WeET18.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1650" name="modify4783" onclick="modify(4783,1650)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4783'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Shape Control of Concentric Tube Robots Via Approximate Follow-The-Leader Motion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#292682" title="Click to go to the Author Index">
             Xu, Yunti
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#256468" title="Click to go to the Author Index">
             Watson, Connor
            </a>
           </td>
           <td class="r">
            Morimoto Lab, UCSD
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#305569" title="Click to go to the Author Index">
             Lin, Jui-Te
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#271726" title="Click to go to the Author Index">
             Hwang, John T.
            </a>
           </td>
           <td class="r">
            University of California, San Diego
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#187439" title="Click to go to the Author Index">
             Morimoto, Tania K.
            </a>
           </td>
           <td class="r">
            University of California San Diego
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4783" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Concentric tube robots (CTRs) are miniaturized continuum robots that are promising for robotic minimally invasive surgeries. Control methods to date have primarily focused on controlling the robot tip. However, small changes in the tip position can result in large deviations in the shape of the robot body, motivating the need for shape control to ensure safe navigation in constrained environments. One proposed method for shape control, known as follow-the-leader (FTL) motion, allows the robot to deploy while occupying minimal volume but is limited to specific CTR designs and deployment sequences. In this paper, we propose a shape control method that approximates FTL motion and is applicable to arbitrary tip navigation tasks without requiring a predefined trajectory or specific tube design. This shape control method is framed as a nonlinear optimization problem, and through linearization of the CTR's kinematics, we turn it into a quadratic program solved by a shape controller that requires minimal knowledge of the robot's shape. Simulation results show that our proposed shape control method enables better approximate FTL motion compared to a state-of-the-art Jacobian-based tip controller across different tube sets and tip paths while remaining computationally comparable. Furthermore, a hardware demonstration validates the effectiveness of the shape controller on a physical system during teleoperation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet18_08">
             17:10-17:15, Paper WeET18.8
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1651" name="modify4905" onclick="modify(4905,1651)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4905'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Model-Based Parameter Selection for a Steerable Continuum Robot — Applications to Bronchoalveolar Lavage (BAL)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#408432" title="Click to go to the Author Index">
             Rothe, Amber K.
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#282411" title="Click to go to the Author Index">
             Brumfiel, Timothy A.
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#254395" title="Click to go to the Author Index">
             Konda, Revanth
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#345761" title="Click to go to the Author Index">
             Williams, Kirsten
            </a>
           </td>
           <td class="r">
            Emory University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#101676" title="Click to go to the Author Index">
             Desai, Jaydev P.
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4905" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#surgical_robotics__steerable_catheters_needles" title="Click to go to the Keyword Index">
               Surgical Robotics: Steerable Catheters/Needles
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#tendon_wire_mechanism" title="Click to go to the Keyword Index">
               Tendon/Wire Mechanism
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#medical_robots_and_systems" title="Click to go to the Keyword Index">
               Medical Robots and Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Bronchoalveolar lavage (BAL) is a minimally invasive procedure for diagnosing lung infections and diseases. However, navigating tortuous lung anatomy to the distal branches of the bronchoalveolar tree for adequate sampling using BAL remains challenging. Continuum robots have been used to improve the navigation of guidewires, catheters, and endoscopes and could be applied to the BAL procedure as well. One class of continuum robots is constructed from a notched tube and actuated using a tendon. Many tendon-driven notched continuum robots use uniform machining parameters to achieve approximately constant-curvature configurations, which may be unsuitable for traversing the tortuous anatomy of the lungs. This letter presents a model that predicts the curvature of a robot with arbitrary notch shapes subjected to tendon tension. The model predicted the deflection of rectangular, elliptical, and sinusoidal notches in a 0.89 mm diameter nitinol tube with 2.32%, 3.65%, and 6.32% error, respectively. Furthermore, an algorithm is developed to determine the optimal pattern of notches to achieve a desired nonuniform robot curvature. A simulated robot designed using the algorithm achieved the desired shape with a root mean square error (RMSE) of 1.52°. Additionally, we present a model for predicting the shape of nonuniformly notched continuum robots which incorporates friction and pre-curvature. This model predicted the shape of a continuum robot with nonuniform rectangular notches with an average RMSE of 5.20° with respect to the actual robot. We also demonstrated navigating the continuum robot through a pulmonary phantom.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet19">
             <b>
              WeET19
             </b>
             Regular Session, 407
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1652" name="modifyWeET19" onclick="modsession(265,1652)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet19" title="Click to go to the Program at a Glance">
             <b>
              Logistics and Task Planning
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#303554" title="Click to go to the Author Index">
             Chirikjian, Gregory
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#106538" title="Click to go to the Author Index">
             Arras, Kai Oliver
            </a>
           </td>
           <td class="r">
            University of Stuttgart
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet19_01">
             16:35-16:40, Paper WeET19.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1653" name="modify221" onclick="modify(221,1653)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('221'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A New Clustering-Based View Planning Method for Building Inspection with Drone
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#400946" title="Click to go to the Author Index">
             Zheng, Yongshuai
            </a>
           </td>
           <td class="r">
            Shandong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#140858" title="Click to go to the Author Index">
             Liu, Guoliang
            </a>
           </td>
           <td class="r">
            Shandong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#401087" title="Click to go to the Author Index">
             Ding, Yan
            </a>
           </td>
           <td class="r">
            Shandong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#125757" title="Click to go to the Author Index">
             Tian, Guohui
            </a>
           </td>
           <td class="r">
            Shandong University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab221" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#surveillance_robotic_systems" title="Click to go to the Keyword Index">
               Surveillance Robotic Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computational_geometry" title="Click to go to the Keyword Index">
               Computational Geometry
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             With the rapid development of drone technology, the application of drones equipped with visual sensors for building inspection and surveillance has attracted much attention. View planning aims to find a set of near-optimal viewpoints for vision-related tasks to achieve the vision coverage goal. This paper proposes a new clustering-based two-step computational method using spectral clustering, local potential field method, and hyper-heuristic algorithm to find near-optimal views to cover the target building surface. In the first step, the proposed method generates candidate viewpoints based on spectral clustering and corrects the positions of candidate viewpoints based on our newly proposed local potential field method. In the second step, the optimization problem is converted into a Set Covering Problem (SCP), and the optimal viewpoint subset is solved using our proposed hyper-heuristic algorithm. Experimental results show that the proposed method is able to obtain better solutions with fewer viewpoints and higher coverage.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet19_02">
             16:40-16:45, Paper WeET19.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1654" name="modify439" onclick="modify(439,1654)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('439'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Towards the Deployment of an Autonomous Last-Mile Delivery Robot in Urban Areas
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#159272" title="Click to go to the Author Index">
             Santamaria-Navarro, Angel
            </a>
           </td>
           <td class="r">
            Universitat Politècnica De Catalunya
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103940" title="Click to go to the Author Index">
             Hernandez Juan, Sergi
            </a>
           </td>
           <td class="r">
            CSIC-UPC (IRI)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#167253" title="Click to go to the Author Index">
             Herrero Cotarelo, Fernando
            </a>
           </td>
           <td class="r">
            IRI, CSIC-UPC
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351952" title="Click to go to the Author Index">
             López Gestoso, Alejandro
            </a>
           </td>
           <td class="r">
            Institut De Robòtica I Informàtica Industrial
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#198304" title="Click to go to the Author Index">
             Del Pino, Ivan
            </a>
           </td>
           <td class="r">
            Instituto Universitario De Investigación Informática (IUII). Uni
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#333157" title="Click to go to the Author Index">
             Rodriguez Linares, Nicolás Adrián
            </a>
           </td>
           <td class="r">
            Universidad Politécnica De Cataluña
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351802" title="Click to go to the Author Index">
             Fernandez, Carlos
            </a>
           </td>
           <td class="r">
            Urbiotica
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351837" title="Click to go to the Author Index">
             Baldó i Canut, Albert
            </a>
           </td>
           <td class="r">
            CARNET Future Mobility Research Hub
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351897" title="Click to go to the Author Index">
             Lemardelé, Clément
            </a>
           </td>
           <td class="r">
            Universitat Politècnica De Catalunya
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#114978" title="Click to go to the Author Index">
             Garrell, Anais
            </a>
           </td>
           <td class="r">
            UPC-CSIC
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#169541" title="Click to go to the Author Index">
             Vallvé, Joan
            </a>
           </td>
           <td class="r">
            CSIC-UPC
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#352561" title="Click to go to the Author Index">
             Taher, Hafsa
            </a>
           </td>
           <td class="r">
            Institut De Robòtica I Informàtica Industrial, CSIC-UPC
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#322699" title="Click to go to the Author Index">
             Puig-Pey, Ana
            </a>
           </td>
           <td class="r">
            Universitat Politecnica De Catalunya
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#352585" title="Click to go to the Author Index">
             Pagès, Laia
            </a>
           </td>
           <td class="r">
            CARNET
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#103488" title="Click to go to the Author Index">
             Sanfeliu, Alberto
            </a>
           </td>
           <td class="r">
            Universitat Politècnica De Cataluyna
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab439" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#logistics" title="Click to go to the Keyword Index">
               Logistics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Nowadays, the skyrocketing last-mile freight transportation in urban areas is leading to very negative effects (e.g., pollution, noise or traffic congestion), which could be minimized by using autonomous electric vehicles. In this sense, this paper presents the first prototype of Ona, an autonomous last-mile delivery robot that, in contrast to existing platforms, has a medium-sized storage capacity with the capability of navigating in both street and pedestrian areas. Here, we describe the platform, its main Software modules and the validation experiments, carried out in the Barcelona Robot Lab (Universitat Politècnica de Catalunya); Esplugues de Llobregat (next to Barcelona); and Debrecen (Hungary), which are representative urban scenarios. Apart from robotic technical details, we also include the results of the technology acceptance by the public present in the Esplugues de Llobregat test, collected in situ through a survey.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet19_03">
             16:45-16:50, Paper WeET19.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1655" name="modify1130" onclick="modify(1130,1655)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1130'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multi-Heuristic Robotic Bin Packing of Regular and Irregular Objects
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#343915" title="Click to go to the Author Index">
             Nickel, Tim
            </a>
           </td>
           <td class="r">
            Fraunhofer IPA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#136993" title="Click to go to the Author Index">
             Bormann, Richard
            </a>
           </td>
           <td class="r">
            Fraunhofer IPA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106538" title="Click to go to the Author Index">
             Arras, Kai Oliver
            </a>
           </td>
           <td class="r">
            University of Stuttgart
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1130" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#logistics" title="Click to go to the Keyword Index">
               Logistics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#factory_automation" title="Click to go to the Keyword Index">
               Factory Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The increasing demand in e-commerce, combined with labor shortages and rising wages, is driving the rapid automation of warehouse operations. A critical aspect of this shift is bin packing, where diverse unknown items of varying sizes and shapes must be optimally arranged within a bin or container. Robot bin packing is receiving growing attention and presents unique challenges due to the broad range of objects, packing rules, and task-specific requirements. In response, we propose So-Pack, a generalist packing heuristic for irregularly shaped objects integrated into a flexible, weighted multi-heuristic planning system. The system demonstrates robust performance across general packing scenarios and exhibits the flexibility to adapt to changing packing rules and specific end-user requirements. Experimental results show that the system outperforms state-of-the-art approaches in key metrics in a new challenging dataset of retail objects in real-world applications.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet19_04">
             16:50-16:55, Paper WeET19.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1656" name="modify1846" onclick="modify(1846,1656)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1846'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              MultiTalk: Introspective and Extrospective Dialogue for Human-Environment-LLM Alignment
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#364416" title="Click to go to the Author Index">
             Devarakonda, Venkata Naren
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#389899" title="Click to go to the Author Index">
             Kaypak, Ali Umut
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#241148" title="Click to go to the Author Index">
             Yuan, Shuaihang
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#111353" title="Click to go to the Author Index">
             Krishnamurthy, Prashanth
            </a>
           </td>
           <td class="r">
            New York University Tandon School of Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#200546" title="Click to go to the Author Index">
             Fang, Yi
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#108037" title="Click to go to the Author Index">
             Khorrami, Farshad
            </a>
           </td>
           <td class="r">
            New York University Tandon School of Engineering
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1846" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             LLMs have shown promising results in task planning due to their strong natural language understanding and reasoning capabilities. However, issues such as hallucinations, ambiguities in human instructions, environmental constraints, and limitations in the executing agent’s capabilities often lead to flawed or incomplete plans. This paper proposes MultiTalk, an LLM-based task planning methodology that addresses these issues through a framework of introspective and extrospective dialogue loops. This approach helps ground generated plans in the context of the environment and the agent's capabilities, while also resolving uncertainties and ambiguities in the given task. These loops are enabled by specialized systems designed to extract and predict task-specific states, and flag mismatches or misalignments among the human user, the LLM agent, and the environment. Effective feedback pathways between these systems and the LLM planner foster meaningful dialogue. The efficacy of this methodology is demonstrated through its application to robotic manipulation tasks. Experiments and ablations highlight the robustness and reliability of our method, and comparisons with baselines further illustrate the superiority of MultiTalk in task planning for embodied agents. Project Website: https://llm-multitalk.github.io/
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet19_05">
             16:55-17:00, Paper WeET19.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1657" name="modify1931" onclick="modify(1931,1657)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1931'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Goal-Guided Reinforcement Learning: Leveraging Large Language Models for Long-Horizon Task Decomposition
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397843" title="Click to go to the Author Index">
             Zhang, Ceng
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422731" title="Click to go to the Author Index">
             Sun, Zhanhong
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#303554" title="Click to go to the Author Index">
             Chirikjian, Gregory
            </a>
           </td>
           <td class="r">
            University of Delaware
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1931" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Reinforcement learning (RL) has long struggled with exploration in vast state-action spaces, particularly for intricate tasks that necessitate a series of well-coordinated actions. Meanwhile, large language models (LLMs) equipped with fundamental knowledge have been utilized for task planning across various domains. However, using them to plan for long-term objectives can be demanding, as they function independently from task environments where their knowledge might not be perfectly aligned, hence often overlooking possible physical limitations. To this end, we propose a goal-based RL framework that leverages prior knowledge of LLMs to benefit the training process. We introduce a hierarchical module that features a goal generator to segment a long-horizon task into reachable subgoals and a policy planner to generate action sequences based on the current goal. Subsequently, the policies derived from LLMs guide the RL to achieve each subgoal sequentially. We validate the effectiveness of the proposed framework across different simulation environments and long-horizon tasks with complex state and action spaces.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet19_06">
             17:00-17:05, Paper WeET19.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1658" name="modify2281" onclick="modify(2281,1658)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2281'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Trustworthy Robot Behavior Tree Generation Based on Multi-Source Heterogeneous Knowledge Graph
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421198" title="Click to go to the Author Index">
             Yuan, Jianchao
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#237341" title="Click to go to the Author Index">
             Yang, Shuo
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424200" title="Click to go to the Author Index">
             Zhang, Qi
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424190" title="Click to go to the Author Index">
             Li, Ge
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424171" title="Click to go to the Author Index">
             Tang, Jianping
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2281" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#software_architecture_for_robotic_and_automation" title="Click to go to the Keyword Index">
               Software Architecture for Robotic and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In robotics, the design of robot behavior trees generally requires roboticists to comprehensively and customizable consider all the relevant factors including the robot hardware capabilities, task descriptions, etc, posing great challenges for design quality and efficiency. The mainstream practice of BT design paradigm has been utilizing the BT component framework to develop task-specific BT structures manually. In contrast, the latest advances in Generative Pretrained Transformers (GPTs) have also opened up the possibility of BT design automation. However, these approaches generally show low efficiency or are less trustworthy for complex robot task goals due to time-consuming manual design and unreliable GPT reasoning. To solve the above limitations, this paper proposes a novel knowledge-driven approach that develops a specialized knowledge graph from multi-sourced and heterogeneous high-quality robot knowledge to reason out a trustworthy robot plan for achieving complex task goals. Then we present the plan transformation and BT merging algorithms to automatically generate the plan-level BT structure. The comparative experiment results have shown that our approach can generate high-quality and trustworthy BT structure regarding the task plan accuracy and consistency, as well as the BT generation time, compared with the manual design and GPT-based approaches.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet19_07">
             17:05-17:10, Paper WeET19.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1659" name="modify4531" onclick="modify(4531,1659)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4531'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Enabling In-Flight Metamorphosis in Multirotors with a Center-Driven Scissor Extendable Airframe for Adaptive Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267595" title="Click to go to the Author Index">
             Yang, Tao
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology, Shenzhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#109518" title="Click to go to the Author Index">
             Li, Peng
            </a>
           </td>
           <td class="r">
            Harbin Institute of Technology ShenZhen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#226276" title="Click to go to the Author Index">
             Wang, Gang
            </a>
           </td>
           <td class="r">
            University of Shanghai for Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100889" title="Click to go to the Author Index">
             Shen, Yantao
            </a>
           </td>
           <td class="r">
            University of Nevada, Reno
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4531" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#foundations_of_automation" title="Click to go to the Keyword Index">
               Foundations of Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             To address complex mission tasks, multirotors benefit from in-flight reconfiguration that enhances their morphological adaptability. This paper presents the Center-Driven Scissor Extendable Airframe (CDSEA), a novel one-degree-of-freedom (DOF) morphing airframe designed to replace traditional fixed-size airframes. The CDSEA allows a quadrotor to achieve significant morphological changes during flight, with rotors deploying radially from a central point. This capability facilitates substantial variations in footprint radius and ensures smooth transitions. The paper details the mechanical design, as well as kinematic and dynamic analyses, and discusses the actuator selection strategy for the CDSEA. Experimental results with a prototype demonstrate that the CDSEA achieves a footprint-radius deformation ratio of 2.5 and a morphing time of 0.3 seconds, surpassing existing solutions. Additionally, the design improves obstacle avoidance and wind resistance. These results underscore the CDSEA's potential as an advanced solution for enhancing UAV adaptive navigation performance in complex environments.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet20">
             <b>
              WeET20
             </b>
             Regular Session, 408
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1660" name="modifyWeET20" onclick="modsession(447,1660)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet20" title="Click to go to the Program at a Glance">
             <b>
              Planning Around People for Social Navigation
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#192270" title="Click to go to the Author Index">
             Mendez, Oscar
            </a>
           </td>
           <td class="r">
            University of Surrey
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#159826" title="Click to go to the Author Index">
             Mavrogiannis, Christoforos
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet20_01">
             16:35-16:40, Paper WeET20.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1661" name="modify275" onclick="modify(275,1661)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('275'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              SafePCA: Enhancing Autonomous Robot Navigation in Dynamic Crowds Using Proximal Policy Optimization and Cellular Automata
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397046" title="Click to go to the Author Index">
             Farouq, Ardiansyah
            </a>
           </td>
           <td class="r">
            Telkom University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#184289" title="Click to go to the Author Index">
             Tran, Dinh Tuan
            </a>
           </td>
           <td class="r">
            College of Information Science and Engineering, Ritsumeikan Univ
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#100204" title="Click to go to the Author Index">
             Lee, Joo-Ho
            </a>
           </td>
           <td class="r">
            Ritsumeikan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab275" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#localization" title="Click to go to the Keyword Index">
               Localization
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Navigating robots in dynamic environments, such as human crowds, is a major challenge due to the trade-off between performance and robustness. Traditional reinforcement learning methods, such as Proximal Policy Optimization (PPO), have shown strong adaptation capabilities but require extensive training and lack explicit mechanisms for collision avoidance. On the other hand, rule-based approaches, such as the Dynamic Window Approach (DWA), offer computational efficiency but struggle with generalization to unseen crowd behaviors. The proposed SafePCA framework aims to address this trade-off by integrating Cellular Automata (CA) into PPO-based navigation. CA enhances robustness by predicting high-risk areas based on pedestrian movement patterns, reducing unnecessary collisions. However, this approach may lead to conservative behavior, potentially affecting navigation performance in reaching the goal efficiently. The core research question addressed in this work is whether SafePCA can balance these trade-offs to ensure safe yet efficient robot navigation in dynamic crowds. Experiments demonstrate that SafePCA outperforms traditional PPO by providing superior risk assessment and avoidance strategies, achieving optimal performance with fewer training episodes. SafePCA’s real-time adaptability ensures robust navigation in dynamic environments. By leveraging PPO’s adaptive learning and CA’s risk analysis, SafePCA offers an efficient solution for autonomous robot navigation in crowded environments, advancing the field and broadening application possibilities.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet20_02">
             16:40-16:45, Paper WeET20.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1662" name="modify970" onclick="modify(970,1662)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('970'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robot Local Planner: A Periodic Sampling-Based Motion Planner with Minimal Waypoints for Home Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#146120" title="Click to go to the Author Index">
             Takeshita, Keisuke
            </a>
           </td>
           <td class="r">
            Toyota Motor Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#371151" title="Click to go to the Author Index">
             Yamazaki, Takahiro
            </a>
           </td>
           <td class="r">
            Toyota Motor Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#371149" title="Click to go to the Author Index">
             Ono, Tomohiro
            </a>
           </td>
           <td class="r">
            Toyota Motor Corporation
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#108840" title="Click to go to the Author Index">
             Yamamoto, Takashi
            </a>
           </td>
           <td class="r">
            Aichi Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab970" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#manipulation_planning" title="Click to go to the Keyword Index">
               Manipulation Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The objective of this study is to enable fast and safe manipulation tasks in home environments. Specifically, we aim to develop a system that can recognize its surroundings and identify target objects while in motion, enabling it to plan and execute actions accordingly.
             <p>
              We propose a periodic sampling-based whole-body trajectory planning method, called the “Robot Local Planner (RLP).” This method leverages unique features of home environments to enhance computational efficiency, motion optimality, and robustness against recognition and control errors, all while ensuring safety. The RLP minimizes computation time by planning with minimal waypoints and generating safe trajectories. Furthermore, overall motion optimality is improved by periodically executing trajectory planning to select more optimal motions. This approach incorporates inverse kinematics that are robust to base position errors, further enhancing robustness.
              <p>
               Evaluation experiments demonstrated that the RLP outperformed existing methods in terms of motion planning time, motion duration, and robustness, confirming its effectiveness in home environments. Moreover, application experiments using a tidy-up task achieved high success rates and short operation times, thereby underscoring its practical feasibility.
              </p>
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet20_03">
             16:45-16:50, Paper WeET20.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1663" name="modify1443" onclick="modify(1443,1663)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1443'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Diff-Refiner: Enhancing Multi-Agent Trajectory Prediction with a Plug-And-Play Diffusion Refiner
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#401937" title="Click to go to the Author Index">
             Zhou, Xiangzheng
            </a>
           </td>
           <td class="r">
            Nanjing University of Science and Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338480" title="Click to go to the Author Index">
             Chen, Xiaobo
            </a>
           </td>
           <td class="r">
            Shandong Technology and Business University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203342" title="Click to go to the Author Index">
             Yang, Jian
            </a>
           </td>
           <td class="r">
            Nanjing University of Science &amp; Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1443" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#planning_under_uncertainty" title="Click to go to the Keyword Index">
               Planning under Uncertainty
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The inherent stochasticity of the agents’ behavior presents a challenge to trajectory prediction models, which are required to generate multiple plausible future trajectories. Recently, diffusion models have been applied to implement multimodal trajectory prediction. Existing approaches typically employ a standard diffusion process, denoising from a sample drawn from a Gaussian distribution. However, we identify that most agents exhibit an obvious movement trend, rendering many initial denoising steps redundant—primarily transitioning from pure noise to an initial coarse trajectory. To conquer this challenge, this paper innovatively proposes a diffusion refiner that can be used along with existing multi-agent trajectory prediction models to improve their performance. Specifically, we first leverage a baseline model for predicting the coarse future trajectory. Then, the diffusion model is applied as a refiner to reduce the prediction error. Moreover, our method is naturally plug-and-play, allowing convenient integration with existing models. To achieve this, we improve the traditional diffusion process to not only converge towards noise but also the coarse predictions from the baseline model. In such a case, standard step-skipping sampling techniques is inapplicable and we further propose an ordinary differential equation (ODE)-based fast sampling method. Extensive experiments with selected baseline models demonstrate the effectiveness of our approach.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet20_04">
             16:50-16:55, Paper WeET20.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1664" name="modify2242" onclick="modify(2242,1664)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2242'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Scene-Aware Explainable Multimodal Trajectory Prediction
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423123" title="Click to go to the Author Index">
             Liu, Pei
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology(GuangZhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423637" title="Click to go to the Author Index">
             Liu, Haipeng
            </a>
           </td>
           <td class="r">
            Shanghai Li Auto Co., Ltd
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423683" title="Click to go to the Author Index">
             Liu, Xingyu
            </a>
           </td>
           <td class="r">
            Shenyang Agricultural University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#438425" title="Click to go to the Author Index">
             Li, Yiqun
            </a>
           </td>
           <td class="r">
            Southeast University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#429722" title="Click to go to the Author Index">
             Chen, Junlan
            </a>
           </td>
           <td class="r">
            Monash University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422600" title="Click to go to the Author Index">
             He, Yangfan
            </a>
           </td>
           <td class="r">
            University of Minnesota - Twin Cities
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#182083" title="Click to go to the Author Index">
             Ma, Jun
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2242" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Advancements in intelligent technologies have significantly improved navigation in complex traffic environments by enhancing environment perception and trajectory prediction for automated vehicles. However, current research often overlooks the joint reasoning of scenario agents and lacks explainability in trajectory prediction models, limiting their practical use in real-world situations. To address this, we introduce the Explainable Conditional Diffusion-based Multimodal Trajectory Prediction (DMTP) model, which is designed to elucidate the environmental factors influencing predictions and reveal the underlying mechanisms. Our model integrates a modified conditional diffusion approach to capture multimodal trajectory patterns and employs a revised Shapley Value model to assess the significance of global and scenario-specific features. Experiments using the Waymo Open Motion Dataset demonstrate that our explainable model excels in identifying critical inputs and significantly outperforms baseline models in accuracy. Moreover, the factors identified align with the human driving experience, underscoring the model’s effectiveness in learning accurate predictions. Code is available in our open-source repository: https://github. com/ocean-luna/Explainable-Prediction.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet20_05">
             16:55-17:00, Paper WeET20.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1665" name="modify2289" onclick="modify(2289,1665)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2289'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Safety-Critical Traffic Simulation with Adversarial Transfer of Driving Intentions
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423828" title="Click to go to the Author Index">
             Huang, Zherui
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#345368" title="Click to go to the Author Index">
             Gao, Xing
            </a>
           </td>
           <td class="r">
            Shanghai AI Lab
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#343395" title="Click to go to the Author Index">
             Zheng, Guanjie
            </a>
           </td>
           <td class="r">
            Shanghai Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#272739" title="Click to go to the Author Index">
             Wen, Licheng
            </a>
           </td>
           <td class="r">
            Shanghai AI Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#272741" title="Click to go to the Author Index">
             Yang, Xuemeng
            </a>
           </td>
           <td class="r">
            Shanghai Artificial Intelligence Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#440563" title="Click to go to the Author Index">
             Sun, Xiao
            </a>
           </td>
           <td class="r">
            Shanghai AI Laboratory, China
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2289" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Traffic simulation, complementing real-world data with a long-tail distribution, allows for effective evaluation and enhancement of the ability of autonomous vehicles to handle accident-prone scenarios. Simulating such safety-critical scenarios is nontrivial, however, from log data that are typically regular scenarios, especially in consideration of dynamic adversarial interactions between the future motions of autonomous vehicles and surrounding traffic participants. To address it, this paper proposes an innovative and efficient strategy, termed IntSim, that explicitly decouples the driving intentions of surrounding actors from their motion planning for realistic and efficient safety-critical simulation. We formulate the adversarial transfer of driving intention as an optimization problem, facilitating extensive exploration of diverse attack behaviors and efficient solution convergence. Simultaneously, intention-conditioned motion planning benefits from powerful deep models and large-scale real-world data, permitting the simulation of realistic motion behaviors for actors. Specially, through adapting driving intentions based on environments, IntSim facilitates the flexible realization of dynamic adversarial interactions with autonomous vehicles. Finally, extensive open-loop and closed-loop experiments on real-world datasets, including nuScenes and Waymo, demonstrate that the proposed IntSim achieves state-of-the-art performance in simulating realistic safety-critical scenarios and further improves planners in handling such scenarios.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet20_06">
             17:00-17:05, Paper WeET20.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1666" name="modify2839" onclick="modify(2839,1666)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2839'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              The Radiance of Neural Fields: Democratizing Photorealistic and Dynamic Robotic Simulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#349156" title="Click to go to the Author Index">
             Alcolado Nuthall, Georgina E
            </a>
           </td>
           <td class="r">
            University of Surrey
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#142992" title="Click to go to the Author Index">
             Bowden, Richard
            </a>
           </td>
           <td class="r">
            University of Surrey
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#192270" title="Click to go to the Author Index">
             Mendez, Oscar
            </a>
           </td>
           <td class="r">
            University of Surrey
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2839" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#human_centered_robotics" title="Click to go to the Keyword Index">
               Human-Centered Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#software_tools_for_robot_programming" title="Click to go to the Keyword Index">
               Software Tools for Robot Programming
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             As robots increasingly coexist with humans, they must navigate complex, dynamic environments rich in visual information and implicit social dynamics, like when to yield or move through crowds. Addressing these challenges requires significant advances in vision-based sensing and a deeper understanding of socio-dynamic factors, particularly in tasks like navigation. To facilitate this, robotics researchers need advanced simulation platforms offering dynamic, photorealistic environments with realistic actors. Unfortunately, most existing simulators fall short, prioritizing geometric accuracy over visual fidelity, and employing unrealistic agents with fixed trajectories and low-quality visuals. To overcome these limitations, we developed a simulator that incorporates three essential elements: (1) photorealistic neural rendering of environments, (2) neurally animated human entities with behavior management, and (3) an ego-centric robotic agent providing multi-sensor output. By utilizing advanced neural rendering techniques in a dual-NeRF simulator, our system produces high-fidelity, photorealistic renderings of both environments and human entities. Additionally, it integrates a state-of-the-art Social Force Model to model dynamic human-human and human-robot interactions, creating the first photorealistic and accessible human-robot simulation system powered by neural rendering.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet20_07">
             17:05-17:10, Paper WeET20.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1667" name="modify3697" onclick="modify(3697,1667)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3697'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Human-Robot Cooperative Distribution Coupling for Hamiltonian-Constrained Social Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#324108" title="Click to go to the Author Index">
             Wang, Weizheng
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267884" title="Click to go to the Author Index">
             Yu, Chao
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#236151" title="Click to go to the Author Index">
             Wang, Yu
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#164680" title="Click to go to the Author Index">
             Min, Byung-Cheol
            </a>
           </td>
           <td class="r">
            Purdue University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3697" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#acceptability_and_trust" title="Click to go to the Keyword Index">
               Acceptability and Trust
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Navigating in human-filled public spaces is a critical challenge for deploying autonomous robots in real-world environments. This paper introduces NaviDIFF, a novel Hamiltonian-constrained socially-aware navigation framework designed to address the complexities of human-robot interaction and socially-aware path planning. NaviDIFF integrates a port-Hamiltonian framework to model dynamic physical interactions and a diffusion model to manage uncertainty in human-robot cooperation. The framework leverages a spatial-temporal transformer to capture social and temporal dependencies, enabling more accurate spatial-temporal environmental dynamics understanding and port-Hamiltonian physical interactive process construction. Additionally, reinforcement learning from human feedback is employed to fine-tune robot policies, ensuring adaptation to human preferences and social norms. Extensive experiments demonstrate that NaviDIFF outperforms state-of-the-art methods in social navigation tasks, offering improved stability, efficiency, and adaptability.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet20_08">
             17:10-17:15, Paper WeET20.8
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1668" name="modify4930" onclick="modify(4930,1668)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4930'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Crowd Perception Communication-Based Multi-Agent Path Finding with Imitation Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#374883" title="Click to go to the Author Index">
             Xie, Jing
            </a>
           </td>
           <td class="r">
            National Innovation Institute of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#246783" title="Click to go to the Author Index">
             Zhang, Yongjun
            </a>
           </td>
           <td class="r">
            National Innovation Institute of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339691" title="Click to go to the Author Index">
             Yang, Huanhuan
            </a>
           </td>
           <td class="r">
            National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#366956" title="Click to go to the Author Index">
             Ouyang, Qianying
            </a>
           </td>
           <td class="r">
            Intelligent Game and Decision Lab; Tianjin Artificial Intelliegnc
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#374847" title="Click to go to the Author Index">
             Dong, Fang
            </a>
           </td>
           <td class="r">
            College of Computer, National University of Defense Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#374882" title="Click to go to the Author Index">
             Guo, Xinyu
            </a>
           </td>
           <td class="r">
            Beijing Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339689" title="Click to go to the Author Index">
             Jin, Songchang
            </a>
           </td>
           <td class="r">
            Defense Innovation Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#246805" title="Click to go to the Author Index">
             Shi, Dianxi
            </a>
           </td>
           <td class="r">
            Defense Innovation Institute
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4930" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#path_planning_for_multiple_mobile_robots_or_agents" title="Click to go to the Keyword Index">
               Path Planning for Multiple Mobile Robots or Agents
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Deep reinforcement learning-based Multi-Agent Path Finding (MAPF) has gained significant attention due to its remarkable adaptability to environments. Existing methods primarily leverage multi-agent communication in a fully-decentralized framework to maintain scalability while enhancing information exchange among agents. However, as the number of agents and obstacles increases, the environment becomes more complex, making cooperation between agents becomes more difficult, and crowding occurs from time to time. To address these issues, we propose a decentralized planner C3PIL, which integrates a Controlled Communication mechanism for Crowd Perception and uses Imitation Learning to improve policy learning. C3PIL first introduces a crowd perception communication module that perceives environmental crowd information and incorporates it into the controlled communication. This effectively prevents and mitigates crowded situations. Furthermore, we employ generative adversarial imitation learning to learn a reward function from expert experiences. It reduces the possible misleading caused by the fixed reward function, improves the flexibility and diversity of agent behaviors, and ultimately enables agents to cooperate effectively. Finally, experimental results show that C3PIL not only outperforms previous learning-based MAPF methods, but also further enhances the cooperation of agents and significantly reduces crowding in complex environments. The code is available at https://github.com/JJingXie/C3PIL.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet21">
             <b>
              WeET21
             </b>
             Regular Session, 410
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1669" name="modifyWeET21" onclick="modsession(203,1669)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet21" title="Click to go to the Program at a Glance">
             <b>
              Integrating Motion Planning and Learning 2
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#106235" title="Click to go to the Author Index">
             Manocha, Dinesh
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#137443" title="Click to go to the Author Index">
             Soh, Harold
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet21_01">
             16:35-16:40, Paper WeET21.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1670" name="modify506" onclick="modify(506,1670)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('506'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              TSPDiffuser: Diffusion Models As Learned Samplers for Traveling Salesperson Path Planning Problems
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#241276" title="Click to go to the Author Index">
             Yonetani, Ryo
            </a>
           </td>
           <td class="r">
            CyberAgent
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab506" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#autonomous_vehicle_navigation" title="Click to go to the Keyword Index">
               Autonomous Vehicle Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents TSPDiffuser, a novel data-driven path planner for traveling salesperson path planning problems (TSPPPs) in environments rich with obstacles. Given a set of destinations within obstacle maps, our objective is to efficiently find the shortest possible collision-free path that visits all the destinations. In TSPDiffuser, we train a diffusion model on a large collection of TSPPP instances and their respective solutions to generate plausible paths for unseen problem instances. The model can then be employed as a learned sampler to construct a roadmap that contains potential solutions with a small number of nodes and edges. This approach enables efficient and accurate estimation of travel costs between destinations, effectively addressing the primary computational challenge in solving TSPPPs. Experimental evaluations with diverse synthetic and real-world indoor/outdoor environments demonstrate the effectiveness of TSPDiffuser over existing methods in terms of the trade-off between solution quality and computational time requirements.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet21_02">
             16:40-16:45, Paper WeET21.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1671" name="modify858" onclick="modify(858,1671)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('858'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Anticipatory Planning for Performant Long-Lived Robot in Large-Scale Home-Like Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#340649" title="Click to go to the Author Index">
             Talukder, Md Ridwan Hossain
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#337458" title="Click to go to the Author Index">
             Arnob, Raihan Islam
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#205862" title="Click to go to the Author Index">
             Stein, Gregory
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab858" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#task_planning" title="Click to go to the Keyword Index">
               Task Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We consider the setting where a robot must complete a sequence of tasks in a persistent large-scale environment, given one at a time. Existing task planners often operate myopically, focusing solely on immediate goals without considering the impact of current actions on future tasks. Anticipatory planning, which reduces the joint objective of the immediate planning cost of the current task and the expected cost associated with future subsequent tasks, offers an approach for improving long-lived task planning. However, applying anticipatory planning in large-scale environments presents significant challenges due to the sheer number of assets involved, which strains the scalability of learning and planning. In this research, we introduce a model-based anticipatory task planning framework designed to scale to large-scale realistic environments. Our framework uses a graph neural network (GNN) in particular via a representation inspired by a 3D scene graph to learn the essential properties of the environment crucial to estimating the state's expected cost and a sampling-based procedure for practical large-scale anticipatory planning. Our experimental results show that our planner reduces the cost of task sequence by 5.38% in home and 31.5% in restaurant settings. If given time to prepare in advance using our model reduces task sequence costs by 40.6% and 42.5%, respectively.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet21_03">
             16:45-16:50, Paper WeET21.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1672" name="modify1881" onclick="modify(1881,1672)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1881'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Scaling Diffusion Policy in Transformer to 1 Billion Parameters for Robotics Manipulation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#377141" title="Click to go to the Author Index">
             Zhu, MinJie
            </a>
           </td>
           <td class="r">
            East China Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#319251" title="Click to go to the Author Index">
             Zhu, Yichen
            </a>
           </td>
           <td class="r">
            Midea Group
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#377137" title="Click to go to the Author Index">
             Li, Jinming
            </a>
           </td>
           <td class="r">
            Shanghai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#377303" title="Click to go to the Author Index">
             Wen, Junjie
            </a>
           </td>
           <td class="r">
            East China Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338492" title="Click to go to the Author Index">
             Xu, Zhiyuan
            </a>
           </td>
           <td class="r">
            Midea Group
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338817" title="Click to go to the Author Index">
             Liu, Ning
            </a>
           </td>
           <td class="r">
            Midea Group
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#311188" title="Click to go to the Author Index">
             Cheng, Ran
            </a>
           </td>
           <td class="r">
            Midea Robozone
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338832" title="Click to go to the Author Index">
             Shen, Chaomin
            </a>
           </td>
           <td class="r">
            East China Normal University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#236605" title="Click to go to the Author Index">
             Peng, Yaxin
            </a>
           </td>
           <td class="r">
            Shanghai University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338835" title="Click to go to the Author Index">
             Feng, Feifei
            </a>
           </td>
           <td class="r">
            Midea Group
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#322428" title="Click to go to the Author Index">
             Tang, Jian
            </a>
           </td>
           <td class="r">
            Midea Group (Shanghai) Co., Ltd
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1881" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Diffusion Policy is a powerful technique tool for learning end-to-end visuomotor robot control. It is expected that Diffusion Policy possesses scalability, a key attribute for deep neural networks, typically suggesting that increasing model size would lead to enhanced performance. However, our observations indicate that Diffusion Policy in transformer architecture (DP) struggles to scale effectively; even minor additions of layers can deteriorate training outcomes. To address this issue, we introduce Scalable Diffusion Transformer Policy for visuomotor learning. Our proposed method, namely textbf{methodname}, introduces two modules that improve the training dynamic of Diffusion Policy and allow the network to better handle multimodal action distribution. First, we identify that DP~suffers from large gradient issues, making the optimization of Diffusion Policy unstable. To resolve this issue, we factorize the feature embedding of observation into multiple affine layers, and integrate it into the transformer blocks. Additionally, our unmasking strategy allows the policy network to enquote{see} future actions during prediction, helping to reduce compounding errors. We demonstrate that our proposed method successfully scales the Diffusion Policy from 10 million to 1 billion parameters. This new model, named methodname, can effectively scale up the model size with improved performance and generalization. We benchmark methodname~across 50 different tasks from MetaWorld and find that our largest methodname~outperforms DP~with an average improvement of 21.6%. Across 7 real-world robot tasks, our ScaleDP demonstrates an average improvement of 22.5% over DP-T on four single-arm tasks and 66.7% on three bimanual tasks. We believe our work paves the way for scaling up models for visuomotor learning. The project page is available at href{scaling-diffusion-policy.github.io/}{https://scaling- diffusion-policy.github.io/}.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet21_04">
             16:50-16:55, Paper WeET21.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1673" name="modify2918" onclick="modify(2918,1673)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2918'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Implicit Contact Diffuser: Sequential Contact Reasoning with Latent Point Cloud Diffusion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#341710" title="Click to go to the Author Index">
             Huang, Zixuan
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424635" title="Click to go to the Author Index">
             He, Yinong
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#355311" title="Click to go to the Author Index">
             Lin, Yating
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#113264" title="Click to go to the Author Index">
             Berenson, Dmitry
            </a>
           </td>
           <td class="r">
            University of Michigan
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2918" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_in_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Deep Learning in Grasping and Manipulation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Long-horizon contact-rich manipulation has long been a challenging problem, as it requires reasoning over both discrete contact modes and continuous object motion. We introduce Implicit Contact Diffuser (ICD), a diffusion-based model that generates a sequence of neural descriptors that specify a series of contact relationships between the object and the environment. This sequence is then used as guidance for an MPC method to accomplish a given task. The key advantage of this approach is that the latent descriptors provide more task- relevant guidance to MPC, helping to avoid local minima for contact-rich manipulation tasks. Our experiments demonstrate that ICD outperforms baselines on complex, long-horizon, contact-rich manipulation tasks, such as cable routing and notebook folding. Additionally, our experiments also indicate that ICD can generalize a target contact relationship to a different environment.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet21_05">
             16:55-17:00, Paper WeET21.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1674" name="modify3879" onclick="modify(3879,1674)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('3879'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Diffusion Meets Options: Hierarchical Generative Skill Composition for Temporally-Extended Tasks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#316717" title="Click to go to the Author Index">
             Feng, Zeyu
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#313610" title="Click to go to the Author Index">
             Luan, Hao
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#292459" title="Click to go to the Author Index">
             Ma, Kevin Yuchen
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#137443" title="Click to go to the Author Index">
             Soh, Harold
            </a>
           </td>
           <td class="r">
            National University of Singapore
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab3879" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#hybrid_logical_dynamical_planning_and_verification" title="Click to go to the Keyword Index">
               Hybrid Logical/Dynamical Planning and Verification
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Safe and successful deployment of robots requires not only the ability to generate complex plans but also the capacity to frequently replan and correct execution errors. This paper addresses the challenge of long-horizon trajectory planning under temporally extended objectives in a receding horizon manner. To this end, we propose DOPPLER, a data-driven hierarchical framework that generates and updates plans based on instruction specified by linear temporal logic (LTL). Our method decomposes temporal tasks into chain of options with hierarchical reinforcement learning from offline non-expert datasets. It leverages diffusion models to generate options with low-level actions. We devise a determinantal-guided posterior sampling technique during batch generation, which improves the speed and diversity of diffusion generated options, leading to more efficient querying. Experiments on robot navigation and manipulation tasks demonstrate that DOPPLER can generate sequences of trajectories that progressively satisfy the specified formulae for obstacle avoidance and sequential visitation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet21_06">
             17:00-17:05, Paper WeET21.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1675" name="modify4389" onclick="modify(4389,1675)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4389'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              PRESTO: Fast Motion Planning Using Diffusion Models Based on Key-Configuration Environment Representation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#211586" title="Click to go to the Author Index">
             Seo, Mingyo
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#323484" title="Click to go to the Author Index">
             Cho, Yoonyoung
            </a>
           </td>
           <td class="r">
            KAIST
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#148836" title="Click to go to the Author Index">
             Sung, Yoonchang
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106083" title="Click to go to the Author Index">
             Stone, Peter
            </a>
           </td>
           <td class="r">
            University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#203352" title="Click to go to the Author Index">
             Zhu, Yuke
            </a>
           </td>
           <td class="r">
            The University of Texas at Austin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#160363" title="Click to go to the Author Index">
             Kim, Beomjoon
            </a>
           </td>
           <td class="r">
            Korea Advanced Institute of Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4389" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#collision_avoidance" title="Click to go to the Keyword Index">
               Collision Avoidance
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_learning" title="Click to go to the Keyword Index">
               Integrated Planning and Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce a learning-guided motion planning framework that generates seed trajectories using a diffusion model for trajectory optimization. Given a workspace, our method approximates the configuration space (C-space) obstacles through an environment representation consisting of a sparse set of task-related key configurations, which is then used as a conditioning input to the diffusion model. The diffusion model integrates regularization terms that encourage smooth, collision-free trajectories during training, and trajectory optimization refines the generated seed trajectories to correct any colliding segments. Our experimental results demonstrate that high-quality trajectory priors, learned through our C-space-grounded diffusion model, enable the efficient generation of collision-free trajectories in narrow-passage environments, outperforming previous learning- and planning-based baselines. Videos and additional materials can be found on the project page: https://kiwi-sherbet.github.io/PRESTO.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet21_07">
             17:05-17:10, Paper WeET21.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1676" name="modify4925" onclick="modify(4925,1676)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4925'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Demonstration Data-Driven Parameter Adjustment for Trajectory Planning in Highly Constrained Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#377808" title="Click to go to the Author Index">
             Lu, Wangtao
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#429405" title="Click to go to the Author Index">
             Chen, Lei
            </a>
           </td>
           <td class="r">
            Beijing Institute of Spacecraft System Engineering
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#286826" title="Click to go to the Author Index">
             Wang, Yunkai
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379112" title="Click to go to the Author Index">
             Wei, Yufei
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#398690" title="Click to go to the Author Index">
             Wu, Zifei
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#113216" title="Click to go to the Author Index">
             Xiong, Rong
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#156231" title="Click to go to the Author Index">
             Wang, Yue
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4925" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Trajectory planning in highly constrained environments is crucial for robotic navigation. Classical algorithms are widely used for their interpretability, generalization, and system robustness. However, these algorithms often require parameter retuning when adapting to new scenarios. To address this issue, we propose a demonstration data-driven reinforcement learning (RL) method for automatic parameter adjustment. Our approach includes two main components: a front-end policy network and a back-end asynchronous controller. The policy network selects appropriate parameters for the trajectory planner, while a discriminator in a Conditional Generative Adversarial Network (CGAN) evaluates the planned trajectory, using this evaluation as an imitation reward in RL. The asynchronous controller is employed for high-frequency trajectory tracking. Experiments conducted in both simulation and realworld demonstrate that our proposed method significantly enhances the performance of classical algorithms.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet21_08">
             17:10-17:15, Paper WeET21.8
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1677" name="modify4991" onclick="modify(4991,1677)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4991'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              VLM-Social-Nav: Socially Aware Robot Navigation through Scoring Using Vision-Language Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#210737" title="Click to go to the Author Index">
             Song, Daeun
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#269549" title="Click to go to the Author Index">
             Liang, Jing
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#350504" title="Click to go to the Author Index">
             Payandeh, Amirreza
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#351172" title="Click to go to the Author Index">
             Raj, Amir Hossain
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#177144" title="Click to go to the Author Index">
             Xiao, Xuesu
            </a>
           </td>
           <td class="r">
            George Mason University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106235" title="Click to go to the Author Index">
             Manocha, Dinesh
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4991" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#motion_and_path_planning" title="Click to go to the Keyword Index">
               Motion and Path Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#integrated_planning_and_control" title="Click to go to the Keyword Index">
               Integrated Planning and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We propose VLM-Social-Nav, a novel Vision-Language Model (VLM) based navigation approach to compute a robot's motion in human-centered environments. Our goal is to make real-time decisions on robot actions that are socially compliant with human expectations. We utilize a perception model to detect important social entities and prompt a VLM to generate guidance for socially compliant robot behavior. VLM-Social-Nav uses a VLM-based scoring module that computes a cost term that ensures socially appropriate and effective robot actions generated by the underlying planner. Our overall approach reduces reliance on large training datasets and enhances adaptability in decision-making. In practice, it results in improved socially compliant navigation in human-shared environments. We demonstrate and evaluate our system in four different real-world social navigation scenarios with a Turtlebot robot. We observe at least 27.38% improvement in the average success rate and 19.05% improvement in the average collision rate in the four social navigation scenarios. Our user study score shows that VLM-Social-Nav generates the most socially compliant navigation behavior.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet22">
             <b>
              WeET22
             </b>
             Regular Session, 411
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1678" name="modifyWeET22" onclick="modsession(115,1678)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet22" title="Click to go to the Program at a Glance">
             <b>
              Deep Learning for Visual Perception 3
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#351637" title="Click to go to the Author Index">
             Le, Ngan
            </a>
           </td>
           <td class="r">
            University of Arkansas
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#299779" title="Click to go to the Author Index">
             Hsu, Winston
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet22_01">
             16:35-16:40, Paper WeET22.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1679" name="modify85" onclick="modify(85,1679)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('85'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Talk2Radar: Bridging Natural Language with 4D mmWave Radar for 3D Referring Expression Comprehension
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#389634" title="Click to go to the Author Index">
             Guan, Runwei
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#412152" title="Click to go to the Author Index">
             Zhang, Ruixiao
            </a>
           </td>
           <td class="r">
            University of Southampton
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411922" title="Click to go to the Author Index">
             Ouyang, Ningwei
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#368875" title="Click to go to the Author Index">
             Liu, Jianan
            </a>
           </td>
           <td class="r">
            Momoni AI
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#389739" title="Click to go to the Author Index">
             Man, Ka Lok
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong-Liverpool University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#412168" title="Click to go to the Author Index">
             Cai, Xiaohao
            </a>
           </td>
           <td class="r">
            University of Southampton
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#411963" title="Click to go to the Author Index">
             Xu, Ming
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong-Liverpool University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#397400" title="Click to go to the Author Index">
             Smith, Jeremy S.
            </a>
           </td>
           <td class="r">
            University of Liverpool
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#303425" title="Click to go to the Author Index">
             Lim, Eng Gee
            </a>
           </td>
           <td class="r">
            Xi'an Jiaotong-Liverpool University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#389831" title="Click to go to the Author Index">
             Yue, Yutao
            </a>
           </td>
           <td class="r">
            Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#390945" title="Click to go to the Author Index">
             Xiong, Hui
            </a>
           </td>
           <td class="r">
            The Hong Kong University of Science and Technology (Guangzhou)
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab85" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#data_sets_for_robotic_vision" title="Click to go to the Keyword Index">
               Data Sets for Robotic Vision
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#intelligent_transportation_systems" title="Click to go to the Keyword Index">
               Intelligent Transportation Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Embodied perception is essential for intelligent vehicles and robots in interactive environmental understanding. However, these advancements primarily focus on vision, with limited attention given to using 3D modeling sensors, restricting a comprehensive understanding of objects in response to prompts containing qualitative and quantitative queries. Recently, as a promising automotive sensor with affordable cost, 4D millimeter-wave radars provide denser point clouds than conventional radars and perceive both semantic and physical characteristics of objects, thereby enhancing the reliability of perception systems. To foster the development of natural language-driven context understanding in radar scenes for 3D visual grounding, we construct the first dataset, Talk2Radar, which bridges these two modalities for 3D Referring Expression Comprehension (REC). Talk2Radar contains 8,682 referring prompt samples with 20,558 referred objects. Moreover, we propose a novel model, T-RadarNet, for 3D REC on point clouds, achieving State-Of-The-Art (SOTA) performance on the Talk2Radar dataset compared to counterparts. Deformable-FPN and Gated Graph Fusion are meticulously designed for efficient point cloud feature modeling and cross-modal fusion between radar and text features, respectively. Comprehensive experiments provide deep insights into radar-based 3D REC. We release our project at https://github.com/GuanRunwei/Talk2Radar.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet22_02">
             16:40-16:45, Paper WeET22.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1680" name="modify181" onclick="modify(181,1680)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('181'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Improving Generalization Ability for 3D Object Detection by Learning Sparsity-Invariant Features
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#371871" title="Click to go to the Author Index">
             Lu, Hsin-Cheng
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#394760" title="Click to go to the Author Index">
             Lin, Chungyi
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#299779" title="Click to go to the Author Index">
             Hsu, Winston
            </a>
           </td>
           <td class="r">
            National Taiwan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab181" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#object_detection__segmentation_and_categorization" title="Click to go to the Keyword Index">
               Object Detection, Segmentation and Categorization
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In autonomous driving, 3D object detection is essential for accurately identifying and tracking objects. Despite the continuous development of various technologies for this task, a significant drawback is observed in most of them—they experience substantial performance degradation when detecting objects in unseen domains. In this paper, we propose a method to improve the generalization ability for 3D object detection on a single domain. We primarily focus on generalizing from a single source domain to target domains with distinct sensor configurations and scene distributions. To learn sparsity-invariant features from a single source domain, we selectively subsample the source data to a specific beam, using confidence scores determined by the current detector to identify the density that holds utmost importance for the detector. Subsequently, we employ the teacher-student framework to align the Bird's Eye View (BEV) features for different point clouds densities. We also utilize feature content alignment (FCA) and graph-based embedding relationship alignment (GERA) to instruct the detector to be domain-agnostic. Extensive experiments demonstrate that our method exhibits superior generalization capabilities compared to other baselines. Furthermore, our approach even outperforms certain domain adaptation methods that can access to the target domain data. The code is available at https://github.com/Tiffamy/3DOD-LSF.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet22_03">
             16:45-16:50, Paper WeET22.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1681" name="modify320" onclick="modify(320,1681)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('320'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Camera-Lidar Consistent Neural Radiance Fields
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338968" title="Click to go to the Author Index">
             Hou, Chao
            </a>
           </td>
           <td class="r">
            The University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#204381" title="Click to go to the Author Index">
             Zhang, Fu
            </a>
           </td>
           <td class="r">
            University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab320" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Neural Radiance Fields (NeRFs) have become a leading technique for novel view synthesis, with promising applications in robotics. However, due to shape-radiance ambiguity, NeRFs often require additional depth inputs for regularization in outdoor scenarios. LiDAR provides accurate depth measurements, but current methods typically combine only a few frames, resulting in sparse depth maps and discrepancies with camera images. The asynchronous nature of LiDAR, where each point is captured at a different timestamp, introduces depth inaccuracies when treated as simultaneous. These errors, along with inherent LiDAR noise, create inconsistencies that hinder reconstruction accuracy. To address these challenges, we propose a continuous-time framework for joint Camera- LiDAR optimization, enabling more consistent radiance field reconstruction and improving both view synthesis and geometric accuracy. To address these issues, we introduce a continuoustime framework for joint Camera-LiDAR optimization, aiming to consistently reconstruct the radiance field for better view synthesis and geometric accuracy.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet22_04">
             16:50-16:55, Paper WeET22.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1682" name="modify508" onclick="modify(508,1682)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('508'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Iterative Volume Fusion for Asymmetric Stereo Matching
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417516" title="Click to go to the Author Index">
             Gao, Yuanting
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#415162" title="Click to go to the Author Index">
             Shen, Linghao
            </a>
           </td>
           <td class="r">
            Sony (China) Ltd
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab508" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_transportation" title="Click to go to the Keyword Index">
               Computer Vision for Transportation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Stereo matching is vital in 3D computer vision, with most algorithms assuming symmetric visual properties between binocular visions. However, the rise of asymmetric multi-camera systems (e.g., tele-wide cameras) challenges this assumption and complicates stereo matching. Visual asymmetry disrupts stereo matching by affecting the crucial cost volume computation. To address this, we explore the matching cost distribution of two established cost volume construction methods in asymmetric stereo. We find that each cost volume experiences distinct information distortion, indicating that both should be comprehensively utilized to solve the issue. Based on this, we propose the two-phase Iterative Volume Fusion network for Asymmetric Stereo matching (IVF-AStereo). Initially, the aggregated concatenation volume refines the correlation volume. Subsequently, both volumes are fused to enhance fine details. Our method excels in asymmetric scenarios and shows robust performance against significant visual asymmetry. Extensive comparative experiments on benchmark datasets, along with ablation studies, confirm the effectiveness of our approach in asymmetric stereo with resolution and color degradation.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet22_05">
             16:55-17:00, Paper WeET22.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1683" name="modify568" onclick="modify(568,1683)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('568'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              OccRWKV: Rethinking Efficient 3D Semantic Occupancy Prediction with Linear Complexity
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#370862" title="Click to go to the Author Index">
             Wang, Junming
            </a>
           </td>
           <td class="r">
            The University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#280806" title="Click to go to the Author Index">
             Yin, Wei
            </a>
           </td>
           <td class="r">
            University of Adelaide
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335110" title="Click to go to the Author Index">
             Long, Xiaoxiao
            </a>
           </td>
           <td class="r">
            The University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417998" title="Click to go to the Author Index">
             Zhang, Xingyu
            </a>
           </td>
           <td class="r">
            Horizon Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417996" title="Click to go to the Author Index">
             Xing, Zebin
            </a>
           </td>
           <td class="r">
            UCAS
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#417997" title="Click to go to the Author Index">
             Guo, Xiaoyang
            </a>
           </td>
           <td class="r">
            Horizon Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#287698" title="Click to go to the Author Index">
             Zhang, Qian
            </a>
           </td>
           <td class="r">
            Horizon Robotics
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab568" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_learning" title="Click to go to the Keyword Index">
               Visual Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#computer_vision_for_automation" title="Click to go to the Keyword Index">
               Computer Vision for Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             3D semantic occupancy prediction networks have demonstrated remarkable capabilities in reconstructing the geometric and semantic structure of 3D scenes, providing crucial information for robot navigation and autonomous driving systems. However, due to their large overhead from dense network structure designs, existing networks face challenges balancing accuracy and latency. In this paper, we introduce OccRWKV, an efficient semantic occupancy network inspired by Receptance Weighted Key Value (RWKV). OccRWKV separates semantics, occupancy prediction, and feature fusion into distinct branches, each incorporating Sem-RWKV and Geo-RWKV blocks. These blocks are designed to capture long-range dependencies, enabling the network to learn domain-specific representation (i.e., semantics and geometry), which enhances prediction accuracy. Leveraging the sparse nature of real-world 3D occupancy, we reduce computational overhead by projecting features into the bird's-eye view (BEV) space and propose a BEV-RWKV block for efficient feature enhancement and fusion. This enables real-time inference at 22.2 FPS without compromising performance. Experiments demonstrate that OccRWKV outperforms the state-of-the-art methods on the SemanticKITTI dataset, achieving a mIoU of 25.1 while being 20 times faster than the best baseline, Co-Occ, making it suitable for real-time deployment on robots to enhance autonomous navigation efficiency. Code and video are available on our project page: https://jmwang0117.github.io/OccRWKV/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet22_06">
             17:00-17:05, Paper WeET22.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1684" name="modify620" onclick="modify(620,1684)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('620'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              ZSORN: Language-Driven Object-Centric Zero-Shot Object Retrieval and Navigation
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#269556" title="Click to go to the Author Index">
             Guan, Tianrui
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#375908" title="Click to go to the Author Index">
             Yang, Yurou
            </a>
           </td>
           <td class="r">
            Amazon
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#375892" title="Click to go to the Author Index">
             Cheng, Harry
            </a>
           </td>
           <td class="r">
            Amazon
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#224771" title="Click to go to the Author Index">
             Lin, Muyuan
            </a>
           </td>
           <td class="r">
            Amazon.com LLC
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#338092" title="Click to go to the Author Index">
             Kim, Richard
            </a>
           </td>
           <td class="r">
            Amazon, Lab126
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#336692" title="Click to go to the Author Index">
             Madhivanan, Rajasimman
            </a>
           </td>
           <td class="r">
            Amazon.com
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#336589" title="Click to go to the Author Index">
             Sen, Arnab
            </a>
           </td>
           <td class="r">
            Amazon
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106235" title="Click to go to the Author Index">
             Manocha, Dinesh
            </a>
           </td>
           <td class="r">
            University of Maryland
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab620" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#vision_based_navigation" title="Click to go to the Keyword Index">
               Vision-Based Navigation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, we present ZSORN, a novel language-driven object-centric image representation for object retrieval and navigation task within complex scenes. We propose an object centric image representation and corresponding losses for visual-language model (VLM) fine-tuning, which can handle complex object-level queries. In addition, we design a novel LLM-based augmentation and prompt templates for stability during training and zero-shot inference. We implement our method on Astro robot and deploy it in both simulated and real-world environments for zero-shot object navigation. We show that our proposed method can achieve an improvement of 1.38 - 13.38% in terms of text-to-image recall on different benchmark settings for the retrieval task. For object navigation, we show the benefit of our approach in simulation and real world, showing 5% and 16.67% improvement in terms of navigation success rate, respectively.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet22_07">
             17:05-17:10, Paper WeET22.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1685" name="modify2602" onclick="modify(2602,1685)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2602'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              PRIDEV: A Plug-And-Play Refinement for Improved Depth Estimation in Videos
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#416145" title="Click to go to the Author Index">
             Xu, Jing
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#110768" title="Click to go to the Author Index">
             Liu, Hong
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421163" title="Click to go to the Author Index">
             Wu, Jianbing
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421538" title="Click to go to the Author Index">
             Xu, Xinhua
            </a>
           </td>
           <td class="r">
            Peking University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2602" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#rgb_d_perception" title="Click to go to the Keyword Index">
               RGB-D Perception
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_for_visual_perception" title="Click to go to the Keyword Index">
               Deep Learning for Visual Perception
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Monocular video depth estimation is a key challenge in computer vision, highlighting its importance in visual understanding. Monocular depth estimation models trained on single images achieve impressive results on individual frames but often lack temporal consistency when applied to videos, leading to flickering and artifacts. Current video depth estimation methods often rely on additional optical flow or camera poses, which are limited by their accuracy, carefullydesigned, and lack robustness. Specially, we propose a plug-and-play method that seamlessly transfers the robustness of image depth estimation to video depth estimation. By leveraging powerful priors from image depth estimation, our method enhances the performance of video depth estimation without requiring additional conditional inputs or extensive pretraining on large and expensive video datasets. We introduce the Temporal Depth Stabilization Module (TDSM), which can seamlessly inflate an image monocular depth estimation model into a video depth estimation model, enabling unified modeling of depth across video sequences and capturing the temporal cues in video. We validate the effectiveness and efficiency of our method across various datasets (e.g., normal and challenging conditions) and different backbones. Extensive experiments demonstrate that our simple and effective method significantly improves monocular depth estimation networks, achieving new state-of-the-art accuracy in both spatial and temporal dimensions.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="weet23">
             <b>
              WeET23
             </b>
             Regular Session, 412
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1686" name="modifyWeET23" onclick="modsession(227,1686)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#weet23" title="Click to go to the Program at a Glance">
             <b>
              Learning for Control
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr>
           <td>
            Chair:
            <a href="ICRA25_AuthorIndexWeb.html#205543" title="Click to go to the Author Index">
             Manchester, Zachary
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            Co-Chair:
            <a href="ICRA25_AuthorIndexWeb.html#300251" title="Click to go to the Author Index">
             Beckers, Thomas
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet23_01">
             16:35-16:40, Paper WeET23.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1687" name="modify185" onclick="modify(185,1687)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('185'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Unsupervised Meta-Testing with Conditional Neural Processes for Hybrid Meta-Reinforcement Learning
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#269717" title="Click to go to the Author Index">
             Ada, Suzan Ece
            </a>
           </td>
           <td class="r">
            Bogazici University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106000" title="Click to go to the Author Index">
             Ugur, Emre
            </a>
           </td>
           <td class="r">
            Bogazici University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab185" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             We introduce Unsupervised Meta-Testing with Conditional Neural Processes (UMCNP), a novel hybrid few-shot meta-reinforcement learning (meta-RL) method that uniquely combines, yet distinctly separates, parameterized policy gradient-based (PPG) and task inference-based few-shot meta-RL. Tailored for settings where the reward signal is missing during meta-testing, our method increases sample efficiency without requiring additional samples in meta-training. UMCNP leverages the efficiency and scalability of Conditional Neural Processes (CNPs) to reduce the number of online interactions required in meta-testing. During meta-training, samples previously collected through PPG meta-RL are efficiently reused for learning task inference in an offline manner. UMCNP infers the latent representation of the transition dynamics model from a single test task rollout with unknown parameters. This approach allows us to generate rollouts for self-adaptation by interacting with the learned dynamics model. We demonstrate our method can adapt to an unseen test task using significantly fewer samples during meta-testing than the baselines in 2D-Point Agent and continuous control meta-RL benchmarks, namely, cartpole with unknown angle sensor bias, walker agent with randomized dynamics parameters.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet23_02">
             16:40-16:45, Paper WeET23.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1688" name="modify718" onclick="modify(718,1688)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('718'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Efficient Online Learning of Contact Force Models for Connector Insertion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#286293" title="Click to go to the Author Index">
             Tracy, Kevin
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#205543" title="Click to go to the Author Index">
             Manchester, Zachary
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#193710" title="Click to go to the Author Index">
             Jain, Ajinkya
            </a>
           </td>
           <td class="r">
            Intrinsic Innovation LLC
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395987" title="Click to go to the Author Index">
             Go, Keegan
            </a>
           </td>
           <td class="r">
            Intrinsic Innovation LLC
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102004" title="Click to go to the Author Index">
             Schaal, Stefan
            </a>
           </td>
           <td class="r">
            Google X
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#111298" title="Click to go to the Author Index">
             Erez, Tom
            </a>
           </td>
           <td class="r">
            Google
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#109154" title="Click to go to the Author Index">
             Tassa, Yuval
            </a>
           </td>
           <td class="r">
            University of Washington
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab718" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#calibration_and_identification" title="Click to go to the Keyword Index">
               Calibration and Identification
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dexterous_manipulation" title="Click to go to the Keyword Index">
               Dexterous Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Contact-rich manipulation tasks with stiff frictional elements, like connector insertion, are difficult to model with rigid-body simulators. In this work, we propose a new approach for modeling these environments by learning a quasi-static contact force model instead of a full simulator. Using a feature vector that contains information about the configuration and control, we find a linear mapping adequately captures the relationship between this feature vector and the sensed contact forces. A novel Linear Model Learning (LML) algorithm is used to solve for the globally optimal mapping in real time without any matrix inversions, resulting in an algorithm that runs in nearly constant time on a GPU as the model size increases. We validate the proposed approach for connector insertion in both simulation and hardware experiments, where the learned model is combined with an optimization-based impedance controller to achieve smooth insertions in the presence of misalignments and uncertainty. Our website featuring videos, code, and more materials is available at https://model-based-plugging.github.io/.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet23_03">
             16:45-16:50, Paper WeET23.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1689" name="modify1596" onclick="modify(1596,1689)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('1596'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Flying Quadrotors in Tight Formations Using Learning-Based Model Predictive Control
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#283625" title="Click to go to the Author Index">
             Chee, Kong Yao
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#325776" title="Click to go to the Author Index">
             Hsieh, Pei-An
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#102357" title="Click to go to the Author Index">
             Pappas, George J.
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106150" title="Click to go to the Author Index">
             Hsieh, M. Ani
            </a>
           </td>
           <td class="r">
            University of Pennsylvania
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab1596" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Flying quadrotors in tight formations is a challenging problem. It is known that in the near-field airflow of a quadrotor, the aerodynamic effects induced by the propellers are complex and difficult to characterize. Although machine learning tools can potentially be used to derive models that capture these effects, these data-driven approaches can be sample inefficient and the resulting models often do not generalize as well as their first-principles counterparts. In this work, we propose a framework that combines the benefits of first-principles modeling and data-driven approaches to construct an accurate and sample efficient representation of the complex aerodynamic effects resulting from quadrotors flying in formation. The data-driven component within our model is lightweight, making it amenable for optimization-based control design. Through simulations and physical experiments, we show that incorporating the model into a novel learning-based nonlinear model predictive control (MPC) framework results in substantial performance improvements in terms of trajectory tracking and disturbance rejection. In particular, our framework significantly outperforms nominal MPC in physical experiments, achieving a 40.1% improvement in the average trajectory tracking errors and a 57.5% reduction in the maximum vertical separation errors. Our framework also achieves exceptional sample efficiency, using only a total of 46 seconds of flight data for training across both simulations and physical experiments. Furthermore, with our proposed framework, the quadrotors achieve an exceptionally tight formation, flying with an average separation of less than 1.5 body lengths throughout the flight.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet23_04">
             16:50-16:55, Paper WeET23.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1690" name="modify2225" onclick="modify(2225,1690)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2225'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Learning Based MPC for Autonomous Driving Using a Low Dimensional Residual Model
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419913" title="Click to go to the Author Index">
             Li, Yaoyu
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420392" title="Click to go to the Author Index">
             Huang, Chaosheng
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420971" title="Click to go to the Author Index">
             Yang, Dongsheng
            </a>
           </td>
           <td class="r">
            BYD Automotive New Technology Research Institute
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419934" title="Click to go to the Author Index">
             Liu, Wenbo
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#383745" title="Click to go to the Author Index">
             Li, Jun
            </a>
           </td>
           <td class="r">
            Tsinghua University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2225" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#motion_control" title="Click to go to the Keyword Index">
               Motion Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this paper, a learning based Model Predictive Control (MPC) using a low dimensional residual model is proposed for autonomous driving. One of the critical challenge in autonomous driving is the complexity of vehicle dynamics, which impedes the formulation of accurate vehicle model. Inaccurate vehicle model can significantly impact the performance of MPC controller. To address this issue, this paper decomposes the nominal vehicle model into invariable and variable elements. The accuracy of invariable elements are ensured by calibration, while the deviations in the variable elements are learned by a low-dimensional residual model. The features of residual model are selected as the physical variables most correlated with nominal model errors. Physical constraints among these features are formulated to explicitly define the valid region within the feature space. The formulated model and constraints are incorporated into the MPC framework and validated through both simulation and real vehicle experiments. The results indicate that the proposed method significantly enhances the model accuracy and controller performance.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet23_05">
             16:55-17:00, Paper WeET23.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1691" name="modify2449" onclick="modify(2449,1691)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2449'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Modeling of Deformable Linear Objects under Incomplete State Information
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418496" title="Click to go to the Author Index">
             Klankers, Marc Kilian
            </a>
           </td>
           <td class="r">
            Technische Universität Braunschweig
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104760" title="Click to go to the Author Index">
             Steil, Jochen J.
            </a>
           </td>
           <td class="r">
            Technische Universität Braunschweig
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2449" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#modeling__control__and_learning_for_soft_robots" title="Click to go to the Keyword Index">
               Modeling, Control, and Learning for Soft Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The robot-based tracking of highly dynamic end point motions of deformable linear objects (DLO) remains challenging due to its non-linear behavior. Since simple feedback control is infeasible, model-based control offers potential to account for the non-linear effects, but requires computation efficient and accurate models. Promising results have been achieved utilizing data-driven models that introduce a latent kinematic chain as model of the DLO and mapping measurements of the tip position in its latent joint space, in which the dynamic motion model is learned. So far, this approach has the limitation that it can not handle situations of incomplete sensory information, for instance if occlusion occurs. Consequently, this paper introduces a fusion network architecture capable of making predictions even if sensory information is incomplete. We achieve additional state estimation of the latent joint state by learning a data driven inverse kinematics with help of wrench measurements at the DLO base and evaluate our approach by simulating occlusion. We demonstrate the computational effectiveness of our approach for in the loop control tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet23_06">
             17:00-17:05, Paper WeET23.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1692" name="modify2524" onclick="modify(2524,1692)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('2524'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Impedance Primitive-Augmented Hierarchical Reinforcement Learning for Sequential Tasks
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#424341" title="Click to go to the Author Index">
             Berjaoui Tahmaz, Amin
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#204329" title="Click to go to the Author Index">
             Prakash, Ravi
            </a>
           </td>
           <td class="r">
            Indian Institute of Science
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#117613" title="Click to go to the Author Index">
             Kober, Jens
            </a>
           </td>
           <td class="r">
            TU Delft
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab2524" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#compliance_and_impedance_control" title="Click to go to the Keyword Index">
               Compliance and Impedance Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#task_and_motion_planning" title="Click to go to the Keyword Index">
               Task and Motion Planning
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents an Impedance Primitive-augmented hierarchical reinforcement learning framework for efficient robotic manipulation in sequential contact tasks. We leverage this hierarchical structure to sequentially execute behavior primitives with variable stiffness control capabilities for contact tasks. Our proposed approach relies on three key components: an action space enabling variable stiffness control, an adaptive stiffness controller for dynamic stiffness adjustments during primitive execution, and affordance coupling for efficient exploration while encouraging compliance. Through comprehensive training and evaluation, our framework learns efficient stiffness control capabilities and demonstrates improvements in learning efficiency, compositionality in primitive selection, and success rates compared to the state-of-the-art. The training environments include block lifting, door opening, object pushing, and surface cleaning. Real world evaluations further confirm the framework's sim2real capability. This work lays the foundation for more adaptive and versatile robotic manipulation systems, with potential applications in more complex contact-based tasks.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet23_07">
             17:05-17:10, Paper WeET23.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1693" name="modify4401" onclick="modify(4401,1693)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4401'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Plug-And-Play Physics-Informed Learning Using Uncertainty Quantified Port-Hamiltonian Models
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#353091" title="Click to go to the Author Index">
             Tan, Kaiyuan
            </a>
           </td>
           <td class="r">
            Washington University in St.Louis
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#426577" title="Click to go to the Author Index">
             Li, Peilun
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#323966" title="Click to go to the Author Index">
             Wang, Jun
            </a>
           </td>
           <td class="r">
            Washington University in St. Louis
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#300251" title="Click to go to the Author Index">
             Beckers, Thomas
            </a>
           </td>
           <td class="r">
            Vanderbilt University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4401" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#model_learning_for_control" title="Click to go to the Keyword Index">
               Model Learning for Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_based_methods" title="Click to go to the Keyword Index">
               AI-Based Methods
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#calibration_and_identification" title="Click to go to the Keyword Index">
               Calibration and Identification
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The ability to predict trajectories of surrounding agents and obstacles is a crucial component in many robotic applications. Data-driven approaches are commonly adopted for state prediction in scenarios where the underlying dynamics are unknown. However, the performance, reliability, and uncertainty of data-driven predictors become compromised when encountering out-of-distribution observations relative to the training data. In this paper, we introduce a Plug-and-Play Physics-Informed Machine Learning (PnP-PIML) framework to address this challenge. Our method employs conformal prediction to identify outlier dynamics and, in that case, switches from a nominal predictor to a physics-consistent model, namely distributed Port-Hamiltonian systems (dPHS). We leverage Gaussian processes to model the energy function of the dPHS, enabling not only the learning of system dynamics but also the quantification of predictive uncertainty through its Bayesian nature. In this way, the proposed framework produces reliable physics-informed predictions even for the out-of-distribution scenarios.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="weet23_08">
             17:10-17:15, Paper WeET23.8
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1694" name="modify4608" onclick="modify(4608,1694)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('4608'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robust Proximal Adversarial Reinforcement Learning under Model Mismatch
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267891" title="Click to go to the Author Index">
             Zhai, Peng
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#373615" title="Click to go to the Author Index">
             Wei, Xiaoyi
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335367" title="Click to go to the Author Index">
             Hou, Taixian
            </a>
           </td>
           <td class="r">
            FuDan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#298227" title="Click to go to the Author Index">
             Ji, Xiaopeng
            </a>
           </td>
           <td class="r">
            Zhejiang University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267858" title="Click to go to the Author Index">
             Dong, Zhiyan
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405338" title="Click to go to the Author Index">
             Yi, Jiafu
            </a>
           </td>
           <td class="r">
            Hainan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#267890" title="Click to go to the Author Index">
             ZHang, Lihua
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab4608" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robust_adaptive_control" title="Click to go to the Keyword Index">
               Robust/Adaptive Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Reinforcement learning (RL) can generate high-performance control policies for complex tasks in simulation through an end-to-end approach. However, the RL policy is not robust to uncertainties caused by modeling mismatch between simulation and real environments, making it difficult to transfer to the real world. In response to the above challenge, this letter introduces a lightweight and efficient robust RL algorithm. The algorithm transforms the optimization objective of the adversary from a long-term cumulative reward to a short-term reward, making the adversary focus on the performance in the near future. Additionally, the adversarial actions are projected onto a finite subset within the perturbation space using projected gradient descent, effectively constraining the adversary's strength and obtaining more robust policies. Extensive experiments in both simulated and real environments show that our algorithm improves the generalization ability of the policy for the modeling mismatch, outperforming the next best prior methods across almost all environments.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="we1ex">
             <b>
              We1EX
             </b>
             Expo Session, Room T25
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1695" name="modifyWe1EX" onclick="modsession(679,1695)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#we1ex" title="Click to go to the Program at a Glance">
             <b>
              EXPO Session I
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we1ex_01">
             13:00-15:00, Paper We1EX.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1696" name="modify5169" onclick="modify(5169,1696)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5169'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              In-Plane Manipulation of Soft Micro-Fiber with Ultrasonic Transducer Array and Microscope
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423778" title="Click to go to the Author Index">
             Zou, Jieyun
            </a>
           </td>
           <td class="r">
            Shanghaitech University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#385274" title="Click to go to the Author Index">
             An, Siyuan
            </a>
           </td>
           <td class="r">
            Shanghaitech University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335221" title="Click to go to the Author Index">
             Wang, Mingyue
            </a>
           </td>
           <td class="r">
            Shanghaitech Univerisity
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#335232" title="Click to go to the Author Index">
             Li, Jiaqi
            </a>
           </td>
           <td class="r">
            ShanghaiTech University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#447563" title="Click to go to the Author Index">
             Shi, Yalin
            </a>
           </td>
           <td class="r">
            The School of Control Science and Engineering (CSE) of Shandong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#169150" title="Click to go to the Author Index">
             Li, You-Fu
            </a>
           </td>
           <td class="r">
            City University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#285160" title="Click to go to the Author Index">
             Liu, Song
            </a>
           </td>
           <td class="r">
            ShanghaiTech University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5169" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#automation_at_micro_nano_scales" title="Click to go to the Keyword Index">
               Automation at Micro-Nano Scales
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grasping" title="Click to go to the Keyword Index">
               Grasping
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Noncontact manipulation of soft micro-fibers has great
potential in advanced manufacturing, materials science, and
biomedical engineering. However, current noncontact
manipulation techniques primarily focus on objects with
regular shapes, e.g., solid particles, cells, or droplets,
with fewer solutions available for manipulating flexible
and elongated structures. In this paper, an automated
ultrasonic manipulation system is introduced for in-plane
soft micro-fiber manipulation, which mainly consists of an
ultrasonic transducer array and a microscope. A real-time
trap generation algorithm is designed to manipulate the
micro-fibers by the visual feedback from microscope. An
adequate theoretical analysis is also provided for
explanation of the deformation behavior of micro-fiber
under external forces. The system is capable of precise
in-plane positioning and motion trajectory planning to
micro-fiber end, and in-plane morphological reshaping to
the micro-fiber. Experiments validated the effectiveness of
the proposed system for the in-plane manipulation of soft
micro-fibers. Finally, the system was showcased by the
practical application of material property
characterization.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we1ex_02">
             13:00-15:00, Paper We1EX.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1697" name="modify5177" onclick="modify(5177,1697)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5177'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CoCube: A Tabletop Modular Multi-Robot Platform for Education and Research
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#399153" title="Click to go to the Author Index">
             Liang, Shuai
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423600" title="Click to go to the Author Index">
             Zhu, Songyi
            </a>
           </td>
           <td class="r">
            Shanghai Artifcial Intelligence Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423597" title="Click to go to the Author Index">
             Zhonghan, Tang
            </a>
           </td>
           <td class="r">
            University of Science and Technology of China
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#421681" title="Click to go to the Author Index">
             Li, Chenhui
            </a>
           </td>
           <td class="r">
            Shanghai Artificial Intelligence Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423624" title="Click to go to the Author Index">
             Wu, Wenjie
            </a>
           </td>
           <td class="r">
            DynaLab
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#423676" title="Click to go to the Author Index">
             Han, Jialing
            </a>
           </td>
           <td class="r">
            Fudan University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425723" title="Click to go to the Author Index">
             Lin, Zemin
            </a>
           </td>
           <td class="r">
            Shanghai Jiaotong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#440357" title="Click to go to the Author Index">
             You, Zhongrui
            </a>
           </td>
           <td class="r">
            Shanghai Artifcial Intelligence Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#441711" title="Click to go to the Author Index">
             Maloney, John
            </a>
           </td>
           <td class="r">
            MicroBlocks
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#441479" title="Click to go to the Author Index">
             Romagosa Carrasquer, Bernat
            </a>
           </td>
           <td class="r">
            SAP
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372118" title="Click to go to the Author Index">
             Zhao, Bin
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#376465" title="Click to go to the Author Index">
             Wang, Zhigang
            </a>
           </td>
           <td class="r">
            Shanghai AI Laboratory
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354792" title="Click to go to the Author Index">
             Zhang, Zhinan
            </a>
           </td>
           <td class="r">
            Shanghai Jiao Tong University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#372120" title="Click to go to the Author Index">
             Li, Xuelong
            </a>
           </td>
           <td class="r">
            Northwestern Polytechnical University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5177" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#cellular_and_modular_robots" title="Click to go to the Keyword Index">
               Cellular and Modular Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This paper presents CoCube, a tabletop modular robotics
platform designed for robotics education and multi-robot
algorithm research. CoCube is characterized by its low
cost, low floors, high ceilings and wide walls, offering
flexibility and broad applicability across various use
cases. The platform comprises four key components: CoCube
robots, which integrate wireless communication, movement
and interaction; CoModules, which provide versatile
external functionality; CoMaps, which enable high-precision
localization via microdot patterns on regular printed
paper; and CoTags for interaction. CoCube operates on
MicroBlocks, a blocks programming language for physical
computing inspired by Scratch, a widely-used coding
language with a simple visual interface that makes
programming accessible to young learners. It offers users
both flexibility and ease of use, with advanced API support
for more complex applications. This paper details the
design of the CoCube platform and demonstrates its
potential in both educational and research contexts.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we1ex_03">
             13:00-15:00, Paper We1EX.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1698" name="modify5179" onclick="modify(5179,1698)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5179'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Loopy Movements: Emergence of Rotation in a Multicellular Robot Demonstration
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#298103" title="Click to go to the Author Index">
             Smith, Trevor
            </a>
           </td>
           <td class="r">
            West Virginia University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#146498" title="Click to go to the Author Index">
             Gu, Yu
            </a>
           </td>
           <td class="r">
            West Virginia University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5179" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#cellular_and_modular_robots" title="Click to go to the Keyword Index">
               Cellular and Modular Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#swarm_robotics" title="Click to go to the Keyword Index">
               Swarm Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Unlike most engineered systems, biological systems often
exhibit emergent behaviors rooted in simple local
interactions, enabling them to remain adaptable and
resilient in complex environments. Inspired by these
principles, this work demonstrates a decentralized,
emergent rotation in Loopy, a multicellular robot composed
of homogeneous, physically linked, one-degree-of-freedom
cells. Each cell simulates local chemical reactions,
diffusion, and active transport of morphogens without
centralized control or awareness of the overall robot
shape. Through these interactions, Loopy self-organizes
into lobed morphologies that rotate, with each cell moving
counter to the macroscopic structure. We investigate (1)
how these local rules generate rotational motion, (2) the
effect of morphology on motion, and (3) the system’s
tolerance to actuator failure. Experiments reveal that
changing lobe size or count redistributes angular
velocities between the cells and overall morphology, and
Loopy maintains rotation despite losing up to one-third of
its actuators. These findings highlight the potential of
bio-inspired, bottom-up strategies for building robust,
adaptive robotic systems.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we1ex_04">
             13:00-15:00, Paper We1EX.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1699" name="modify5183" onclick="modify(5183,1699)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5183'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Pipe-Like Joints &amp; Single-Carrier Compound Gearbox (SCCG)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#419741" title="Click to go to the Author Index">
             Ferrin Pozuelo, Rafael
            </a>
           </td>
           <td class="r">
            National Institute of Advanced Industrial Science and Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5183" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#physical_human_robot_interaction" title="Click to go to the Keyword Index">
               Physical Human-Robot Interaction
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Abstract - In the ever-evolving field of robotics, the
continuous exploration and testing of new ideas and
approaches in hardware design are essential for driving
innovation and improving performance. Sometimes,
innovation comes from reconsidering and improving upon
designs that were developed in the past but did
not achieve widespread adoption. This exhibition proposes a
reconsideration of one such development: the
concept of coordinated rotary joints in robotic systems,
introduced in the early 1980s by renowned Japanese
roboticist Professor Hirose Satoshi.
The design of these coordinated rotary joints, where
multiple rotary joints work in unison to achieve a
combined bending movement, creates hollow, pipe-like
structures that enable efficient force transmission
through the walls while offering a continuous exterior
surface. The efficient force transmission and pipe-like
shape make these joints ideal for multi-redundant
inspection robot arms. The hollow space and continuous
surface also make them highly suitable for exoskeletons and
pressurized suits. Additionally, the absence of
overlapping external surfaces makes these joints easy to
clean and sterilize, while preventing damage to
fingers, plants, or other surrounding elements. These
features make the joints particularly advantageous in
applications requiring interaction with humans or delicate
environments, such as medical or service robots.
Our patented improvement to these Pipe-Like joints involves
a compact...
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we1ex_05">
             13:00-15:00, Paper We1EX.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1700" name="modify5191" onclick="modify(5191,1700)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5191'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              The Mini Wheelbot: A Testbed for Learning-Based Balancing, Flips, and Articulated Driving (EXPO Proposal)
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#297671" title="Click to go to the Author Index">
             Hose, Henrik
            </a>
           </td>
           <td class="r">
            Institute for Data Science in Mechanical Engineering (DSME), RWT
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420576" title="Click to go to the Author Index">
             Weisgerber, Jan Luca
            </a>
           </td>
           <td class="r">
            RWTH Aachen
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#133317" title="Click to go to the Author Index">
             Trimpe, Sebastian
            </a>
           </td>
           <td class="r">
            RWTH Aachen University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5191" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#wheeled_robots" title="Click to go to the Keyword Index">
               Wheeled Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#underactuated_robots" title="Click to go to the Keyword Index">
               Underactuated Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The Mini Wheelbot is a balancing, reaction wheel unicycle
robot designed as a testbed for learning-based control. It
is an unstable system with highly nonlinear yaw dynamics,
non-holonomic driving, and discrete contact switches in a
small, powerful, and rugged form factor. The Mini Wheelbot
can use its wheels to stand up from any initial orientation
– enabling automatic environment resets in repetitive
experiments and even challenging half flips. With imitation
learning from an expert nonlinear MPC that uses gyroscopic
effects, the Mini Wheelbot can reorient and track
higher-level velocity and orientation commands. This allows
the
robot to drive around based on user commands – for the
first time in this class of robots.
At the ICRA 2025 EXPO, we showcase the Mini Wheelbots
automatic environment reset and intriguing nonlinear yaw
control to convince the robotics community that the robot
is not only compelling for testing learning-based control
algorithms, but it is also just fun to work with. The
supplementary video of our paper shows the experiments we
will bring the the ICRA 2025 EXPO at
https://youtu.be/_d7AqTRjz6g
             <p>
              The paper on the Mini Wheelbot is accepted to ICRA under ID
1248.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we1ex_06">
             13:00-15:00, Paper We1EX.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1701" name="modify5202" onclick="modify(5202,1701)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5202'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Lighter-Than-Air Robotic Platform for Energy-Efficient Autonomy
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#395938" title="Click to go to the Author Index">
             Koley, Subhadeep
            </a>
           </td>
           <td class="r">
            Indian Institute of Engineering Science and Technology, Shibpur
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#283996" title="Click to go to the Author Index">
             Xu, Jiawei
            </a>
           </td>
           <td class="r">
            Lehigh University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#286799" title="Click to go to the Author Index">
             S. D'Antonio, Diego
            </a>
           </td>
           <td class="r">
            Lehigh University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#171052" title="Click to go to the Author Index">
             Saldaña, David
            </a>
           </td>
           <td class="r">
            Lehigh University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5202" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__perception_and_autonomy" title="Click to go to the Keyword Index">
               Aerial Systems: Perception and Autonomy
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__applications" title="Click to go to the Keyword Index">
               Aerial Systems: Applications
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic blimps, unlike other types of aerial vehicles,
leverage buoyancy from lighter-than-air gases such as
helium to prolong their flight duration. In addition, the
typical flexibility of LTA gas containers, such as
balloons, makes them inherently safer in collisions, ideal
for environments with humans or sensitive equipment. These
unique characteristics advocate their potential
applications in surveillance, environmental monitoring, and
human-centered robotics.
             <p>
              This demonstration presents two different robotic
micro-blimps implemented using the same open-source
software-hardware framework. We propose demonstrating their
real-time manual and autonomous operation to highlight the
scalability, energy efficiency, and independence from an
external infrastructure of the framework. It features a
customizable hardware and software stack, a detachable
perception module, and robust communication protocols that
allow one base station to coordinate up to 20 blimps. The
Mochi is the default blimp construct, designed for
autonomous pickup-and-delivery tasks. The Spinning Blimp
showcases a custom modification that achieves stable flight
through a novel spin actuation mechanism. Its design allows
for pendulum-like passive stabilization through continuous
rotation. The demo includes side-by-side operation of both
platforms, demonstrating the onboard detection and autonomy
of the Mochi, and continuous flight stability of the
Spinning Blimp. Expo audiences are encouraged to interact
with a
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we1ex_07">
             13:00-15:00, Paper We1EX.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1702" name="modify5207" onclick="modify(5207,1702)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5207'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Robot Utility Models: General Policies for Zero-Shot Deployment in New Environments
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#393660" title="Click to go to the Author Index">
             Etukuru, Haritheja
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420647" title="Click to go to the Author Index">
             Erciyes, Mehmet Enes
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#314022" title="Click to go to the Author Index">
             Shafiullah, Nur Muhammad (Mahi)
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#161575" title="Click to go to the Author Index">
             Pinto, Lerrel
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5207" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mobile_manipulation" title="Click to go to the Keyword Index">
               Mobile Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In recent years, imitation learning has enabled robots to
autonomously complete increasingly complex tasks. The
formula is simple: first, we collect some demonstrations
for the robot, and then we train a policy to run the robot
in the same environment. As we want our robots to help us
with every task, everywhere, we have seen some impressive
pushes in enabling robots to perform many tasks. However, a
notable gap remains in training robot policies that can
simply work everywhere, out of the box. In this demo, we
will present robot policies that can perform a task
practically anywhere, on a broad class of target objects,
on multiple embodiments, right out of the box. We will
demonstrate the system that let us accomplish this,
including a novel data collection tool, a large
demonstration dataset that we collected, and the policies
that we trained on this data that works on a new robot out
of the box in any environment.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we1ex_08">
             13:00-15:00, Paper We1EX.8
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1703" name="modify5221" onclick="modify(5221,1703)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5221'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Interactive Teleoperation of Simulated Space Robots
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#323500" title="Click to go to the Author Index">
             Orsula, Andrej
            </a>
           </td>
           <td class="r">
            University of Luxembourg
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#166569" title="Click to go to the Author Index">
             Geist, Matthieu
            </a>
           </td>
           <td class="r">
            Université De Lorraine
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#127610" title="Click to go to the Author Index">
             Olivares-Mendez, Miguel A.
            </a>
           </td>
           <td class="r">
            Interdisciplinary Centre for Security, Reliability and Trust - U
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#127618" title="Click to go to the Author Index">
             Martinez, Carol
            </a>
           </td>
           <td class="r">
            UniversitÉ Du Luxembourg
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5221" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#simulation_and_animation" title="Click to go to the Keyword Index">
               Simulation and Animation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robots play an increasingly critical role in the future of
space exploration. Whether it is fleets of autonomous
rovers exploring planetary surfaces or robotic manipulators
constructing large orbital structures, technological
advances in this domain will be vital for the success of
envisioned missions. However, developing and validating
flight-ready robotic systems is challenging due to the
limited availability of extraterrestrial data and the
prohibitive cost of technology demonstrations.
High-fidelity simulations offer a solution for bridging
this gap. Yet, the majority of simulators developed for
space applications are limited in scope or unavailable to
the general public. To address these challenges, we present
the Space Robotics Bench (SRB), an open-source simulation
platform that provides a collection of diverse environments
and tasks across various space application domains. To
simulate the vast diversity of unpredictable space
environments, SRB integrates procedural generation and
domain randomization. For ICRA Expo 2025, we aim to
demonstrate the features of SRB through an interactive
experience in which participants can teleoperate robots
across multiple space-relevant scenarios. Additionally,
participants will be able to compare their performance
against a reinforcement learning agent, highlighting the
importance of robust autonomy in the presence of
communication latency and environmental uncertainties that
are inherent to all operations beyond Earth.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we1ex_09">
             13:00-15:00, Paper We1EX.9
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1704" name="modify5227" onclick="modify(5227,1704)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5227'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Hopcopter - the Most Agile Jumping Robot
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457407" title="Click to go to the Author Index">
             Wang, Fangzheng
            </a>
           </td>
           <td class="r">
            City University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#245320" title="Click to go to the Author Index">
             Bai, Songnan
            </a>
           </td>
           <td class="r">
            City University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#308281" title="Click to go to the Author Index">
             Ding, Runze
            </a>
           </td>
           <td class="r">
            City University of Hongkong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#310136" title="Click to go to the Author Index">
             Li, Song
            </a>
           </td>
           <td class="r">
            City University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#394830" title="Click to go to the Author Index">
             Jia, Ruihan
            </a>
           </td>
           <td class="r">
            City University of Hong Kong
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#155694" title="Click to go to the Author Index">
             Chirarattananon, Pakpong
            </a>
           </td>
           <td class="r">
            City University of Hong Kong
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5227" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#aerial_systems__mechanics_and_control" title="Click to go to the Keyword Index">
               Aerial Systems: Mechanics and Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#dynamics" title="Click to go to the Keyword Index">
               Dynamics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Nature demonstrates remarkable examples of animals that
excel by combining flight and ground movement. Inspired by
this multimodal approach, we've developed an innovative
hybrid robot that both hops and flies efficiently. Our
design integrates a nano quadcopter with a passive
telescopic leg, moving beyond traditional jumping robots
that require active leg actuation during the stance phase.
We developed specific thrust controls and removable
aerodynamic surfaces that allow the robot to perform
sequential jumps with or without position feedback. This
configuration allows for adjustable jump heights and
minimizes time spent on the ground, creating nimble hopping
movement. In testing, our robot achieved average vertical
hopping speeds of 2.38 m/s and reached heights of 1.63
meters. The multimodal capability enables mid-flight jumps
that produce rapid accelerations and direction changes,
significantly improving maneuverability in challenging
environments. The passive leg mechanism shows promise for
integration with standard rotorcraft, potentially enabling
seamless transitions between hopping and flying modes.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we1ex_10">
             13:00-15:00, Paper We1EX.10
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1705" name="modify5234" onclick="modify(5234,1705)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5234'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Wheel-Gripper: Enabling Multifunctionality through Factorability
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#454649" title="Click to go to the Author Index">
             Luo, Hao
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#454574" title="Click to go to the Author Index">
             Cui, Jiajun
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#192394" title="Click to go to the Author Index">
             Plecnik, Mark
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#105795" title="Click to go to the Author Index">
             Goodwine, Bill
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5234" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Manipulation with legs on multi-pedal robots is not a new
concept, but it has rarely been considered on wheel-legged
robots due to their mechanical structure. This paper
presents a mechanism that transitions between a wheel and a
gripper, allowing wheel-legged robots to perform
manipulation tasks with their legs. The mechanism uses the
same motor for both wheeled locomotion and gripping, and no
new actuator is needed for transitioning.
It is capable of storing small objects, liquid, or soil
while still functioning as a wheel. 
Our analysis showed that those distinctive modes
corresponded to the factors of the complex kinematics
polynomials of the mechanism. The two modes exist because
the polynomials that govern the mechanism's kinematics
factor.  That is to say, its overall motion is the union of
two lower degree irreducible components. A single-leg
platform was built to demonstrate its ability to grasp
objects and collect water or soil samples, and explore its
capability as a contact force sensor through experiments.
Such a design could enable wheel-legged robots to perform
more diverse loco-manipulation tasks without installing
additional limbs.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we1ex_11">
             13:00-15:00, Paper We1EX.11
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1706" name="modify5251" onclick="modify(5251,1706)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5251'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Design of an Articulated Modular Caterpillar Using Spherical Linkages
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#425124" title="Click to go to the Author Index">
             O'Connor, Sam
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#192394" title="Click to go to the Author Index">
             Plecnik, Mark
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5251" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#multi_robot_systems" title="Click to go to the Keyword Index">
               Multi-Robot Systems
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Articulation between body segments of small insects
and animals is a three degree-of-freedom (DOF) motion.
Implementing this kind of motion in a compact robot is
usually
not tractable due to limitations in small actuator
technologies.
In this work, we concede full 3-DOF control and instead
select a
one degree-of-freedom curve in SO(3) to articulate segments
of
a caterpillar robot. The curve is approximated with a
spherical
four-bar, which is synthesized through optimal rigid body
guidance.
We specify the desired SO(3) motion using discrete task
positions, then solve for candidate mechanisms by computing
all roots of the stationary conditions using numerical
homotopy
continuation. A caterpillar robot prototype demonstrates
the
utility of this approach. This synthesis procedure is also
used to
design prolegs for the caterpillar robot. Each segment
contains
two DC motors and a shape memory alloy, which is used
for latching and unlatching between segments. The
caterpillar
robot is capable of walking, steering, object manipulation,
body
articulation, and climbing.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we1ex_12">
             13:00-15:00, Paper We1EX.12
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1707" name="modify5255" onclick="modify(5255,1707)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5255'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              GelSLAM: A Real-Time, High-Resolution, and Robust 3D Tactile SLAM System
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#220233" title="Click to go to the Author Index">
             Huang, Hung-Jui
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#172670" title="Click to go to the Author Index">
             Yuan, Wenzhen
            </a>
           </td>
           <td class="r">
            University of Illinois
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#104298" title="Click to go to the Author Index">
             Kaess, Michael
            </a>
           </td>
           <td class="r">
            Carnegie Mellon University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5255" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#force_and_tactile_sensing" title="Click to go to the Keyword Index">
               Force and Tactile Sensing
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#slam" title="Click to go to the Keyword Index">
               SLAM
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#perception_for_grasping_and_manipulation" title="Click to go to the Keyword Index">
               Perception for Grasping and Manipulation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This demo presents GelSLAM, a real-time, tactile-based SLAM
system for object pose estimation and 3D reconstruction.
Using only tactile sensing, GelSLAM achieves sub-millimeter
accuracy in both tracking and 3D reconstruction. Its
precise pose estimation enhances robot dexterity by
enabling real-time action adjustments during tasks such as
grasping, in-hand manipulation, tool use, and assembly.
Beyond robotics, GelSLAM’s high-resolution reconstructions
in the wild benefit fields like biology, geology, and
archaeology—capturing objects such as seeds, rocks, and
artifacts without lighting constraints, and even when they
are transparent or specular.
            </div>
           </td>
          </tr>
         </table>
         <table class="trk">
          <tr>
           <td colspan="2">
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a name="we2ex">
             <b>
              We2EX
             </b>
             Expo Session, Room T25
            </a>
           </td>
           <td class="r" nowrap="">
            Add to My Program
            <input id="mod1708" name="modifyWe2EX" onclick="modsession(681,1708)" type="checkbox" value="ON"/>
           </td>
          </tr>
          <tr class="sHdr">
           <td nowrap="">
            <a href="ICRA25_ProgramAtAGlanceWeb.html#we2ex" title="Click to go to the Program at a Glance">
             <b>
              EXPO Session II
             </b>
            </a>
           </td>
           <td>
           </td>
          </tr>
          <tr class="sHdr">
           <td colspan="2" style="line-height: 0pt">
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we2ex_01">
             15:00-17:00, Paper We2EX.1
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1709" name="modify5269" onclick="modify(5269,1709)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5269'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              CyberRunner: An Inexpensive Research and Education Robotics Platform
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#219464" title="Click to go to the Author Index">
             Bi, Thomas
            </a>
           </td>
           <td class="r">
            ETH Zurich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#178493" title="Click to go to the Author Index">
             Ramachandran Venkatapathy, Aswin Karthik
            </a>
           </td>
           <td class="r">
            ETH Zürich
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#118138" title="Click to go to the Author Index">
             D'Andrea, Raffaello
            </a>
           </td>
           <td class="r">
            ETHZ
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5269" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#reinforcement_learning" title="Click to go to the Keyword Index">
               Reinforcement Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#education_robotics" title="Click to go to the Keyword Index">
               Education Robotics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#software_tools_for_benchmarking_and_reproducibility" title="Click to go to the Keyword Index">
               Software Tools for Benchmarking and Reproducibility
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             In this demo, we present CyberRunner, an inexpensive,
open-source robotics platform designed to advance research
and education in reinforcement learning (RL) and
learning-based control. Based on the classic labyrinth
game, CyberRunner encapsulates the rich dynamics of
real-world environments while maintaining simplicity,
reproducibility, and affordability. Further, we demonstrate
how model-based RL techniques can be employed to achieve
superhuman performance on the physical labyrinth game.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we2ex_02">
             15:00-17:00, Paper We2EX.2
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1710" name="modify5291" onclick="modify(5291,1710)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5291'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              A Direct-Drive Gripper Designed by Ellipse Synthesis across Two Output Modes
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#257211" title="Click to go to the Author Index">
             Ramesh, Shashank
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#192394" title="Click to go to the Author Index">
             Plecnik, Mark
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5291" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#grippers_and_other_end_effectors" title="Click to go to the Keyword Index">
               Grippers and Other End-Effectors
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#kinematics" title="Click to go to the Keyword Index">
               Kinematics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             There are many ways for a gripper to estimate the forces
between its fingers.
If powered by direct-drive brushless motors, then one
technique is to measure their current.
This is not the most accurate technique, but it is simple,
keeps the sensor remote, and requires no new components.
The estimation involves multiplying current signals through
by the torque constant and the inverse transpose of the
Jacobian.
The Jacobian either amplifies the signal from fingertip
force to motor current (at the cost of tip force
production), or diminishes it (with the gain of tip force
production), indicating an inherent trade-off.
However, the Jacobian is a function of configuration, and
for any workspace point there are multiple configurations
(multiple inverse kinematics solutions), therefore a
selection of Jacobian exists.
For a given workspace point, the number of Jacobian choices
is just a few, (equal to the number inverse kinematics
solutions), 
but these choices can be designed (through dimensional
synthesis) to overcome the trade-off.
The problem can be framed as velocity ellipse synthesis
over multiple output modes.
In this work, we conduct optimal synthesis to compute a new
gripper design.
The gripper was built and tested.
It transitions between two different modes: sense mode and
grip mode.
Sense mode can sense forces 3 times smaller than grip mode.
Grip mode can exert forces 4 times greater than sense mode.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we2ex_03">
             15:00-17:00, Paper We2EX.3
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1711" name="modify5297" onclick="modify(5297,1711)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5297'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              RUKA Robot Hand Teleoperation with Learned Controls
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457083" title="Click to go to the Author Index">
             Zorin, Anya
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#337167" title="Click to go to the Author Index">
             Guzey, Irmak
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#161575" title="Click to go to the Author Index">
             Pinto, Lerrel
            </a>
           </td>
           <td class="r">
            New York University
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5297" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#multifingered_hands" title="Click to go to the Keyword Index">
               Multifingered Hands
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#telerobotics_and_teleoperation" title="Click to go to the Keyword Index">
               Telerobotics and Teleoperation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#ai_enabled_robotics" title="Click to go to the Keyword Index">
               AI-Enabled Robotics
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Dexterous manipulation is a fundamental capability for
robotic systems, yet progress has been limited by hardware
trade-offs between precision, compactness, strength, and
affordability. Existing control methods impose these
compromises on hand designs and applications. However,
learning-based approaches present opportunities to rethink
these trade-offs. In this interactive demo, we present
RUKA, a tendon-driven robotic hand that is compact,
affordable, and capable, made possible by the use of
learned controls. Made from 3D-printed parts and
off-the-shelf components, RUKA has 5 fingers with 15
underactuated degrees of freedom, enabling diverse
human-like grasps. Using motion-capture data collected with
the MANUS glove (manus-meta.com), we learn
joint-to-actuator and fingertip-to-actuator models for
controlling RUKA. During the demo, attendees will
teleoperate RUKA using the MANUS glove. They will have the
opportunity to try classic tasks with a variety of objects.
RUKA’s open-source design, assembly instructions, code, and
data are available at ruka-hand.github.io.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we2ex_04">
             15:00-17:00, Paper We2EX.4
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1712" name="modify5305" onclick="modify(5305,1712)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5305'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Smart Foot System for Enhanced Robot Mobility on Challenging Terrains
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379592" title="Click to go to the Author Index">
             Kerimoglu, Deniz
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457519" title="Click to go to the Author Index">
             Catalbas, Burak
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457521" title="Click to go to the Author Index">
             Catalbas, Bahadir
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#142549" title="Click to go to the Author Index">
             Goldman, Daniel
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5305" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#actuation_and_joint_mechanisms" title="Click to go to the Keyword Index">
               Actuation and Joint Mechanisms
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#humanoid_and_bipedal_locomotion" title="Click to go to the Keyword Index">
               Humanoid and Bipedal Locomotion
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic platforms mainly focus on locomoting and operating
in structured environments such as homes, factory settings,
highways and streets etc. These robots can navigate
reliably in relatively predictable and controlled settings
by relying on predictable ground interactions to perform
various tasks. However, robots must also achieve stable
locomotion in unpredictable, and challenging terrain such
as natural environments and hazardous areas where human
operation is difficult, enabling tasks such as exploration,
load carrying, and infrastructure maintenance. Flowable and
deformable surfaces that can deform unpredictably under
stress such as sandy deserts, snowy mountains and
extraterrestrial environments pose great challenges for
robot locomotion.
We designed smart foot systems that incorporates plates
(cleats) extending perpendicularly from the bottom of the
foot to manipulate deformable surfaces for efficient
robotic locomotion. By integrating a motor-controlled
mechanism, the cleats can be extended and retracted,
allowing the feet to engage or disengage with the
deformable terrain. Cleat interaction significantly
improves mobility efficiency in deformable and flowable
environments by enhancing traction and stability. In
addition, the motor-controlled cleat length adjustment
enables seamless transitions between soft (penetrable) and
rigid surfaces. The ability to regulate and manipulate the
flow and deformation of soft, flowable surfaces via cleat
extension—while smoothly tr
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we2ex_05">
             15:00-17:00, Paper We2EX.5
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1713" name="modify5313" onclick="modify(5313,1713)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5313'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Ground Control Robotics ICRA 2025 Demo Proposal
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#366553" title="Click to go to the Author Index">
             Soto, Daniel
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#405705" title="Click to go to the Author Index">
             Flores, Esteban
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#142549" title="Click to go to the Author Index">
             Goldman, Daniel
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5313" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#robotics_and_automation_in_agriculture_and_forestry" title="Click to go to the Keyword Index">
               Robotics and Automation in Agriculture and Forestry
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Multi-legged, undulatory robots possess many advantageous
properties for locomotion over unstructured and crowded
terrain including low profiles and robustness to missing
foot contacts. Despite these advantages, coordinating a
high number of legs (6+) and body joints represents a many
degree of freedom control problem that has limited their
practical and commercial viability. Ground Control Robotics
LLC. (GCR), in collaboration with researchers at Georgia
Tech, seeks to commercialize these systems for agricultural
use by advancing robophysical theories and developing
robust mechanical systems to explore the capabilities of
these robots in locomotion, navigation, and obstacle
negotiation. Recent successes include the development of
steering gaits, IMU-assisted automatic self righting,
tactile feedback enhanced locomotion for climbing, and
antenna sensing. Specifically, GCR has developed a flagship
commercial platform (Major Tom) that is a 5 link myriapod.
Major Tom aims to be a low cost, all terrestrial
alternative for weeding, pest control, and agricultural
data collection.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we2ex_06">
             15:00-17:00, Paper We2EX.6
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1714" name="modify5318" onclick="modify(5318,1714)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5318'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Multimodal Perception with Legged Mobile Manipulator for Visual, Thermal, and Radiation Monitoring
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#384162" title="Click to go to the Author Index">
             Son, Hojoon
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#418776" title="Click to go to the Author Index">
             Do, Youndo
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#420678" title="Click to go to the Author Index">
             Zebrowitz, Marc
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457512" title="Click to go to the Author Index">
             Faile, Jacob
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457460" title="Click to go to the Author Index">
             Banks, Spencer
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457458" title="Click to go to the Author Index">
             Choi, Myeongjun
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#383791" title="Click to go to the Author Index">
             Zhang, Fan
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5318" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#engineering_for_robotic_systems" title="Click to go to the Keyword Index">
               Engineering for Robotic Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#robotics_in_hazardous_fields" title="Click to go to the Keyword Index">
               Robotics in Hazardous Fields
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#sensor_fusion" title="Click to go to the Keyword Index">
               Sensor Fusion
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             The proposal presents a multimodal robotic platform for
remote visual, thermal, and radiation monitoring in
hazardous or unknown environments. The system integrates a
Unitree B1 quadruped robot with a Unitree Z1 robotic arm to
create a mobile and semi-autonomous perception platform.
Equipped with a Teledyne FLIR Hadron 640R, which integrates
a long-wave infrared (thermal) camera and a 1080p
visible-light imaging sensor, along with an SPRD-ER gamma
radiation detector, the robot fuses visual, thermal, and
radiation data for real-time monitoring and environmental
awareness. Sensor fusion and SLAM are performed onboard
using ROS, and the resulting data is streamed wirelessly to
a remote PC for real-time visualization and operator
monitoring. While the robot is primarily teleoperated, it
can autonomously perform simple tasks such as environmental
scanning and predefined manipulations via the Z1 arm.
             <p>
              This platform demonstrates a perception pipeline that
extends beyond vision-based sensing by incorporating
multiple physical modalities, including ionizing radiation
and heat signatures, thus enabling richer scene
understanding and opening pathways for advanced research in
multimodal robotic perception. The demonstration will
include a representative monitoring scenario using heated
and cooled sealed containers to simulate thermal anomalies.
A low-energy, non-harmful radiation source may be placed in
the environment to demonstrate detection and localization;
if restricted by ICRA Expo
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we2ex_07">
             15:00-17:00, Paper We2EX.7
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1715" name="modify5335" onclick="modify(5335,1715)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5335'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Kid COSMO: A Humanoid Robot Movie Character
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#355101" title="Click to go to the Author Index">
             Zhu, Mingzhang
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457259" title="Click to go to the Author Index">
             Liu, Havel
            </a>
           </td>
           <td class="r">
            UCLA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#438278" title="Click to go to the Author Index">
             Flores Alvarez, Arturo Moises
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457261" title="Click to go to the Author Index">
             Parres, Federico Parres
            </a>
           </td>
           <td class="r">
            UCLA
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457246" title="Click to go to the Author Index">
             Ku, Conrad
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457277" title="Click to go to the Author Index">
             Lo, Yuan Hung
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles (UCLA)
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457564" title="Click to go to the Author Index">
             Lee, Yena
            </a>
           </td>
           <td class="r">
            University of California, Los Angeles
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#106488" title="Click to go to the Author Index">
             Hong, Dennis
            </a>
           </td>
           <td class="r">
            UCLA
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5335" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#humanoid_robot_systems" title="Click to go to the Keyword Index">
               Humanoid Robot Systems
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#gesture__posture_and_facial_expressions" title="Click to go to the Keyword Index">
               Gesture, Posture and Facial Expressions
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             COSMO is a humanoid robot developed for Netflix’s film The
Electric State, designed to convey expressive,
character-driven behavior through motion and speech. With
28 actuated degrees of freedom, COSMO can perform dynamic
gestures, walk, and interact vocally. It can be
demonstrated either walking within expo spaces or seated on
a compact stage, requiring minimal setup and space, making
it ideal for public exhibitions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we2ex_08">
             15:00-17:00, Paper We2EX.8
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1716" name="modify5364" onclick="modify(5364,1716)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5364'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Sea Turtle-Inspired Adaptive Gait Strategies for Multi-Terrain Robotic Locomotion
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#354986" title="Click to go to the Author Index">
             Chikere, Nnamdi
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#366721" title="Click to go to the Author Index">
             McElroy, John
            </a>
           </td>
           <td class="r">
            University College Dublin
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457983" title="Click to go to the Author Index">
             Oberrieder, Jacob
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#149224" title="Click to go to the Author Index">
             Ozkan-Aydin, Yasemin
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5364" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#biologically_inspired_robots" title="Click to go to the Keyword Index">
               Biologically-Inspired Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#biomimetics" title="Click to go to the Keyword Index">
               Biomimetics
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#soft_robot_applications" title="Click to go to the Keyword Index">
               Soft Robot Applications
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Robotic locomotion in complex and unstructured environments
presents significant challenges, requiring unconventional
designs that incorporate mechanical intelligence and
bioinspired design. Inspired by the adaptive locomotion of
sea turtle hatchlings, we designed a bioinspired
flipper-based
robotic system to traverse soft and irregular terrains. Our
robot features an oval-shaped body and four independently
actuated flippers (rigid or soft), combined with adaptive
control strategies that adjust gait patterns in real time.
We demonstrate effective locomotion on dry and wet sand,
foam stairs, rocky surfaces, and inclined terrains,
achieving high displacement and energy efficiency. These
results showcase the potential of flipper-based mobility
systems for search and rescue, planetary exploration, and
other off-road robotic missions.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we2ex_09">
             15:00-17:00, Paper We2EX.9
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1717" name="modify5365" onclick="modify(5365,1717)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5365'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              EgoMimic-Expo: Demonstrating Robot Learning from Egocentric Data
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339109" title="Click to go to the Author Index">
             Kareer, Simar
            </a>
           </td>
           <td class="r">
            Georgia Tech
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#339071" title="Click to go to the Author Index">
             Patel, Dhruv
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#422018" title="Click to go to the Author Index">
             Punamiya, Ryan
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#376113" title="Click to go to the Author Index">
             Mathur, Pranay
            </a>
           </td>
           <td class="r">
            Collaborative Robotics
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#285427" title="Click to go to the Author Index">
             Cheng, Shuo
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#222003" title="Click to go to the Author Index">
             Wang, Chen
            </a>
           </td>
           <td class="r">
            Stanford University
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#147280" title="Click to go to the Author Index">
             Hoffman, Judy
            </a>
           </td>
           <td class="r">
            Georgia Tech
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#158823" title="Click to go to the Author Index">
             Xu, Danfei
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5365" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#imitation_learning" title="Click to go to the Keyword Index">
               Imitation Learning
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#learning_from_demonstration" title="Click to go to the Keyword Index">
               Learning from Demonstration
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#big_data_in_robotics_and_automation" title="Click to go to the Keyword Index">
               Big Data in Robotics and Automation
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             This demo showcases EgoMimic, a robotic system
that learns from egocentric human data captured by wearable
smart glasses. We will demonstrate how robot manipulation
skills can be scaled using easily collected human data.
This
interactive demo features: (1) Live egocentric video
streaming from Project Aria glasses capturing human
demonstrations.(2) Policy execution on ’Eve’, our low-cost,
humanoid-style bimanual robot performing contact-rich tasks
(e.g., shirt folding, grocery packing). We illustrate the
end-to-end pipeline, highlighting how EgoMimic bridges the
human-robot gap for effective skill transfer. Additional
information about the project can be found at
https://egomimic.github.io/
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we2ex_10">
             15:00-17:00, Paper We2EX.10
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1718" name="modify5366" onclick="modify(5366,1718)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5366'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Planar Locomotion of Soft Robots Equipped with Microspine Arrays
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#383277" title="Click to go to the Author Index">
             Ervin, Lauren
            </a>
           </td>
           <td class="r">
            University of Alabama
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#322030" title="Click to go to the Author Index">
             Bezawada, Harish
            </a>
           </td>
           <td class="r">
            The University of Alabama
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#140014" title="Click to go to the Author Index">
             Vikas, Vishesh
            </a>
           </td>
           <td class="r">
            University of Alabama
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5366" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#mechanism_design" title="Click to go to the Keyword Index">
               Mechanism Design
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#search_and_rescue_robots" title="Click to go to the Keyword Index">
               Search and Rescue Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#field_robots" title="Click to go to the Keyword Index">
               Field Robots
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Microspine grippers are small spines commonly found on
insect legs that reinforce surface interaction by engaging
with asperities to increase traction. An array of such
microspines, when integrated into the limbs of a robot, can
provide the ability to maneuver uneven terrains, traverse
inclines, and even climb walls. Meanwhile, the
conformability of soft robots makes them ideal candidates
for applications involving traversal of complex,
unstructured terrains. However, there remains a real-life
realization gap transitioning from controlled lab
environment to the field that can be bridged by improving
grip stability through effective integration of
microspines. In this robot demo, a passive, compliant
microspine stacked array design is proposed to enhance the
locomotion capabilities of mobile soft robots. A microspine
array integration method effectively addresses the
stiffness mismatch between soft, compliant, and rigid
components. Additionally, a reduction in complexity results
from actuation of the surface-conformable soft limb using a
single actuator. The two-row, stacked microspine array
configuration offers improved gripping capabilities on
steep and irregular surfaces. This design is incorporated
into three different robot configurations - the baseline
without microspines and two others with different
combinations of microspine arrays. In-person demonstrations
will be conducted on varying surfaces such as rocks,
carpet, and a rubber mat.
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we2ex_11">
             15:00-17:00, Paper We2EX.11
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1719" name="modify5367" onclick="modify(5367,1719)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5367'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Coordinating Spinal and Limb Dynamics for Enhanced Sprawling Robot Mobility
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#396641" title="Click to go to the Author Index">
             Atasever, Merve
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#453090" title="Click to go to the Author Index">
             Okhovat, Ali
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#452936" title="Click to go to the Author Index">
             Nazaripouya, Azhang
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#458168" title="Click to go to the Author Index">
             Nisbet, John
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#366693" title="Click to go to the Author Index">
             Kurkutlu, Omer
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#241241" title="Click to go to the Author Index">
             Deshmukh, Jyotirmoy
            </a>
           </td>
           <td class="r">
            University of Southern California
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#149224" title="Click to go to the Author Index">
             Ozkan-Aydin, Yasemin
            </a>
           </td>
           <td class="r">
            University of Notre Dame
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5367" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#legged_robots" title="Click to go to the Keyword Index">
               Legged Robots
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#deep_learning_methods" title="Click to go to the Keyword Index">
               Deep Learning Methods
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Salamanders, with their ability to switch between walking
and swimming, showcase how spinal flexibility enhances
locomotion. Their undulating body motion helps them move
over uneven terrain and adapt to unpredictable
environments. Inspired by this, we explore control
strategies for a salamander-like robot with two
configurations: one with a fixed spine and one with an
active, flexible spine.
             <p>
              We compare biologically inspired gaits and learning-based
approaches under different scenarios to see how well each
performs. Our findings show that combining models like the
Hildebrand gait with deep reinforcement learning (DRL)
leads to more robust and efficient movement. Building on
this, we developed a modular Hopf oscillator-based CPG
framework, which successfully generates coordinated
locomotion across multiple limbs. This work is part of our
ongoing effort to merge the adaptability of DRL with the
rhythmic stability of CPGs for better performance in
real-world conditions.
             </p>
            </div>
           </td>
          </tr>
          <tr style="line-height: 0.2em">
           <td colspan="2">
           </td>
          </tr>
          <tr class="pHdr">
           <td valign="bottom">
            <a name="we2ex_12">
             15:00-17:00, Paper We2EX.12
            </a>
           </td>
           <td class="r">
            Add to My Program
            <input id="mod1720" name="modify5368" onclick="modify(5368,1720)" type="checkbox" value="on"/>
           </td>
          </tr>
          <tr>
           <td colspan="2">
            <span class="pTtl">
             <a href="" onclick="viewAbstract('5368'); return false" title="Click to show or hide the keywords and abstract (text summary)">
              Light Following Robophysical Space Rover with Closed-Loop Gait Strategies at Granular Slope
             </a>
            </span>
           </td>
          </tr>
          <tr>
           <td colspan="2" style="height: 2px">
            <hr class="thin"/>
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457521" title="Click to go to the Author Index">
             Catalbas, Bahadir
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379592" title="Click to go to the Author Index">
             Kerimoglu, Deniz
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#457519" title="Click to go to the Author Index">
             Catalbas, Burak
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#379624" title="Click to go to the Author Index">
             Hemsley, Malone Lincoln
            </a>
           </td>
           <td class="r">
            Morehouse College
           </td>
          </tr>
          <tr>
           <td>
            <a href="ICRA25_AuthorIndexWeb.html#142549" title="Click to go to the Author Index">
             Goldman, Daniel
            </a>
           </td>
           <td class="r">
            Georgia Institute of Technology
           </td>
          </tr>
          <tr>
           <td colspan="2" style="padding: 0px">
            <div id="Ab5368" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
             <span style="line-height: 2em">
              <strong>
               Keywords:
              </strong>
              <a href="ICRA25_KeywordIndexWeb.html#space_robotics_and_automation" title="Click to go to the Keyword Index">
               Space Robotics and Automation
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#machine_learning_for_robot_control" title="Click to go to the Keyword Index">
               Machine Learning for Robot Control
              </a>
              ,
              <a href="ICRA25_KeywordIndexWeb.html#visual_tracking" title="Click to go to the Keyword Index">
               Visual Tracking
              </a>
             </span>
             <br/>
             <strong>
              Abstract:
             </strong>
             Exploring extraterrestrial environments requires planetary
rovers to gather data and conduct experiments on
challenging terrains like steep granular slopes, obstacles,
and craters. To overcome these difficulties, modern rovers
have leg-like movement systems that can lift, sweep, and
spin their wheels; such a mechanism can apply selective
substrate fluidization by changing the sweep and spin speed
of wheels to generate effective thrust. Previously, optimum
open-loop gaits using selective fluidization for forward
locomotion and in-place rotation are discovered on granular
slopes. However, real-life exploration entails dealing with
more intricate locomotion scenarios, such as maneuvering in
deformable, flowable, extensive granular slopes with
challenging approach configurations. To address this, we
utilize a 30 cm-long laboratory-scale robophysical rover
model on a tiltable fluidizing testbed containing poppy
seeds. We propose a new gait capable of moving laterally
while moving forward, by limiting the sweep angle and
turning speed of the wheels on one side of the robot; this
generates torque asymmetry between the sides of the robot's
sagittal plane. In addition, we present a closed-loop gait
sequencing algorithm that switches between small direction
corrections, sharp in-place rotations and self-burial
movements to follow an externally imposed moving light
source. Using these strategies, we succeed in following
closed trajectories up to 15-degree granular slopes.
            </div>
           </td>
          </tr>
         </table>
        </div>
        <p>
         <br/>
        </p>
        <p>
         <br/>
        </p>
       </td>
       <td height="100%" style="background-color:#2C1A77;" width="5">
       </td>
      </tr>
      <tr>
       <td alt="" border="0" colspan="4" height="8" style="background-color:#2C1A77;" valign="center" width="100%">
        <p align="center">
         <span style="font-size:8pt;line-height:10pt;color:#fff;">
          Technical Content ©
IEEE Robotics &amp; Automation Society
         </span>
        </p>
       </td>
      </tr>
      <tr>
       <td colspan="4" width="100%">
        <p align="right">
         <span style="text-decoration:none;">
          <img align="right" border="0" src="/images/pc_logo_small.png" style="margin-left: 10px; margin-right: 10px"/>
          This site is protected
by copyright and trademark laws under US and International law.
          <br/>
          All rights
reserved. © 2002-2025 PaperCept, Inc.
          <br/>
          Page generated 2025-05-14  16:17:03 PST
          <a href="" onclick="window.open('/conferences/scripts/about.pl','tc','width=1000,scrollbars=yes'); return false">
           Terms
of use
          </a>
         </span>
        </p>
       </td>
      </tr>
     </table>
    </body>
   </div>
  </form>
 </body>
</html>
